12/13/2021 10:29:29 - WARNING - configs -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, cpu count: 48
12/13/2021 10:29:29 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, batch_size=32, beam_size=10, cache_path='save_models/summarize/php/t5/cache_data', cpu_count=48, data_dir='/data/pretrain-attention/CodeAttention/data', data_num=-1, device=device(type='cuda'), do_eval=True, do_eval_bleu=True, do_test=True, do_train=True, gpu=0, gradient_accumulation_steps=1, local_rank=-1, lr=5e-05, max_grad_norm=1.0, max_source_length=256, max_target_length=128, model_dir='saved_models', model_name='t5', n_gpu=1, no_cuda=False, num_train_epochs=15, output_dir='save_models/summarize/php/t5', patience=2, res_dir='results/summarize/php/t5', res_fn='results/summarize/php/t5.txt', save_last_checkpoints=True, seed=1234, start_epoch=0, sub_task='php', summary_dir='tensorboard', task='summarize', warmup_steps=1000, weight_decay=0.0)
Downloading:   0%|          | 0.00/1.17k [00:00<?, ?B/s]Downloading: 100%|██████████| 1.17k/1.17k [00:00<00:00, 312kB/s]
Downloading:   0%|          | 0.00/773k [00:00<?, ?B/s]Downloading:   1%|          | 4.00k/773k [00:00<00:48, 16.4kB/s]Downloading:   5%|▍         | 36.0k/773k [00:00<00:09, 83.4kB/s]Downloading:  10%|█         | 80.0k/773k [00:00<00:05, 128kB/s] Downloading:  24%|██▍       | 188k/773k [00:01<00:02, 251kB/s] Downloading:  51%|█████     | 396k/773k [00:01<00:01, 344kB/s]Downloading:  97%|█████████▋| 748k/773k [00:01<00:00, 646kB/s]Downloading: 100%|██████████| 773k/773k [00:01<00:00, 451kB/s]
Downloading:   0%|          | 0.00/1.32M [00:00<?, ?B/s]Downloading:   0%|          | 4.00k/1.32M [00:00<01:22, 16.7kB/s]Downloading:   3%|▎         | 36.0k/1.32M [00:00<00:25, 53.5kB/s]Downloading:   8%|▊         | 112k/1.32M [00:00<00:08, 145kB/s]  Downloading:  12%|█▏        | 160k/1.32M [00:01<00:07, 162kB/s]Downloading:  15%|█▌        | 208k/1.32M [00:01<00:06, 175kB/s]Downloading:  19%|█▉        | 256k/1.32M [00:01<00:06, 183kB/s]Downloading:  22%|██▏       | 304k/1.32M [00:01<00:05, 188kB/s]Downloading:  27%|██▋       | 368k/1.32M [00:02<00:04, 212kB/s]Downloading:  31%|███       | 416k/1.32M [00:02<00:04, 209kB/s]Downloading:  35%|███▌      | 480k/1.32M [00:02<00:03, 226kB/s]Downloading:  39%|███▉      | 528k/1.32M [00:02<00:03, 219kB/s]Downloading:  44%|████▎     | 592k/1.32M [00:03<00:03, 233kB/s]Downloading:  47%|████▋     | 640k/1.32M [00:03<00:03, 225kB/s]Downloading:  52%|█████▏    | 704k/1.32M [00:03<00:02, 237kB/s]Downloading:  55%|█████▌    | 752k/1.32M [00:03<00:02, 226kB/s]Downloading:  60%|██████    | 816k/1.32M [00:04<00:02, 238kB/s]Downloading:  64%|██████▎   | 864k/1.32M [00:04<00:01, 267kB/s]Downloading:  66%|██████▌   | 892k/1.32M [00:04<00:01, 260kB/s]Downloading:  68%|██████▊   | 928k/1.32M [00:04<00:01, 220kB/s]Downloading:  72%|███████▏  | 976k/1.32M [00:04<00:01, 241kB/s]Downloading:  75%|███████▌  | 1.00M/1.32M [00:04<00:01, 276kB/s]Downloading:  78%|███████▊  | 1.03M/1.32M [00:05<00:01, 233kB/s]Downloading:  80%|████████  | 1.06M/1.32M [00:05<00:01, 229kB/s]Downloading:  85%|████████▍ | 1.12M/1.32M [00:05<00:00, 215kB/s]Downloading:  88%|████████▊ | 1.17M/1.32M [00:05<00:00, 254kB/s]Downloading:  91%|█████████ | 1.20M/1.32M [00:05<00:00, 247kB/s]Downloading:  93%|█████████▎| 1.23M/1.32M [00:06<00:00, 259kB/s]Downloading:  95%|█████████▌| 1.26M/1.32M [00:06<00:00, 249kB/s]Downloading:  98%|█████████▊| 1.30M/1.32M [00:06<00:00, 268kB/s]Downloading: 100%|█████████▉| 1.32M/1.32M [00:06<00:00, 253kB/s]Downloading: 100%|██████████| 1.32M/1.32M [00:06<00:00, 218kB/s]
Traceback (most recent call last):
  File "/data/pretrain-attention/CodeAttention/main.py", line 419, in <module>
    main()
  File "/data/pretrain-attention/CodeAttention/main.py", line 173, in main
    config, model, tokenizer = bulid_or_load_gen_model(args)
  File "/data/pretrain-attention/CodeAttention/models.py", line 31, in bulid_or_load_gen_model
    tokenizer = AutoTokenizer.from_pretrained(checkpoint)
  File "/opt/conda/lib/python3.7/site-packages/transformers/models/auto/tokenization_auto.py", line 542, in from_pretrained
    return tokenizer_class_fast.from_pretrained(pretrained_model_name_or_path, *inputs, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py", line 1700, in from_pretrained
    user_agent=user_agent,
  File "/opt/conda/lib/python3.7/site-packages/transformers/file_utils.py", line 1633, in cached_path
    local_files_only=local_files_only,
  File "/opt/conda/lib/python3.7/site-packages/transformers/file_utils.py", line 1850, in get_from_cache
    "Connection error, and we cannot find the requested files in the cached path."
ValueError: Connection error, and we cannot find the requested files in the cached path. Please try again or make sure your Internet connection is on.
