12/09/2021 17:29:02 - WARNING - configs -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, cpu count: 10
12/09/2021 17:29:02 - INFO - __main__ -   Namespace(adam_epsilon=1e-08, add_lang_ids=False, add_task_prefix=False, always_save_model=True, batch_size=48, beam_size=10, cache_path='save_models/summarize/java/graphcodebert/cache_data', cpu_count=10, data_dir='/data/pretrain-attention/CodeAttention/data', data_num=-1, device=device(type='cuda'), do_eval=True, do_eval_bleu=True, do_test=True, do_train=True, gpu=0, gradient_accumulation_steps=1, local_rank=-1, lr=5e-05, max_grad_norm=1.0, max_source_length=256, max_target_length=128, model_dir='saved_models', model_name='graphcodebert', n_gpu=1, no_cuda=False, num_train_epochs=15, output_dir='save_models/summarize/java/graphcodebert', patience=2, res_dir='results/summarize/java/graphcodebert', res_fn='results/summarize/java/graphcodebert.txt', save_last_checkpoints=True, seed=1234, start_epoch=0, sub_task='java', summary_dir='tensorboard', task='summarize', warmup_steps=1000, weight_decay=0.0)
Some weights of the model checkpoint at microsoft/graphcodebert-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaModel were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
12/09/2021 17:29:29 - INFO - models -   Finish loading model [173M] parameters from graphcodebert
Token indices sequence length is longer than the specified maximum sequence length for this model (621 > 512). Running this sequence through the model will result in indexing errors
12/09/2021 17:30:55 - INFO - utils -   Read 164923 examples, avg src len: 101, avg trg len: 13, max src len: 512, max trg len: 173
12/09/2021 17:30:55 - INFO - utils -   [TOKENIZE] avg src len: 141, avg trg len: 14, max src len: 3118, max trg len: 255
12/09/2021 17:30:55 - INFO - utils -   Load cache data from save_models/summarize/java/graphcodebert/cache_data/train_all.pt
12/09/2021 17:30:55 - INFO - __main__ -   ***** Running training *****
12/09/2021 17:30:55 - INFO - __main__ -     Num examples = 164923
12/09/2021 17:30:55 - INFO - __main__ -     Batch size = 48
12/09/2021 17:30:55 - INFO - __main__ -     Batch num = 3436
12/09/2021 17:30:55 - INFO - __main__ -     Num epoch = 15
Training:   0%|          | 0/3436 [00:00<?, ?it/s][0] Train loss 6.077:   0%|          | 0/3436 [00:01<?, ?it/s][0] Train loss 6.077:   0%|          | 1/3436 [00:01<1:11:48,  1.25s/it][0] Train loss 8.104:   0%|          | 1/3436 [00:02<1:11:48,  1.25s/it][0] Train loss 8.104:   0%|          | 2/3436 [00:02<1:03:31,  1.11s/it][0] Train loss 9.116:   0%|          | 2/3436 [00:03<1:03:31,  1.11s/it][0] Train loss 9.116:   0%|          | 3/3436 [00:03<1:00:47,  1.06s/it][0] Train loss 9.726:   0%|          | 3/3436 [00:04<1:00:47,  1.06s/it][0] Train loss 9.726:   0%|          | 4/3436 [00:04<59:28,  1.04s/it]  [0] Train loss 10.118:   0%|          | 4/3436 [00:05<59:28,  1.04s/it][0] Train loss 10.118:   0%|          | 5/3436 [00:05<58:54,  1.03s/it][0] Train loss 10.382:   0%|          | 5/3436 [00:06<58:54,  1.03s/it][0] Train loss 10.382:   0%|          | 6/3436 [00:06<58:32,  1.02s/it][0] Train loss 10.594:   0%|          | 6/3436 [00:07<58:32,  1.02s/it][0] Train loss 10.594:   0%|          | 7/3436 [00:07<58:10,  1.02s/it][0] Train loss 10.759:   0%|          | 7/3436 [00:08<58:10,  1.02s/it][0] Train loss 10.759:   0%|          | 8/3436 [00:08<58:05,  1.02s/it][0] Train loss 10.88:   0%|          | 8/3436 [00:09<58:05,  1.02s/it] [0] Train loss 10.88:   0%|          | 9/3436 [00:09<57:57,  1.01s/it][0] Train loss 10.972:   0%|          | 9/3436 [00:10<57:57,  1.01s/it][0] Train loss 10.972:   0%|          | 10/3436 [00:10<57:53,  1.01s/it][0] Train loss 11.053:   0%|          | 10/3436 [00:11<57:53,  1.01s/it][0] Train loss 11.053:   0%|          | 11/3436 [00:11<57:56,  1.02s/it][0] Train loss 11.123:   0%|          | 11/3436 [00:12<57:56,  1.02s/it][0] Train loss 11.123:   0%|          | 12/3436 [00:12<57:56,  1.02s/it][0] Train loss 11.173:   0%|          | 12/3436 [00:13<57:56,  1.02s/it][0] Train loss 11.173:   0%|          | 13/3436 [00:13<57:45,  1.01s/it][0] Train loss 11.215:   0%|          | 13/3436 [00:14<57:45,  1.01s/it][0] Train loss 11.215:   0%|          | 14/3436 [00:14<57:40,  1.01s/it][0] Train loss 11.245:   0%|          | 14/3436 [00:15<57:40,  1.01s/it][0] Train loss 11.245:   0%|          | 15/3436 [00:15<57:35,  1.01s/it][0] Train loss 11.274:   0%|          | 15/3436 [00:16<57:35,  1.01s/it][0] Train loss 11.274:   0%|          | 16/3436 [00:16<57:43,  1.01s/it][0] Train loss 11.29:   0%|          | 16/3436 [00:17<57:43,  1.01s/it] [0] Train loss 11.29:   0%|          | 17/3436 [00:17<57:42,  1.01s/it][0] Train loss 11.306:   0%|          | 17/3436 [00:18<57:42,  1.01s/it][0] Train loss 11.306:   1%|          | 18/3436 [00:18<57:30,  1.01s/it][0] Train loss 11.312:   1%|          | 18/3436 [00:19<57:30,  1.01s/it][0] Train loss 11.312:   1%|          | 19/3436 [00:19<57:30,  1.01s/it][0] Train loss 11.317:   1%|          | 19/3436 [00:20<57:30,  1.01s/it][0] Train loss 11.317:   1%|          | 20/3436 [00:20<57:31,  1.01s/it][0] Train loss 11.318:   1%|          | 20/3436 [00:21<57:31,  1.01s/it][0] Train loss 11.318:   1%|          | 21/3436 [00:21<57:34,  1.01s/it][0] Train loss 11.312:   1%|          | 21/3436 [00:22<57:34,  1.01s/it][0] Train loss 11.312:   1%|          | 22/3436 [00:22<57:29,  1.01s/it][0] Train loss 11.309:   1%|          | 22/3436 [00:23<57:29,  1.01s/it][0] Train loss 11.309:   1%|          | 23/3436 [00:23<57:28,  1.01s/it][0] Train loss 11.301:   1%|          | 23/3436 [00:24<57:28,  1.01s/it][0] Train loss 11.301:   1%|          | 24/3436 [00:24<57:23,  1.01s/it][0] Train loss 11.288:   1%|          | 24/3436 [00:25<57:23,  1.01s/it][0] Train loss 11.288:   1%|          | 25/3436 [00:25<57:36,  1.01s/it][0] Train loss 11.276:   1%|          | 25/3436 [00:26<57:36,  1.01s/it][0] Train loss 11.276:   1%|          | 26/3436 [00:26<57:39,  1.01s/it][0] Train loss 11.258:   1%|          | 26/3436 [00:27<57:39,  1.01s/it][0] Train loss 11.258:   1%|          | 27/3436 [00:27<57:32,  1.01s/it][0] Train loss 11.241:   1%|          | 27/3436 [00:28<57:32,  1.01s/it][0] Train loss 11.241:   1%|          | 28/3436 [00:28<57:34,  1.01s/it][0] Train loss 11.222:   1%|          | 28/3436 [00:29<57:34,  1.01s/it][0] Train loss 11.222:   1%|          | 29/3436 [00:29<57:37,  1.01s/it][0] Train loss 11.2:   1%|          | 29/3436 [00:30<57:37,  1.01s/it]  [0] Train loss 11.2:   1%|          | 30/3436 [00:30<57:35,  1.01s/it][0] Train loss 11.175:   1%|          | 30/3436 [00:31<57:35,  1.01s/it][0] Train loss 11.175:   1%|          | 31/3436 [00:31<57:35,  1.01s/it][0] Train loss 11.149:   1%|          | 31/3436 [00:32<57:35,  1.01s/it][0] Train loss 11.149:   1%|          | 32/3436 [00:32<57:39,  1.02s/it][0] Train loss 11.122:   1%|          | 32/3436 [00:33<57:39,  1.02s/it][0] Train loss 11.122:   1%|          | 33/3436 [00:33<57:38,  1.02s/it][0] Train loss 11.093:   1%|          | 33/3436 [00:34<57:38,  1.02s/it][0] Train loss 11.093:   1%|          | 34/3436 [00:34<57:43,  1.02s/it][0] Train loss 11.061:   1%|          | 34/3436 [00:35<57:43,  1.02s/it][0] Train loss 11.061:   1%|          | 35/3436 [00:35<57:33,  1.02s/it][0] Train loss 11.029:   1%|          | 35/3436 [00:36<57:33,  1.02s/it][0] Train loss 11.029:   1%|          | 36/3436 [00:36<57:37,  1.02s/it][0] Train loss 10.994:   1%|          | 36/3436 [00:37<57:37,  1.02s/it][0] Train loss 10.994:   1%|          | 37/3436 [00:37<57:24,  1.01s/it]