12/16/2021 03:50:19 - WARNING - configs -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, cpu count: 48
12/16/2021 03:50:38 - INFO - models -   Finish loading model [173.0M] parameters from codebert
12/16/2021 03:50:52 - INFO - utils -   Read 5000 examples, avg src len: 88, avg trg len: 15, max src len: 512, max trg len: 157
12/16/2021 03:50:52 - INFO - utils -   Sample 5k data for computing bleu/attention from /data/pretrain-attention/CodeAttention/data/summarize/go/train.jsonl
  0%|          | 0/5000 [00:00<?, ?it/s]  1%|          | 54/5000 [00:00<00:12, 381.91it/s]  3%|▎         | 135/5000 [00:00<00:09, 509.61it/s]  4%|▍         | 189/5000 [00:00<00:09, 500.00it/s]  5%|▌         | 270/5000 [00:00<00:08, 539.17it/s]  7%|▋         | 351/5000 [00:00<00:07, 592.21it/s]  9%|▊         | 432/5000 [00:00<00:07, 612.70it/s] 10%|█         | 513/5000 [00:00<00:07, 616.76it/s] 12%|█▏        | 594/5000 [00:01<00:07, 629.23it/s] 13%|█▎        | 658/5000 [00:01<00:06, 627.87it/s] 15%|█▍        | 729/5000 [00:01<00:07, 595.12it/s] 16%|█▌        | 810/5000 [00:01<00:06, 622.83it/s] 18%|█▊        | 891/5000 [00:01<00:06, 651.96it/s] 19%|█▉        | 972/5000 [00:01<00:06, 642.92it/s] 21%|██        | 1037/5000 [00:01<00:06, 642.90it/s] 22%|██▏       | 1107/5000 [00:01<00:06, 599.67it/s] 24%|██▍       | 1188/5000 [00:01<00:06, 612.39it/s] 25%|██▌       | 1269/5000 [00:02<00:06, 616.44it/s] 27%|██▋       | 1350/5000 [00:02<00:05, 628.98it/s] 29%|██▊       | 1431/5000 [00:02<00:05, 650.32it/s] 30%|███       | 1512/5000 [00:02<00:05, 660.37it/s] 32%|███▏      | 1620/5000 [00:02<00:04, 718.49it/s] 35%|███▍      | 1728/5000 [00:02<00:04, 708.54it/s] 36%|███▌      | 1809/5000 [00:02<00:04, 687.19it/s] 38%|███▊      | 1890/5000 [00:02<00:04, 700.43it/s] 39%|███▉      | 1971/5000 [00:03<00:04, 670.56it/s] 41%|████      | 2052/5000 [00:03<00:04, 674.87it/s] 43%|████▎     | 2133/5000 [00:03<00:04, 684.15it/s] 44%|████▍     | 2202/5000 [00:03<00:05, 517.01it/s] 46%|████▌     | 2295/5000 [00:03<00:04, 590.97it/s] 48%|████▊     | 2403/5000 [00:03<00:03, 663.52it/s] 50%|█████     | 2511/5000 [00:03<00:03, 732.27it/s] 52%|█████▏    | 2619/5000 [00:04<00:02, 813.17it/s] 55%|█████▍    | 2727/5000 [00:04<00:02, 872.87it/s] 57%|█████▋    | 2835/5000 [00:04<00:02, 916.98it/s] 59%|█████▉    | 2943/5000 [00:04<00:02, 939.61it/s] 62%|██████▏   | 3078/5000 [00:04<00:01, 995.41it/s] 64%|██████▍   | 3213/5000 [00:04<00:01, 1031.71it/s] 67%|██████▋   | 3348/5000 [00:04<00:01, 1058.38it/s] 70%|██████▉   | 3483/5000 [00:04<00:01, 1084.83it/s] 72%|███████▏  | 3592/5000 [00:05<00:01, 868.15it/s]  74%|███████▎  | 3685/5000 [00:05<00:01, 861.48it/s] 76%|███████▌  | 3776/5000 [00:05<00:01, 837.72it/s] 77%|███████▋  | 3863/5000 [00:05<00:01, 758.21it/s] 79%|███████▉  | 3969/5000 [00:05<00:01, 809.17it/s] 82%|████████▏ | 4077/5000 [00:05<00:01, 870.64it/s] 84%|████████▎ | 4185/5000 [00:05<00:00, 905.59it/s] 86%|████████▌ | 4293/5000 [00:05<00:00, 894.00it/s] 89%|████████▊ | 4428/5000 [00:05<00:00, 962.53it/s] 91%|█████████▏| 4563/5000 [00:06<00:00, 1011.30it/s] 94%|█████████▍| 4698/5000 [00:06<00:00, 1051.59it/s] 96%|█████████▌| 4806/5000 [00:06<00:00, 1044.57it/s] 99%|█████████▉| 4941/5000 [00:06<00:00, 1069.29it/s]100%|██████████| 5000/5000 [00:06<00:00, 771.15it/s] 
12/16/2021 03:50:59 - INFO - __main__ -   Parse AST trees
  0%|          | 0/5000 [00:00<?, ?it/s]source: func (a *Application) EnsureMinUnits() (err error) {
	defer errors.DeferredAnnotatef(&err, "cannot ensure minimum units for application %q", a)
	app := &Application{st: a.st, doc: a.doc}
	for {
		// Ensure the application is alive.
		if app.doc.Life != Alive {
			return errors.New("application is not alive")
		}
		// Exit without errors if the MinUnits for the application is not set.
		if app.doc.MinUnits == 0 {
			return nil
		}
		// Retrieve the number of alive units for the application.
		aliveUnits, err := aliveUnitsCount(app)
		if err != nil {
			return err
		}
		// Calculate the number of required units to be added.
		missing := app.doc.MinUnits - aliveUnits
		if missing <= 0 {
			return nil
		}
		name, ops, err := ensureMinUnitsOps(app)
		if err != nil {
			return err
		}
		// Add missing unit.
		switch err := a.st.db().RunTransaction(ops); err {
		case nil:
			// Assign the new unit.
			unit, err := a.st.Unit(name)
			if err != nil {
				return err
			}
			if err := app.st.AssignUnit(unit, AssignNew); err != nil {
				return err
			}
			// No need to proceed and refresh the application if this was the
			// last/only missing unit.
			if missing == 1 {
				return nil
			}
		case txn.ErrAborted:
			// Refresh the application and restart the loop.
		default:
			return err
		}
		if err := app.Refresh(); err != nil {
			return err
		}
	}
}
source: func (q Query) SelectManyByIndexed(selector func(int, interface{}) Query,
	resultSelector func(interface{}, interface{}) interface{}) Query {

	return Query{
		Iterate: func() Iterator {
			outernext := q.Iterate()
			index := 0
			var outer interface{}
			var innernext Iterator

			return func() (item interface{}, ok bool) {
				for !ok {
					if outer == nil {
						outer, ok = outernext()
						if !ok {
							return
						}

						innernext = selector(index, outer).Iterate()
						index++
					}

					item, ok = innernext()
					if !ok {
						outer = nil
					}
				}

				item = resultSelector(item, outer)
				return
			}
		},
	}
}
source: func (agp *AuthGroupPermission) Save(db XODB) error {
	if agp.Exists() {
		return agp.Update(db)
	}

	return agp.Insert(db)
}
source: func Errorf(name, format string, arg ...interface{}) Error {
	return Error{name, fmt.Sprintf(format, arg...)}
}
source: func InitWorkflowClient(ns ...string) v1alpha1.WorkflowInterface {
	if wfClient != nil {
		return wfClient
	}
	initKubeClient()
	var namespace string
	var err error
	if len(ns) > 0 {
		namespace = ns[0]
	} else {
		namespace, _, err = clientConfig.Namespace()
		if err != nil {
			log.Fatal(err)
		}
	}
	wfcs := wfclientset.NewForConfigOrDie(restConfig)
	wfClient = wfcs.ArgoprojV1alpha1().Workflows(namespace)
	return wfClient
}
source: func (dp *MockStaticDiscoveryProvider) CreateLocalDiscoveryService(mspID string) (fab.DiscoveryService, error) {

	if dp.customDiscoveryService != nil {
		return dp.customDiscoveryService, nil
	}

	return NewMockDiscoveryService(dp.Error, dp.Peers...), nil
}
source: func (lp ListParser) Parse(req *http.Request, params imageserver.Params) error {
	for _, subParser := range lp {
		err := subParser.Parse(req, params)
		if err != nil {
			return err
		}
	}
	return nil
}
source: func DecodeReader(r io.Reader, v interface{}) (MetaData, error) {
	bs, err := ioutil.ReadAll(r)
	if err != nil {
		return MetaData{}, err
	}
	return Decode(string(bs), v)
}
source: func (c *cache) _addEntry(qname string) {
	_, ok := c.entries[qname]
	if !ok {
		c._evict()
		// For NXDOMAIN responses,
		// the cache entry is present, but nil.
		c.entries[qname] = nil
	}
}
source: func (s1 Byte) IsSuperset(s2 Byte) bool {
	for item := range s2 {
		if !s1.Has(item) {
			return false
		}
	}
	return true
}
source: func NeighSubscribeWithOptions(ch chan<- NeighUpdate, done <-chan struct{}, options NeighSubscribeOptions) error {
	if options.Namespace == nil {
		none := netns.None()
		options.Namespace = &none
	}
	return neighSubscribeAt(*options.Namespace, netns.None(), ch, done, options.ErrorCallback, options.ListExisting)
}
source: func HasAutoSync(ctx context.Context) bool {
	_, ok := ctx.Value(ctxKeyAutoSync).(bool)
	return ok
}
source: func (f *Function) Invoke(event, context interface{}) (reply, logs io.Reader, err error) {
	eventBytes, err := json.Marshal(event)
	if err != nil {
		return nil, nil, err
	}

	contextBytes, err := json.Marshal(context)
	if err != nil {
		return nil, nil, err
	}

	res, err := f.Service.Invoke(&lambda.InvokeInput{
		ClientContext:  aws.String(base64.StdEncoding.EncodeToString(contextBytes)),
		FunctionName:   &f.FunctionName,
		InvocationType: aws.String(string(RequestResponse)),
		LogType:        aws.String("Tail"),
		Qualifier:      &f.Alias,
		Payload:        eventBytes,
	})

	if err != nil {
		return nil, nil, err
	}

	logs = base64.NewDecoder(base64.StdEncoding, strings.NewReader(*res.LogResult))

	if res.FunctionError != nil {
		e := &InvokeError{
			Handled: *res.FunctionError == "Handled",
		}

		if err := json.Unmarshal(res.Payload, e); err != nil {
			return nil, logs, err
		}

		return nil, logs, e
	}

	reply = bytes.NewReader(res.Payload)
	return reply, logs, nil
}
source: func (y *Yaml) IsMap() bool {
	_, err := y.Map()
	return err == nil
}
source: func (c *Client) DecodeScriptAsync(serializedScript []byte) FutureDecodeScriptResult {
	scriptHex := hex.EncodeToString(serializedScript)
	cmd := btcjson.NewDecodeScriptCmd(scriptHex)
	return c.sendCmd(cmd)
}
source: func (c *client) Approve(namespace, name string, build, stage int) error {
	uri := fmt.Sprintf(pathApprove, c.addr, namespace, name, build, stage)
	err := c.post(uri, nil, nil)
	return err
}
source: func ParseSerialNumber(serial, aki string, dbAccessor certdb.Accessor) (*Certificate, error) {
	normalizedAKI := strings.ToLower(aki)
	normalizedAKI = strings.Replace(normalizedAKI, ":", "", -1)

	certificates, err := dbAccessor.GetCertificate(serial, normalizedAKI)
	if err != nil {
		return nil, err
	}

	if len(certificates) < 1 {
		return nil, errors.New("no certificate found")
	}

	if len(certificates) > 1 {
		return nil, errors.New("more than one certificate found")
	}

	return ParseCertificatePEM([]byte(certificates[0].PEM))
}
source: func (d *Driver) fixRoutingRules(sshClient ssh.Client) {
	output, err := sshClient.Output("route del -net 172.16.0.0/12")
	log.Debugf("%s | Delete route command err, output: %v: %s", d.MachineName, err, output)

	output, err = sshClient.Output("if [ -e /etc/network/interfaces ]; then sed -i '/^up route add -net 172.16.0.0 netmask 255.240.0.0 gw/d' /etc/network/interfaces; fi")
	log.Debugf("%s | Fix route in /etc/network/interfaces command err, output: %v: %s", d.MachineName, err, output)

	output, err = sshClient.Output("if [ -e /etc/sysconfig/network-scripts/route-eth0 ]; then sed -i '/^172.16.0.0\\/12 via /d' /etc/sysconfig/network-scripts/route-eth0; fi")
	log.Debugf("%s | Fix route in /etc/sysconfig/network-scripts/route-eth0 command err, output: %v: %s", d.MachineName, err, output)
}
source: func (o *OrgsClient) Get(ctx context.Context, orgID *identity.ID) (*envelope.Org, error) {
	org := envelope.Org{}
	err := o.client.RoundTrip(ctx, "GET", "/orgs/"+orgID.String(), nil, nil, &org)
	return &org, err
}
source: func OptionSetDescription(description string) Option {
	return func(p *ProgressBar) {
		p.config.description = description
	}
}
source: func (s *NetlinkSocket) Request(req *NlMsgBuilder) (resp *NlMsgParser, err error) {
	seq, err := s.send(req)
	if err != nil {
		return nil, err
	}

	err = s.Receive(func(msg *NlMsgParser) (bool, error) {
		relevant, err := msg.checkResponseHeader(s.PortId(), seq)
		if relevant && err == nil {
			resp = msg
		}
		return true, err
	})
	return
}
source: func UintptrField(name string, value uintptr) FieldOpt {
	inType := inTypeNull
	var writeItem func(*eventData, uintptr)
	switch unsafe.Sizeof(value) {
	case 4:
		inType = inTypeHexInt32
		writeItem = func(ed *eventData, item uintptr) { ed.writeUint32(uint32(item)) }
	case 8:
		inType = inTypeHexInt64
		writeItem = func(ed *eventData, item uintptr) { ed.writeUint64(uint64(item)) }
	default:
		panic("Unsupported uintptr size")
	}

	return func(em *eventMetadata, ed *eventData) {
		em.writeField(name, inType, outTypeDefault, 0)
		writeItem(ed, value)
	}
}
source: func addMultiMutator(shardClient Client, mapping *ShardMapping) []MutateResponse {
	return shardClient.AddMulti(mapping.Items)
}
source: func (s *HumanTaskConfig) SetTaskDescription(v string) *HumanTaskConfig {
	s.TaskDescription = &v
	return s
}
source: func (self *ConnectionString) Protocol(defaults ...string) string {

	if _, protocol := self.Scheme(); protocol != `` {
		return protocol
	} else if len(defaults) > 0 {
		return defaults[0]
	} else {
		return ``
	}
}
source: func numCPU() int {
	// Gets the affinity mask for a process: The very one invoking this function.
	pid, _, _ := unix.RawSyscall(unix.SYS_GETPID, 0, 0, 0)

	var mask [1024 / 64]uintptr
	_, _, err := unix.RawSyscall(unix.SYS_SCHED_GETAFFINITY, pid, uintptr(len(mask)*8), uintptr(unsafe.Pointer(&mask[0])))
	if err != 0 {
		return 0
	}

	// For every available thread a bit is set in the mask.
	ncpu := 0
	for _, e := range mask {
		if e == 0 {
			continue
		}
		ncpu += int(popcnt(uint64(e)))
	}
	return ncpu
}
source: func CheckValidHashStructures(hashes Hashes) error {
	cnt := 0

	for k, v := range hashes {
		switch k {
		case notary.SHA256:
			if len(v) != sha256.Size {
				return ErrInvalidChecksum{alg: notary.SHA256}
			}
			cnt++
		case notary.SHA512:
			if len(v) != sha512.Size {
				return ErrInvalidChecksum{alg: notary.SHA512}
			}
			cnt++
		}
	}

	if cnt == 0 {
		return fmt.Errorf("at least one supported hash needed")
	}

	return nil
}
source: func (d *indirectIndex) Delete(keys [][]byte) bool {
	if len(keys) == 0 {
		return false
	}

	d.mu.RLock()
	iter := d.ro.Iterator()
	for _, key := range keys {
		if !iter.Next() || !bytes.Equal(iter.Key(&d.b), key) {
			if exact, _ := iter.Seek(key, &d.b); !exact {
				continue
			}
		}

		delete(d.tombstones, iter.Offset())
		iter.Delete()
	}
	d.mu.RUnlock()

	if !iter.HasDeletes() {
		return false
	}

	d.mu.Lock()
	iter.Done()
	d.mu.Unlock()

	return true
}
source: func (o *OnionErrorEncrypter) Encode(w io.Writer) error {
	_, err := w.Write(o.sharedSecret[:])
	return err
}
source: func mustExpandAlias(aliasedURL string) (alias string, urlStr string, hostCfg *hostConfigV9) {
	alias, urlStr, hostCfg, _ = expandAlias(aliasedURL)
	return alias, urlStr, hostCfg
}
source: func (o *UpdateTaskParams) WithID(id int64) *UpdateTaskParams {
	o.SetID(id)
	return o
}
source: func (c *ClusterManager) SetSize(size int) error {
	kvdb := kvdb.Instance()
	kvlock, err := kvdb.LockWithID(clusterLockKey, c.config.NodeId)
	if err != nil {
		logrus.Warnln("Unable to obtain cluster lock for updating config", err)
		return nil
	}
	defer kvdb.Unlock(kvlock)

	db, _, err := readClusterInfo()
	if err != nil {
		return err
	}

	db.Size = size

	_, err = writeClusterInfo(&db)

	return err
}
source: func DeleteCommentByID(doer *User, id int64) error {
	comment, err := GetCommentByID(id)
	if err != nil {
		if IsErrCommentNotExist(err) {
			return nil
		}
		return err
	}

	sess := x.NewSession()
	defer sess.Close()
	if err = sess.Begin(); err != nil {
		return err
	}

	if _, err = sess.ID(comment.ID).Delete(new(Comment)); err != nil {
		return err
	}

	if comment.Type == COMMENT_TYPE_COMMENT {
		if _, err = sess.Exec("UPDATE `issue` SET num_comments = num_comments - 1 WHERE id = ?", comment.IssueID); err != nil {
			return err
		}
	}

	if err = sess.Commit(); err != nil {
		return fmt.Errorf("commit: %v", err)
	}

	_, err = DeleteAttachmentsByComment(comment.ID, true)
	if err != nil {
		log.Error(2, "Failed to delete attachments by comment[%d]: %v", comment.ID, err)
	}

	if err = comment.Issue.LoadAttributes(); err != nil {
		log.Error(2, "Issue.LoadAttributes [issue_id: %d]: %v", comment.IssueID, err)
	} else if err = PrepareWebhooks(comment.Issue.Repo, HOOK_EVENT_ISSUE_COMMENT, &api.IssueCommentPayload{
		Action:     api.HOOK_ISSUE_COMMENT_DELETED,
		Issue:      comment.Issue.APIFormat(),
		Comment:    comment.APIFormat(),
		Repository: comment.Issue.Repo.APIFormat(nil),
		Sender:     doer.APIFormat(),
	}); err != nil {
		log.Error(2, "PrepareWebhooks [comment_id: %d]: %v", comment.ID, err)
	}
	return nil
}
source: func New(reg *descriptor.Registry, useRequestContext bool, registerFuncSuffix, pathTypeString string, allowPatchFeature bool) gen.Generator {
	var imports []descriptor.GoPackage
	for _, pkgpath := range []string{
		"context",
		"io",
		"net/http",
		"github.com/grpc-ecosystem/grpc-gateway/runtime",
		"github.com/grpc-ecosystem/grpc-gateway/utilities",
		"github.com/golang/protobuf/proto",
		"google.golang.org/grpc",
		"google.golang.org/grpc/codes",
		"google.golang.org/grpc/grpclog",
		"google.golang.org/grpc/status",
	} {
		pkg := descriptor.GoPackage{
			Path: pkgpath,
			Name: path.Base(pkgpath),
		}
		if err := reg.ReserveGoPackageAlias(pkg.Name, pkg.Path); err != nil {
			for i := 0; ; i++ {
				alias := fmt.Sprintf("%s_%d", pkg.Name, i)
				if err := reg.ReserveGoPackageAlias(alias, pkg.Path); err != nil {
					continue
				}
				pkg.Alias = alias
				break
			}
		}
		imports = append(imports, pkg)
	}

	var pathType pathType
	switch pathTypeString {
	case "", "import":
		// paths=import is default
	case "source_relative":
		pathType = pathTypeSourceRelative
	default:
		glog.Fatalf(`Unknown path type %q: want "import" or "source_relative".`, pathTypeString)
	}

	return &generator{
		reg:                reg,
		baseImports:        imports,
		useRequestContext:  useRequestContext,
		registerFuncSuffix: registerFuncSuffix,
		pathType:           pathType,
		allowPatchFeature:  allowPatchFeature,
	}
}
source: func (chat *Chat) ServiceHookToken() string {
	data, _ := chat.getData()
	//TODO: test backward compatibility cases
	for _, hook := range data.Hooks {
		for _, service := range hook.Services {
			if service == chat.ctx.ServiceName {
				return hook.Token
			}
		}
	}
	token := "c" + rndStr.Get(10)
	chat.addHook(serviceHook{
		Token:    token,
		Services: []string{chat.ctx.ServiceName},
	})
	return token
}
source: func (h *topNChunkHeap) Less(i, j int) bool {
	rowI := h.rowChunks.GetRow(h.rowPtrs[i])
	rowJ := h.rowChunks.GetRow(h.rowPtrs[j])
	return h.greaterRow(rowI, rowJ)
}
source: func Step(dbp Process) (err error) {
	if _, err := dbp.Valid(); err != nil {
		return err
	}
	if dbp.Breakpoints().HasInternalBreakpoints() {
		return fmt.Errorf("next while nexting")
	}

	if err = next(dbp, true, false); err != nil {
		switch err.(type) {
		case ErrThreadBlocked: // Noop
		default:
			dbp.ClearInternalBreakpoints()
			return
		}
	}

	return Continue(dbp)
}
source: func (b *Box) String(name string) (string, error) {
	// check if box is embedded, optimized fast path
	if b.IsEmbedded() {
		// find file in embed
		ef := b.embed.Files[name]
		if ef == nil {
			return "", os.ErrNotExist
		}
		// return as string
		return ef.Content, nil
	}

	bts, err := b.Bytes(name)
	if err != nil {
		return "", err
	}
	return string(bts), nil
}
source: func (md *RootMetadataV2) IsReader(
	_ context.Context, user keybase1.UID, deviceKey kbfscrypto.CryptPublicKey,
	_ TeamMembershipChecker, _ ExtraMetadata,
	_ keybase1.OfflineAvailability) (bool, error) {
	switch md.ID.Type() {
	case tlf.Public:
		return true, nil
	case tlf.Private:
		return md.RKeys.IsReader(user, deviceKey), nil
	case tlf.SingleTeam:
		// There are no read-only users of single-team TLFs.
		return false, nil
	default:
		panic(fmt.Sprintf("Unexpected TLF type: %s", md.ID.Type()))
	}
}
source: func (d DefaultLogger) Logf(level LogLevel, format string, a ...interface{}) (n int, err error) {
	if level >= logThreshhold {
		return fmt.Fprintf(os.Stderr, prefix(level)+" "+format+"\n", a...)
	}

	return 0, nil
}
source: func (claims *Claims) GatewayRight(gatewayID string, right types.Right) bool {
	return claims.GatewayAccess(gatewayID) && containsRight(claims.Gateways[gatewayID], right)
}
source: func NewAbsURLInXMLTransformer(path string) transform.Transformer {
	return func(ft transform.FromTo) error {
		ar.replaceInXML(path, ft)
		return nil
	}
}
source: func xfsSupported() error {
	// Make sure mkfs.xfs is available
	if _, err := exec.LookPath("mkfs.xfs"); err != nil {
		return err // error text is descriptive enough
	}

	// Check if kernel supports xfs filesystem or not.
	exec.Command("modprobe", "xfs").Run()

	f, err := os.Open("/proc/filesystems")
	if err != nil {
		return errors.Wrapf(err, "error checking for xfs support")
	}
	defer f.Close()

	s := bufio.NewScanner(f)
	for s.Scan() {
		if strings.HasSuffix(s.Text(), "\txfs") {
			return nil
		}
	}

	if err := s.Err(); err != nil {
		return errors.Wrapf(err, "error checking for xfs support")
	}

	return errors.New(`kernel does not support xfs, or "modprobe xfs" failed`)
}
source: func GetBalanceTotals() (fSaved, fAcknowledged, eSaved, eAcknowledged int64, err error) {
	type multiBalanceResponse struct {
		FactoidAccountBalances struct {
			Ack   int64 `json:"ack"`
			Saved int64 `json:"saved"`
		} `json:"fctaccountbalances"`
		EntryCreditAccountBalances struct {
			Ack   int64 `json:"ack"`
			Saved int64 `json:"saved"`
		} `json:"ecaccountbalances"`
	}

	req := NewJSON2Request("wallet-balances", APICounter(), nil)
	resp, err := walletRequest(req)
	if err != nil {
		return
	} else if resp.Error != nil {
		err = resp.Error
		return
	}

	balances := new(multiBalanceResponse)
	err = json.Unmarshal(resp.JSONResult(), balances)
	if err != nil {
		return
	}

	fSaved = balances.FactoidAccountBalances.Saved
	fAcknowledged = balances.FactoidAccountBalances.Ack
	eSaved = balances.EntryCreditAccountBalances.Saved
	eAcknowledged = balances.EntryCreditAccountBalances.Ack

	return
}
source: func (r *Response) Map(fn MapResponseFunc) *Response {
	r.Mappers = append(r.Mappers, fn)
	return r
}
source: func (c *imageResolutionCache) resolveImageStreamTag(namespace, name, tag string, partial, forceResolveLocalNames bool) (*rules.ImagePolicyAttributes, error) {
	attrs := &rules.ImagePolicyAttributes{IntegratedRegistry: true}
	resolved, err := c.imageClient.ImageStreamTags(namespace).Get(imageapi.JoinImageStreamTag(name, tag), metav1.GetOptions{})
	if err != nil {
		if partial {
			attrs.IntegratedRegistry = false
		}
		// if a stream exists, resolves names, and a registry is installed, change the reference to be a pointer
		// to the internal registry. This prevents the lookup from going to the original location, which is consistent
		// with the intent of resolving local names.
		if isImageStreamTagNotFound(err) {
			if stream, err := c.imageClient.ImageStreams(namespace).Get(name, metav1.GetOptions{}); err == nil && (forceResolveLocalNames || stream.Spec.LookupPolicy.Local) && len(stream.Status.DockerImageRepository) > 0 {
				if ref, err := imageapi.ParseDockerImageReference(stream.Status.DockerImageRepository); err == nil {
					klog.V(4).Infof("%s/%s:%s points to a local name resolving stream, but the tag does not exist", namespace, name, tag)
					ref.Tag = tag
					attrs.Name = ref
					attrs.LocalRewrite = true
					return attrs, nil
				}
			}
		}
		return attrs, err
	}
	if partial {
		if !forceResolveLocalNames && !resolved.LookupPolicy.Local {
			attrs.IntegratedRegistry = false
			return attrs, fmt.Errorf("ImageStreamTag does not allow local references and the resource did not request image stream resolution")
		}
		attrs.LocalRewrite = true
	}
	ref, err := imageapi.ParseDockerImageReference(resolved.Image.DockerImageReference)
	if err != nil {
		return attrs, fmt.Errorf("image reference %s could not be parsed: %v", resolved.Image.DockerImageReference, err)
	}
	ref.Tag = ""
	ref.ID = resolved.Image.Name

	now := now()
	c.cache.Add(resolved.Image.Name, imageCacheEntry{expires: now.Add(c.expiration), image: &resolved.Image})

	attrs.Name = ref
	attrs.Image = &resolved.Image
	return attrs, nil
}
source: func (client *Client) GetApplication(guid string) (Application, Warnings, error) {
	request, err := client.newHTTPRequest(requestOptions{
		RequestName: internal.GetAppRequest,
		URIParams:   Params{"app_guid": guid},
	})
	if err != nil {
		return Application{}, nil, err
	}

	var app Application
	response := cloudcontroller.Response{
		DecodeJSONResponseInto: &app,
	}

	err = client.connection.Make(request, &response)
	return app, response.Warnings, err
}
source: func (s *OutputGroup) SetOutputGroupSettings(v *OutputGroupSettings) *OutputGroup {
	s.OutputGroupSettings = v
	return s
}
source: func createManagerNS(ns walletdb.ReadWriteBucket,
	defaultScopes map[KeyScope]ScopeAddrSchema) error {

	// First, we'll create all the relevant buckets that stem off of the
	// main bucket.
	mainBucket, err := ns.CreateBucket(mainBucketName)
	if err != nil {
		str := "failed to create main bucket"
		return managerError(ErrDatabase, str, err)
	}
	_, err = ns.CreateBucket(syncBucketName)
	if err != nil {
		str := "failed to create sync bucket"
		return managerError(ErrDatabase, str, err)
	}

	// We'll also create the two top-level scope related buckets as
	// preparation for the operations below.
	scopeBucket, err := ns.CreateBucket(scopeBucketName)
	if err != nil {
		str := "failed to create scope bucket"
		return managerError(ErrDatabase, str, err)
	}
	scopeSchemas, err := ns.CreateBucket(scopeSchemaBucketName)
	if err != nil {
		str := "failed to create scope schema bucket"
		return managerError(ErrDatabase, str, err)
	}

	// Next, we'll create the namespace for each of the relevant default
	// manager scopes.
	for scope, scopeSchema := range defaultScopes {
		// Before we create the entire namespace of this scope, we'll
		// update the schema mapping to note what types of addresses it
		// prefers.
		scopeKey := scopeToBytes(&scope)
		schemaBytes := scopeSchemaToBytes(&scopeSchema)
		err := scopeSchemas.Put(scopeKey[:], schemaBytes)
		if err != nil {
			return err
		}

		err = createScopedManagerNS(scopeBucket, &scope)
		if err != nil {
			return err
		}

		err = putLastAccount(ns, &scope, DefaultAccountNum)
		if err != nil {
			return err
		}
	}

	if err := putManagerVersion(ns, latestMgrVersion); err != nil {
		return err
	}

	createDate := uint64(time.Now().Unix())
	var dateBytes [8]byte
	binary.LittleEndian.PutUint64(dateBytes[:], createDate)
	err = mainBucket.Put(mgrCreateDateName, dateBytes[:])
	if err != nil {
		str := "failed to store database creation time"
		return managerError(ErrDatabase, str, err)
	}

	return nil
}
source: func (h *Handle) SetValue(value []byte) error {
	return json.Unmarshal(value, h)
}
source: func NewPaperDocOwnershipChangedType(Description string) *PaperDocOwnershipChangedType {
	s := new(PaperDocOwnershipChangedType)
	s.Description = Description
	return s
}
source: func (tpl *Template) RegisterPartialFile(filePath string, name string) error {
	b, err := ioutil.ReadFile(filePath)
	if err != nil {
		return err
	}

	tpl.RegisterPartial(name, string(b))

	return nil
}
source: func (c contextValues) Keys() (keys []string) {
	for key := range c {
		keys = append(keys, key)
	}
	return
}
source: func (p *Buffer) Marshal(pb Message) error {
	// Can the object marshal itself?
	if m, ok := pb.(Marshaler); ok {
		data, err := m.Marshal()
		if err != nil {
			return err
		}
		p.buf = append(p.buf, data...)
		return nil
	}

	t, base, err := getbase(pb)
	if structPointer_IsNil(base) {
		return ErrNil
	}
	if err == nil {
		err = p.enc_struct(GetProperties(t.Elem()), base)
	}

	if collectStats {
		stats.Encode++
	}

	return err
}
source: func (r Virtual_Guest_Block_Device_Template_Group) SetCompatiblePlatforms(platformNames []string) (resp bool, err error) {
	params := []interface{}{
		platformNames,
	}
	err = r.Session.DoRequest("SoftLayer_Virtual_Guest_Block_Device_Template_Group", "setCompatiblePlatforms", params, &r.Options, &resp)
	return
}
source: func (t *Template) GetAllAWSDMSEndpointResources() map[string]*resources.AWSDMSEndpoint {
	results := map[string]*resources.AWSDMSEndpoint{}
	for name, untyped := range t.Resources {
		switch resource := untyped.(type) {
		case *resources.AWSDMSEndpoint:
			results[name] = resource
		}
	}
	return results
}
source: func mismatchUnitStatus(u1, u2 *UnitStatus) bool {
	return u1.Name != u2.Name ||
		u1.Description != u2.Description ||
		u1.LoadState != u2.LoadState ||
		u1.ActiveState != u2.ActiveState ||
		u1.SubState != u2.SubState
}
source: func FieldsEqual(f1, f2 []*querypb.Field) bool {
	if len(f1) != len(f2) {
		return false
	}
	for i, f := range f1 {
		if !proto.Equal(f, f2[i]) {
			return false
		}
	}
	return true
}
source: func (s *Service) AppWebhookDeliveryList(ctx context.Context, appIdentity string, lr *ListRange) (AppWebhookDeliveryListResult, error) {
	var appWebhookDelivery AppWebhookDeliveryListResult
	return appWebhookDelivery, s.Get(ctx, &appWebhookDelivery, fmt.Sprintf("/apps/%v/webhook-deliveries", appIdentity), nil, lr)
}
source: func (r *reader) readBitsAsBytes(n uint32) []byte {
	tmp := make([]byte, 0)
	for n >= 8 {
		tmp = append(tmp, r.readByte())
		n -= 8
	}
	if n > 0 {
		tmp = append(tmp, byte(r.readBits(n)))
	}
	return tmp
}
source: func (mg *MailgunImpl) GetStoredAttachment(ctx context.Context, url string) ([]byte, error) {
	r := newHTTPRequest(url)
	r.setClient(mg.Client())
	r.setBasicAuth(basicAuthUser, mg.APIKey())
	r.addHeader("Accept", "message/rfc2822")

	response, err := makeGetRequest(ctx, r)

	return response.Data, err
}
source: func snmpTable(oid string) (mibName string, oidNum string, oidText string, fields []Field, err error) {
	snmpTableCachesLock.Lock()
	if snmpTableCaches == nil {
		snmpTableCaches = map[string]snmpTableCache{}
	}

	var stc snmpTableCache
	var ok bool
	if stc, ok = snmpTableCaches[oid]; !ok {
		stc.mibName, stc.oidNum, stc.oidText, stc.fields, stc.err = snmpTableCall(oid)
		snmpTableCaches[oid] = stc
	}

	snmpTableCachesLock.Unlock()
	return stc.mibName, stc.oidNum, stc.oidText, stc.fields, stc.err
}
source: func Convert_kubeadm_Discovery_To_v1beta2_Discovery(in *kubeadm.Discovery, out *Discovery, s conversion.Scope) error {
	return autoConvert_kubeadm_Discovery_To_v1beta2_Discovery(in, out, s)
}
source: func toLowerASCII(s string) string {
	var b []byte
	for i := 0; i < len(s); i++ {
		if c := s[i]; 'A' <= c && c <= 'Z' {
			if b == nil {
				b = make([]byte, len(s))
				copy(b, s)
			}
			b[i] = s[i] + ('a' - 'A')
		}
	}

	if b == nil {
		return s
	}

	return string(b)
}
source: func NewBroker(opts ...broker.Option) broker.Broker {
	options := broker.Options{
		Context: context.Background(),
	}

	for _, o := range opts {
		o(&options)
	}

	return &sqsBroker{
		options: options,
	}
}
source: func (c *TCPClient) QueryIndex(q string) ([]Event, error) {
	err := c.conn.SetDeadline(time.Now().Add(c.timeout))
	if err != nil {
		return nil, err
	}
	query := &proto.Query{}
	query.String_ = pb.String(q)

	message := &proto.Msg{}
	message.Query = query

	response, err := c.Send(message)
	if err != nil {
		return nil, err
	}

	return ProtocolBuffersToEvents(response.GetEvents()), nil
}
source: func randomBytesMod(length int, mod byte) (b []byte) {
	if length == 0 {
		return nil
	}
	if mod == 0 {
		panic("captcha: bad mod argument for randomBytesMod")
	}
	maxrb := 255 - byte(256%int(mod))
	b = make([]byte, length)
	i := 0
	for {
		r := randomBytes(length + (length / 4))
		for _, c := range r {
			if c > maxrb {
				// Skip this number to avoid modulo bias.
				continue
			}
			b[i] = c % mod
			i++
			if i == length {
				return
			}
		}
	}

}
source: func Convert_config_RoutingConfig_To_v1_RoutingConfig(in *config.RoutingConfig, out *v1.RoutingConfig, s conversion.Scope) error {
	return autoConvert_config_RoutingConfig_To_v1_RoutingConfig(in, out, s)
}
source: func (a *Application) StatusHistory(filter status.StatusHistoryFilter) ([]status.StatusInfo, error) {
	args := &statusHistoryArgs{
		db:        a.st.db(),
		globalKey: a.globalKey(),
		filter:    filter,
	}
	return statusHistory(args)
}
source: func (m *MetricsServer) IncReconcile(app *argoappv1.Application, duration time.Duration) {
	m.reconcileHistogram.WithLabelValues(app.Namespace, app.Name, app.Spec.GetProject()).Observe(duration.Seconds())
}
source: func (l *CompositeLogger) Error(v ...interface{}) {
	for _, log := range l.loggers {
		log.Error(v...)
	}
}
source: func (s *promScope) GaugeDelta(stat string, value int64) {
	s.autoGauge(s.statName(stat)).Add(float64(value))
}
source: func GetBoolQueryParam(c *gin.Context, value *bool, queryParam string, defaultValue bool) bool {
	var err error
	if c.Query(queryParam) != "" {
		if *value, err = strconv.ParseBool(c.Query(queryParam)); err != nil {
			c.JSON(BuildRequestError(
				errors.New("query parameter '" + queryParam + "' value should be true or false (omit the key and default value '" + strconv.FormatBool(defaultValue) + "' will be applied)")),
			)
			return false
		}
	} else {
		*value = defaultValue
	}
	return true
}
source: func loadFileHcl(root string) (configurable, []string, error) {
	// Read the HCL file and prepare for parsing
	d, err := ioutil.ReadFile(root)
	if err != nil {
		return nil, nil, fmt.Errorf(
			"Error reading %s: %s", root, err)
	}

	// Parse it
	hclRoot, err := hcl.Parse(string(d))
	if err != nil {
		return nil, nil, fmt.Errorf(
			"Error parsing %s: %s", root, err)
	}

	// Start building the result
	result := &hclConfigurable{
		File: root,
		Root: hclRoot,
	}

	// Dive in, find the imports. This is disabled for now since
	// imports were removed prior to Terraform 0.1. The code is
	// remaining here commented for historical purposes.
	/*
		imports := obj.Get("import")
		if imports == nil {
			result.Object.Ref()
			return result, nil, nil
		}

		if imports.Type() != libucl.ObjectTypeString {
			imports.Close()

			return nil, nil, fmt.Errorf(
				"Error in %s: all 'import' declarations should be in the format\n"+
					"`import \"foo\"` (Got type %s)",
				root,
				imports.Type())
		}

		// Gather all the import paths
		importPaths := make([]string, 0, imports.Len())
		iter := imports.Iterate(false)
		for imp := iter.Next(); imp != nil; imp = iter.Next() {
			path := imp.ToString()
			if !filepath.IsAbs(path) {
				// Relative paths are relative to the Terraform file itself
				dir := filepath.Dir(root)
				path = filepath.Join(dir, path)
			}

			importPaths = append(importPaths, path)
			imp.Close()
		}
		iter.Close()
		imports.Close()

		result.Object.Ref()
	*/

	return result, nil, nil
}
source: func (m Metrics) incBytesReceived(delta uint64) {
	atomic.AddUint64(m.BytesReceived, delta)
}
source: func (m *MockisBatchRequest_Request_Request) isBatchRequest_Request_Request() {
	m.ctrl.T.Helper()
	m.ctrl.Call(m, "isBatchRequest_Request_Request")
}
source: func (w *worker) start(d *ddlCtx) {
	logutil.Logger(w.logCtx).Info("[ddl] start DDL worker")
	defer w.wg.Done()

	// We use 4 * lease time to check owner's timeout, so here, we will update owner's status
	// every 2 * lease time. If lease is 0, we will use default 1s.
	// But we use etcd to speed up, normally it takes less than 1s now, so we use 1s as the max value.
	checkTime := chooseLeaseTime(2*d.lease, 1*time.Second)

	ticker := time.NewTicker(checkTime)
	defer ticker.Stop()

	for {
		select {
		case <-ticker.C:
			logutil.Logger(w.logCtx).Debug("[ddl] wait to check DDL status again", zap.Duration("interval", checkTime))
		case <-w.ddlJobCh:
		case <-w.quitCh:
			return
		}

		err := w.handleDDLJobQueue(d)
		if err != nil {
			logutil.Logger(w.logCtx).Error("[ddl] handle DDL job failed", zap.Error(err))
		}
	}
}
source: func (d *Decoder) next() byte {
	d.pos++
	if d.pos < d.end {
		return d.data[d.pos]
	}
	return 0
}
source: func (n *NotifyRouter) HandleFSOnlineStatusChanged(online bool) {
	if n == nil {
		return
	}
	// For all connections we currently have open...
	n.cm.ApplyAll(func(id ConnectionID, xp rpc.Transporter) bool {
		// If the connection wants the `kbfs` notification type
		if n.getNotificationChannels(id).Kbfs {
			// In the background do...
			go func() {
				// A send of a `FSOnlineStatusChanged` RPC with the
				// notification
				(keybase1.NotifyFSClient{
					Cli: rpc.NewClient(xp, NewContextifiedErrorUnwrapper(n.G()), nil),
				}).FSOnlineStatusChanged(context.Background(), online)
			}()
		}
		return true
	})
	n.runListeners(func(listener NotifyListener) {
		listener.FSOnlineStatusChanged(online)
	})
}
source: func Type(v interface{}) ValueType {
	t := Unknown
	switch v.(type) {
	case nil:
		t = Null
	case bool:
		t = Bool
	case string:
		t = String
	case float64:
		t = Number
	case []interface{}:
		t = Array
	case map[string]interface{}:
		t = Object
	}
	return t
}
source: func (c *Ctx) Logout(sh SessionHandle) error {
	if c.ctx == nil {
		return toError(CKR_CRYPTOKI_NOT_INITIALIZED)
	}
	e := C.Logout(c.ctx, C.CK_SESSION_HANDLE(sh))
	return toError(e)
}
source: func claimsIntfAttrValue(claims claimsIntf, attr string, at time.Time, signerFilter SignerRefSet) string {
	if claims == nil {
		panic("nil claims argument in claimsIntfAttrValue")
	}

	if at.IsZero() {
		at = time.Now()
	}

	// use a small static buffer as it speeds up
	// search.BenchmarkQueryPermanodeLocation by 6-7%
	// with go 1.7.1
	var buf [8]string
	v := buf[:][:0]

	for i := 0; i < claims.Len(); i++ {
		cl := claims.Claim(i)
		if cl.Attr != attr || cl.Date.After(at) {
			continue
		}

		if len(signerFilter) > 0 {
			if !signerFilter.blobMatches(cl.Signer) {
				continue
			}
		}

		switch cl.Type {
		case string(schema.DelAttributeClaim):
			if cl.Value == "" {
				v = v[:0]
			} else {
				i := 0
				for _, w := range v {
					if w != cl.Value {
						v[i] = w
						i++
					}
				}
				v = v[:i]
			}
		case string(schema.SetAttributeClaim):
			v = append(v[:0], cl.Value)
		case string(schema.AddAttributeClaim):
			v = append(v, cl.Value)
		}
	}
	if len(v) != 0 {
		return v[0]
	}
	return ""
}
source: func (c *chainRegistry) ActiveChains() []chainCode {
	c.RLock()
	defer c.RUnlock()

	chains := make([]chainCode, 0, len(c.activeChains))
	for activeChain := range c.activeChains {
		chains = append(chains, activeChain)
	}

	return chains
}
source: func (b *FugaJSONBuilder) Remove(info *FugaPropertyInfo) *FugaJSONBuilder {
	delete(b._properties, info.fieldName)
	return b
}
source: func format(enc []byte, mime string) string {
	switch mime {
	case "image/gif", "image/jpeg", "image/pjpeg", "image/png", "image/tiff":
		return fmt.Sprintf("data:%s;base64,%s", mime, enc)
	default:
	}

	return fmt.Sprintf("data:image/png;base64,%s", enc)
}
source: func (r *Route) save() {
	r.Size = len(r.Path)
	r.Token.Tokens = strings.Split(r.Path, "/")
	for i, s := range r.Token.Tokens {
		if len(s) >= 1 {
			switch s[:1] {
			case ":":
				s = s[1:]
				if r.Pattern == nil {
					r.Pattern = make(map[int]string)
				}
				if validators := containsValidators(s); validators != nil {
					if r.validators == nil {
						r.validators = make(map[string][]string)
					}
					for _, vali := range validators {
						s = s[:validators[0].start]
						r.validators[s] = append(r.validators[s], vali.name[1:])
					}
				}
				r.Pattern[i] = s
				r.Atts |= PARAM
			case "#":
				if r.Compile == nil {
					r.Compile = make(map[int]*regexp.Regexp)
					r.Tag = make(map[int]string)
				}
				tmp := strings.Split(s, "^")
				r.Tag[i] = tmp[0][1:]
				r.Compile[i] = regexp.MustCompile("^" + tmp[1][:len(tmp[1])-1])
				r.Atts |= REGEX
			case "*":
				r.wildPos = i
				r.Atts |= WC
			default:
				r.Token.raw = append(r.Token.raw, i)
			}
		}
		r.Token.Size++
	}
}
source: func handleSwaggerOrigin(h goa.Handler) goa.Handler {

	return func(ctx context.Context, rw http.ResponseWriter, req *http.Request) error {
		origin := req.Header.Get("Origin")
		if origin == "" {
			// Not a CORS request
			return h(ctx, rw, req)
		}
		if cors.MatchOrigin(origin, "*") {
			ctx = goa.WithLogContext(ctx, "origin", origin)
			rw.Header().Set("Access-Control-Allow-Origin", origin)
			rw.Header().Set("Access-Control-Allow-Credentials", "false")
			if acrm := req.Header.Get("Access-Control-Request-Method"); acrm != "" {
				// We are handling a preflight request
				rw.Header().Set("Access-Control-Allow-Methods", "GET, OPTIONS")
			}
			return h(ctx, rw, req)
		}
		if cors.MatchOrigin(origin, "http://swagger.goa.design") {
			ctx = goa.WithLogContext(ctx, "origin", origin)
			rw.Header().Set("Access-Control-Allow-Origin", origin)
			rw.Header().Set("Vary", "Origin")
			rw.Header().Set("Access-Control-Max-Age", "600")
			rw.Header().Set("Access-Control-Allow-Credentials", "true")
			if acrm := req.Header.Get("Access-Control-Request-Method"); acrm != "" {
				// We are handling a preflight request
				rw.Header().Set("Access-Control-Allow-Methods", "GET, POST, PUT, PATCH, DELETE")
			}
			return h(ctx, rw, req)
		}

		return h(ctx, rw, req)
	}
}
source: func DbPermissionPrimaryKey(dp *tabletmanagerdatapb.DbPermission) string {
	return dp.Host + ":" + dp.Db + ":" + dp.User
}
source: func New(branch int) (generator.Generator, error) {
	if branch < 1 {
		return nil, fmt.Errorf("invalid branch factor %d", branch)
	}
	nt, err := node.NewType("/tn")
	if err != nil {
		return nil, err
	}
	p, err := predicate.NewImmutable("parent_of")
	if err != nil {
		return nil, err
	}
	return &treeGenerator{
		branch:    branch,
		nodeType:  nt,
		predicate: p,
	}, nil
}
source: func NewRuntime(runtimeCommand string, bundleDir string) (Runtime, error) {
	var r Runtime
	var err error
	r.RuntimeCommand, err = exec.LookPath(runtimeCommand)
	if err != nil {
		return Runtime{}, err
	}

	r.BundleDir = bundleDir
	return r, err
}
source: func filterExternalCAURLS(ctx context.Context, desiredCert, defaultCert []byte, apiExternalCAs []*api.ExternalCA) (urls []string) {
	desiredCert = NormalizePEMs(desiredCert)

	// TODO(aaronl): In the future, this will be abstracted with an ExternalCA interface that has different
	// implementations for different CA types. At the moment, only CFSSL is supported.
	for i, extCA := range apiExternalCAs {
		// We want to support old external CA specifications which did not have a CA cert.  If there is no cert specified,
		// we assume it's the old cert
		certForExtCA := extCA.CACert
		if len(certForExtCA) == 0 {
			certForExtCA = defaultCert
		}
		certForExtCA = NormalizePEMs(certForExtCA)
		if extCA.Protocol != api.ExternalCA_CAProtocolCFSSL {
			log.G(ctx).Debugf("skipping external CA %d (url: %s) due to unknown protocol type", i, extCA.URL)
			continue
		}
		if !bytes.Equal(certForExtCA, desiredCert) {
			log.G(ctx).Debugf("skipping external CA %d (url: %s) because it has the wrong CA cert", i, extCA.URL)
			continue
		}
		urls = append(urls, extCA.URL)
	}
	return
}
source: func String(data string) p.Plugin {
	return p.NewRequestPlugin(func(ctx *c.Context, h c.Handler) {
		ctx.Request.Method = getMethod(ctx)
		ctx.Request.Body = utils.StringReader(data)
		ctx.Request.ContentLength = int64(bytes.NewBufferString(data).Len())
		h.Next(ctx)
	})
}
source: func (j *Driver) loadFile() error {
	file, e := ioutil.ReadFile(j.configPath)
	if e != nil {
		return e
	}

	var jsontype joystickConfig
	json.Unmarshal(file, &jsontype)
	j.config = jsontype
	return nil
}
source: func (cache *Cache) pruneInterval() time.Duration {
	if cache.AccessUpdateInterval > 0 && cache.PruneFactor > 0 {
		return cache.AccessUpdateInterval * time.Duration(1+cache.PruneFactor)
	}
	return 0
}
source: func (mr *MockBaseWatcherMockRecorder) WatchCollectionWithFilter(arg0, arg1, arg2 interface{}) *gomock.Call {
	return mr.mock.ctrl.RecordCallWithMethodType(mr.mock, "WatchCollectionWithFilter", reflect.TypeOf((*MockBaseWatcher)(nil).WatchCollectionWithFilter), arg0, arg1, arg2)
}
source: func (c *OperatorGenerateRootCommand) status(client *api.Client, drToken bool) int {
	f := client.Sys().GenerateRootStatus
	if drToken {
		f = client.Sys().GenerateDROperationTokenStatus
	}
	status, err := f()
	if err != nil {
		c.UI.Error(fmt.Sprintf("Error getting root generation status: %s", err))
		return 2
	}
	switch Format(c.UI) {
	case "table":
		return c.printStatus(status)
	default:
		return OutputData(c.UI, status)
	}
}
source: func (m *MockQuery) One(arg0 interface{}) error {
	ret := m.ctrl.Call(m, "One", arg0)
	ret0, _ := ret[0].(error)
	return ret0
}
source: func (c *ConnectionManager) LookupConnection(i ConnectionID) rpc.Transporter {
	c.Lock()
	defer c.Unlock()
	if conn := c.lookup[i]; conn != nil {
		return conn.transporter
	}
	return nil
}
source: func (r *Region) GetContext() *kvrpcpb.Context {
	return &kvrpcpb.Context{
		RegionId:    r.meta.Id,
		RegionEpoch: r.meta.RegionEpoch,
		Peer:        r.peer,
	}
}
source: func (g *Group) Uint() *Statement {
	// notest
	s := Uint()
	g.items = append(g.items, s)
	return s
}
source: func (b *Base) GetCropOption(name string) *image.Rectangle {
	if cropOption := b.CropOptions[strings.Split(name, "@")[0]]; cropOption != nil {
		return &image.Rectangle{
			Min: image.Point{X: cropOption.X, Y: cropOption.Y},
			Max: image.Point{X: cropOption.X + cropOption.Width, Y: cropOption.Y + cropOption.Height},
		}
	}
	return nil
}
source: func (self *Coder) Unmarshal(in []byte, data interface{}) error {
	return self.unmarshaller(in, data)
}
source: func (s storageProvider) DefaultPools() []*storage.Config {
	latencyPool, _ := storage.NewConfig("oracle-latency", oracleStorageProviderType, map[string]interface{}{
		oracleVolumeType: latencyPool,
	})
	return []*storage.Config{latencyPool}
}
source: func (c *client) Close() {
	c.closeOnce.Do(func() {
		close(c.done)
		if c.clientType == adminClient {
			if ac := c.adminRegionInfo.Client(); ac != nil {
				ac.Close()
			}
		}
		c.clients.closeAll()
	})
}
source: func NewVersionedColumnPrinter(printer ColumnPrinter, convertor runtime.ObjectConvertor, version runtime.GroupVersioner) ColumnPrinter {
	return &VersionedColumnPrinter{
		printer:   printer,
		convertor: convertor,
		version:   version,
	}
}
source: func RangeWithStep(start, end, step float64) []float64 {
	return Seq{NewLinear().WithStart(start).WithEnd(end).WithStep(step)}.Array()
}
source: func (p *PodHealthCheck) SetTimeout(timeoutSeconds int) *PodHealthCheck {
	p.TimeoutSeconds = &timeoutSeconds
	return p
}  2%|▏         | 110/5000 [00:00<00:04, 1095.25it/s]
source: func TrailingZeros16(x uint16) (n int) {
	if x == 0 {
		return 16
	}
	// see comment in TrailingZeros64
	return int(deBruijn32tab[uint32(x&-x)*deBruijn32>>(32-5)])
}
source: func (s *Simulation) StopRandomNodes(count int) (ids []enode.ID, err error) {
	ids = make([]enode.ID, 0, count)
	for i := 0; i < count; i++ {
		n := s.Net.GetRandomUpNode()
		if n == nil {
			return nil, ErrNodeNotFound
		}
		err = s.Net.Stop(n.ID())
		if err != nil {
			return nil, err
		}
		ids = append(ids, n.ID())
	}
	return ids, nil
}
source: func LogErrorAndExit(err error, opts ...int) {
	var rc int
	if len(opts) > 0 {
		rc = opts[0]
	}
	if gLogLevel <= LError {
		logMessage("ERROR - ", err.Error())
	}
	os.Exit(rc)
}
source: func ensureEOF(r io.Reader) error {
	n, err := tryReadFull(r, []byte{0})
	switch {
	case n > 0:
		return ErrWriteTooLong
	case err == io.EOF:
		return nil
	default:
		return err
	}
}
source: func deliveryAck(delivery amqp.Delivery) {
	retryCount := 3
	var err error
	for retryCount > 0 {
		if err = delivery.Ack(false); err == nil {
			break
		}
	}
	if err != nil {
		log.Printf("amqp_backend: failed to acknowledge result message %+v: %+v", delivery.MessageId, err)
	}
}
source: func (rc *RequestContext) MarshalJSON() ([]byte, error) {
	return json.Marshal(&jsonRequestContext{
		(*requestContextAlias)(rc),
		rc.Authorizer,
	})
}
source: func (s *Selection) PrevMatcher(m Matcher) *Selection {
	return filterAndPush(s, getSiblingNodes(s.Nodes, siblingPrev, nil, nil), m)
}
source: func (e *GrantExec) grantColumnPriv(priv *ast.PrivElem, user *ast.UserSpec) error {
	dbName, tbl, err := getTargetSchemaAndTable(e.ctx, e.Level.DBName, e.Level.TableName, e.is)
	if err != nil {
		return err
	}

	for _, c := range priv.Cols {
		col := table.FindCol(tbl.Cols(), c.Name.L)
		if col == nil {
			return errors.Errorf("Unknown column: %s", c)
		}
		asgns, err := composeColumnPrivUpdateForGrant(e.ctx, priv.Priv, user.User.Username, user.User.Hostname, dbName, tbl.Meta().Name.O, col.Name.O)
		if err != nil {
			return err
		}
		sql := fmt.Sprintf(`UPDATE %s.%s SET %s WHERE User='%s' AND Host='%s' AND DB='%s' AND Table_name='%s' AND Column_name='%s';`, mysql.SystemDB, mysql.ColumnPrivTable, asgns, user.User.Username, user.User.Hostname, dbName, tbl.Meta().Name.O, col.Name.O)
		_, _, err = e.ctx.(sqlexec.RestrictedSQLExecutor).ExecRestrictedSQL(e.ctx, sql)
		if err != nil {
			return err
		}
	}
	return nil
}
source: func (c *IndexedDB) DeleteObjectStoreEntriesWithParams(v *IndexedDBDeleteObjectStoreEntriesParams) (*gcdmessage.ChromeResponse, error) {
	return gcdmessage.SendDefaultRequest(c.target, c.target.GetSendCh(), &gcdmessage.ParamRequest{Id: c.target.GetId(), Method: "IndexedDB.deleteObjectStoreEntries", Params: v})
}
source: func (s *GetCampaignActivitiesOutput) SetActivitiesResponse(v *ActivitiesResponse) *GetCampaignActivitiesOutput {
	s.ActivitiesResponse = v
	return s
}
source: func NewAPICache(rules []*policy.HTTPRule, id string, external bool) *APICache {
	a := &APICache{
		methodRoots: map[string]*node{},
		ID:          id,
		External:    external,
	}

	for _, rule := range rules {
		sc := &scopeRule{
			rule: rule,
		}
		for _, method := range rule.Methods {
			if _, ok := a.methodRoots[method]; !ok {
				a.methodRoots[method] = &node{}
			}
			for _, uri := range rule.URIs {
				insert(a.methodRoots[method], uri, sc)
			}
		}
	}

	return a
}
source: func (s *Store) CreateDate() int64 {
	s.mtx.RLock()
	defer s.mtx.RUnlock()

	return s.createDate
}
source: func Field(fieldPtr interface{}, rules ...Rule) *FieldRules {
	return &FieldRules{
		fieldPtr: fieldPtr,
		rules:    rules,
	}
}
source: func (b *WriterHandler) Handle(rec *Record) {
	message := b.BaseHandler.FilterAndFormat(rec)
	if message == "" {
		return
	}
	if b.Colorize {
		b.w.Write([]byte(fmt.Sprintf("\033[%dm", LevelColors[rec.Level])))
	}
	fmt.Fprint(b.w, message)
	if b.Colorize {
		b.w.Write([]byte("\033[0m")) // reset color
	}
}
source: func proxyStream(w http.ResponseWriter, r *http.Request, url *url.URL) {
	// TODO(random-liu): Set MaxBytesPerSec to throttle the stream.
	handler := proxy.NewUpgradeAwareHandler(url, nil /*transport*/, false /*wrapTransport*/, true /*upgradeRequired*/, &responder{})
	handler.ServeHTTP(w, r)
}
source: func (win *Window) OptionText(text string, is_active bool) bool {
	style := &win.ctx.Style
	state, bounds, fitting := win.widget()
	if fitting != nil {
		fitting(toggleWidth(text, toggleOption, &style.Option, style.Font))
	}
	if !state {
		return false
	}
	in := win.inputMaybe(state)
	is_active = doToggle(win, bounds, is_active, text, toggleOption, &style.Option, in, style.Font)
	return is_active
}
source: func (p *RemotePeer) String() string {
	return fmt.Sprintf("%s, PKIid:%v", p.Endpoint, p.PKIID)
}
source: func (u Vec) Cross(v Vec) float64 {
	return u.X*v.Y - v.X*u.Y
}
source: func Convert_apiserver_AdmissionConfiguration_To_v1alpha1_AdmissionConfiguration(in *apiserver.AdmissionConfiguration, out *AdmissionConfiguration, s conversion.Scope) error {
	return autoConvert_apiserver_AdmissionConfiguration_To_v1alpha1_AdmissionConfiguration(in, out, s)
}
source: func (s *InstancePatchState) SetInstallOverrideList(v string) *InstancePatchState {
	s.InstallOverrideList = &v
	return s
}
source: func LongAbs(path string) (string, error) {
	if strings.HasPrefix(path, `\\?\`) || strings.HasPrefix(path, `\\.\`) {
		return path, nil
	}
	if !filepath.IsAbs(path) {
		absPath, err := filepath.Abs(path)
		if err != nil {
			return "", err
		}
		path = absPath
	}
	if strings.HasPrefix(path, `\\`) {
		return `\\?\UNC\` + path[2:], nil
	}
	return `\\?\` + path, nil
}
source: func (f *FloatAttribute) UnmarshalJSON(data []byte) error {
	var d map[string]interface{}
	err := json.Unmarshal(data, &d)
	if err != nil {
		return err
	}
	if precision, ok := d["precision"]; ok {
		f.Precision = int(precision.(float64))
		return nil
	}
	return fmt.Errorf("Precision must be specified")
}
source: func NewFilteredApplicationInformer(client versioned.Interface, namespace string, resyncPeriod time.Duration, indexers cache.Indexers, tweakListOptions internalinterfaces.TweakListOptionsFunc) cache.SharedIndexInformer {
	return cache.NewSharedIndexInformer(
		&cache.ListWatch{
			ListFunc: func(options v1.ListOptions) (runtime.Object, error) {
				if tweakListOptions != nil {
					tweakListOptions(&options)
				}
				return client.ArgoprojV1alpha1().Applications(namespace).List(options)
			},
			WatchFunc: func(options v1.ListOptions) (watch.Interface, error) {
				if tweakListOptions != nil {
					tweakListOptions(&options)
				}
				return client.ArgoprojV1alpha1().Applications(namespace).Watch(options)
			},
		},
		&applicationv1alpha1.Application{},
		resyncPeriod,
		indexers,
	)
}
source: func NewKeyValueYARPCClient(clientConfig transport.ClientConfig, options ...protobuf.ClientOption) KeyValueYARPCClient {
	return &_KeyValueYARPCCaller{protobuf.NewStreamClient(
		protobuf.ClientParams{
			ServiceName:  "uber.yarpc.internal.examples.protobuf.example.KeyValue",
			ClientConfig: clientConfig,
			Options:      options,
		},
	)}
}
source: func componentColumnCountOfType(columns map[string]*ColumnMetadata, kind ColumnKind) int {
	maxComponentIndex := -1
	for _, column := range columns {
		if column.Kind == kind && column.ComponentIndex > maxComponentIndex {
			maxComponentIndex = column.ComponentIndex
		}
	}
	return maxComponentIndex + 1
}
source: func (controller *LocalController) OnValidationFail(ctx context.Context, err error) error {
	return controller.moveToErrorDir(ctx)
}
source: func (c *Controller) RemoveNotifier(name string) error {
	c.mu.Lock()
	defer c.mu.Unlock()
	currentNotifier, ok := c.notifiers[name]
	if !ok {
		return fmt.Errorf("Unknown notification service %s", name)
	}
	currentNotifier.removeSubscription()
	delete(c.notifiers, name)
	return nil
}
source: func (samplerOptions) Metrics(m *Metrics) SamplerOption {
	return func(o *samplerOptions) {
		o.metrics = m
	}
}
source: func CheckIPInRange(ip string, start net.IP, end net.IP) bool {
	//sanity check
	input := net.ParseIP(ip)
	if input.To4() == nil {
		log.Printf("%v is not a valid IPv4 address", input)
		return false
	}

	if bytes.Compare(input, start) >= 0 && bytes.Compare(input, end) <= 0 {
		return true
	}

	log.Printf("%v is NOT between %v and %v", input, start, end)
	return false
}
source: func (srv *Instance) StartMachine(ctx context.Context, wg *sync.WaitGroup) (err error) {
	if srv.cfg.Choria.MachineSourceDir == "" {
		return fmt.Errorf("Choria Autonomous Agent source directory not configured, skipping initialization")
	}

	srv.machines, err = aagent.New(srv.cfg.Choria.MachineSourceDir, srv)
	if err != nil {
		return err
	}

	return srv.machines.ManageMachines(ctx, wg)
}
source: func (m *SubjectAlternateName) Validate() error {
	if m == nil {
		return nil
	}

	switch m.Name.(type) {

	case *SubjectAlternateName_Dns:
		// no validation rules for Dns

	case *SubjectAlternateName_Uri:
		// no validation rules for Uri

	}

	return nil
}
source: func (r *Reader) MustDuration(name string) time.Duration {
	b, err := r.readDuration(name)
	if err != nil {
		panic(err)
	}
	return b
}
source: func generateUsername(r *http.Request, firstname, lastname string) (string, error) {
	counter := 0
	var username string
	for _, r := range firstname {
		if unicode.IsSpace(r) {
			continue
		}
		username += string(unicode.ToLower(r))
	}
	username += "_"
	for _, r := range lastname {
		if unicode.IsSpace(r) {
			continue
		}
		username += string(unicode.ToLower(r))
	}
	username += "_"
	userMgr := user.NewManager(r)

	count, err := userMgr.GetPendingRegistrationsCount()
	if err != nil {
		return "", err
	}
	log.Debug("count", count)
	if count >= MAX_PENDING_REGISTRATION_COUNT {
		return "", errors.New("Max amount of pending registrations reached")
	}

	orgMgr := organization.NewManager(r)
	exists := true
	for exists {
		counter++
		var err error
		exists, err = userMgr.Exists(username + strconv.Itoa(counter))
		if err != nil {
			return "", err
		}
		if !exists {
			exists = orgMgr.Exists(username + strconv.Itoa(counter))
		}
	}
	username = username + strconv.Itoa(counter)
	return username, nil
}
source: func handleDiscovery(w http.ResponseWriter, r *http.Request) {
	// For other example see: https://accounts.google.com/.well-known/openid-configuration
	data := map[string]interface{}{
		"issuer":                                issuer,
		"authorization_endpoint":                issuer + "/authorize",
		"token_endpoint":                        issuer + "/token",
		"jwks_uri":                              issuer + "/publickeys",
		"response_types_supported":              []string{"code"},
		"subject_types_supported":               []string{"public"},
		"id_token_signing_alg_values_supported": []string{"RS256"},
		"scopes_supported":                      []string{"openid", "email", "profile"},
		"token_endpoint_auth_methods_supported": []string{"client_secret_basic"},
		"claims_supported": []string{
			"aud", "email", "email_verified", "exp",
			"family_name", "given_name", "iat", "iss",
			"locale", "name", "sub",
		},
	}

	raw, err := json.MarshalIndent(data, "", "  ")
	if err != nil {
		log.Printf("failed to marshal data: %v", err)
		http.Error(w, "Internal server error", http.StatusInternalServerError)
		return
	}
	w.Header().Set("Content-Type", "application/json")
	w.Header().Set("Content-Length", strconv.Itoa(len(raw)))
	w.Write(raw)
}
source: func (s *EcsCluster) SetEcsClusterName(v string) *EcsCluster {
	s.EcsClusterName = &v
	return s
}
source: func (o TaintOptions) RunTaint() error {
	r := o.builder.Do()
	if err := r.Err(); err != nil {
		return err
	}

	return r.Visit(func(info *resource.Info, err error) error {
		if err != nil {
			return err
		}

		obj := info.Object
		name, namespace := info.Name, info.Namespace
		oldData, err := json.Marshal(obj)
		if err != nil {
			return err
		}
		operation, err := o.updateTaints(obj)
		if err != nil {
			return err
		}
		newData, err := json.Marshal(obj)
		if err != nil {
			return err
		}
		patchBytes, err := strategicpatch.CreateTwoWayMergePatch(oldData, newData, obj)
		createdPatch := err == nil
		if err != nil {
			klog.V(2).Infof("couldn't compute patch: %v", err)
		}

		mapping := info.ResourceMapping()
		client, err := o.ClientForMapping(mapping)
		if err != nil {
			return err
		}
		helper := resource.NewHelper(client, mapping)

		var outputObj runtime.Object
		if createdPatch {
			outputObj, err = helper.Patch(namespace, name, types.StrategicMergePatchType, patchBytes, nil)
		} else {
			outputObj, err = helper.Replace(namespace, name, false, obj)
		}
		if err != nil {
			return err
		}

		printer, err := o.ToPrinter(operation)
		if err != nil {
			return err
		}
		return printer.PrintObj(outputObj, o.Out)
	})
}
source: func ParseErr(cmd interface{}, args []string, opts ...parseOpt) (err error) {
	p, err := newParser(cmd, opts...)
	if err != nil {
		return
	}
	return p.parse(args)
}
source: func NewTranslator(filename string, fields ...string) (bt *Translator, err error) {
	bt = &Translator{
		fields: make(map[string]struct{}),
	}
	bt.Db, err = bolt.Open(filename, 0600, &bolt.Options{Timeout: 1 * time.Second, InitialMmapSize: 50000000, NoGrowSync: true})
	if err != nil {
		return nil, errors.Wrapf(err, "opening db file '%v'", filename)
	}
	bt.Db.MaxBatchDelay = 400 * time.Microsecond
	err = bt.Db.Update(func(tx *bolt.Tx) error {
		ib, err := tx.CreateBucketIfNotExists(idBucket)
		if err != nil {
			return errors.Wrap(err, "creating idKey bucket")
		}
		vb, err := tx.CreateBucketIfNotExists(valBucket)
		if err != nil {
			return errors.Wrap(err, "creating valKey bucket")
		}
		for _, field := range fields {
			_, _, err = bt.addField(ib, vb, field)
			if err != nil {
				return err
			}
		}
		return nil
	})
	if err != nil {
		return nil, errors.Wrap(err, "ensuring bucket existence")
	}
	return bt, nil
}
source: func GetCommentsByRepoIDSince(repoID, since int64) ([]*Comment, error) {
	return getCommentsByRepoIDSince(x, repoID, since)
}
source: func WithField(key string, val interface{}, message string) Goof {
	return WithFields(Fields{key: val}, message)
}
source: func replyWithJSON(w http.ResponseWriter, obj interface{}) error {
	w.Header().Set("Content-Type", "application/json; charset=utf-8")
	w.WriteHeader(http.StatusOK)
	enc := json.NewEncoder(w)
	enc.SetIndent("", "  ")
	enc.SetEscapeHTML(false)
	return enc.Encode(obj)
}
source: func newPulloutSubquery(opcode engine.PulloutOpcode, sqName, hasValues string, subquery builder) *pulloutSubquery {
	return &pulloutSubquery{
		subquery: subquery,
		eSubquery: &engine.PulloutSubquery{
			Opcode:         opcode,
			SubqueryResult: sqName,
			HasValues:      hasValues,
		},
	}
}
source: func GetServerInformation() (i ServerInformation, err error) {
	conn, err := dbus.SessionBus()
	if err != nil {
		return
	}

	obj := conn.Object(DbusInterfacePath, DbusObjectPath)
	call := obj.Call(CallGetServerInformation, 0)
	if err = call.Err; err != nil {
		return
	}

	err = call.Store(&i.Name, &i.Vendor, &i.Version, &i.SpecVersion)
	return
}
source: func (k *Keyrings) GetSecretKeyLocked(m MetaContext, ska SecretKeyArg) (ret *SKB, err error) {
	defer m.Trace("Keyrings#GetSecretKeyLocked()", func() error { return err })()
	m.Debug("| LoadMe w/ Secrets on")

	if ska.Me == nil {
		if ska.Me, err = LoadMe(NewLoadUserArg(k.G())); err != nil {
			return nil, err
		}
	}

	ret, err = LockedLocalSecretKey(m, ska)
	if err != nil {
		return nil, err
	}

	if ret != nil {
		m.Debug("| Getting local secret key")
		return ret, nil
	}

	var pub GenericKey

	if ska.KeyType != PGPKeyType {
		m.Debug("| Skipped Synced PGP key (via options)")
		err = NoSecretKeyError{}
		return nil, err
	}

	if ret, err = ska.Me.SyncedSecretKey(m); err != nil {
		m.Warning("Error fetching synced PGP secret key: %s", err)
		return nil, err
	}
	if ret == nil {
		err = NoSecretKeyError{}
		return nil, err
	}

	if pub, err = ret.GetPubKey(); err != nil {
		return nil, err
	}

	if !KeyMatchesQuery(pub, ska.KeyQuery, ska.ExactMatch) {
		m.Debug("| Can't use Synced PGP key; doesn't match query %s", ska.KeyQuery)
		err = NoSecretKeyError{}
		return nil, err

	}
	return ret, nil
}
source: func (tx *Tx) Stmt(stmt *Stmt) *Stmt {
	stmt, err := tx.Prepare(stmt.q)
	if err != nil {
		return &Stmt{stickyErr: err}
	}
	return stmt
}
source: func (m *MockPathio) WriteReader(path string, input io.ReadSeeker) error {
	m.ctrl.T.Helper()
	ret := m.ctrl.Call(m, "WriteReader", path, input)
	ret0, _ := ret[0].(error)
	return ret0
}
source: func SortedKeys(m interface{}) []string {
	list := Keys(m)
	sort.Strings(list)

	return list
}
source: func BinaryID(v checked.Bytes) ID {
	v.IncRef()
	return &id{data: v}
}
source: func (c *Context) Source(filepath string, loader func(string) ([]byte, error)) error {
	if loader == nil {
		loader = ioutil.ReadFile
	}
	data, err := loader(filepath)
	if err != nil {
		return err
	}
	c.Lock()
	defer c.Unlock()
	c.scripts = append(c.scripts, data)
	return nil
}
source: func (c cacheObjects) GetBucketInfo(ctx context.Context, bucket string) (bucketInfo BucketInfo, err error) {
	getBucketInfoFn := c.GetBucketInfoFn
	bucketInfo, err = getBucketInfoFn(ctx, bucket)
	if backendDownError(err) {
		for _, cache := range c.cache.cfs {
			// ignore disk-caches that might be missing/offline
			if cache == nil {
				continue
			}
			if bucketInfo, err = cache.GetBucketInfo(ctx, bucket); err == nil {
				return
			}
		}
	}
	return
}
source: func (loc *Location) Filesize() int64 {
	f, _ := os.Open(loc.Path())
	defer f.Close()

	fi, err := f.Stat()
	if err != nil {
		return 0
	}

	return fi.Size()
}
source: func NewSfTeamGrantAccessType(Description string) *SfTeamGrantAccessType {
	s := new(SfTeamGrantAccessType)
	s.Description = Description
	return s
}
source: func upgradeStatusHistoryAndOps(mb modelBackend, upgradeStatus UpgradeStatus, now time.Time) ([]txn.Op, error) {
	var modelStatus status.Status
	var msg string
	switch upgradeStatus {
	case UpgradeComplete:
		modelStatus = status.Available
		msg = fmt.Sprintf("upgraded on %q", now.UTC().Format(time.RFC3339))
	case UpgradeRunning:
		modelStatus = status.Busy
		msg = fmt.Sprintf("upgrade in progress since %q", now.UTC().Format(time.RFC3339))
	case UpgradeAborted:
		modelStatus = status.Available
		msg = fmt.Sprintf("last upgrade aborted on %q", now.UTC().Format(time.RFC3339))
	default:
		return []txn.Op{}, nil
	}
	doc := statusDoc{
		Status:     modelStatus,
		StatusInfo: msg,
		Updated:    now.UnixNano(),
	}
	ops, err := statusSetOps(mb.db(), doc, modelGlobalKey)
	if err != nil {
		return nil, errors.Trace(err)
	}
	probablyUpdateStatusHistory(mb.db(), modelGlobalKey, doc)
	return ops, nil
}
source: func createJujuRegistryKeyCmds(series string) []string {
	aclCmds := setACLs(osenv.JujuRegistryKey, registryEntry, series)
	regCmds := []string{

		// Create a registry key for storing juju related information
		fmt.Sprintf(`New-Item -Path '%s'`, osenv.JujuRegistryKey),

		// Create a JUJU_DEV_FEATURE_FLAGS entry which may or may not be empty.
		fmt.Sprintf(`New-ItemProperty -Path '%s' -Name '%s'`,
			osenv.JujuRegistryKey,
			osenv.JujuFeatureFlagEnvKey),
		fmt.Sprintf(`Set-ItemProperty -Path '%s' -Name '%s' -Value '%s'`,
			osenv.JujuRegistryKey,
			osenv.JujuFeatureFlagEnvKey,
			featureflag.AsEnvironmentValue()),
	}
	return append(regCmds[:1], append(aclCmds, regCmds[1:]...)...)
}
source: func (t *Tracer) StartSpanFromContext(ctx context.Context, operationName string) (tracing.Span, context.Context) {
	var opts []opentracing.StartSpanOption
	if parent := opentracing.SpanFromContext(ctx); parent != nil {
		opts = append(opts, opentracing.ChildOf(parent.Context()))
	}
	span := t.tracer.StartSpan(operationName, opts...)
	return span, opentracing.ContextWithSpan(ctx, span)
}
source: func (r FutureGetWorkSubmit) Receive() (bool, error) {
	res, err := receiveFuture(r)
	if err != nil {
		return false, err
	}

	// Unmarshal result as a boolean.
	var accepted bool
	err = json.Unmarshal(res, &accepted)
	if err != nil {
		return false, err
	}

	return accepted, nil
}
source: func (r Dns_Domain_Registration) SetAuthenticationCode(authenticationCode *string) (resp bool, err error) {
	params := []interface{}{
		authenticationCode,
	}
	err = r.Session.DoRequest("SoftLayer_Dns_Domain_Registration", "setAuthenticationCode", params, &r.Options, &resp)
	return
}
source: func (remote *RemoteDebugger) CloseTab(tab *Tab) error {
	resp, err := responseError(remote.http.Get("/json/close/"+tab.ID, nil, nil))
	resp.Close()
	return err
}
source: func FromMinioClientListBucketResult(bucket string, result minio.ListBucketResult) ListObjectsInfo {
	objects := make([]ObjectInfo, len(result.Contents))

	for i, oi := range result.Contents {
		objects[i] = FromMinioClientObjectInfo(bucket, oi)
	}

	prefixes := make([]string, len(result.CommonPrefixes))
	for i, p := range result.CommonPrefixes {
		prefixes[i] = p.Prefix
	}

	return ListObjectsInfo{
		IsTruncated: result.IsTruncated,
		NextMarker:  result.NextMarker,
		Prefixes:    prefixes,
		Objects:     objects,
	}
}
source: func (s *NeutrinoClient) notificationHandler() {
	hash, height, err := s.GetBestBlock()
	if err != nil {
		log.Errorf("Failed to get best block from chain service: %s",
			err)
		s.Stop()
		s.wg.Done()
		return
	}

	bs := &waddrmgr.BlockStamp{Hash: *hash, Height: height}

	// TODO: Rather than leaving this as an unbounded queue for all types of
	// notifications, try dropping ones where a later enqueued notification
	// can fully invalidate one waiting to be processed.  For example,
	// blockconnected notifications for greater block heights can remove the
	// need to process earlier blockconnected notifications still waiting
	// here.

	var notifications []interface{}
	enqueue := s.enqueueNotification
	var dequeue chan interface{}
	var next interface{}
out:
	for {
		s.clientMtx.Lock()
		rescanErr := s.rescanErr
		s.clientMtx.Unlock()
		select {
		case n, ok := <-enqueue:
			if !ok {
				// If no notifications are queued for handling,
				// the queue is finished.
				if len(notifications) == 0 {
					break out
				}
				// nil channel so no more reads can occur.
				enqueue = nil
				continue
			}
			if len(notifications) == 0 {
				next = n
				dequeue = s.dequeueNotification
			}
			notifications = append(notifications, n)

		case dequeue <- next:
			if n, ok := next.(BlockConnected); ok {
				bs = &waddrmgr.BlockStamp{
					Height: n.Height,
					Hash:   n.Hash,
				}
			}

			notifications[0] = nil
			notifications = notifications[1:]
			if len(notifications) != 0 {
				next = notifications[0]
			} else {
				// If no more notifications can be enqueued, the
				// queue is finished.
				if enqueue == nil {
					break out
				}
				dequeue = nil
			}

		case err := <-rescanErr:
			if err != nil {
				log.Errorf("Neutrino rescan ended with error: %s", err)
			}

		case s.currentBlock <- bs:

		case <-s.quit:
			break out
		}
	}

	s.Stop()
	close(s.dequeueNotification)
	s.wg.Done()
}
source: func (s *HistoryEvent) SetExecutionAbortedEventDetails(v *ExecutionAbortedEventDetails) *HistoryEvent {
	s.ExecutionAbortedEventDetails = v
	return s
}
source: func (tp Platform) Expander() Expander {
	return Expander{
		"os":       tp.OS,
		"arch":     tp.Arch,
		"platform": tp.String(),
	}
}
source: func (d Datastore) Download(ctx context.Context, path string, param *soap.Download) (io.ReadCloser, int64, error) {
	u, p, err := d.downloadTicket(ctx, path, param)
	if err != nil {
		return nil, 0, err
	}
	return d.Client().Download(ctx, u, p)
}
source: func FromMap(m map[string]string) Labels {
	l := make(Labels, 0, len(m))
	for k, v := range m {
		l = append(l, Label{Name: k, Value: v})
	}
	sort.Sort(l)

	return l
}
source: func (uvm *UtilityVM) RemovePlan9(share *Plan9Share) (err error) {
	op := "uvm::RemovePlan9"
	log := logrus.WithFields(logrus.Fields{
		logfields.UVMID: uvm.id,
		"name":          share.name,
		"uvm-path":      share.uvmPath,
	})
	log.Debug(op + " - Begin Operation")
	defer func() {
		if err != nil {
			log.Data[logrus.ErrorKey] = err
			log.Error(op + " - End Operation - Error")
		} else {
			log.Debug(op + " - End Operation - Success")
		}
	}()

	if uvm.operatingSystem != "linux" {
		return errNotSupported
	}

	modification := &hcsschema.ModifySettingRequest{
		RequestType: requesttype.Remove,
		Settings: hcsschema.Plan9Share{
			Name:       share.name,
			AccessName: share.name,
			Port:       plan9Port,
		},
		ResourcePath: fmt.Sprintf("VirtualMachine/Devices/Plan9/Shares"),
		GuestRequest: guestrequest.GuestRequest{
			ResourceType: guestrequest.ResourceTypeMappedDirectory,
			RequestType:  requesttype.Remove,
			Settings: guestrequest.LCOWMappedDirectory{
				MountPath: share.uvmPath,
				ShareName: share.name,
				Port:      plan9Port,
			},
		},
	}
	if err := uvm.Modify(modification); err != nil {
		return fmt.Errorf("failed to remove plan9 share %s from %s: %+v: %s", share.name, uvm.id, modification, err)
	}
	return nil
}
source: func NewMutable(body Mutable) (ID, error) {
	id := ID{idVersion, body.Type()}
	_, err := rand.Read(id[2:])
	if err != nil {
		return ID{}, err
	}
	return id, nil
}
source: func (mc *metricContext) Observe(err error) error {
	apiMetrics.latency.WithLabelValues(mc.attributes...).Observe(
		time.Since(mc.start).Seconds())
	if err != nil {
		apiMetrics.errors.WithLabelValues(mc.attributes...).Inc()
	}

	return err
}
source: func NewInlineKeyboardButtonData(text, data string) InlineKeyboardButton {
	return InlineKeyboardButton{
		Text:         text,
		CallbackData: &data,
	}
}
source: func (rw *GCS) Delete(id string) error {
	ctx := context.Background()
	obj := rw.bucket.Object(rw.Prefixed.Name(id))
	return obj.Delete(ctx)
}
source: func (o *DeleteNodesMacaddressDhcpWhitelistParams) WithMacaddress(macaddress string) *DeleteNodesMacaddressDhcpWhitelistParams {
	o.Macaddress = macaddress
	return o
}
source: func (s *Record) SetApproximateArrivalTimestamp(v time.Time) *Record {
	s.ApproximateArrivalTimestamp = &v
	return s
}
source: func (g *Graph) GetBytes(path string) ([]byte, error) {

	if len(path) == 0 {
		return g.Bytes(), nil
	}

	i := g.Get(path)
	if i == nil {
		return nil, errors.New("not found")
	}
	if i.Len() == 0 {
		return nil, errors.New("Get() design error: not subnodes")
	}
	return _bytes(i.Out[0].This), nil
}
source: func (c *Channel) Send(message string, recursive bool) {
	textMessage := TextMessage{
		Message: message,
	}
	if recursive {
		textMessage.Trees = []*Channel{c}
	} else {
		textMessage.Channels = []*Channel{c}
	}
	c.client.Send(&textMessage)
}
source: func (c *Catalog) Datacenters() ([]string, error) {
	r := c.c.newRequest("GET", "/v1/catalog/datacenters")
	_, resp, err := requireOK(c.c.doRequest(r))
	if err != nil {
		return nil, err
	}
	defer resp.Body.Close()

	var out []string
	if err := decodeBody(resp, &out); err != nil {
		return nil, err
	}
	return out, nil
}
source: func (r *RenameFamilies) Transform(mfs []*dto.MetricFamily) []*dto.MetricFamily {
	renamed := mfs[:0]
	for _, mf := range mfs {
		if to, ok := r.FromTo[mf.GetName()]; ok {
			mf.Name = &to
		}
		renamed = append(renamed, mf)

	}
	sort.Sort(familySorter(renamed))
	return renamed
}
source: func (e ShortcutExpander) KindFor(resource unversioned.GroupVersionResource) (unversioned.GroupVersionKind, error) {
	resource = expandResourceShortcut(resource)
	return e.RESTMapper.KindFor(resource)
}
source: func (k KeybaseServiceMeasured) ResolveImplicitTeamByID(
	ctx context.Context, teamID keybase1.TeamID) (name string, err error) {
	k.resolveImplicitTeamByIDTimer.Time(func() {
		name, err = k.delegate.ResolveImplicitTeamByID(ctx, teamID)
	})
	return name, err
}
source: func Copy(ie interface{}) error {
	if ie == nil {
		return nil
	}
	switch e := ie.(type) {
	case *Error:
		return e.Copy()
	case error:
		val := reflect.ValueOf(e)
		if types.AnySettableValue(val) {
			return types.Copy(val).Interface().(error)
		}
		return errors.New(e.Error())
	default:
		panic("type not supported")
	}
}
source: func (s *GetObjectInput) SetResponseContentType(v string) *GetObjectInput {
	s.ResponseContentType = &v
	return s
}
source: func (tr *TaskRunner) Restore() error {
	ls, ts, err := tr.stateDB.GetTaskRunnerState(tr.allocID, tr.taskName)
	if err != nil {
		return err
	}

	if ls != nil {
		ls.Canonicalize()
		tr.localState = ls
	}

	if ts != nil {
		ts.Canonicalize()
		tr.state = ts
	}

	// If a TaskHandle was persisted, ensure it is valid or destroy it.
	if taskHandle := tr.localState.TaskHandle; taskHandle != nil {
		//TODO if RecoverTask returned the DriverNetwork we wouldn't
		//     have to persist it at all!
		tr.restoreHandle(taskHandle, tr.localState.DriverNetwork)
	}
	return nil
}
source: func (w *Window) Resize(width, height int) {
	w.Configure(xproto.ConfigWindowWidth|xproto.ConfigWindowHeight, 0, 0,
		width, height, 0, 0)
}
source: func (d *DB) Clear() error {
	return d.db.Update(func(tx *bolt.Tx) error {
		return tx.DeleteBucket(tableURLs)
	})
}
source: func (c *Component) ExchangeAppKeyForToken(appID, key string) (string, error) {
	issuerID := keys.KeyIssuer(key)
	if issuerID == "" {
		// Take the first configured auth server
		for k := range c.Config.AuthServers {
			issuerID = k
			break
		}
		key = fmt.Sprintf("%s.%s", issuerID, key)
	}
	issuer, ok := c.Config.AuthServers[issuerID]
	if !ok {
		return "", fmt.Errorf("Auth server \"%s\" not registered", issuerID)
	}

	token, err := getTokenFromCache(oauthCache, appID, key)
	if err != nil {
		return "", err
	}

	if token != nil {
		return token.AccessToken, nil
	}

	srv, _ := parseAuthServer(issuer)
	acc := account.New(srv.url)

	if srv.username != "" {
		acc = acc.WithAuth(auth.BasicAuth(srv.username, srv.password))
	} else {
		acc = acc.WithAuth(auth.AccessToken(c.AccessToken))
	}

	token, err = acc.ExchangeAppKeyForToken(appID, key)
	if err != nil {
		return "", err
	}

	saveTokenToCache(oauthCache, appID, key, token)

	return token.AccessToken, nil
}
source: func NewOutbox(cb *Chequebook, beneficiary common.Address) *Outbox {
	return &Outbox{cb, beneficiary}
}
source: func (s *Set) Intersection(other *Set) *Set {
	result := new(Set)
	if s == nil {
		return result
	}
	if other != nil {
		for _, v := range s.m {
			if other.Include(v) {
				result.Add(v)
			}
		}
	}

	return result
}
source: func (c oauthClient) File(fileID uint) (wl.File, error) {
	if fileID == 0 {
		return wl.File{}, errors.New("fileID must be > 0")
	}

	url := fmt.Sprintf(
		"%s/files/%d",
		c.apiURL,
		fileID,
	)

	req, err := c.newGetRequest(url)
	if err != nil {
		return wl.File{}, err
	}

	resp, err := c.do(req)
	if err != nil {
		return wl.File{}, err
	}

	if resp.StatusCode != http.StatusOK {
		return wl.File{}, fmt.Errorf("Unexpected response code %d - expected %d", resp.StatusCode, http.StatusOK)
	}

	task := wl.File{}
	err = json.NewDecoder(resp.Body).Decode(&task)
	if err != nil {
		return wl.File{}, err
	}
	return task, nil
}
source: func (e ErrorList) Error() string {
	var msg string

	for _, err := range e {
		msg += fmt.Sprintf("%s\n", err.Error())
	}

	return msg
}
source: func WithEnv(environmentVariables []string) SpecOpts {
	return func(_ context.Context, _ Client, _ *containers.Container, s *Spec) error {
		if len(environmentVariables) > 0 {
			setProcess(s)
			s.Process.Env = replaceOrAppendEnvValues(s.Process.Env, environmentVariables)
		}
		return nil
	}
}
source: func (d *Diff) DeepCopy() *Diff {
	copy, err := copystructure.Config{Lock: true}.Copy(d)
	if err != nil {
		panic(err)
	}

	return copy.(*Diff)
}
source: func NewDeployer(kubeClient kubernetes.Interface, images imageclientv1.Interface, out, errOut io.Writer,
	until string) *Deployer {
	return &Deployer{
		out:    out,
		errOut: errOut,
		until:  until,
		getDeployment: func(namespace, name string) (*corev1.ReplicationController, error) {
			return kubeClient.CoreV1().ReplicationControllers(namespace).Get(name, metav1.GetOptions{})
		},
		getDeployments: func(namespace, configName string) (*corev1.ReplicationControllerList, error) {
			return kubeClient.CoreV1().ReplicationControllers(namespace).List(metav1.ListOptions{LabelSelector: appsutil.ConfigSelector(configName).
				String()})
		},
		scaler: appsutil.NewReplicationControllerScaler(kubeClient),
		strategyFor: func(config *appsv1.DeploymentConfig) (strategy.DeploymentStrategy, error) {
			switch config.Spec.Strategy.Type {
			case appsv1.DeploymentStrategyTypeRecreate:
				return recreate.NewRecreateDeploymentStrategy(kubeClient, images.ImageV1(),
					&kv1core.EventSinkImpl{Interface: kubeClient.CoreV1().Events("")}, out, errOut, until), nil
			case appsv1.DeploymentStrategyTypeRolling:
				recreateDeploymentStrategy := recreate.NewRecreateDeploymentStrategy(kubeClient, images.ImageV1(),
					&kv1core.EventSinkImpl{Interface: kubeClient.CoreV1().Events("")}, out, errOut, until)
				return rolling.NewRollingDeploymentStrategy(config.Namespace, kubeClient, images.ImageV1(),
					recreateDeploymentStrategy, out, errOut, until), nil
			default:
				return nil, fmt.Errorf("unsupported strategy type: %s", config.Spec.Strategy.Type)
			}
		},
	}
}
source: func (oci8Connector *OCI8Connector) Connect(ctx context.Context) (driver.Conn, error) {
	oci8Conn := &OCI8Conn{
		logger: oci8Connector.Logger,
	}
	if oci8Conn.logger == nil {
		oci8Conn.logger = log.New(ioutil.Discard, "", 0)
	}

	return oci8Conn, nil
}
source: func (m *Module) LoadConfig(path string) error {
	_, err := os.Stat(path)
	if err != nil {
		if os.IsNotExist(err) {
			m.Byte = []byte(`{}`)
			return nil
		}
		return err
	}
	m.Byte, err = ioutil.ReadFile(path)
	if err != nil {
		return err
	}
	return nil
}
source: func BuildLogicalPlan(ctx sessionctx.Context, node ast.Node, is infoschema.InfoSchema) (Plan, error) {
	ctx.GetSessionVars().PlanID = 0
	ctx.GetSessionVars().PlanColumnID = 0
	builder := &PlanBuilder{
		ctx:       ctx,
		is:        is,
		colMapper: make(map[*ast.ColumnNameExpr]int),
	}
	p, err := builder.Build(node)
	if err != nil {
		return nil, err
	}
	return p, nil
}
source: func Convert_v1beta1_IngressRuleValue_To_networking_IngressRuleValue(in *v1beta1.IngressRuleValue, out *networking.IngressRuleValue, s conversion.Scope) error {
	return autoConvert_v1beta1_IngressRuleValue_To_networking_IngressRuleValue(in, out, s)
}
source: func (db *DirBlock) ClearIndirectPtrSize(i int) {
	if !db.IsInd {
		panic("ClearIndirectPtrSize called on a direct directory block")
	}
	db.IPtrs[i].EncodedSize = 0
}
source: func (agent *ActionAgent) updateState(ctx context.Context, newTablet *topodatapb.Tablet, reason string) {
	oldTablet := agent.Tablet()
	if oldTablet == nil {
		oldTablet = &topodatapb.Tablet{}
	}
	log.Infof("Running tablet callback because: %v", reason)
	agent.changeCallback(ctx, oldTablet, newTablet)
	agent.setTablet(newTablet)
	event.Dispatch(&events.StateChange{
		OldTablet: *oldTablet,
		NewTablet: *newTablet,
		Reason:    reason,
	})
}
source: func Entry(logLevel lager.LogLevel, options ...option) logEntry {
	entry := logEntry(lager.LogFormat{
		LogLevel: logLevel,
		Data:     lager.Data{},
	})

	for _, option := range options {
		option(&entry)
	}

	return entry
}
source: func newStringSet(keys ...string) stringSet {
	ss := make(stringSet, len(keys))
	ss.add(keys...)
	return ss
}
source: func Scope(xs XStater, scope string, scopes ...string) XStater {
	if c, ok := xs.(Scoper); ok {
		return c.Scope(scope, scopes...)
	}
	return nop
}
source: func (m *MockFacade) StartUnitCompletion(arg0 string) error {
	ret := m.ctrl.Call(m, "StartUnitCompletion", arg0)
	ret0, _ := ret[0].(error)
	return ret0
}
source: func (attacher *rbdAttacher) MountDevice(spec *volume.Spec, devicePath string, deviceMountPath string) error {
	klog.V(4).Infof("rbd: mouting device %s to %s", devicePath, deviceMountPath)
	notMnt, err := attacher.mounter.IsLikelyNotMountPoint(deviceMountPath)
	if err != nil {
		if os.IsNotExist(err) {
			if err := os.MkdirAll(deviceMountPath, 0750); err != nil {
				return err
			}
			notMnt = true
		} else {
			return err
		}
	}
	if !notMnt {
		return nil
	}
	fstype, err := getVolumeSourceFSType(spec)
	if err != nil {
		return err
	}
	ro, err := getVolumeSourceReadOnly(spec)
	if err != nil {
		return err
	}
	options := []string{}
	if ro {
		options = append(options, "ro")
	}
	mountOptions := volutil.MountOptionFromSpec(spec, options...)
	err = attacher.mounter.FormatAndMount(devicePath, deviceMountPath, fstype, mountOptions)
	if err != nil {
		os.Remove(deviceMountPath)
		return fmt.Errorf("rbd: failed to mount device %s at %s (fstype: %s), error %v", devicePath, deviceMountPath, fstype, err)
	}
	klog.V(3).Infof("rbd: successfully mount device %s at %s (fstype: %s)", devicePath, deviceMountPath, fstype)
	return nil
}
source: func (ctx *Context) AcceptCharset(preferred ...string) string {
	return negotiator.New(ctx.Req.Header).Charset(preferred...)
}
source: func (r Billing_Item_Virtual_DedicatedHost) GetCancellationRequests() (resp []datatypes.Billing_Item_Cancellation_Request, err error) {
	err = r.Session.DoRequest("SoftLayer_Billing_Item_Virtual_DedicatedHost", "getCancellationRequests", nil, &r.Options, &resp)
	return
}
source: func (c *ResourceController) Register(ctx *app.RegisterResourceContext) error {

	if !token.IsServiceAccount(ctx) {
		log.Error(ctx, map[string]interface{}{}, "Unable to register resource. Not a service account")
		return jsonapi.JSONErrorResponse(ctx, errors.NewUnauthorizedError("not a service account"))
	}

	var managerIdentityID *uuid.UUID
	if ctx.Payload.IdentityID != nil {
		identityID, err := uuid.FromString(*ctx.Payload.IdentityID)
		if err != nil {
			return jsonapi.JSONErrorResponse(ctx, errors.NewBadParameterError("identityID", "incorrect identity ID"))
		}
		managerIdentityID = &identityID
	}

	svc := c.app.ResourceService()
	res, err := svc.Register(ctx, ctx.Payload.Type, ctx.Payload.ResourceID, ctx.Payload.ParentResourceID, managerIdentityID)
	if err != nil {
		log.Error(ctx, map[string]interface{}{
			"resource_type": ctx.Payload.Type,
		}, "unable to register resource")
		return jsonapi.JSONErrorResponse(ctx, err)
	}

	return ctx.Created(&app.RegisterResourceResponse{ResourceID: &res.ResourceID})
}
source: func updatePolicyKey(pa *PolicyUpdateArgs, add bool) {
	// The map needs not to be transparently initialized here even if
	// it's not present for some reason. Triggering map recreation with
	// OpenOrCreate when some map attribute had changed would be much worse.
	policyMap, err := policymap.Open(pa.path)
	if err != nil {
		Fatalf("Cannot open policymap %q : %s", pa.path, err)
	}

	for _, proto := range pa.protocols {
		u8p := u8proto.U8proto(proto)
		entry := fmt.Sprintf("%d %d/%s", pa.label, pa.port, u8p.String())
		if add {
			var proxyPort uint16
			if err := policyMap.Allow(pa.label, pa.port, u8p, pa.trafficDirection, proxyPort); err != nil {
				Fatalf("Cannot add policy key '%s': %s\n", entry, err)
			}
		} else {
			if err := policyMap.Delete(pa.label, pa.port, u8p, pa.trafficDirection); err != nil {
				Fatalf("Cannot delete policy key '%s': %s\n", entry, err)
			}
		}
	}
}
source: func getOVAFileInfo(ovafile string, filename string) (int64, string, error) {
	of, err := NewOVAFile(ovafile)
	if err != nil {
		return 0, "", err
	}

	hdr, err := of.Find(filename)
	if err != nil {
		return 0, "", err
	}

	hash := md5.New()
	_, err = io.Copy(hash, of)
	if err != nil {
		return 0, "", err
	}
	md5String := hex.EncodeToString(hash.Sum(nil)[:16])

	return hdr.Size, md5String, nil
}
source: func (options) SynchronousInitialization(b bool) Option {
	return func(o *options) {
		o.synchronousInitialization = b
	}
}
source: func Interface(usv UnionSassValue) interface{} {
	switch {
	case IsNil(usv):
		return nil
	case IsBool(usv):
		return Bool(usv)
	case IsString(usv):
		return String(usv)
	case IsColor(usv):
		return Color(usv)
	case IsNumber(usv):
		return Number(usv)
	case IsList(usv):
		fallthrough
		//return List(usv)
	case IsMap(usv):
		fallthrough
		//return Map(usv)
	default:
		return nil
	}
	panic("call of interface not supported on type")
}
source: func (self *domAttr) verifyConstraint(b bool) {
	s := self.getData()
	if b {
		if s == "" {
			panic(fmt.Sprintf("expected to have constraint on %s but did not!", self.id))
		}
		if s != CONSTRAINT_MARKER {
			panic(fmt.Sprintf("expected to find constraint marker but found %s", s))
		}
	} else {
		if s != "" {
			panic(fmt.Sprintf("did not expect to have constraint on %s but found one: %s", self.id, s))
		}
	}
}
source: func (md *RootMetadata) KeyGenerationsToUpdate() (kbfsmd.KeyGen, kbfsmd.KeyGen) {
	return md.bareMd.KeyGenerationsToUpdate()
}
source: func DurationString(d time.Duration) string {
	sign := 1
	if d < 0 {
		sign = -1
		d = -d
	}
	ns := int(d % 1e9)
	d /= 1e9
	sec := int(d % 60)
	d /= 60
	min := int(d % 60)
	hour := int(d/60) * sign
	if ns == 0 {
		return fmt.Sprintf("%d:%02d:%02d", hour, min, sec)
	}
	return fmt.Sprintf("%d:%02d:%02d.%09d", hour, min, sec, ns)
}
source: func initSeparatorMap() map[string]bool {
	m := map[string]bool{}

	for _, s := range nsPriorityList {
		m[s] = false
	}
	return m
}
source: func ProtosBelow(dirs []string) ([]string, error) {
	protos := []string{}
	for _, dir := range dirs {
		err := filepath.Walk(dir, func(path string, info os.FileInfo, err error) error {
			if err != nil {
				return err
			}
			if !info.IsDir() && strings.HasSuffix(info.Name(), ".proto") {
				protos = append(protos, path)
			}
			return nil
		})
		if err != nil {
			return nil, err
		}
	}
	return protos, nil
}
source: func doPost(client ClientInterface, path, blogName string, params url.Values) (*PostRef, error) {
	if blogName == "" {
		return nil, errors.New("No blog name provided")
	}
	response, err := client.PostWithParams(blogPath(path, blogName), params)
	if err != nil {
		return nil, err
	}
	post := struct {
		Response struct {
			Id uint64 `json:"id"`
		} `json:"response"`
	}{}
	if err = json.Unmarshal(response.body, &post); err == nil {
		ref := NewPostRefById(client, post.Response.Id)
		ref.BlogName = blogName
		return ref, nil
	}
	return nil, err
}  4%|▍         | 224/5000 [00:00<00:04, 1121.44it/s]
source: func (*StdClock) NowNanoseconds() int64 {
	sec, nsec, _ := now()
	return sec*1e9 + int64(nsec)
}
source: func (c *Client) VendorData() (string, error) {
	var vendordata string
	err := c.doGet("vendor-data", func(r io.Reader) error {
		vendordataraw, err := ioutil.ReadAll(r)
		vendordata = string(vendordataraw)
		return err
	})
	return vendordata, err
}
source: func (w *ResponseWriter) finish() {

	// Determine if we should Base64 encode the output
	contentType := w.response.Headers["Content-Type"]

	// Only encode text content types without base64 encoding
	w.response.IsBase64Encoded = !textContentTypesRegexp.MatchString(contentType)

	if w.response.IsBase64Encoded {
		w.response.Body = base64.StdEncoding.EncodeToString(w.output.Bytes())
	} else {
		w.response.Body = w.output.String()
	}
}
source: func trimUDPResponse(req, resp *dns.Msg, udpAnswerLimit int) (trimmed bool) {
	numAnswers := len(resp.Answer)
	hasExtra := len(resp.Extra) > 0
	maxSize := defaultMaxUDPSize

	// Update to the maximum edns size
	if edns := req.IsEdns0(); edns != nil {
		if size := edns.UDPSize(); size > uint16(maxSize) {
			maxSize = int(size)
		}
	}

	// We avoid some function calls and allocations by only handling the
	// extra data when necessary.
	var index map[string]dns.RR
	if hasExtra {
		index = make(map[string]dns.RR, len(resp.Extra))
		indexRRs(resp.Extra, index)
	}

	// This cuts UDP responses to a useful but limited number of responses.
	maxAnswers := lib.MinInt(maxUDPAnswerLimit, udpAnswerLimit)
	compress := resp.Compress
	if maxSize == defaultMaxUDPSize && numAnswers > maxAnswers {
		// We disable computation of Len ONLY for non-eDNS request (512 bytes)
		resp.Compress = false
		resp.Answer = resp.Answer[:maxAnswers]
		if hasExtra {
			syncExtra(index, resp)
		}
	}

	// This enforces the given limit on the number bytes. The default is 512 as
	// per the RFC, but EDNS0 allows for the user to specify larger sizes. Note
	// that we temporarily switch to uncompressed so that we limit to a response
	// that will not exceed 512 bytes uncompressed, which is more conservative and
	// will allow our responses to be compliant even if some downstream server
	// uncompresses them.
	// Even when size is too big for one single record, try to send it anyway
	// (useful for 512 bytes messages)
	for len(resp.Answer) > 1 && resp.Len() > maxSize {
		// More than 100 bytes, find with a binary search
		if resp.Len()-maxSize > 100 {
			bestIndex := dnsBinaryTruncate(resp, maxSize, index, hasExtra)
			resp.Answer = resp.Answer[:bestIndex]
		} else {
			resp.Answer = resp.Answer[:len(resp.Answer)-1]
		}
		if hasExtra {
			syncExtra(index, resp)
		}
	}
	// For 512 non-eDNS responses, while we compute size non-compressed,
	// we send result compressed
	resp.Compress = compress

	return len(resp.Answer) < numAnswers
}
source: func (s *DescribeHsmConfigurationsOutput) SetHsmConfigurations(v []*HsmConfiguration) *DescribeHsmConfigurationsOutput {
	s.HsmConfigurations = v
	return s
}
source: func (b *buffer) wordBackward() (err error) {
	for start := false; ; {
		start, err = b.backward()
		if start == true || err != nil || b.data[b.pos-1] == 32 {
			return
		}
	}
}
source: func statusFromErr(err error) git.FilterProcessStatus {
	if err != nil && err != io.EOF {
		return git.StatusError
	}
	return git.StatusSuccess
}
source: func (tpm *TPM) ExtendPCR(pcr int, data []byte, eventtype int, event []byte) error {
	var outlen C.UINT32
	var pcrval *C.BYTE
	var eventstruct C.TSS_PCR_EVENT
	var err error

	shasum := sha1.Sum(data)

	if event != nil {
		var pcrdata *C.BYTE
		var pcrdatalen C.UINT32

		eventstruct.versionInfo.bMajor = 1
		eventstruct.versionInfo.bMinor = 2
		eventstruct.versionInfo.bRevMajor = 1
		eventstruct.versionInfo.bRevMinor = 0
		eventstruct.ulPcrIndex = C.UINT32(pcr)
		eventstruct.rgbPcrValue = (*C.BYTE)(&shasum[0])
		eventstruct.eventType = C.TSS_EVENTTYPE(eventtype)
		eventstruct.ulEventLength = C.UINT32(len(event))
		eventstruct.rgbEvent = (*C.BYTE)(&event[0])

		if data == nil || len(data) == 0 {
			pcrdata = nil
			pcrdatalen = C.UINT32(0)
		} else {
			pcrdata = (*C.BYTE)(&data[0])
			pcrdatalen = C.UINT32(len(data))
		}

		err = tspiError(C.Tspi_TPM_PcrExtend(tpm.handle, C.UINT32(pcr), pcrdatalen, pcrdata, &eventstruct, &outlen, &pcrval))
	} else {
		err = tspiError(C.Tspi_TPM_PcrExtend(tpm.handle, C.UINT32(pcr), C.UINT32(len(shasum)), (*C.BYTE)(&shasum[0]), nil, &outlen, &pcrval))
	}

	C.Tspi_Context_FreeMemory(tpm.context, pcrval)

	return err
}
source: func (rt *Router) Put(path string, handler http.Handler) {
	rt.Handle(http.MethodPut, path, handler)
}
source: func processShard(c context.Context, cfg *Config, timestamp time.Time, shard uint64, loop bool) error {

	logging.Fields{
		"shard": shard,
	}.Infof(c, "Processing tumble shard.")

	q := processShardQuery(c, cfg, shard)
	if q == nil {
		logging.Warningf(c, "dead shard, quitting")
		return nil
	}

	// Calculate our end itme. If we're not looping or we have a <= 0 duration,
	// we will perform a single loop.
	var endTime time.Time
	if cfg.ProcessLoopDuration > 0 {
		endTime = clock.Now(c).Add(time.Duration(cfg.ProcessLoopDuration))
		logging.Debugf(c, "Process loop is configured to exit after [%s] at %s",
			cfg.ProcessLoopDuration.String(), endTime)
	}

	// Lock around the shard that we are trying to modify.
	//
	// Since memcache is namespaced, we don't need to include the namespace in our
	// lock name.
	task := makeProcessTask(timestamp, endTime, shard, loop)
	lockKey := fmt.Sprintf("%s.%d.lock", baseName, shard)
	clientID := fmt.Sprintf("%d_%d_%s", timestamp.Unix(), shard, info.RequestID(c))

	err := memlock.TryWithLock(c, lockKey, clientID, func(c context.Context) error {
		return task.process(c, cfg, q)
	})
	if err == memlock.ErrFailedToLock {
		logging.Infof(c, "Couldn't obtain lock (giving up): %s", err)
		return nil
	}
	return err
}
source: func (s *StoragePacker) DeleteItem(_ context.Context, itemID string) error {

	if itemID == "" {
		return fmt.Errorf("empty item ID")
	}

	// Get the bucket key
	bucketKey := s.BucketKey(itemID)

	// Prepend the view prefix
	bucketPath := s.BucketPath(bucketKey)

	// Read from underlying view
	storageEntry, err := s.view.Get(context.Background(), bucketPath)
	if err != nil {
		return errwrap.Wrapf("failed to read packed storage value: {{err}}", err)
	}
	if storageEntry == nil {
		return nil
	}

	uncompressedData, notCompressed, err := compressutil.Decompress(storageEntry.Value)
	if err != nil {
		return errwrap.Wrapf("failed to decompress packed storage value: {{err}}", err)
	}
	if notCompressed {
		uncompressedData = storageEntry.Value
	}

	var bucket Bucket
	err = proto.Unmarshal(uncompressedData, &bucket)
	if err != nil {
		return errwrap.Wrapf("failed decoding packed storage entry: {{err}}", err)
	}

	// Look for a matching storage entry
	foundIdx := -1
	for itemIdx, item := range bucket.Items {
		if item.ID == itemID {
			foundIdx = itemIdx
			break
		}
	}

	// If there is a match, remove it from the collection and persist the
	// resulting collection
	if foundIdx != -1 {
		bucket.Items = append(bucket.Items[:foundIdx], bucket.Items[foundIdx+1:]...)

		// Persist bucket entry only if there is an update
		err = s.PutBucket(&bucket)
		if err != nil {
			return err
		}
	}

	return nil
}
source: func treat(s string, color string) string {
	if len(s) > 2 && s[:2] == "\x1b[" {
		return s
	}
	return color + s + ANSIReset
}
source: func ReverseUint64(v uint64) (x uint64) {
	x |= uint64(ReverseLUT[byte(v>>0)]) << 56
	x |= uint64(ReverseLUT[byte(v>>8)]) << 48
	x |= uint64(ReverseLUT[byte(v>>16)]) << 40
	x |= uint64(ReverseLUT[byte(v>>24)]) << 32
	x |= uint64(ReverseLUT[byte(v>>32)]) << 24
	x |= uint64(ReverseLUT[byte(v>>40)]) << 16
	x |= uint64(ReverseLUT[byte(v>>48)]) << 8
	x |= uint64(ReverseLUT[byte(v>>56)]) << 0
	return x
}
source: func (s *Servo) SetAngle(angle int) error {
	us := util.Map(int64(angle), 0, 180, int64(s.Minus), int64(s.Maxus))

	glog.V(1).Infof("servo: given angle %v calculated %v us", angle, us)

	return s.PWM.SetMicroseconds(int(us))
}
source: func (s *Session) SetDataEncoded(encodedData []byte) error {
	if len(encodedData) == 0 {
		return nil
	}
	var data map[string]interface{}
	err := json.Unmarshal(encodedData, &data)
	if err != nil {
		return err
	}
	return s.SetData(data)
}
source: func (t *Table) Rows() []Row {
	t.mu.RLock()
	defer t.mu.RUnlock()
	return t.Data
}
source: func ext(path string) string {
	var ext string
	for i := len(path) - 1; i >= 0 && !os.IsPathSeparator(path[i]); i-- {
		if path[i] == '.' {
			ext = path[i:]
			if index := strings.LastIndex(ext, "."); index > 0 {
				ext = ext[index:]
			}
		}
	}
	if ext != "" {
		return ext[1:]
	}
	return ""
}
source: func (c *ContainerServer) GetStorageContainer(container string) (*cstorage.Container, error) {
	ociCtr, err := c.LookupContainer(container)
	if err != nil {
		return nil, err
	}
	return c.store.Container(ociCtr.ID())
}
source: func (w *Worker) TaskInfo(taskId string) (task TaskInfo, err error) {
	out := TaskInfo{}
	err = w.tasks(taskId).Req("GET", nil, &out)
	return out, err
}
source: func (g *Generator) SetSolarisCappedCPUNcpus(ncpus string) {
	g.initConfigSolarisCappedCPU()
	g.Config.Solaris.CappedCPU.Ncpus = ncpus
}
source: func TimestampFromSigned(s *Signed) (*SignedTimestamp, error) {
	ts := Timestamp{}
	if err := defaultSerializer.Unmarshal(*s.Signed, &ts); err != nil {
		return nil, err
	}
	if err := IsValidTimestampStructure(ts); err != nil {
		return nil, err
	}
	sigs := make([]Signature, len(s.Signatures))
	copy(sigs, s.Signatures)
	return &SignedTimestamp{
		Signatures: sigs,
		Signed:     ts,
	}, nil
}
source: func (r *multiReaderSeeker) Seek(offset int64, whence int) (int64, error) {
	if offset != 0 || whence != 0 {
		return 0, errors.New("cannot only seek to the start of multipart reader")
	}
	for _, reader := range r.readers {
		if _, err := reader.Seek(0, 0); err != nil {
			return 0, errors.Trace(err)
		}
	}
	r.index = 0
	return 0, nil
}
source: func (set Mysql56GTIDSet) String() string {
	buf := &bytes.Buffer{}

	for i, sid := range set.SIDs() {
		if i != 0 {
			buf.WriteByte(',')
		}
		buf.WriteString(sid.String())

		for _, interval := range set[sid] {
			buf.WriteByte(':')
			buf.WriteString(strconv.FormatInt(interval.start, 10))

			if interval.end != interval.start {
				buf.WriteByte('-')
				buf.WriteString(strconv.FormatInt(interval.end, 10))
			}
		}
	}

	return buf.String()
}
source: func New(c dropbox.Config) Client {
	ctx := apiImpl(dropbox.NewContext(c))
	return &ctx
}
source: func parseBinaryOnlyBody(mailMsg *mail.Message, mimeMsg *MIMEBody) error {
	// Determine mediatype
	ctype := mailMsg.Header.Get("Content-Type")
	mediatype, mparams, err := mime.ParseMediaType(ctype)
	if err != nil {
		mediatype = "attachment"
	}

	// Build the MIME part representing most of this message
	p := NewMIMEPart(nil, mediatype)
	content, err := decodeSection(mailMsg.Header.Get("Content-Transfer-Encoding"), mailMsg.Body)
	if err != nil {
		return err
	}
	p.SetContent(content)
	p.SetHeader(make(textproto.MIMEHeader, 4))

	// Determine and set headers for: content disposition, filename and character set
	disposition, dparams, err := mime.ParseMediaType(mailMsg.Header.Get("Content-Disposition"))
	if err == nil {
		// Disposition is optional
		p.SetDisposition(disposition)
		p.SetFileName(DecodeHeader(dparams["filename"]))
	}
	if p.FileName() == "" && mparams["name"] != "" {
		p.SetFileName(DecodeHeader(mparams["name"]))
	}
	if p.FileName() == "" && mparams["file"] != "" {
		p.SetFileName(DecodeHeader(mparams["file"]))
	}
	if p.Charset() == "" {
		p.SetCharset(mparams["charset"])
	}

	p.Header().Set("Content-Type", mailMsg.Header.Get("Content-Type"))
	p.Header().Set("Content-Disposition", mailMsg.Header.Get("Content-Disposition"))

	// Add our part to the appropriate section of MIMEBody
	mimeMsg.Root = NewMIMEPart(nil, mediatype)

	if disposition == "inline" {
		mimeMsg.Inlines = append(mimeMsg.Inlines, p)
	} else {
		mimeMsg.Attachments = append(mimeMsg.Attachments, p)
	}

	return nil
}
source: func checkDirectoryNotExists(path string, errorMessage string) {
	_, err := os.Stat(path)
	if err == nil {
		handleError(errors.New(errorMessage))
	}
}
source: func (k *KeybaseServiceBase) ResolveImplicitTeamByID(
	ctx context.Context, teamID keybase1.TeamID) (name string, err error) {
	arg := keybase1.ResolveImplicitTeamArg{
		Id: teamID,
	}

	res, err := k.identifyClient.ResolveImplicitTeam(ctx, arg)
	if err != nil {
		return "", err
	}
	return res.Name, nil
}
source: func NewDeleteRowsEvent(f BinlogFormat, s *FakeBinlogStream, tableID uint64, rows Rows) BinlogEvent {
	return newRowsEvent(f, s, eDeleteRowsEventV2, tableID, rows)
}
source: func (_class HostCPUClass) GetAllRecords(sessionID SessionRef) (_retval map[HostCPURef]HostCPURecord, _err error) {
	_method := "host_cpu.get_all_records"
	_sessionIDArg, _err := convertSessionRefToXen(fmt.Sprintf("%s(%s)", _method, "session_id"), sessionID)
	if _err != nil {
		return
	}
	_result, _err := _class.client.APICall(_method, _sessionIDArg)
	if _err != nil {
		return
	}
	_retval, _err = convertHostCPURefToHostCPURecordMapToGo(_method + " -> ", _result.Value)
	return
}
source: func (q *sessionQueue) increaseBackoff() {
	q.retryBackoff *= 2
	if q.retryBackoff > q.cfg.MaxBackoff {
		q.retryBackoff = q.cfg.MaxBackoff
	}
}
source: func StellarProof(m MetaContext, me *User, walletAddress stellar1.AccountID,
	signingKey GenericKey) (*ProofMetadataRes, error) {
	if me == nil {
		return nil, fmt.Errorf("missing user object for proof")
	}
	walletPubKey, err := MakeNaclSigningKeyPairFromStellarAccountID(walletAddress)
	if err != nil {
		return nil, err
	}
	walletKID := walletPubKey.GetKID()

	ret, err := ProofMetadata{
		Me:                  me,
		LinkType:            LinkTypeWalletStellar,
		SigningKey:          signingKey,
		SigVersion:          KeybaseSignatureV2,
		IgnoreIfUnsupported: SigIgnoreIfUnsupported(true),
	}.ToJSON2(m)
	if err != nil {
		return nil, err
	}

	walletSection := jsonw.NewDictionary()
	walletSection.SetKey("address", jsonw.NewString(walletAddress.String()))
	walletSection.SetKey("network", jsonw.NewString(string(WalletNetworkStellar)))

	// Inner links can be hidden. To prevent an attacker from figuring out the
	// contents from the hash of the inner link, add 18 random bytes.
	entropy, err := LinkEntropy()
	if err != nil {
		return nil, err
	}
	walletSection.SetKey("entropy", jsonw.NewString(entropy))

	walletKeySection := jsonw.NewDictionary()
	walletKeySection.SetKey("kid", jsonw.NewString(walletKID.String()))
	// The caller is responsible for overwriting reverse_sig after signing.
	walletKeySection.SetKey("reverse_sig", jsonw.NewNil())

	body := ret.J.AtKey("body")
	body.SetKey("wallet", walletSection)
	body.SetKey("wallet_key", walletKeySection)

	return ret, nil
}
source: func (s *Server) CancelInvoice(ctx context.Context,
	in *CancelInvoiceMsg) (*CancelInvoiceResp, error) {

	paymentHash, err := lntypes.MakeHash(in.PaymentHash)
	if err != nil {
		return nil, err
	}

	err = s.cfg.InvoiceRegistry.CancelInvoice(paymentHash)
	if err != nil {
		return nil, err
	}

	log.Infof("Canceled invoice %v", paymentHash)

	return &CancelInvoiceResp{}, nil
}
source: func (service *IYOPhonenumberValidationService) RequestValidation(request *http.Request, username string, phonenumber user.Phonenumber, confirmationurl string, langKey string) (key string, err error) {
	valMngr := validation.NewManager(request)
	info, err := valMngr.NewPhonenumberValidationInformation(username, phonenumber)
	if err != nil {
		return
	}
	err = valMngr.SavePhonenumberValidationInformation(info)
	if err != nil {
		return
	}

	translationValues := tools.TranslationValues{
		"smsconfirmation": struct {
			Code string
			Link string
		}{
			Code: info.SMSCode,
			Link: fmt.Sprintf("%s?c=%s&k=%s&l=%s", confirmationurl, info.SMSCode, url.QueryEscape(info.Key), langKey),
		},
	}

	translations, err := tools.ParseTranslations(langKey, translationValues)
	if err != nil {
		log.Error("Failed to parse translations: ", err)
		return
	}

	go service.SMSService.Send(phonenumber.Phonenumber, translations["smsconfirmation"])
	key = info.Key
	return
}
source: func NewErrParamRequired(field string) *ErrParamRequired {
	return &ErrParamRequired{
		errInvalidParam{
			code:  ParamRequiredErrCode,
			field: field,
			msg:   fmt.Sprintf("missing required field"),
		},
	}
}
source: func (s *SyncState) maybePruneModule(addr addrs.ModuleInstance) {
	if addr.IsRoot() {
		// We never prune the root.
		return
	}

	ms := s.state.Module(addr)
	if ms == nil {
		return
	}

	if ms.empty() {
		log.Printf("[TRACE] states.SyncState: pruning %s because it is empty", addr)
		s.state.RemoveModule(addr)
	}
}
source: func (i *Index) GetStatus(taskID int) (res TaskStatusRes, err error) {
	path := i.path("/task/%d", taskID)
	err = i.transport.Request(&res, http.MethodGet, path, nil, call.Read)
	return
}
source: func (t *DryRunTarget) HasChanges() bool {
	return len(t.changes)+len(t.deletions) != 0
}
source: func NewGetGreeting(ctx *middleware.Context, handler GetGreetingHandler) *GetGreeting {
	return &GetGreeting{Context: ctx, Handler: handler}
}
source: func (h *Client) CampaignName(campaignName string) *Client {
	h.campaignName = campaignName
	h.campaignNameSet = true
	return h
}
source: func (service *Service) EvaluateHealthCheckTemplate(gs GetService, fc FindChildService, instanceID int) (err error) {
	log.WithFields(log.Fields{
		"servicename": service.Name,
		"serviceid": service.ID,
		"instanceid": instanceID,
	}).Debug("Evaluating HealthCheck scripts")

	for key, healthcheck := range service.HealthChecks {
		err, result := service.evaluateTemplate(gs, fc, instanceID, healthcheck.Script)
		if err != nil {
			return err
		}
		if result != "" {
			healthcheck.Script = result
			service.HealthChecks[key] = healthcheck
		}
	}
	return
}
source: func (s *PhoneNumberCapabilities) SetInboundSMS(v bool) *PhoneNumberCapabilities {
	s.InboundSMS = &v
	return s
}
source: func NewShowcaseTrashedType(Description string) *ShowcaseTrashedType {
	s := new(ShowcaseTrashedType)
	s.Description = Description
	return s
}
source: func (s *AssessmentRunNotification) SetSnsPublishStatusCode(v string) *AssessmentRunNotification {
	s.SnsPublishStatusCode = &v
	return s
}
source: func IdentifiedBy(jti string) Validator {
	return func(token *JSONToken) error {
		if token.Jti != jti {
			return errors.Wrapf(ErrTokenValidationError, `token was expected to be identified by "%s"`, jti)
		}
		return nil
	}
}
source: func (*Namespace) Or(arg0 reflect.Value, args ...reflect.Value) reflect.Value {
	if truth(arg0) {
		return arg0
	}
	for i := range args {
		arg0 = args[i]
		if truth(arg0) {
			break
		}
	}
	return arg0
}
source: func ParseReleaseVersion(bytes []byte) (int, error) {
	var hook BuildHookResponse
	if err := json.Unmarshal(bytes, &hook); err != nil {
		return 0, fmt.Errorf("invalid application json configuration")
	}

	if hook.Release == nil {
		return 0, fmt.Errorf("invalid application version")
	}

	return hook.Release["version"], nil
}
source: func (aa Acceptors) Accept(from interface{}) bool {
	for _, a := range aa {
		if !a.Accept(from) {
			return false
		}
	}
	return true
}
source: func (m *Manager) Create(ctx context.Context, factoryName string, args []string) (string, error) {
	m.mu.Lock()
	defer m.mu.Unlock()

	// Find the factory.
	factory, ok := factories[factoryName]
	if !ok {
		return "", fmt.Errorf("no factory named %v is registered", factoryName)
	}

	// Create the initial workflowpb.Workflow object.
	w := &workflowpb.Workflow{
		Uuid:        gouuid.NewUUID().String(),
		CreateTime:  time.Now().UnixNano(),
		FactoryName: factoryName,
		State:       workflowpb.WorkflowState_NotStarted,
	}

	// Let the factory parse the parameters and initialize the
	// object.
	if err := factory.Init(m, w, args); err != nil {
		return "", err
	}
	rw, err := m.instantiateWorkflow(w)
	if err != nil {
		return "", err
	}

	// Now save the workflow in the topo server.
	rw.wi, err = m.ts.CreateWorkflow(ctx, w)
	if err != nil {
		return "", err
	}

	// And we're done.
	log.Infof("Created workflow %s (%s, %s)", w.Uuid, factoryName, w.Name)
	return w.Uuid, nil
}
source: func (in *SuspendTemplate) DeepCopy() *SuspendTemplate {
	if in == nil {
		return nil
	}
	out := new(SuspendTemplate)
	in.DeepCopyInto(out)
	return out
}
source: func newFormatXLV3(numSets int, setLen int) *formatXLV3 {
	format := &formatXLV3{}
	format.Version = formatMetaVersionV1
	format.Format = formatBackendXL
	format.ID = mustGetUUID()
	format.XL.Version = formatXLVersionV3
	format.XL.DistributionAlgo = formatXLVersionV2DistributionAlgo
	format.XL.Sets = make([][]string, numSets)

	for i := 0; i < numSets; i++ {
		format.XL.Sets[i] = make([]string, setLen)
		for j := 0; j < setLen; j++ {
			format.XL.Sets[i][j] = mustGetUUID()
		}
	}
	return format
}
source: func (m *Mutate) DeserializeCellBlocks(pm proto.Message, b []byte) (uint32, error) {
	resp := pm.(*pb.MutateResponse)
	if resp.Result == nil {
		// TODO: is this possible?
		return 0, nil
	}
	cells, read, err := deserializeCellBlocks(b, uint32(resp.Result.GetAssociatedCellCount()))
	if err != nil {
		return 0, err
	}
	resp.Result.Cell = append(resp.Result.Cell, cells...)
	return read, nil
}
source: func NewCmdCreateRoleBinding(f cmdutil.Factory, ioStreams genericclioptions.IOStreams) *cobra.Command {
	o := &RoleBindingOpts{
		CreateSubcommandOptions: NewCreateSubcommandOptions(ioStreams),
	}

	cmd := &cobra.Command{
		Use:                   "rolebinding NAME --clusterrole=NAME|--role=NAME [--user=username] [--group=groupname] [--serviceaccount=namespace:serviceaccountname] [--dry-run]",
		DisableFlagsInUseLine: true,
		Short:                 i18n.T("Create a RoleBinding for a particular Role or ClusterRole"),
		Long:                  roleBindingLong,
		Example:               roleBindingExample,
		Run: func(cmd *cobra.Command, args []string) {
			cmdutil.CheckErr(o.Complete(f, cmd, args))
			cmdutil.CheckErr(o.Run())
		},
	}

	o.CreateSubcommandOptions.PrintFlags.AddFlags(cmd)

	cmdutil.AddApplyAnnotationFlags(cmd)
	cmdutil.AddValidateFlags(cmd)
	cmdutil.AddGeneratorFlags(cmd, generateversioned.RoleBindingV1GeneratorName)
	cmd.Flags().String("clusterrole", "", i18n.T("ClusterRole this RoleBinding should reference"))
	cmd.Flags().String("role", "", i18n.T("Role this RoleBinding should reference"))
	cmd.Flags().StringArray("user", []string{}, "Usernames to bind to the role")
	cmd.Flags().StringArray("group", []string{}, "Groups to bind to the role")
	cmd.Flags().StringArray("serviceaccount", []string{}, "Service accounts to bind to the role, in the format <namespace>:<name>")
	return cmd
}
source: func (whisper *Whisper) DeleteKeyPair(key string) bool {
	whisper.keyMu.Lock()
	defer whisper.keyMu.Unlock()

	if whisper.privateKeys[key] != nil {
		delete(whisper.privateKeys, key)
		return true
	}
	return false
}
source: func getFileSystemBlockSize(fileIo FileIoProcessor) (int, error) {
	var stat syscall.Stat_t
	err := syscall.Stat(fileIo.Name(), &stat)
	return int(stat.Blksize), err
}
source: func NewStatusSetter(st state.EntityFinder, getCanModify GetAuthFunc) *StatusSetter {
	return &StatusSetter{
		st:           st,
		getCanModify: getCanModify,
	}
}
source: func (s *Session) Clear() {
	s.Lock()
	defer s.Unlock()

	s.uid = ""
	s.data = map[string]interface{}{}
	s.updateEncodedData()
}
source: func postUnassignedReviewRequest(
	config *moduleConfig,
	owner string,
	repo string,
	commit *git.Commit,
	opts map[string]interface{},
) (*github.Issue, []*git.Commit, error) {

	// Search for an existing issue.
	task := fmt.Sprintf("Search for an existing review issue for commit %v", commit.SHA)
	log.Run(task)

	client := ghutil.NewClient(config.Token)
	issue, err := ghissues.FindReviewIssueForCommit(client, owner, repo, commit.SHA)
	if err != nil {
		return nil, nil, errs.NewError(task, err)
	}

	// Return an error in case the issue for the given commit already exists.
	if issue != nil {
		issueNum := *issue.Number
		err = fmt.Errorf("existing review issue found for commit %v: %v", commit.SHA, issueNum)
		return nil, nil, errs.NewError("Make sure the review issue can be created", err)
	}

	// Create a new unassigned review request.
	issue, err = createUnassignedReviewRequest(config, owner, repo, commit, opts)
	if err != nil {
		return nil, nil, err
	}
	return issue, []*git.Commit{commit}, nil
}
source: func (r *Lexer) fetchNull() {
	r.pos += 4
	if r.pos > len(r.Data) ||
		r.Data[r.pos-3] != 'u' ||
		r.Data[r.pos-2] != 'l' ||
		r.Data[r.pos-1] != 'l' ||
		(r.pos != len(r.Data) && !isTokenEnd(r.Data[r.pos])) {

		r.pos -= 4
		r.errSyntax()
	}
}
source: func (n *Node) Leave(ctx context.Context, req *api.LeaveRequest) (*api.LeaveResponse, error) {
	if req.Node == nil {
		return nil, status.Errorf(codes.InvalidArgument, "no node information provided")
	}

	nodeInfo, err := ca.RemoteNode(ctx)
	if err != nil {
		return nil, err
	}

	ctx, cancel := n.WithContext(ctx)
	defer cancel()

	fields := logrus.Fields{
		"node.id": nodeInfo.NodeID,
		"method":  "(*Node).Leave",
		"raft_id": fmt.Sprintf("%x", n.Config.ID),
	}
	if nodeInfo.ForwardedBy != nil {
		fields["forwarder.id"] = nodeInfo.ForwardedBy.NodeID
	}
	log.G(ctx).WithFields(fields).Debug("")

	if err := n.removeMember(ctx, req.Node.RaftID); err != nil {
		return nil, err
	}

	return &api.LeaveResponse{}, nil
}
source: func (b *BigIP) Upload(r io.Reader, size int64, path ...string) (*Upload, error) {
	client := &http.Client{
		Transport: b.Transport,
		Timeout:   b.ConfigOptions.APICallTimeout,
	}
	options := &APIRequest{
		Method:      "post",
		URL:         b.iControlPath(path),
		ContentType: "application/octet-stream",
	}
	var format string
	if strings.Contains(options.URL, "mgmt/") {
		format = "%s/%s"
	} else {
		format = "%s/mgmt/%s"
	}
	url := fmt.Sprintf(format, b.Host, options.URL)
	chunkSize := 512 * 1024
	var start, end int64
	for {
		// Read next chunk
		chunk := make([]byte, chunkSize)
		n, err := r.Read(chunk)
		if err != nil {
			return nil, err
		}
		end = start + int64(n)
		// Resize buffer size to number of bytes read
		if n < chunkSize {
			chunk = chunk[:n]
		}
		body := bytes.NewReader(chunk)
		req, _ := http.NewRequest(strings.ToUpper(options.Method), url, body)
		if b.Token != "" {
			req.Header.Set("X-F5-Auth-Token", b.Token)
		} else {
			req.SetBasicAuth(b.User, b.Password)
		}
		req.Header.Add("Content-Type", options.ContentType)
		req.Header.Add("Content-Range", fmt.Sprintf("%d-%d/%d", start, end-1, size))
		// Try to upload chunk
		res, err := client.Do(req)
		if err != nil {
			return nil, err
		}
		data, _ := ioutil.ReadAll(res.Body)
		if res.StatusCode >= 400 {
			if res.Header.Get("Content-Type") == "application/json" {
				return nil, b.checkError(data)
			}

			return nil, fmt.Errorf("HTTP %d :: %s", res.StatusCode, string(data[:]))
		}
		defer res.Body.Close()
		var upload Upload
		err = json.Unmarshal(data, &upload)
		if err != nil {
			return nil, err
		}
		start = end
		if start >= size {
			// Final chunk was uploaded
			return &upload, err
		}
	}
}
source: func (c *CacheStorage) RequestCacheNamesWithParams(v *CacheStorageRequestCacheNamesParams) ([]*CacheStorageCache, error) {
	resp, err := gcdmessage.SendCustomReturn(c.target, c.target.GetSendCh(), &gcdmessage.ParamRequest{Id: c.target.GetId(), Method: "CacheStorage.requestCacheNames", Params: v})
	if err != nil {
		return nil, err
	}

	var chromeData struct {
		Result struct {
			Caches []*CacheStorageCache
		}
	}

	if resp == nil {
		return nil, &gcdmessage.ChromeEmptyResponseErr{}
	}

	// test if error first
	cerr := &gcdmessage.ChromeErrorResponse{}
	json.Unmarshal(resp.Data, cerr)
	if cerr != nil && cerr.Error != nil {
		return nil, &gcdmessage.ChromeRequestErr{Resp: cerr}
	}

	if err := json.Unmarshal(resp.Data, &chromeData); err != nil {
		return nil, err
	}

	return chromeData.Result.Caches, nil
}
source: func hasToFQDN(rule *api.Rule) bool {
	for _, egressRule := range rule.Egress {
		if len(egressRule.ToFQDNs) > 0 {
			return true
		}
	}

	return false
}
source: func (m *Mirror) SaveAddress(addr string) error {
	configPath := m.Repo.GitConfigPath()
	cfg, err := ini.Load(configPath)
	if err != nil {
		return fmt.Errorf("Load: %v", err)
	}

	cfg.Section(`remote "origin"`).Key("url").SetValue(escapeMirrorCredentials(addr))
	return cfg.SaveToIndent(configPath, "\t")
}
source: func ConstProvider(key, algorithm string) Provider {
	return &constProvider{
		key: &TokenKey{
			Algorithm: algorithm,
			Key:       key,
		},
	}
}
source: func (m *Model) AllActions() ([]Action, error) {
	actionLogger.Tracef("AllActions()")
	actions, closer := m.st.db().GetCollection(actionsC)
	defer closer()

	results := []Action{}
	docs := []actionDoc{}
	err := actions.Find(nil).All(&docs)
	if err != nil {
		return nil, errors.Annotatef(err, "cannot get all actions")
	}
	for _, doc := range docs {
		results = append(results, newAction(m.st, doc))
	}
	return results, nil
}
source: func DeleteAttachmentsByIssue(issueId int64, remove bool) (int, error) {
	attachments, err := GetAttachmentsByIssueID(issueId)
	if err != nil {
		return 0, err
	}

	return DeleteAttachments(attachments, remove)
}
source: func FindFloat64(s []float64, cb func(s float64) bool) (float64, bool) {
	for _, i := range s {
		result := cb(i)

		if result {
			return i, true
		}
	}

	return 0.0, false
}
source: func (e *Enforcer) Enforce(rvals ...interface{}) bool {
	return enforce(e.Enforcer, e.defaultRole, e.claimsEnforcerFunc, rvals...)
}
source: func (c *Clique) Prepare(chain consensus.ChainReader, header *types.Header) error {
	// If the block isn't a checkpoint, cast a random vote (good enough for now)
	header.Coinbase = common.Address{}
	header.Nonce = types.BlockNonce{}

	number := header.Number.Uint64()
	// Assemble the voting snapshot to check which votes make sense
	snap, err := c.snapshot(chain, number-1, header.ParentHash, nil)
	if err != nil {
		return err
	}
	if number%c.config.Epoch != 0 {
		c.lock.RLock()

		// Gather all the proposals that make sense voting on
		addresses := make([]common.Address, 0, len(c.proposals))
		for address, authorize := range c.proposals {
			if snap.validVote(address, authorize) {
				addresses = append(addresses, address)
			}
		}
		// If there's pending proposals, cast a vote on them
		if len(addresses) > 0 {
			header.Coinbase = addresses[rand.Intn(len(addresses))]
			if c.proposals[header.Coinbase] {
				copy(header.Nonce[:], nonceAuthVote)
			} else {
				copy(header.Nonce[:], nonceDropVote)
			}
		}
		c.lock.RUnlock()
	}
	// Set the correct difficulty
	header.Difficulty = CalcDifficulty(snap, c.signer)

	// Ensure the extra data has all it's components
	if len(header.Extra) < extraVanity {
		header.Extra = append(header.Extra, bytes.Repeat([]byte{0x00}, extraVanity-len(header.Extra))...)
	}
	header.Extra = header.Extra[:extraVanity]

	if number%c.config.Epoch == 0 {
		for _, signer := range snap.signers() {
			header.Extra = append(header.Extra, signer[:]...)
		}
	}
	header.Extra = append(header.Extra, make([]byte, extraSeal)...)

	// Mix digest is reserved for now, set to empty
	header.MixDigest = common.Hash{}

	// Ensure the timestamp has the correct delay
	parent := chain.GetHeader(header.ParentHash, number-1)
	if parent == nil {
		return consensus.ErrUnknownAncestor
	}
	header.Time = parent.Time + c.config.Period
	if header.Time < uint64(time.Now().Unix()) {
		header.Time = uint64(time.Now().Unix())
	}
	return nil
}
source: func (p *Pod) MarshalJSON() ([]byte, error) {
	env := make(map[string]interface{})
	secrets := make(map[string]TmpSecret)

	if p.Env != nil {
		for k, v := range p.Env {
			env[string(k)] = string(v)
		}
	}
	if p.Secrets != nil {
		for k, v := range p.Secrets {
			// Only add it to the root level pod environment if it's used
			// Otherwise it's likely in one of the container environments
			if v.EnvVar != "" {
				env[v.EnvVar] = TmpEnvSecret{Secret: k}
			}
			secrets[k] = TmpSecret{v.Source}
		}
	}
	aux := &struct {
		*PodAlias
		Env     map[string]interface{} `json:"environment,omitempty"`
		Secrets map[string]TmpSecret   `json:"secrets,omitempty"`
	}{PodAlias: (*PodAlias)(p), Env: env, Secrets: secrets}

	return json.Marshal(aux)
}
source: func (fp *FileProvider) SessionInit(maxlifetime int64, savePath string) error {
	fp.maxlifetime = maxlifetime
	fp.savePath = savePath
	return nil
}
source: func (s *customResourceDefinitionLister) List(selector labels.Selector) (ret []*apiextensions.CustomResourceDefinition, err error) {
	err = cache.ListAll(s.indexer, selector, func(m interface{}) {
		ret = append(ret, m.(*apiextensions.CustomResourceDefinition))
	})
	return ret, err
}
source: func FromString(in string) (*Signature, error) {
	var res Signature = Signature{}
	var key string
	var value string

	for _, m := range signatureRegex.FindAllStringSubmatch(in, -1) {
		key = m[1]
		value = m[2]

		if key == "keyId" {
			res.KeyID = value
		} else if key == "algorithm" {
			alg, err := algorithmFromString(value)
			if err != nil {
				return nil, err
			}
			res.Algorithm = alg
		} else if key == "headers" {
			res.Headers = headerListFromString(value)
		} else if key == "signature" {
			res.Signature = value
		} else {
			return nil, errors.New(fmt.Sprintf("Unexpected key in signature '%s'", key))
		}
	}

	if len(res.Signature) == 0 {
		return nil, errors.New("Missing signature")
	}

	if len(res.KeyID) == 0 {
		return nil, errors.New("Missing keyId")
	}

	if res.Algorithm == nil {
		return nil, errors.New("Missing algorithm")
	}

	return &res, nil
}
source: func (s *LoggingConfiguration) SetLogDestinationConfigs(v []*string) *LoggingConfiguration {
	s.LogDestinationConfigs = v
	return s
}
source: func TotalOutFromMsgTx(msgTx *wire.MsgTx) dcrutil.Amount {
	var amtOut int64
	for _, v := range msgTx.TxOut {
		amtOut += v.Value
	}
	return dcrutil.Amount(amtOut)
}
source: func (u *FakeVolumeUtil) AddNewDirEntries(mountDir string, dirFiles map[string][]*FakeDirEntry) {
	for dir, files := range dirFiles {
		mountedPath := filepath.Join(mountDir, dir)
		curFiles := u.directoryFiles[mountedPath]
		if curFiles == nil {
			curFiles = []*FakeDirEntry{}
		}
		glog.Infof("Adding to directory %q: files %v\n", dir, files)
		u.directoryFiles[mountedPath] = append(curFiles, files...)
	}
}
source: func (ep *TabletPlan) AddStats(queryCount int64, duration, mysqlTime time.Duration, rowCount, errorCount int64) {
	ep.mu.Lock()
	ep.QueryCount += queryCount
	ep.Time += duration
	ep.MysqlTime += mysqlTime
	ep.RowCount += rowCount
	ep.ErrorCount += errorCount
	ep.mu.Unlock()
}
source: func New() *Adler32 {
	return &Adler32{
		a:       1,
		b:       0,
		n:       0,
		window:  make([]byte, 0, rollinghash.DefaultWindowCap),
		oldest:  0,
		vanilla: vanilla.New(),
	}
}
source: func WithCheckpointTask(ctx context.Context, client *Client, c *containers.Container, index *imagespec.Index, copts *options.CheckpointOptions) error {
	any, err := typeurl.MarshalAny(copts)
	if err != nil {
		return nil
	}
	task, err := client.TaskService().Checkpoint(ctx, &tasks.CheckpointTaskRequest{
		ContainerID: c.ID,
		Options:     any,
	})
	if err != nil {
		return err
	}
	for _, d := range task.Descriptors {
		platformSpec := platforms.DefaultSpec()
		index.Manifests = append(index.Manifests, imagespec.Descriptor{
			MediaType:   d.MediaType,
			Size:        d.Size_,
			Digest:      d.Digest,
			Platform:    &platformSpec,
			Annotations: d.Annotations,
		})
	}
	// save copts
	data, err := any.Marshal()
	if err != nil {
		return err
	}
	r := bytes.NewReader(data)
	desc, err := writeContent(ctx, client.ContentStore(), images.MediaTypeContainerd1CheckpointOptions, c.ID+"-checkpoint-options", r)
	if err != nil {
		return err
	}
	desc.Platform = &imagespec.Platform{
		OS:           runtime.GOOS,
		Architecture: runtime.GOARCH,
	}
	index.Manifests = append(index.Manifests, desc)
	return nil
}
source: func (c *UIDCache) Add(uid types.UID) {
	c.mutex.Lock()
	defer c.mutex.Unlock()
	c.cache.Add(uid, nil)
}
source: func (co *Context) GetReductionIndicesSize(reduceTensorDesc *Reduction, aDesc *TensorDescriptor, cDesc *TensorDescriptor) (sizeInBytes uintptr, err error) {
	var sizeInBytesC C.size_t
	// call cudnnGetReductionIndicesSize
	err = result(C.cudnnGetReductionIndicesSize(co.internal, reduceTensorDesc.internal, aDesc.internal, cDesc.internal, &sizeInBytesC))
	sizeInBytes = uintptr(sizeInBytesC)
	return
}
source: func (this *Reader) Read(p []byte) (n int, err error) {
	// checks for when we have no data
	for this.writePos == 0 || this.readPos == this.writePos {
		// if we have an error / EOF, just return it
		if this.err != nil {
			return n, this.err
		}

		// else, fill our buffer
		this.fillBuffer()
	}

	// TODO: checks for when we have less data than len(p)

	// we should have an appropriate amount of data, convert it into the given buffer
	bytesRead, bytesWritten, err := this.converter.Convert(this.buffer[this.readPos:this.writePos], p)

	// adjust byte counters
	this.readPos += bytesRead
	n += bytesWritten

	// if we experienced an iconv error, check it
	if err != nil {
		// E2BIG errors can be ignored (we'll get them often) as long
		// as at least 1 byte was written. If we experienced an E2BIG
		// and no bytes were written then the buffer is too small for
		// even the next character
		if err != syscall.E2BIG || bytesWritten == 0 {
			// track anything else
			this.err = err
		}
	}

	// return our results
	return n, this.err
}
source: func New() *Source {
	return &Source{
		tablenamelist: make([]string, 0),
		raw:           make(map[string]string),
		tables:        make(map[string]*membtree.StaticDataSource),
	}
}
source: func (m *MockInterface) RbacV1alpha1() v1alpha10.RbacV1alpha1Interface {
	ret := m.ctrl.Call(m, "RbacV1alpha1")
	ret0, _ := ret[0].(v1alpha10.RbacV1alpha1Interface)
	return ret0
}
source: func (s *HandlebarsEngine) loadAssets() error {
	// register the global helpers
	if len(s.templateCache) == 0 && s.helpers != nil {
		raymond.RegisterHelpers(s.helpers)
	}

	virtualDirectory, virtualExtension := s.directory, s.extension
	assetFn, namesFn := s.assetFn, s.namesFn

	if len(virtualDirectory) > 0 {
		if virtualDirectory[0] == '.' { // first check for .wrong
			virtualDirectory = virtualDirectory[1:]
		}
		if virtualDirectory[0] == '/' || virtualDirectory[0] == os.PathSeparator { // second check for /something, (or ./something if we had dot on 0 it will be removed
			virtualDirectory = virtualDirectory[1:]
		}
	}
	var templateErr error

	names := namesFn()
	for _, path := range names {
		if !strings.HasPrefix(path, virtualDirectory) {
			continue
		}
		ext := filepath.Ext(path)
		if ext == virtualExtension {

			rel, err := filepath.Rel(virtualDirectory, path)
			if err != nil {
				templateErr = err
				return err
			}

			buf, err := assetFn(path)
			if err != nil {
				templateErr = err
				return err
			}
			contents := string(buf)
			name := filepath.ToSlash(rel)

			tmpl, err := raymond.Parse(contents)
			if err != nil {
				templateErr = err
				return err
			}
			s.templateCache[name] = tmpl

		}
	}
	return templateErr
}
source: func (c *Client) EstimateFee(numBlocks int64) (float64, error) {
	return c.EstimateFeeAsync(numBlocks).Receive()
}
source: func (m *CPUMiner) Start() {
	m.Lock()
	defer m.Unlock()

	// Nothing to do if the miner is already running or if running in
	// discrete mode (using GenerateNBlocks).
	if m.started || m.discreteMining {
		return
	}

	m.quit = make(chan struct{})
	m.speedMonitorQuit = make(chan struct{})
	m.wg.Add(2)
	go m.speedMonitor()
	go m.miningWorkerController()

	m.started = true
	log.Infof("CPU miner started")
}
source: func fixateScanBar(text string, width int) string {
	if len([]rune(text)) > width {
		// Trim text to fit within the screen
		trimSize := len([]rune(text)) - width + 3 //"..."
		if trimSize < len([]rune(text)) {
			text = "..." + text[trimSize:]
		}
	} else {
		text += strings.Repeat(" ", width-len([]rune(text)))
	}
	return text
}
source: func fcopy(src, dest string, info os.FileInfo) error {

	if err := os.MkdirAll(filepath.Dir(dest), os.ModePerm); err != nil {
		return err
	}

	f, err := os.Create(dest)
	if err != nil {
		return err
	}
	defer f.Close()

	if err = os.Chmod(f.Name(), info.Mode()); err != nil {
		return err
	}

	s, err := os.Open(src)
	if err != nil {
		return err
	}
	defer s.Close()

	_, err = io.Copy(f, s)
	return err
}
source: func (d *DataSource) GetByUsername(username string) (Model, bool) {
	return d.GetBy(func(u Model) bool {
		return u.Username == username
	})
}
source: func Convert_admissionregistration_RuleWithOperations_To_v1beta1_RuleWithOperations(in *admissionregistration.RuleWithOperations, out *v1beta1.RuleWithOperations, s conversion.Scope) error {
	return autoConvert_admissionregistration_RuleWithOperations_To_v1beta1_RuleWithOperations(in, out, s)
}
source: func (c *convergence) lrpInstanceCounts(logger lager.Logger, domainSet map[string]struct{}) {
	logger = logger.Session("lrp-instance-counts")

	rows, err := c.selectLRPInstanceCounts(logger, c.db)
	if err != nil {
		logger.Error("failed-query", err)
		return
	}

	for rows.Next() {
		var existingIndicesStr sql.NullString
		var actualInstances int

		schedulingInfo, err := c.fetchDesiredLRPSchedulingInfoAndMore(logger, rows, &actualInstances, &existingIndicesStr)
		if err != nil {
			continue
		}

		indices := []int{}
		existingIndices := make(map[int]struct{})
		if existingIndicesStr.String != "" {
			for _, indexStr := range strings.Split(existingIndicesStr.String, ",") {
				index, err := strconv.Atoi(indexStr)
				if err != nil {
					logger.Error("cannot-parse-index", err, lager.Data{
						"index":                indexStr,
						"existing-indices-str": existingIndicesStr,
					})
					return
				}
				existingIndices[index] = struct{}{}
			}
		}

		for i := 0; i < int(schedulingInfo.Instances); i++ {
			_, found := existingIndices[i]
			if found {
				continue
			}

			indices = append(indices, i)
			index := int32(i)
			c.missingLRPKeys = append(c.missingLRPKeys, &models.ActualLRPKeyWithSchedulingInfo{
				Key: &models.ActualLRPKey{
					ProcessGuid: schedulingInfo.ProcessGuid,
					Domain:      schedulingInfo.Domain,
					Index:       index,
				},
				SchedulingInfo: schedulingInfo,
			})
			logger.Info("creating-start-request",
				lager.Data{"reason": "missing-instance", "process_guid": schedulingInfo.ProcessGuid, "index": index})
		}

		for index := range existingIndices {
			if index < int(schedulingInfo.Instances) {
				continue
			}

			// only take destructive actions for fresh domains
			if _, ok := domainSet[schedulingInfo.Domain]; ok {
				c.keysToRetire = append(c.keysToRetire, &models.ActualLRPKey{
					ProcessGuid: schedulingInfo.ProcessGuid,
					Index:       int32(index),
					Domain:      schedulingInfo.Domain,
				})
			}
		}
	}

	if rows.Err() != nil {
		logger.Error("failed-getting-next-row", rows.Err())
	}
}  7%|▋         | 337/5000 [00:00<00:07, 621.98it/s] 
source: func (s *AssociationOverview) SetAssociationStatusAggregatedCount(v map[string]*int64) *AssociationOverview {
	s.AssociationStatusAggregatedCount = v
	return s
}
source: func (s *EventRiskType) SetRiskLevel(v string) *EventRiskType {
	s.RiskLevel = &v
	return s
}
source: func (p *V2) SetRetryInterval(retryInterval *time.Duration) {
	p.Lock()
	p.retryInterval = retryInterval
	p.Unlock()
}
source: func (s *ListApplicationsInput) SetExclusiveStartApplicationName(v string) *ListApplicationsInput {
	s.ExclusiveStartApplicationName = &v
	return s
}
source: func MustNewIngressRule(protocol string, from, to int, sourceCIDRs ...string) IngressRule {
	rule, err := NewIngressRule(protocol, from, to, sourceCIDRs...)
	if err != nil {
		panic(err)
	}
	return rule
}
source: func MakeHashFromStr(newHash string) (Hash, error) {
	// Return error if hash string is of incorrect length.
	if len(newHash) != HashSize*2 {
		return Hash{}, fmt.Errorf("invalid hash string length of %v, "+
			"want %v", len(newHash), HashSize*2)
	}

	hash, err := hex.DecodeString(newHash)
	if err != nil {
		return Hash{}, err
	}

	return MakeHash(hash)
}
source: func Tracef(e *logrus.Entry, format string, args ...interface{}) {
	level := logrus.Level(atomic.LoadUint32((*uint32)(&e.Logger.Level)))
	if level >= TraceLevel {
		e.Debugf(format, args...)
	}
}
source: func FindKubernetesVersionSpec(versions []KubernetesVersionSpec, version semver.Version) *KubernetesVersionSpec {
	for i := range versions {
		v := &versions[i]
		if v.Range != "" {
			versionRange, err := semver.ParseRange(v.Range)
			if err != nil {
				glog.Warningf("unable to parse range in channel version spec: %q", v.Range)
				continue
			}
			if !versionRange(version) {
				glog.V(8).Infof("version range %q does not apply to version %q; skipping", v.Range, version)
				continue
			}
		}
		return v
	}

	return nil
}
source: func (c *commandConn) kill() error {
	var werr error
	c.cmdMutex.Lock()
	if c.cmdExited {
		werr = c.cmdWaitErr
	} else {
		werr = killAndWait(c.cmd)
		c.cmdWaitErr = werr
		c.cmdExited = true
	}
	c.cmdMutex.Unlock()
	if werr == nil {
		return nil
	}
	wExitErr, ok := werr.(*exec.ExitError)
	if ok {
		if wExitErr.ProcessState.Exited() {
			return nil
		}
	}
	return errors.Wrapf(werr, "commandconn: failed to wait")
}
source: func methodNotAllowed(w http.ResponseWriter, r *http.Request) {
	w.WriteHeader(http.StatusMethodNotAllowed)
}
source: func (p *Packet) NewTCPPayload(newPayload string) error {

	if p.tcpLayer.Payload != nil {
		return errors.New("payload already exists")
	}

	p.tcpLayer.Payload = []byte(newPayload)

	return nil
}
source: func newShareClaim(cl *client.Client, target blob.Ref) (blob.Ref, error) {
	var claim blob.Ref
	signer, err := cl.ServerPublicKeyBlobRef()
	if err != nil {
		return claim, fmt.Errorf("could not get signer: %v", err)
	}
	shareSchema := schema.NewShareRef(schema.ShareHaveRef, true)
	shareSchema.SetShareTarget(target)
	unsignedClaim, err := shareSchema.SetSigner(signer).JSON()
	if err != nil {
		return claim, fmt.Errorf("could not create unsigned share claim: %v", err)
	}
	signedClaim, err := cl.Sign(context.TODO(), "", strings.NewReader("json="+unsignedClaim))
	if err != nil {
		return claim, fmt.Errorf("could not get signed share claim: %v", err)
	}
	sbr, err := cl.Upload(context.TODO(), client.NewUploadHandleFromString(string(signedClaim)))
	if err != nil {
		return claim, fmt.Errorf("could not upload share claim: %v", err)
	}
	return sbr.BlobRef, nil
}
source: func EscapeGlobString(gs string, options *Options) string {
	if options == nil {
		options = DefaultOptions
	}

	runesToEscapeMap := make(map[string]bool, len(expanders))
	for _, r := range expanders {
		runesToEscapeMap[string(r)] = true
	}

	scanner := bufio.NewScanner(strings.NewReader(gs))
	scanner.Split(separatorsScanner(expanders))
	buf := new(bytes.Buffer)
	for scanner.Scan() {
		part := scanner.Text()
		if runesToEscapeMap[part] {
			buf.WriteRune(Escaper)
		}
		buf.WriteString(part)
	}

	return buf.String()
}
source: func createCertsDir() *probe.Error {
	p, err := getCertsDir()
	if err != nil {
		return err.Trace()
	}
	if e := os.MkdirAll(p, 0700); e != nil {
		return probe.NewError(e)
	}
	return nil
}
source: func extractParams(p url.Values) Params {
	params := Params{}
	for k, l := range p {
		for _, v := range l {
			params[k] = v
		}
	}
	return params
}
source: func cmdRoutine(parsersPath, parserName, projectPath string, c chan *bytes.Buffer) {
	outBuf := new(bytes.Buffer)
	errBuf := new(bytes.Buffer)

	parserBin := filepath.Join(parsersPath, parserName, "parser")

	cmd := exec.Command(parserBin, projectPath)
	cmd.Stdout = outBuf
	cmd.Stderr = errBuf

	log.Debug("command: ", strings.Join(cmd.Args, " "))

	if err := cmd.Run(); err != nil {
		log.Debug("debug:", err)
		log.Fatal(fmt.Sprintf("failed to parse with the %s parser", parserName))
	}

	if errBuf.Len() > 0 {
		log.Info(fmt.Sprintf("parser %s errors:", parserName))
		log.Fail(errBuf.String())
	}

	if outBuf.Len() == 0 {
		log.Fatal(fmt.Sprintf("the %s parser did not produce any output", parserName))
	}

	c <- outBuf
}
source: func DeleteSecret(tx Tx, id string) error {
	return tx.delete(tableSecret, id)
}
source: func (a *CompositeAggregation) SubAggregation(name string, subAggregation Aggregation) *CompositeAggregation {
	a.subAggregations[name] = subAggregation
	return a
}
source: func parseRate(r *http.Response) Rate {
	var rate Rate
	if limit := r.Header.Get(headerRateLimit); limit != "" {
		rate.Limit, _ = strconv.Atoi(limit)
	}
	if remaining := r.Header.Get(headerRateRemaining); remaining != "" {
		rate.Remaining, _ = strconv.Atoi(remaining)
	}
	if reset := r.Header.Get(headerRateReset); reset != "" {
		if v, _ := strconv.ParseInt(reset, 10, 64); v != 0 {
			rate.Reset = Timestamp{time.Unix(v, 0)}
		}
	}
	return rate
}
source: func (s *Server) RegisterWallet(w *wallet.Wallet) {
	s.handlerMu.Lock()
	s.wallet = w
	s.handlerMu.Unlock()
}
source: func (c ConfigResourceResult) String() string {
	if c.Error.Code() != 0 {
		return fmt.Sprintf("ResourceResult(%s, %s, \"%v\")", c.Type, c.Name, c.Error)

	}
	return fmt.Sprintf("ResourceResult(%s, %s, %d config(s))", c.Type, c.Name, len(c.Config))
}
source: func randBytes(length int) (string, error) {
	// len("0123456789abcdefghijklmnopqrstuvwxyz") = 36 which doesn't evenly divide
	// the possible values of a byte: 256 mod 36 = 4. Discard any random bytes we
	// read that are >= 252 so the bytes we evenly divide the character set.
	const maxByteValue = 252

	var (
		b     byte
		err   error
		token = make([]byte, length)
	)

	reader := bufio.NewReaderSize(rand.Reader, length*2)
	for i := range token {
		for {
			if b, err = reader.ReadByte(); err != nil {
				return "", err
			}
			if b < maxByteValue {
				break
			}
		}

		token[i] = validBootstrapTokenChars[int(b)%len(validBootstrapTokenChars)]
	}

	return string(token), nil
}
source: func (c *Client) SendRawTransaction(tx *wire.MsgTx, allowHighFees bool) (*chainhash.Hash, error) {
	return c.SendRawTransactionAsync(tx, allowHighFees).Receive()
}
source: func (s *UnionSchema) GetType(v reflect.Value) int {
	if s.Types != nil {
		for i := range s.Types {
			if t := s.Types[i]; t.Validate(v) {
				return i
			}
		}
	}

	return -1
}
source: func NewResourceNotFoundf(cause error, context interface{}, format string, args ...interface{}) Error {
	if format == "" {
		format = fmt.Sprintf("Resource Not Found: %s", context)
	}
	return makeErrorf(ResourceNotFoundError, cause, format, args...)
}
source: func NewCmdImage(fullName string, f kcmdutil.Factory, streams genericclioptions.IOStreams) *cobra.Command {
	cmd := set.NewCmdImage(f, streams)
	cmd.Long = setImageLong
	cmd.Example = fmt.Sprintf(setImageExample, fullName)

	return cmd
}
source: func (rb *ringBuffer) Cap() int {
	c := 1
	current := rb.start
	for current.next != rb.start {
		c++
		current = current.next
	}
	return c
}
source: func (wr *Wrangler) diffPermissions(ctx context.Context, masterPermissions *tabletmanagerdatapb.Permissions, masterAlias *topodatapb.TabletAlias, alias *topodatapb.TabletAlias, wg *sync.WaitGroup, er concurrency.ErrorRecorder) {
	defer wg.Done()
	log.Infof("Gathering permissions for %v", topoproto.TabletAliasString(alias))
	slavePermissions, err := wr.GetPermissions(ctx, alias)
	if err != nil {
		er.RecordError(err)
		return
	}

	log.Infof("Diffing permissions for %v", topoproto.TabletAliasString(alias))
	tmutils.DiffPermissions(topoproto.TabletAliasString(masterAlias), masterPermissions, topoproto.TabletAliasString(alias), slavePermissions, er)
}
source: func (a *PrintToPDFArgs) SetPaperWidth(paperWidth float64) *PrintToPDFArgs {
	a.PaperWidth = &paperWidth
	return a
}
source: func MakeV1ConfigFromConfig(configJSON []byte, v1ID, parentV1ID string, throwaway bool) ([]byte, error) {
	// Top-level v1compatibility string should be a modified version of the
	// image config.
	var configAsMap map[string]*json.RawMessage
	if err := json.Unmarshal(configJSON, &configAsMap); err != nil {
		return nil, err
	}

	// Delete fields that didn't exist in old manifest
	delete(configAsMap, "rootfs")
	delete(configAsMap, "history")
	configAsMap["id"] = rawJSON(v1ID)
	if parentV1ID != "" {
		configAsMap["parent"] = rawJSON(parentV1ID)
	}
	if throwaway {
		configAsMap["throwaway"] = rawJSON(true)
	}

	return json.Marshal(configAsMap)
}
source: func (x *XC) NameFromKey(ctx context.Context, id string) string {
	if key := x.pubring.Get(id); key != nil {
		return key.Identity.Name
	}
	if key := x.secring.Get(id); key != nil {
		return key.PublicKey.Identity.Name
	}
	return id
}
source: func (mr *MockNetworkAPIClientMockRecorder) NetworksPrune(ctx, pruneFilter interface{}) *gomock.Call {
	return mr.mock.ctrl.RecordCallWithMethodType(mr.mock, "NetworksPrune", reflect.TypeOf((*MockNetworkAPIClient)(nil).NetworksPrune), ctx, pruneFilter)
}
source: func (xc *CommonExchange) setLastFail(t time.Time) {
	xc.mtx.Lock()
	defer xc.mtx.Unlock()
	xc.lastFail = t
}
source: func (e ext) ReadExt(v interface{}, buf []byte) {
	err := e.codec.Decode(buf, v)
	if err != nil {
		panic(fmt.Sprintf("Couldn't decode data into %v", v))
	}
}
source: func (l *Limiter) OnMessage(m *utils.Message, done utils.Done) {
	if l.paused {
		<-l.keepSending
		l.currentMessages = 0
		l.currentBytes = 0
		l.paused = false
	}

	l.currentMessages++
	if l.Config.BytesLimit > 0 {
		if payload, err := m.PopPayload(); err == nil {
			l.currentBytes += uint64(len(payload))
			m.PushPayload(payload)
		}
	}
	done(m, 0, "")

	if l.Config.MessageLimit > 0 && l.currentMessages >= l.Config.MessageLimit ||
		l.Config.BytesLimit > 0 && l.currentBytes >= l.Config.BytesLimit {
		l.paused = true
	}
}
source: func (l Hyperlink) Expand(m M) (u *url.URL, err error) {
	sawyerHyperlink := hypermedia.Hyperlink(string(l))
	u, err = sawyerHyperlink.Expand(hypermedia.M(m))
	return
}
source: func (c *UpdatesClient) Check(ctx context.Context) (*apitypes.UpdateInfo, error) {
	var needsUpdate apitypes.UpdateInfo
	err := c.client.DaemonRoundTrip(ctx, "GET", "/updates", nil, nil, &needsUpdate, nil)
	return &needsUpdate, err
}
source: func (p *PGeometry) Intersects(other *Geometry) (bool, error) {
	return p.predicate("intersects", cGEOSPreparedIntersects, other)
}
source: func (o *ReplicationControllerOptions) ApplyTo(cfg *replicationconfig.ReplicationControllerConfiguration) error {
	if o == nil {
		return nil
	}

	cfg.ConcurrentRCSyncs = o.ConcurrentRCSyncs

	return nil
}
source: func (s *Store) Initialized(ctx context.Context) bool {
	if s == nil || s.storage == nil {
		return false
	}
	return s.storage.Exists(ctx, s.idFile(ctx, ""))
}
source: func (c IndexEntries) TimeByTag(tag int) time.Time {
	vals := c.TimesByTag(tag)
	if vals == nil || len(vals) == 0 {
		return time.Time{}
	}
	return vals[0]
}
source: func (s *CreateHsmConfigurationInput) SetHsmPartitionPassword(v string) *CreateHsmConfigurationInput {
	s.HsmPartitionPassword = &v
	return s
}
source: func (x Vector) Cumsum() Vector {
	y := make(Vector, len(x))

	y[0] = x[0]

	i := 1
	for i < len(x) {
		y[i] = x[i] + y[i-1]
		i++
	}

	return y
}
source: func (r *Encoder) EncodeBytes(b []byte) error {
	if len(b) < STR_FIXED_COUNT {
		_, err := r.w.Write([]byte{byte(STR_FIXED_START + len(b))})
		if err != nil {
			return err
		}
		_, err = r.w.Write(b)
		return err
	}

	prefix := []byte(fmt.Sprintf("%d:", len(b)))

	_, err := r.w.Write(prefix)
	if err != nil {
		return err
	}

	_, err = r.w.Write(b)
	return err
}
source: func (c Checkout) Filter(whiteset stringset.Set) Checkout {
	newCheckout := make(Checkout)
	for repo, commit := range c {
		if whiteset.Has(repo) {
			newCheckout[repo] = commit
		}
	}
	return newCheckout
}
source: func (w *Watcher) Add(name string) (err error) {
	w.mu.Lock()
	defer w.mu.Unlock()

	name, err = filepath.Abs(name)
	if err != nil {
		return err
	}

	// If name is on the ignored list or if hidden files are
	// ignored and name is a hidden file or directory, simply return.
	_, ignored := w.ignored[name]

	isHidden, err := isHiddenFile(name)
	if err != nil {
		return err
	}

	if ignored || (w.ignoreHidden && isHidden) {
		return nil
	}

	// Add the directory's contents to the files list.
	fileList, err := w.list(name)
	if err != nil {
		return err
	}
	for k, v := range fileList {
		w.files[k] = v
	}

	// Add the name to the names list.
	w.names[name] = false

	return nil
}
source: func (gce *Cloud) DeleteForwardingRule(name string) error {
	region, err := GetGCERegion(gce.localZone)
	if err != nil {
		return err
	}
	return gce.deleteForwardingRule(name, region)
}
source: func GetEtcdImage(cfg *kubeadmapi.ClusterConfiguration) string {
	// Etcd uses default image repository by default
	etcdImageRepository := cfg.ImageRepository
	// unless an override is specified
	if cfg.Etcd.Local != nil && cfg.Etcd.Local.ImageRepository != "" {
		etcdImageRepository = cfg.Etcd.Local.ImageRepository
	}
	// Etcd uses an imageTag that corresponds to the etcd version matching the Kubernetes version
	etcdImageTag := constants.DefaultEtcdVersion
	etcdVersion, err := constants.EtcdSupportedVersion(cfg.KubernetesVersion)
	if err == nil {
		etcdImageTag = etcdVersion.String()
	}
	// unless an override is specified
	if cfg.Etcd.Local != nil && cfg.Etcd.Local.ImageTag != "" {
		etcdImageTag = cfg.Etcd.Local.ImageTag
	}
	return GetGenericImage(etcdImageRepository, constants.Etcd, etcdImageTag)
}
source: func BuildCommand(factory app.ProjectFactory) cli.Command {
	return cli.Command{
		Name:   "build",
		Usage:  "Build or rebuild services.",
		Action: app.WithProject(factory, app.ProjectBuild),
		Flags: []cli.Flag{
			cli.BoolFlag{
				Name:  "no-cache",
				Usage: "Do not use cache when building the image",
			},
			cli.BoolFlag{
				Name:  "force-rm",
				Usage: "Always remove intermediate containers",
			},
			cli.BoolFlag{
				Name:  "pull",
				Usage: "Always attempt to pull a newer version of the image",
			},
		},
	}
}
source: func (a *AdjacencyMatrixAggregation) Filters(name string, filter Query) *AdjacencyMatrixAggregation {
	a.filters[name] = filter
	return a
}
source: func NewPrivateKey(curve elliptic.Curve) (*PrivateKey, error) {
	key, err := ecdsa.GenerateKey(curve, rand.Reader)
	if err != nil {
		return nil, err
	}
	return (*PrivateKey)(key), nil
}
source: func (s3Select *S3Select) Open(getReader func(offset, length int64) (io.ReadCloser, error)) error {
	switch s3Select.Input.format {
	case csvFormat:
		rc, err := getReader(0, -1)
		if err != nil {
			return err
		}

		s3Select.progressReader, err = newProgressReader(rc, s3Select.Input.CompressionType)
		if err != nil {
			return err
		}

		s3Select.recordReader, err = csv.NewReader(s3Select.progressReader, &s3Select.Input.CSVArgs)
		if err != nil {
			return err
		}

		return nil
	case jsonFormat:
		rc, err := getReader(0, -1)
		if err != nil {
			return err
		}

		s3Select.progressReader, err = newProgressReader(rc, s3Select.Input.CompressionType)
		if err != nil {
			return err
		}

		s3Select.recordReader = json.NewReader(s3Select.progressReader, &s3Select.Input.JSONArgs)
		return nil
	case parquetFormat:
		var err error
		s3Select.recordReader, err = parquet.NewReader(getReader, &s3Select.Input.ParquetArgs)
		return err
	}

	panic(fmt.Errorf("unknown input format '%v'", s3Select.Input.format))
}
source: func (st *State) PrepareLocalCharmUpload(curl *charm.URL) (chosenURL *charm.URL, err error) {
	// Perform a few sanity checks first.
	if curl.Schema != "local" {
		return nil, errors.Errorf("expected charm URL with local schema, got %q", curl)
	}
	if curl.Revision < 0 {
		return nil, errors.Errorf("expected charm URL with revision, got %q", curl)
	}

	revisionSeq := charmRevSeqName(curl.WithRevision(-1).String())
	revision, err := sequenceWithMin(st, revisionSeq, curl.Revision)
	if err != nil {
		return nil, errors.Annotate(err, "unable to allocate charm revision")
	}
	allocatedURL := curl.WithRevision(revision)

	ops, err := insertPendingCharmOps(st, allocatedURL)
	if err != nil {
		return nil, errors.Trace(err)
	}

	if err := st.db().RunTransaction(ops); err != nil {
		return nil, errors.Trace(err)
	}
	return allocatedURL, nil
}
source: func (s *DescribeDirectoryConfigsOutput) SetDirectoryConfigs(v []*DirectoryConfig) *DescribeDirectoryConfigsOutput {
	s.DirectoryConfigs = v
	return s
}
source: func (b *boundManager) pinOp(leaseName string, entity string, ch chan pin) error {
	return errors.Trace(pin{
		leaseKey: b.leaseKey(leaseName),
		entity:   entity,
		response: make(chan error),
		stop:     b.manager.catacomb.Dying(),
	}.invoke(ch))
}
source: func incByteSlice(b []byte) (next []byte) {
	l := len(b)
	next = make([]byte, l)
	copy(next, b)
	for i := l - 1; i >= 0; i-- {
		if b[i] == 255 {
			next[i] = 0
		} else {
			next[i] = b[i] + 1
			return next
		}
	}
	return nil
}
source: func (u *URI) Path(path string) string {
	return fmt.Sprintf("%s%s", u.normalize(), path)
}
source: func NewMockCryptoSetup(ctrl *gomock.Controller) *MockCryptoSetup {
	mock := &MockCryptoSetup{ctrl: ctrl}
	mock.recorder = &MockCryptoSetupMockRecorder{mock}
	return mock
}
source: func (t Type) String() string {
	switch t {
	case Bool:
		return "bool"
	case Int64:
		return "int64"
	case Float64:
		return "float64"
	case Text:
		return "text"
	case Blob:
		return "blob"
	default:
		return "UNKNOWN"
	}
}
source: func (r Routes) FindRouteByName(name string) (Route, bool) {
	for _, route := range r {
		if route.Name == name {
			return route, true
		}
	}
	return Route{}, false
}
source: func (s *SHT3xDriver) Heater() (status bool, err error) {
	sr, err := s.getStatusRegister()
	if err == nil {
		if (1 << 13) == (sr & (1 << 13)) {
			status = true
		}
	}
	return
}
source: func NewBufferFrom(p []byte) *Buffer {
	buf := NewBuffer(len(p))
	buf.Write(p)
	zero(p, len(p))
	return buf
}
source: func (p *Provider) PolicyManager(channelID string) (policies.Manager, bool) {
	m := p.Peer.GetPolicyManager(channelID)
	return m, (m != nil)
}
source: func (t *table) hash(s string) (h1, h2 uint32) {
	h := fnv(t.h0, s)
	h1 = h & t.mask
	h2 = (h >> 16) & t.mask
	return
}
source: func (m *Module) InitDependencies(a app.App) error {
	if err := a.DependencyProvider().InjectTo(&m.deps); err != nil {
		return err
	}
	m.app = a
	return nil
}
source: func (c *Client) SendMessage(message *Message) {
	c.lastEventID = message.id
	c.send <- message
}
source: func NewCmdImage(f cmdutil.Factory, streams genericclioptions.IOStreams) *cobra.Command {
	o := NewImageOptions(streams)

	cmd := &cobra.Command{
		Use:                   "image (-f FILENAME | TYPE NAME) CONTAINER_NAME_1=CONTAINER_IMAGE_1 ... CONTAINER_NAME_N=CONTAINER_IMAGE_N",
		DisableFlagsInUseLine: true,
		Short:                 i18n.T("Update image of a pod template"),
		Long:                  imageLong,
		Example:               imageExample,
		Run: func(cmd *cobra.Command, args []string) {
			cmdutil.CheckErr(o.Complete(f, cmd, args))
			cmdutil.CheckErr(o.Validate())
			cmdutil.CheckErr(o.Run())
		},
	}

	o.PrintFlags.AddFlags(cmd)
	o.RecordFlags.AddFlags(cmd)

	usage := "identifying the resource to get from a server."
	cmdutil.AddFilenameOptionFlags(cmd, &o.FilenameOptions, usage)
	cmd.Flags().BoolVar(&o.All, "all", o.All, "Select all resources, including uninitialized ones, in the namespace of the specified resource types")
	cmd.Flags().StringVarP(&o.Selector, "selector", "l", o.Selector, "Selector (label query) to filter on, not including uninitialized ones, supports '=', '==', and '!='.(e.g. -l key1=value1,key2=value2)")
	cmd.Flags().BoolVar(&o.Local, "local", o.Local, "If true, set image will NOT contact api-server but run locally.")
	cmdutil.AddDryRunFlag(cmd)
	cmdutil.AddIncludeUninitializedFlag(cmd)
	return cmd
}
source: func Close() {
	logger.Infof("Closing ledger mgmt")
	lock.Lock()
	defer lock.Unlock()
	if !initialized {
		return
	}
	for _, l := range openedLedgers {
		l.(*closableLedger).closeWithoutLock()
	}
	ledgerProvider.Close()
	openedLedgers = nil
	logger.Infof("ledger mgmt closed")
}
source: func (a *AuthServer) SetCache(clt AuthCache) {
	a.lock.Lock()
	defer a.lock.Unlock()
	a.cache = clt
}
source: func (s *SearchContext) PolicyTraceVerbose(format string, a ...interface{}) {
	switch s.Trace {
	case TRACE_VERBOSE:
		log.Debugf(format, a...)
		if s.Logging != nil {
			s.Logging.Logger.Printf(format, a...)
		}
	}
}
source: func NewQueryEvent(f BinlogFormat, s *FakeBinlogStream, q Query) BinlogEvent {
	statusVarLength := 0
	if q.Charset != nil {
		statusVarLength += 1 + 2 + 2 + 2
	}
	length := 4 + // slave proxy id
		4 + // execution time
		1 + // schema length
		2 + // error code
		2 + // status vars length
		statusVarLength +
		len(q.Database) + // schema
		1 + // [00]
		len(q.SQL) // query
	data := make([]byte, length)

	pos := 8
	data[pos] = byte(len(q.Database))
	pos += 1 + 2
	data[pos] = byte(statusVarLength)
	data[pos+1] = byte(statusVarLength >> 8)
	pos += 2
	if q.Charset != nil {
		data[pos] = QCharsetCode
		data[pos+1] = byte(q.Charset.Client)
		data[pos+2] = byte(q.Charset.Client >> 8)
		data[pos+3] = byte(q.Charset.Conn)
		data[pos+4] = byte(q.Charset.Conn >> 8)
		data[pos+5] = byte(q.Charset.Server)
		data[pos+6] = byte(q.Charset.Server >> 8)
		pos += 7
	}
	pos += copy(data[pos:pos+len(q.Database)], q.Database)
	data[pos] = 0
	pos++
	copy(data[pos:], q.SQL)

	ev := s.Packetize(f, eQueryEvent, 0, data)
	return NewMysql56BinlogEvent(ev)
}
source: func (in *Rate) DeepCopy() *Rate {
	if in == nil {
		return nil
	}
	out := new(Rate)
	in.DeepCopyInto(out)
	return out
}
source: func (t Term) GetAllByIndex(index interface{}, keys ...interface{}) Term {
	return constructMethodTerm(t, "GetAll", p.Term_GET_ALL, keys, map[string]interface{}{"index": index})
}
source: func (i *Index) DropMeasurement(name []byte) error {
	n := i.availableThreads()

	// Store results.
	errC := make(chan error, i.PartitionN)

	var pidx uint32 // Index of maximum Partition being worked on.
	for k := 0; k < n; k++ {
		go func() {
			for {
				idx := int(atomic.AddUint32(&pidx, 1) - 1) // Get next partition to work on.
				if idx >= len(i.partitions) {
					return // No more work.
				}
				errC <- i.partitions[idx].DropMeasurement(name)
			}
		}()
	}

	// Remove any cached bitmaps for the measurement.
	i.tagValueCache.DeleteMeasurement(name)

	// Check for error
	for i := 0; i < cap(errC); i++ {
		if err := <-errC; err != nil {
			return err
		}
	}
	return nil
}
source: func (f *AckFrame) Write(b *bytes.Buffer, version protocol.VersionNumber) error {
	b.WriteByte(0x2)
	utils.WriteVarInt(b, uint64(f.LargestAcked()))
	utils.WriteVarInt(b, encodeAckDelay(f.DelayTime))

	numRanges := f.numEncodableAckRanges()
	utils.WriteVarInt(b, uint64(numRanges-1))

	// write the first range
	_, firstRange := f.encodeAckRange(0)
	utils.WriteVarInt(b, firstRange)

	// write all the other range
	for i := 1; i < numRanges; i++ {
		gap, len := f.encodeAckRange(i)
		utils.WriteVarInt(b, gap)
		utils.WriteVarInt(b, len)
	}
	return nil
}
source: func (c *Client) callOnTokenExpireHandlers() {
	c.m.RLock()
	defer c.m.RUnlock()

	for _, handler := range c.onTokenExpireHandlers {
		func() {
			defer nopRecover()
			handler()
		}()
	}
}
source: func (in *Secret) DeepCopy() *Secret {
	if in == nil {
		return nil
	}
	out := new(Secret)
	in.DeepCopyInto(out)
	return out
}
source: func ParseInstanceGroupRole(input string, lenient bool) (InstanceGroupRole, bool) {
	findRole := strings.ToLower(input)
	if lenient {
		// Accept pluralized "bastions" for "bastion"
		findRole = strings.TrimSuffix(findRole, "s")
	}

	for _, role := range AllInstanceGroupRoles {
		s := string(role)
		s = strings.ToLower(s)
		if lenient {
			s = strings.TrimSuffix(s, "s")
		}
		if s == findRole {
			return role, true
		}
	}
	return "", false
}
source: func (chs *ChartChangeSync) DeleteRelease(fhr fluxv1beta1.HelmRelease) {
	// FIXME(michael): these may need to stop mirroring a repo.
	name := release.GetReleaseName(fhr)
	err := chs.release.Delete(name)
	if err != nil {
		chs.logger.Log("warning", "chart release not deleted", "resource", fhr.ResourceID().String(), "release", name, "err", err)
	}

	// Remove the clone we may have for this HelmRelease
	chs.clonesMu.Lock()
	cloneForChart, ok := chs.clones[name]
	if ok {
		if cloneForChart.export != nil {
			cloneForChart.export.Clean()
		}
		delete(chs.clones, name)
	}
	chs.clonesMu.Unlock()
}
source: func (s *OutputGroupSettings) SetArchiveGroupSettings(v *ArchiveGroupSettings) *OutputGroupSettings {
	s.ArchiveGroupSettings = v
	return s
}
source: func (i Int) OrElse(v int) int {
	if i.Present() {
		return *i.value
	}
	return v
}
source: func NewCacheKeyIterator(cache *Cache, size int, interrupt chan struct{}) KeyIterator {
	keys := cache.Keys()

	chans := make([]chan struct{}, len(keys))
	for i := 0; i < len(keys); i++ {
		chans[i] = make(chan struct{}, 1)
	}

	cki := &cacheKeyIterator{
		i:         -1,
		size:      size,
		cache:     cache,
		order:     keys,
		ready:     chans,
		blocks:    make([][]cacheBlock, len(keys)),
		interrupt: interrupt,
	}
	go cki.encode()
	return cki
}
source: func (t TimeRange) IsZero() bool {
	return t.Min.IsZero() && t.Max.IsZero()
}
source: func (s *Ulimit) SetSoftLimit(v int64) *Ulimit {
	s.SoftLimit = &v
	return s
}
source: func (e *Enforcer) InitWithAdapter(modelPath string, adapter persist.Adapter) {
	m := NewModel(modelPath, "")
	e.InitWithModelAndAdapter(m, adapter)

	e.modelPath = modelPath
}
source: func (w *bufferFallbackWriter) Write(b []byte) (int, error) {
	if w.writerErr != nil {
		return w.buf.Write(b)
	}
	n, err := w.w.Write(b)
	w.n += int64(n)
	if err != nil {
		// begin buffering input. bytes.Buffer does not return errors and so we
		// do not need complex error handling here.
		w.writerErr = err
		w.Write(b[n:])
		return len(b), nil
	}
	return n, nil
}
source: func (m *Meta) RemoveDDLReorgHandle(job *model.Job) error {
	err := m.txn.HDel(mDDLJobReorgKey, m.reorgJobStartHandle(job.ID))
	if err != nil {
		return errors.Trace(err)
	}
	if err = m.txn.HDel(mDDLJobReorgKey, m.reorgJobEndHandle(job.ID)); err != nil {
		logutil.Logger(context.Background()).Warn("remove DDL reorg end handle", zap.Error(err))
	}
	if err = m.txn.HDel(mDDLJobReorgKey, m.reorgJobPhysicalTableID(job.ID)); err != nil {
		logutil.Logger(context.Background()).Warn("remove DDL reorg physical ID", zap.Error(err))
	}
	return nil
}
source: func (*Service) ListMachines(c context.Context, req *crimson.ListMachinesRequest) (*crimson.ListMachinesResponse, error) {
	machines, err := listMachines(c, database.Get(c), req)
	if err != nil {
		return nil, err
	}
	return &crimson.ListMachinesResponse{
		Machines: machines,
	}, nil
}
source: func (q *SearchSortField) Type(value string) *SearchSortField {
	q.options["type"] = value
	return q
}
source: func (d PoolDescriptor) Dimensions() strpair.Map {
	m := strpair.ParseMap(d)
	m.Del(SwarmingHostnameKey)
	return m
}
source: func hasPathPrefix(s, prefix string) bool {
	switch {
	default:
		return false
	case len(s) == len(prefix):
		return s == prefix
	case len(s) > len(prefix):
		if prefix != "" && prefix[len(prefix)-1] == '/' {
			return strings.HasPrefix(s, prefix)
		}
		return s[len(prefix)] == '/' && s[:len(prefix)] == prefix
	}
}
source: func (s *Service) UpdateSourceRole(w http.ResponseWriter, r *http.Request) {
	var req sourceRoleRequest
	if err := json.NewDecoder(r.Body).Decode(&req); err != nil {
		invalidJSON(w, s.Logger)
		return
	}
	if err := req.ValidUpdate(); err != nil {
		invalidData(w, err, s.Logger)
		return
	}

	ctx := r.Context()
	srcID, ts, err := s.sourcesSeries(ctx, w, r)
	if err != nil {
		return
	}

	roles, ok := s.hasRoles(ctx, ts)
	if !ok {
		Error(w, http.StatusNotFound, fmt.Sprintf("Source %d does not have role capability", srcID), s.Logger)
		return
	}

	rid := httprouter.GetParamFromContext(ctx, "rid")
	req.Name = rid

	if err := roles.Update(ctx, &req.Role); err != nil {
		Error(w, http.StatusBadRequest, err.Error(), s.Logger)
		return
	}

	role, err := roles.Get(ctx, req.Name)
	if err != nil {
		Error(w, http.StatusBadRequest, err.Error(), s.Logger)
		return
	}
	rr := newSourceRoleResponse(srcID, role)
	location(w, rr.Links.Self)
	encodeJSON(w, http.StatusOK, rr, s.Logger)
}
source: func (c *Client) SetPort(p int) *Client {
	c.Port = p
	return c
}
source: func addValueFuncs(out map[string]reflect.Value, in FuncMap) {
	for name, fn := range in {
		v := reflect.ValueOf(fn)
		if v.Kind() != reflect.Func {
			panic("value for " + name + " not a function")
		}
		if !goodFunc(v.Type()) {
			panic(fmt.Errorf("can't install method/function %q with %d results", name, v.Type().NumOut()))
		}
		out[name] = v
	}
}
source: func (converter ListConverter) Convert(value interface{}, item AttributeAccessor) (interface{}, error) {
	if value == nil {
		return make([]string, 0), nil
	}
	result := make([]string, 1)
	result[0] = value.(string)
	return result, nil
}
source: func isOpaque(img image.Image) bool {
	type opaquer interface {
		Opaque() bool
	}
	if o, ok := img.(opaquer); ok {
		return o.Opaque()
	}
	return false
}
source: func (col *Column) EvalDuration(ctx sessionctx.Context, row chunk.Row) (types.Duration, bool, error) {
	if row.IsNull(col.Index) {
		return types.Duration{}, true, nil
	}
	duration := row.GetDuration(col.Index, col.RetType.Decimal)
	return duration, false, nil
}
source: func config(c context.Context) *Config {
	cfg, _ := c.Value(configContextKey(0)).(*Config)
	if cfg == nil {
		panic("impossible, configContextKey is not set")
	}
	return cfg
}
source: func CheckResponse(response *APIResponse) (err error) {
	if response.HTTP.StatusCode < 200 || response.HTTP.StatusCode >= 400 {

		errorParts := []string{
			fmt.Sprintf("Received HTTP Status '%s'", response.HTTP.Status),
		}
		if message := createErrorResponseMessage(response.Body); message != "" {
			errorParts = append(errorParts, message)
		}

		err = errors.New(strings.Join(errorParts, ": "))
	}
	return
}
source: func (fmd *FakeMysqlDaemon) GetSchema(dbName string, tables, excludeTables []string, includeViews bool) (*tabletmanagerdatapb.SchemaDefinition, error) {
	if fmd.SchemaFunc != nil {
		return fmd.SchemaFunc()
	}
	if fmd.Schema == nil {
		return nil, fmt.Errorf("no schema defined")
	}
	return tmutils.FilterTables(fmd.Schema, tables, excludeTables, includeViews)
}
source: func (r Region) Intersection(other Region) (ret Region) {
	if !r.Contains(other.Begin()) && !other.Contains(r.Begin()) {
		return
	}
	r2 := Region{Max(r.Begin(), other.Begin()), Min(r.End(), other.End())}
	if r2.Size() != 0 {
		ret = r2
	}
	return
}
source: func getBuildName(pod metav1.Object) string {
	if pod == nil {
		return ""
	}
	return pod.GetAnnotations()[buildutil.BuildAnnotation]
}
source: func (p *PGeometry) Within(other *Geometry) (bool, error) {
	return p.predicate("within", cGEOSPreparedWithin, other)
}
source: func (p *pathObject) Map(call goja.FunctionCall) goja.Value {
	return p.ForEach(call)
}
source: func (array orderTabletsForSwap) Less(i, j int) bool {
	return tabletSortIndex(&array[i]) < tabletSortIndex(&array[j])
}
source: func (c *Compiler) GetRules() (*Rules, error) {
	if c.cptr.errors != 0 {
		return nil, errors.New("Compiler cannot be used after parse error")
	}
	var yrRules *C.YR_RULES
	if err := newError(C.yr_compiler_get_rules(c.cptr, &yrRules)); err != nil {
		return nil, err
	}
	r := &Rules{rules: &rules{cptr: yrRules}}
	runtime.SetFinalizer(r.rules, (*rules).finalize)
	keepAlive(c)
	return r, nil
}
source: func MakeColor(c color.RGBA) UnionSassValue {
	r := C.double(c.R)
	g := C.double(c.G)
	b := C.double(c.B)
	a := C.double(c.A)
	return C.sass_make_color(r, g, b, a)
}
source: func (repo *Repository) PatchPath(index int64) (string, error) {
	if err := repo.GetOwner(); err != nil {
		return "", err
	}

	return filepath.Join(RepoPath(repo.Owner.Name, repo.Name), "pulls", com.ToStr(index)+".patch"), nil
}
source: func isIPV6(v interface{}) bool {
	s, ok := v.(string)
	if !ok {
		return false
	}
	if !strings.Contains(s, ":") {
		return false
	}
	return net.ParseIP(s) != nil
}
source: func readUgen(r io.Reader) (*Ugen, error) {
	var (
		numInputs    int32
		numOutputs   int32
		specialIndex int16
		rate         int8
	)
	// read name
	name, err := readPstring(r)
	if err != nil {
		return nil, err
	}
	// read calculation rate
	if err := binary.Read(r, byteOrder, &rate); err != nil {
		return nil, err
	}
	// read number of inputs
	if err := binary.Read(r, byteOrder, &numInputs); err != nil {
		return nil, err
	}
	// read number of outputs
	if err := binary.Read(r, byteOrder, &numOutputs); err != nil {
		return nil, err
	}
	// read special index
	if err := binary.Read(r, byteOrder, &specialIndex); err != nil {
		return nil, err
	}
	var (
		inputs  = make([]UgenInput, numInputs)
		outputs = make([]Output, numOutputs)
	)
	// read inputs
	for i := 0; int32(i) < numInputs; i++ {
		in, err := readInput(r)
		if err != nil {
			return nil, err
		}
		inputs[i] = in
	}
	// read outputs
	for i := 0; int32(i) < numOutputs; i++ {
		out, err := readOutput(r)
		if err != nil {
			return nil, err
		}
		outputs[i] = out
	}
	return &Ugen{
		Name:         name.String(),
		Rate:         rate,
		SpecialIndex: specialIndex,
		Inputs:       inputs,
		Outputs:      outputs,
		NumOutputs:   int(numOutputs),
	}, nil
}  9%|▉         | 442/5000 [00:00<00:06, 735.20it/s]
source: func (builder *OnBuild) hasAssembleScript(config *api.Config) bool {
	assemblePath := filepath.Join(config.WorkingDir, "upload", "src", constants.Assemble)
	_, err := builder.fs.Stat(assemblePath)
	return err == nil
}
source: func (b Box) Shift(x, y int) Box {
	return Box{
		Top:    b.Top + y,
		Left:   b.Left + x,
		Right:  b.Right + x,
		Bottom: b.Bottom + y,
	}
}
source: func (in *TemplateInstanceList) DeepCopy() *TemplateInstanceList {
	if in == nil {
		return nil
	}
	out := new(TemplateInstanceList)
	in.DeepCopyInto(out)
	return out
}
source: func SendMessage(tel, msg string) (uint64, error) {
	omsg := &outgoingMessage{
		tel: tel,
		msg: msg,
	}
	return sendMessage(omsg)
}
source: func Dial(url_, protocol, origin string) (ws *Conn, err error) {
	config, err := NewConfig(url_, origin)
	if err != nil {
		return nil, err
	}
	if protocol != "" {
		config.Protocol = []string{protocol}
	}
	return DialConfig(config)
}
source: func (m *Machine) WatchInstanceData() NotifyWatcher {
	return newEntityWatcher(m.st, instanceDataC, m.doc.Id)
}
source: func (attrs *attributes) Add(attrType asn1.ObjectIdentifier, value interface{}) {
	attrs.types = append(attrs.types, attrType)
	attrs.values = append(attrs.values, value)
}
source: func GetTokenUser(token syscall.Token) (User, error) {
	tokenUser, err := token.GetTokenUser()
	if err != nil {
		return User{}, errors.Wrap(err, "GetTokenUser failed")
	}

	var user User
	user.SID, err = tokenUser.User.Sid.String()
	if err != nil {
		return user, errors.Wrap(err, "ConvertSidToStringSid failed")
	}

	user.Account, user.Domain, user.Type, err = tokenUser.User.Sid.LookupAccount("")
	if err != nil {
		return user, errors.Wrap(err, "LookupAccountSid failed")
	}

	return user, nil
}
source: func generateTags(f *compile.FieldSpec) (string, error) {
	tags, err := structtag.Parse("") // no tags
	if err != nil {
		return "", fmt.Errorf("failed to parse tag: %v", err)
	}

	// Default to the field name or label as the name used in the JSON
	// representation.
	if err := tags.Set(compileJSONTag(f, entityLabel(f))); err != nil {
		return "", fmt.Errorf("failed to set tag: %v", err)
	}

	// Process go.tags and overwrite JSON tag if specified in Thrift
	// annotation.
	if goAnnotation := f.Annotations[goTagKey]; goAnnotation != "" {
		goTags, err := structtag.Parse(goAnnotation)
		if err != nil {
			return "", fmt.Errorf("failed to parse tags %q: %v", goAnnotation, err)
		}

		for _, t := range goTags.Tags() {
			if t.Key == jsonTagKey {
				t = compileJSONTag(f, t.Name, t.Options...)
			}
			if err := tags.Set(t); err != nil {
				return "", fmt.Errorf("failed to set tag: %v", err)
			}
		}
	}

	return fmt.Sprintf("`%s`", tags.String()), nil
}
source: func NewScheduledRecording1Clients() (clients []*ScheduledRecording1, errors []error, err error) {
	var genericClients []goupnp.ServiceClient
	if genericClients, errors, err = goupnp.NewServiceClients(URN_ScheduledRecording_1); err != nil {
		return
	}
	clients = newScheduledRecording1ClientsFromGenericClients(genericClients)
	return
}
source: func checkCacheDisksSliceConsistency(formats []*formatCacheV1) error {
	var sentinelDisks []string
	// Extract first valid Disks slice.
	for _, format := range formats {
		if format == nil {
			continue
		}
		sentinelDisks = format.Cache.Disks
		break
	}
	for _, format := range formats {
		if format == nil {
			continue
		}
		currentDisks := format.Cache.Disks
		if !reflect.DeepEqual(sentinelDisks, currentDisks) {
			return errors.New("inconsistent cache drives found")
		}
	}
	return nil
}
source: func (p *PointParser) scan() (Token, string) {
	// If we have a token on the buffer, then return it.
	if p.buf.n != 0 {
		idx := p.buf.n % MAX_BUFFER_SIZE
		tok, lit := p.buf.tok[idx], p.buf.lit[idx]
		p.buf.n -= 1
		return tok, lit
	}

	// Otherwise read the next token from the scanner.
	tok, lit := p.s.Scan()

	// Save it to the buffer in case we unscan later.
	p.buffer(tok, lit)

	return tok, lit
}
source: func NewAPI(
	auth facade.Authorizer,
	resources facade.Resources,
	externalControllers state.ExternalControllers,
) (*ExternalControllerUpdaterAPI, error) {
	if !auth.AuthController() {
		return nil, common.ErrPerm
	}
	return &ExternalControllerUpdaterAPI{
		externalControllers,
		resources,
	}, nil
}
source: func (a *API) NewManifest(ctx context.Context, toEncrypt bool) (storage.Address, error) {
	var manifest Manifest
	data, err := json.Marshal(&manifest)
	if err != nil {
		return nil, err
	}
	addr, wait, err := a.Store(ctx, bytes.NewReader(data), int64(len(data)), toEncrypt)
	if err != nil {
		return nil, err
	}
	err = wait(ctx)
	return addr, err
}
source: func defaultObjectPauser(obj runtime.Object) ([]byte, error) {
	switch obj := obj.(type) {
	case *extensionsv1beta1.Deployment:
		if obj.Spec.Paused {
			return nil, errors.New("is already paused")
		}
		obj.Spec.Paused = true
		return runtime.Encode(scheme.Codecs.LegacyCodec(extensionsv1beta1.SchemeGroupVersion), obj)

	case *appsv1.Deployment:
		if obj.Spec.Paused {
			return nil, errors.New("is already paused")
		}
		obj.Spec.Paused = true
		return runtime.Encode(scheme.Codecs.LegacyCodec(appsv1.SchemeGroupVersion), obj)

	case *appsv1beta2.Deployment:
		if obj.Spec.Paused {
			return nil, errors.New("is already paused")
		}
		obj.Spec.Paused = true
		return runtime.Encode(scheme.Codecs.LegacyCodec(appsv1beta2.SchemeGroupVersion), obj)

	case *appsv1beta1.Deployment:
		if obj.Spec.Paused {
			return nil, errors.New("is already paused")
		}
		obj.Spec.Paused = true
		return runtime.Encode(scheme.Codecs.LegacyCodec(appsv1beta1.SchemeGroupVersion), obj)

	default:
		return nil, fmt.Errorf("pausing is not supported")
	}
}
source: func (bf *BlockFilterer) FilterBlock(block *wire.MsgBlock) bool {
	var hasRelevantTxns bool
	for _, tx := range block.Transactions {
		if bf.FilterTx(tx) {
			bf.RelevantTxns = append(bf.RelevantTxns, tx)
			hasRelevantTxns = true
		}
	}

	return hasRelevantTxns
}
source: func (rp *Reply) BytesValue() ([]byte, error) {
	if rp.Type == ErrorReply {
		return nil, errors.New(rp.Error)
	}
	if rp.Type != BulkReply {
		return nil, errors.New("invalid reply type, not bulk")
	}
	return rp.Bulk, nil
}
source: func AddProject(project Project) error {
	o := orm.NewOrm()

	_, err := o.Insert(&project)

	return err
}
source: func (e simpleFSError) ToStatus() keybase1.Status {
	return keybase1.Status{
		Name: e.reason,
		Code: int(keybase1.StatusCode_SCGeneric),
		Desc: e.Error(),
	}
}
source: func (c *ImportMetricCounter) countRepositoryImport(isi *imagev1.ImageStreamImport, err error) {
	errInfo := getIsImportRepositoryInfo(isi)
	if errInfo == nil {
		return
	}

	c.counterMutex.Lock()
	defer c.counterMutex.Unlock()

	if len(errInfo.Reason) == 0 {
		c.importSuccessCounts[errInfo.Registry]++
	} else {
		c.importErrorCounts[*defaultErrorInfoReason(errInfo, err)]++
	}
}
source: func FromTokenWithoutValidation(accessToken string) (*Claims, error) {
	claims := &Claims{}
	return claims, fromTokenWithoutValidation(accessToken, claims)
}
source: func scanString(buf []byte) ([]byte, error) {
	n := len(buf)
	if n == 0 || n == 1 {
		return buf, nil
	}
	// Is the string quoted?
	quote := buf[0]
	if quote != '"' && quote != '\'' {
		// Not quoted.
		return buf, nil
	}

	// Quoted.
	var escapers []int
	idx := 1
	for buf[idx] != quote {
		if c := buf[idx]; c == '\\' {
			escapers = append(escapers, idx)
			idx++
		}
		idx++
		if idx == n {
			return nil, errInvalidKeyValue
		}
	}
	buf = buf[1:idx]

	if len(escapers) == 0 {
		return buf, nil
	}

	// Remove escapers.
	for i, pos := range escapers {
		copy(buf[pos-i-1:], buf[pos-i:])
	}

	return buf[:len(buf)-len(escapers)], nil
}
source: func EncryptData(password string, data []byte) ([]byte, error) {
	salt := make([]byte, 32)
	if _, err := io.ReadFull(rand.Reader, salt); err != nil {
		return nil, err
	}

	// derive an encryption key from the master key and the nonce
	var key [32]byte
	copy(key[:], argon2.IDKey([]byte(password), salt, 1, 64*1024, 4, 32))

	encrypted, err := sio.EncryptReader(bytes.NewReader(data), sio.Config{
		Key: key[:]},
	)
	if err != nil {
		return nil, err
	}
	edata, err := ioutil.ReadAll(encrypted)
	return append(salt, edata...), err
}
source: func (e *Errors) Warning(format string, a ...interface{}) error {
	return e.add(Warning, format, a...)
}
source: func (s *SnapshotGetService) Verbose(verbose bool) *SnapshotGetService {
	s.verbose = &verbose
	return s
}
source: func (f *Form) RemoveValue(name, val string) error {
	if _, ok := f.fields[name]; !ok {
		return errors.NewElementNotFound("No input found with name '%s'.", name)
	}
	var save []string
	for _, v := range f.fields[name] {
		if v != val {
			save = append(save, v)
		}
	}
	if len(save) == 0 {
		f.fields.Del(name)
	} else {
		f.fields[name] = save
	}
	return nil
}
source: func (m *Monitor) Run(looper director.Looper) {
	looper.Loop(func() error {
		log.Debugf("Running checks")

		var wg sync.WaitGroup

		// Make immutable copy of m.Checks (checks are still mutable)
		m.RLock()
		checks := make(map[string]*Check, len(m.Checks))
		for k, v := range m.Checks {
			checks[k] = v
		}
		m.RUnlock()

		wg.Add(len(checks))
		for _, check := range checks {
			// Run all checks in parallel in goroutines
			resultChan := make(chan checkResult, 1)

			go func(check *Check, resultChan chan checkResult) {
				result, err := check.Command.Run(check.Args)
				resultChan <- checkResult{result, err}
			}(check, resultChan) // copy check pointer for the goroutine

			go func(check *Check, resultChan chan checkResult) {
				defer wg.Done()

				// We make the call but we time out if it gets too close to the
				// m.CheckInterval.
				select {
				case result := <-resultChan:
					check.UpdateStatus(result.status, result.err)
				case <-time.After(m.CheckInterval - 1*time.Millisecond):
					log.Errorf("Error, check %s timed out! (%v)", check.ID, check.Args)
					check.UpdateStatus(UNKNOWN, errors.New("Timed out!"))
				}
			}(check, resultChan) // copy check pointer for the goroutine
		}

		// Let's make sure we don't continue to spool up
		// huge quantities of goroutines. Wait on all of them
		// to complete before moving on. This could slow down
		// our check loop if something doesn't time out properly.
		wg.Wait()

		return nil
	})
}
source: func (s *StartBuildInput) SetLogsConfigOverride(v *LogsConfig) *StartBuildInput {
	s.LogsConfigOverride = v
	return s
}
source: func (f FeedMeta) ToTableWriterRow() []string {
	y, _, _ := f.Year()
	fetched, latest := f.modifiedTimesToStrs()
	return []string{
		f.color(f.source()),
		f.color(y),
		f.StatusForStdout(),
		f.color(fetched),
		f.color(latest),
	}
}
source: func (o *FilterOptions) Bind(flags *pflag.FlagSet) {
	flags.StringVar(&o.FilterByOS, "filter-by-os", o.FilterByOS, "A regular expression to control which images are considered when multiple variants are available. Images will be passed as '<platform>/<architecture>[/<variant>]'.")
}
source: func CreditCardExp() string {
	month := strconv.Itoa(randIntRange(1, 12))
	if len(month) == 1 {
		month = "0" + month
	}
	return month + "/" + strconv.Itoa(randIntRange(currentYear+1, currentYear+10))
}
source: func UnionSeriesIDIterators(itr0, itr1 SeriesIDIterator) SeriesIDIterator {
	// Return other iterator if either one is nil.
	if itr0 == nil {
		return itr1
	} else if itr1 == nil {
		return itr0
	}

	// Create series id set, if available.
	if a := NewSeriesIDSetIterators([]SeriesIDIterator{itr0, itr1}); a != nil {
		itr0.Close()
		itr1.Close()
		ss := NewSeriesIDSet()
		ss.Merge(a[0].SeriesIDSet(), a[1].SeriesIDSet())
		return NewSeriesIDSetIterator(ss)
	}

	return &seriesIDUnionIterator{itrs: [2]SeriesIDIterator{itr0, itr1}}
}
source: func Mul(a, b *T) T {
	q := T{
		a[3]*b[0] + a[0]*b[3] + a[1]*b[2] - a[2]*b[1],
		a[3]*b[1] + a[1]*b[3] + a[2]*b[0] - a[0]*b[2],
		a[3]*b[2] + a[2]*b[3] + a[0]*b[1] - a[1]*b[0],
		a[3]*b[3] - a[0]*b[0] - a[1]*b[1] - a[2]*b[2],
	}
	return q.Normalized()
}
source: func sendJoinRequest(node *Node, target string, timeout time.Duration) (*joinResponse, error) {
	ctx, cancel := shared.NewTChannelContext(timeout)
	defer cancel()

	peer := node.channel.Peers().GetOrAdd(target)

	req := joinRequest{
		App:         node.app,
		Source:      node.address,
		Incarnation: node.Incarnation(),
		Timeout:     timeout,
		Labels:      node.Labels().AsMap(),
	}
	res := &joinResponse{}

	// make request
	errC := make(chan error, 1)
	go func() {
		errC <- json.CallPeer(ctx, peer, node.service, "/protocol/join", req, res)
	}()

	// wait for result or timeout
	var err error
	select {
	case err = <-errC:
	case <-ctx.Done():
		err = errJoinTimeout
	}

	if err != nil {
		logging.Logger("join").WithFields(log.Fields{
			"local": node.Address(),
			"error": err,
		}).Debug("could not complete join")

		return nil, err
	}

	return res, err
}
source: func IsFont(buf []byte) bool {
	kind, _ := Font(buf)
	return kind != types.Unknown
}
source: func (w *writer) WriteChunked(r io.Reader) error {
	if w.phase != body {
		return &phaseError{body, w.phase}
	}
	cw := httputil.NewChunkedWriter(w)
	if _, err := io.Copy(cw, r); err != nil {
		return nil
	}
	w.phase = requestline
	return cw.Close()
}
source: func (p *printer) Enum(enum *descriptor.EnumDescriptorProto) {
	p.MaybeLeadingComments(enum)
	defer p.open("enum %s", enum.GetName())()

	for _, v := range enum.Value {
		p.EnumValue(v)
	}
}
source: func ParsePackage(input string) (*Package, error) {
	stmt, err := ParseStatement(input)
	if err != nil {
		return nil, err
	}
	pkg, ok := stmt.(*Package)
	if !ok {
		return nil, fmt.Errorf("expected package but got %T", stmt)
	}
	return pkg, nil
}
source: func (s *Server) GetAllPublicEndpoints(empty struct{}, publicEndpoints *[]service.PublicEndpoint) error {
	peps, err := s.f.GetAllPublicEndpoints(s.context())
	if err != nil {
		return err
	}
	*publicEndpoints = peps
	return nil
}
source: func RequireTaskQueue(queue string) router.Middleware {
	return func(c *router.Context, next router.Handler) {
		if !devAppserverBypassFn(c.Context) {
			qName := c.Request.Header.Get("X-AppEngine-QueueName")
			if qName == "" || (queue != "" && queue != qName) {
				logging.Errorf(c.Context, "request made from wrong taskqueue: %q v %q", qName, queue)
				http.Error(c.Writer, "error: must be run from the correct taskqueue", http.StatusForbidden)
				return
			}
		}
		next(c)
	}
}
source: func (w *mlWriter) writeIndent(open bool) {
	if w.context.prettyPrint {
		for i := 0; i < w.indent; i++ {
			w.context.Writef(w.context.indentStr)
		}
	} else if open {
		w.context.Writef(" ")
	}
}
source: func (b *PlanBuilder) buildTrace(trace *ast.TraceStmt) (Plan, error) {
	if _, ok := trace.Stmt.(*ast.SelectStmt); !ok && trace.Format == "row" {
		return nil, errors.New("trace only supports select query when format is row")
	}

	p := &Trace{StmtNode: trace.Stmt, Format: trace.Format}

	switch trace.Format {
	case "row":
		retFields := []string{"operation", "duration", "spanID"}
		schema := expression.NewSchema(make([]*expression.Column, 0, len(retFields))...)
		schema.Append(buildColumn("", "operation", mysql.TypeString, mysql.MaxBlobWidth))
		schema.Append(buildColumn("", "startTS", mysql.TypeString, mysql.MaxBlobWidth))
		schema.Append(buildColumn("", "duration", mysql.TypeString, mysql.MaxBlobWidth))
		p.SetSchema(schema)
	case "json":
		retFields := []string{"json"}
		schema := expression.NewSchema(make([]*expression.Column, 0, len(retFields))...)
		schema.Append(buildColumn("", "operation", mysql.TypeString, mysql.MaxBlobWidth))
		p.SetSchema(schema)
	default:
		return nil, errors.New("trace format should be one of 'row' or 'json'")
	}
	return p, nil
}
source: func newWritePump(cnx redis.Conn) *writePump {
	return &writePump{
		cnx:    cnx,
		data:   make(chan command),
		errs:   make(chan error),
		closer: make(chan struct{}),
	}
}
source: func (f *freeClientPool) unregisterPeer(p *peer) {
	if addr, ok := p.RemoteAddr().(*net.TCPAddr); ok {
		f.disconnect(addr.IP.String())
	}
}
source: func (v *typeInferrer) handleLikeExpr(x *ast.PatternLikeExpr) {
	x.SetType(types.NewFieldType(mysql.TypeLonglong))
	x.Type.Charset = charset.CharsetBin
	x.Type.Collate = charset.CollationBin
	x.Expr = v.addCastToString(x.Expr)
	x.Pattern = v.addCastToString(x.Pattern)
}
source: func (m *MockScope) Tagged(tags map[string]string) metrics.Scope {
	ret := m.ctrl.Call(m, "Tagged", tags)
	ret0, _ := ret[0].(metrics.Scope)
	return ret0
}
source: func getOperator(op configs.Operator) (libseccomp.ScmpCompareOp, error) {
	switch op {
	case configs.EqualTo:
		return libseccomp.CompareEqual, nil
	case configs.NotEqualTo:
		return libseccomp.CompareNotEqual, nil
	case configs.GreaterThan:
		return libseccomp.CompareGreater, nil
	case configs.GreaterThanOrEqualTo:
		return libseccomp.CompareGreaterEqual, nil
	case configs.LessThan:
		return libseccomp.CompareLess, nil
	case configs.LessThanOrEqualTo:
		return libseccomp.CompareLessOrEqual, nil
	case configs.MaskEqualTo:
		return libseccomp.CompareMaskedEqual, nil
	default:
		return libseccomp.CompareInvalid, fmt.Errorf("invalid operator, cannot use in rule")
	}
}
source: func (g GenHeaders) HasSomeDefaults() bool {
	// NOTE: this is currently used by templates to avoid empty constructs
	for _, header := range g {
		if header.HasDefault {
			return true
		}
	}
	return false
}
source: func (b *Batch) Close() (err error) {
	if b.err != nil {
		return b.err
	}

	defer func() {
		err = b.conn.termContext(err)
		if b.conn != nil && b.connPool != nil {
			b.connPool.Release(b.conn)
		}
	}()

	for i := b.resultsRead; i < len(b.items); i++ {
		if _, err = b.ExecResults(); err != nil {
			return err
		}
	}

	if err = b.conn.ensureConnectionReadyForQuery(); err != nil {
		return err
	}

	return nil
}
source: func NewReplicatedOrchestrator(store *store.MemoryStore) *Orchestrator {
	restartSupervisor := restart.NewSupervisor(store)
	updater := update.NewSupervisor(store, restartSupervisor)
	return &Orchestrator{
		store:             store,
		stopChan:          make(chan struct{}),
		doneChan:          make(chan struct{}),
		reconcileServices: make(map[string]*api.Service),
		restartTasks:      make(map[string]struct{}),
		updater:           updater,
		restarts:          restartSupervisor,
	}
}
source: func (t *Template) GetAWSRDSOptionGroupWithName(name string) (*resources.AWSRDSOptionGroup, error) {
	if untyped, ok := t.Resources[name]; ok {
		switch resource := untyped.(type) {
		case *resources.AWSRDSOptionGroup:
			return resource, nil
		}
	}
	return nil, fmt.Errorf("resource %q of type AWSRDSOptionGroup not found", name)
}
source: func ValidateCode(ctx context.Context, b Backend, address common.Address) (bool, error) {
	code, err := b.CodeAt(ctx, address, nil)
	if err != nil {
		return false, err
	}
	return bytes.Equal(code, common.FromHex(contract.ContractDeployedCode)), nil
}
source: func (c *ChannelStream) Listen(m Reactor) {
	if atomic.LoadInt64(&c.closed) > 0 {
		return
	}

	m.React(func(m Reactor, err error, data interface{}) {
		if err != nil {
			c.error(err)
			m.ReplyError(err)
			return
		}
		c.data(data)
		m.Reply(err)
	}, true)
}
source: func (s *GetDomainDetailOutput) SetRegistryDomainId(v string) *GetDomainDetailOutput {
	s.RegistryDomainId = &v
	return s
}
source: func (h *PublicPortHandler) SetExports(data []registry.ExportDetails) {
	h.exports.Set(data)
}
source: func (s *XDSServer) RemoveListener(name string, wg *completion.WaitGroup) xds.AckingResourceMutatorRevertFunc {
	log.Debugf("Envoy: removeListener %s", name)

	var listenerRevertFunc func(*completion.Completion)

	s.mutex.Lock()
	listener, ok := s.listeners[name]
	if ok && listener != nil {
		listener.count--
		if listener.count == 0 {
			delete(s.listeners, name)
			listenerRevertFunc = s.listenerMutator.Delete(ListenerTypeURL, name, []string{"127.0.0.1"}, wg.AddCompletion())
		}
	} else {
		// Bail out if this listener does not exist
		log.Fatalf("Envoy: Attempt to remove non-existent listener: %s", name)
	}
	s.mutex.Unlock()

	return func(completion *completion.Completion) {
		s.mutex.Lock()
		if listenerRevertFunc != nil {
			listenerRevertFunc(completion)
		}
		listener.count++
		s.listeners[name] = listener
		s.mutex.Unlock()
	}
}
source: func (s *EC2InstanceCounts) SetACTIVE(v int64) *EC2InstanceCounts {
	s.ACTIVE = &v
	return s
}
source: func (st *State) isUserSuperuser(user names.UserTag) (bool, error) {
	access, err := st.UserAccess(user, st.controllerTag)
	if err != nil {
		// TODO(jam): 2017-11-27 We weren't suppressing NotFound here so that we would know when someone asked for
		// the list of models of a user that doesn't exist.
		// However, now we will not even check if its a known user if they aren't asking for all=true.
		return false, errors.Trace(err)
	}
	isControllerSuperuser := (access.Access == permission.SuperuserAccess)
	return isControllerSuperuser, nil
}
source: func (i *instanceManager) Reserve(d *structs.AllocatedDeviceResource) (*device.ContainerReservation, error) {
	// Get a device plugin
	devicePlugin, err := i.dispense()
	if err != nil {
		i.logger.Error("dispensing plugin failed", "error", err)
		return nil, err
	}

	// Send the reserve request
	return devicePlugin.Reserve(d.DeviceIDs)
}
source: func (r Network_Storage) GetAllowableSubnets(filterNetworkIdentifier *string) (resp []datatypes.Network_Subnet, err error) {
	params := []interface{}{
		filterNetworkIdentifier,
	}
	err = r.Session.DoRequest("SoftLayer_Network_Storage", "getAllowableSubnets", params, &r.Options, &resp)
	return
}
source: func (api *API) Call(method string, params interface{}) (response Response, err error) {
	b, err := api.callBytes(method, params)
	if err == nil {
		err = json.Unmarshal(b, &response)
	}
	return
}
source: func newTodo(raw string) *todo {
	result := &todo{
		name:    s5.NewStringSimple(raw),
		done:    s5.NewBooleanSimple(false),
		editing: s5.NewBooleanSimple(false),
	}
	result.modName = s5.NewModelName(result)
	return result
}
source: func (o *OIDCConnectorV2) MapClaims(claims jose.Claims) []string {
	var roles []string
	for _, mapping := range o.Spec.ClaimsToRoles {
		for claimName := range claims {
			if claimName != mapping.Claim {
				continue
			}
			var claimValues []string
			claimValue, ok, _ := claims.StringClaim(claimName)
			if ok {
				claimValues = []string{claimValue}
			} else {
				claimValues, _, _ = claims.StringsClaim(claimName)
			}
		claimLoop:
			for _, claimValue := range claimValues {
				for _, role := range mapping.Roles {
					outRole, err := utils.ReplaceRegexp(mapping.Value, role, claimValue)
					switch {
					case err != nil:
						if trace.IsNotFound(err) {
							log.Debugf("Failed to match expression %v, replace with: %v input: %v, err: %v", mapping.Value, role, claimValue, err)
						}
						// this claim value clearly did not match, move on to another
						continue claimLoop
						// skip empty replacement or empty role
					case outRole == "":
					case outRole != "":
						roles = append(roles, outRole)
					}
				}
			}
		}
	}
	return utils.Deduplicate(roles)
}
source: func PrivateKeyToEncryptedPEM(privateKey interface{}, pwd []byte) ([]byte, error) {
	if privateKey == nil {
		return nil, errors.New("Invalid private key. It must be different from nil.")
	}

	switch k := privateKey.(type) {
	case *ecdsa.PrivateKey:
		if k == nil {
			return nil, errors.New("Invalid ecdsa private key. It must be different from nil.")
		}
		raw, err := x509.MarshalECPrivateKey(k)

		if err != nil {
			return nil, err
		}

		block, err := x509.EncryptPEMBlock(
			rand.Reader,
			"PRIVATE KEY",
			raw,
			pwd,
			x509.PEMCipherAES256)

		if err != nil {
			return nil, err
		}

		return pem.EncodeToMemory(block), nil

	default:
		return nil, errors.New("Invalid key type. It must be *ecdsa.PrivateKey")
	}
}
source: func (m *VisionSpeedEstimate) Decode(buf []byte) {
	data := bytes.NewBuffer(buf)
	binary.Read(data, binary.LittleEndian, &m.USEC)
	binary.Read(data, binary.LittleEndian, &m.X)
	binary.Read(data, binary.LittleEndian, &m.Y)
	binary.Read(data, binary.LittleEndian, &m.Z)
}
source: func (s *QueryExecutionStatistics) SetDataScannedInBytes(v int64) *QueryExecutionStatistics {
	s.DataScannedInBytes = &v
	return s
}
source: func missingKey(resp http.ResponseWriter, args *structs.KeyRequest) bool {
	if args.Key == "" {
		resp.WriteHeader(http.StatusBadRequest)
		fmt.Fprint(resp, "Missing key name")
		return true
	}
	return false
}
source: func (c *Config) Open(id string, logger log.Logger) (connector.Connector, error) {
	if c.BaseURL == "" {
		c.BaseURL = "https://gitlab.com"
	}
	return &gitlabConnector{
		baseURL:      c.BaseURL,
		redirectURI:  c.RedirectURI,
		clientID:     c.ClientID,
		clientSecret: c.ClientSecret,
		logger:       logger,
	}, nil
}
source: func ValidateThrottleIOpsDevice(val string) (*blkiodev.ThrottleDevice, error) {
	split := strings.SplitN(val, ":", 2)
	if len(split) != 2 {
		return nil, fmt.Errorf("bad format: %s", val)
	}
	if !strings.HasPrefix(split[0], "/dev/") {
		return nil, fmt.Errorf("bad format for device path: %s", val)
	}
	rate, err := strconv.ParseUint(split[1], 10, 64)
	if err != nil {
		return nil, fmt.Errorf("invalid rate for device: %s. The correct format is <device-path>:<number>. Number must be a positive integer", val)
	}
	if rate < 0 {
		return nil, fmt.Errorf("invalid rate for device: %s. The correct format is <device-path>:<number>. Number must be a positive integer", val)
	}

	return &blkiodev.ThrottleDevice{Path: split[0], Rate: rate}, nil
}
source: func SetCapacity(file *os.File) error {
	if err := ioctlLoopSetCapacity(file.Fd(), 0); err != nil {
		logrus.Errorf("Error loopbackSetCapacity: %s", err)
		return ErrSetCapacity
	}
	return nil
}
source: func (c *Runtime) QueryObjects(prototypeObjectId string, objectGroup string) (*RuntimeRemoteObject, error) {
	var v RuntimeQueryObjectsParams
	v.PrototypeObjectId = prototypeObjectId
	v.ObjectGroup = objectGroup
	return c.QueryObjectsWithParams(&v)
}
source: func divMod(l, r, m *big.Int) *big.Int {
	return mulMod(l, modInverse(r, m), m)
}
source: func (s *Factory) ReplicationControllers() corev1.ReplicationControllerInterface {
	return s.coreClientSet.ReplicationControllers(s.namespace)
}
source: func (t *TTFParser) ReadShortInt16(fd *bytes.Reader) (int16, error) {
	n, err := t.ReadShort(fd)
	if err != nil {
		return 0, err
	}
	return int16(n), nil
}
source: func (q *Query) WithStore(store storage.Store) *Query {
	q.store = store
	return q
}
source: func (m Metric) Before(o Metric) bool {
	return LabelSet(m).Before(LabelSet(o))
}
source: func (gov *Governmint) RunTx(store base.KVStore, ctx base.CallContext, txBytes []byte) tmsp.Result {
	var tx types.Tx
	err := wire.ReadBinaryBytes(txBytes, &tx)
	if err != nil {
		return tmsp.ErrEncodingError.SetLog(
			Fmt("Error parsing Governmint tx bytes: %v", err.Error()))
	}
	return gov.RunTxParsed(store, tx)
}
source: func (s *CopyImageInput) SetDestinationImageDescription(v string) *CopyImageInput {
	s.DestinationImageDescription = &v
	return s
}
source: func (i ImportBinding) GetPortNumber(instanceID int) (uint16, error) {
	t := template.Must(template.New(i.Application).Funcs(funcs).Parse(i.PortTemplate))

	var buffer bytes.Buffer
	if err := t.Execute(&buffer, struct{ InstanceID int }{instanceID}); err != nil {
		return 0, &TemplateError{
			Application: i.Application,
			Field:       i.PortTemplate,
			Message:     "could not interpret value",
		}
	}

	if port := buffer.String(); port != "" {
		portNumber, err := strconv.Atoi(port)
		if err != nil {
			return 0, &TemplateError{
				Application: i.Application,
				Field:       i.PortTemplate,
				Message:     "port value is not an integer",
			}
		} else if portNumber < 0 {
			return 0, &TemplateError{
				Application: i.Application,
				Field:       i.PortTemplate,
				Message:     "port value must be gte zero",
			}
		}
		return uint16(portNumber), nil
	}

	return i.PortNumber, nil
}
source: func (in *PodSecurityPolicySubjectReviewSpec) DeepCopy() *PodSecurityPolicySubjectReviewSpec {
	if in == nil {
		return nil
	}
	out := new(PodSecurityPolicySubjectReviewSpec)
	in.DeepCopyInto(out)
	return out
}
source: func createDistinctChecker(sc *stmtctx.StatementContext) *distinctChecker {
	return &distinctChecker{
		existingKeys: mvmap.NewMVMap(),
		sc:           sc,
	}
}
source: func (m *Machine) WatchContainers(ctype instance.ContainerType) (watcher.StringsWatcher, error) {
	if string(ctype) == "" {
		return nil, fmt.Errorf("container type must be specified")
	}
	supported := false
	for _, c := range instance.ContainerTypes {
		if ctype == c {
			supported = true
			break
		}
	}
	if !supported {
		return nil, fmt.Errorf("unsupported container type %q", ctype)
	}
	var results params.StringsWatchResults
	args := params.WatchContainers{
		Params: []params.WatchContainer{
			{MachineTag: m.tag.String(), ContainerType: string(ctype)},
		},
	}
	err := m.st.facade.FacadeCall("WatchContainers", args, &results)
	if err != nil {
		return nil, err
	}
	if len(results.Results) != 1 {
		return nil, fmt.Errorf("expected 1 result, got %d", len(results.Results))
	}
	result := results.Results[0]
	if result.Error != nil {
		return nil, result.Error
	}
	w := apiwatcher.NewStringsWatcher(m.st.facade.RawAPICaller(), result)
	return w, nil
}
source: func SetTLSConfig(c *tls.Config) MailerSetting {
	return func(m *Mailer) {
		m.config = c
	}
}
source: func (s *LDBStore) Has(_ context.Context, addr Address) bool {
	s.lock.RLock()
	defer s.lock.RUnlock()

	ikey := getIndexKey(addr)
	_, err := s.db.Get(ikey)

	return err == nil
}
source: func (c *Client) updateNodeFromDevicesLocked(devices []*structs.NodeDeviceResource) bool {
	if !structs.DevicesEquals(c.config.Node.NodeResources.Devices, devices) {
		c.logger.Debug("new devices detected", "devices", len(devices))
		c.config.Node.NodeResources.Devices = devices
		return true
	}

	return false
}
source: func (a *SetPausedInDebuggerMessageArgs) SetMessage(message string) *SetPausedInDebuggerMessageArgs {
	a.Message = &message
	return a
}
source: func (p *parser) lookupVariable(varReference string) (interface{}, bool, error) {
	// Do special check to see if it is a raw bcrypt string.
	if strings.HasPrefix(varReference, bcryptPrefix) {
		return "$" + varReference, true, nil
	}

	// Loop through contexts currently on the stack.
	for i := len(p.ctxs) - 1; i >= 0; i-- {
		ctx := p.ctxs[i]
		// Process if it is a map context
		if m, ok := ctx.(map[string]interface{}); ok {
			if v, ok := m[varReference]; ok {
				return v, ok, nil
			}
		}
	}

	// If we are here, we have exhausted our context maps and still not found anything.
	// Parse from the environment.
	if vStr, ok := os.LookupEnv(varReference); ok {
		// Everything we get here will be a string value, so we need to process as a parser would.
		if vmap, err := Parse(fmt.Sprintf("%s=%s", pkey, vStr)); err == nil {
			v, ok := vmap[pkey]
			return v, ok, nil
		} else {
			return nil, false, err
		}
	}
	return nil, false, nil
}
source: func Equal(a, b string) bool {
	au, err := url.Parse(a)
	if err != nil {
		a = filepath.Clean(a)
		b = filepath.Clean(b)
		// If urls are paths, return true only if they are an exact match
		return a == b
	}
	bu, err := url.Parse(b)
	if err != nil {
		return false
	}

	for _, u := range []*url.URL{au, bu} {
		if u.Path == "" {
			u.Path = "/"
		}
		u.Path = filepath.Clean(u.Path)
	}
	return au.String() == bu.String()
}
source: func BlockPullerFromConfigBlock(conf PullerConfig, block *common.Block, verifierRetriever VerifierRetriever) (*BlockPuller, error) {
	if block == nil {
		return nil, errors.New("nil block")
	}

	endpointconfig, err := EndpointconfigFromConfigBlock(block)
	if err != nil {
		return nil, err
	}

	dialer := &StandardDialer{
		Dialer: NewTLSPinningDialer(comm.ClientConfig{
			Timeout: conf.Timeout,
			SecOpts: &comm.SecureOptions{
				ServerRootCAs:     endpointconfig.TLSRootCAs,
				Certificate:       conf.TLSCert,
				Key:               conf.TLSKey,
				RequireClientCert: true,
				UseTLS:            true,
			},
		})}

	tlsCertAsDER, _ := pem.Decode(conf.TLSCert)
	if tlsCertAsDER == nil {
		return nil, errors.Errorf("unable to decode TLS certificate PEM: %s", base64.StdEncoding.EncodeToString(conf.TLSCert))
	}

	return &BlockPuller{
		Logger:  flogging.MustGetLogger("orderer.common.cluster.replication"),
		Dialer:  dialer,
		TLSCert: tlsCertAsDER.Bytes,
		VerifyBlockSequence: func(blocks []*common.Block, channel string) error {
			verifier := verifierRetriever.RetrieveVerifier(channel)
			if verifier == nil {
				return errors.Errorf("couldn't acquire verifier for channel %s", channel)
			}
			return VerifyBlocks(blocks, verifier)
		},
		MaxTotalBufferBytes: conf.MaxTotalBufferBytes,
		Endpoints:           endpointconfig.Endpoints,
		RetryTimeout:        RetryTimeout,
		FetchTimeout:        conf.Timeout,
		Channel:             conf.Channel,
		Signer:              conf.Signer,
	}, nil
}
source: func NewRule(scope, namePrefix, connector string) (*Rule, error) {
	if namePrefix == "" {
		return nil, errors.New("namePrefix could not be empty, should be defined in yaml file")
	}

	if scope == "" {
		return nil, errors.New("scope could not be empty, should be defined in yaml file")
	}

	if strings.HasPrefix(namePrefix, "*") && len(namePrefix) != 1 {
		// we don't support name like '*.service.v1'
		return nil, errors.Errorf(
			"namePrefix like %v is not supported, cannot put * at the beginning of namePrefix.", namePrefix)
	}

	globMatch := glob.MustCompile(namePrefix)

	return &Rule{NamePrefix: namePrefix, Scope: scope, Connector: connector, GlobMatch: globMatch}, nil
}
source: func (c *Callbacks) OnCDOTAUserMsg_HeroRelicProgress(fn func(*dota.CDOTAUserMsg_HeroRelicProgress) error) {
	c.onCDOTAUserMsg_HeroRelicProgress = append(c.onCDOTAUserMsg_HeroRelicProgress, fn)
}
source: func MustGetDialect(name string) Dialect {
	dialect, err := GetDialect(name)
	if err != nil {
		log.Panic(err)
	}
	return dialect
}
source: func rawRowAsPointers(ei *dosa.EntityInfo, values map[string]dosa.FieldValue) map[string]dosa.FieldValue {
	convertedValues := map[string]dosa.FieldValue{}
	// Using the type of the column as source of truth, convert from an interface{} back
	// to its native type before taking the address.
	// Values from the cache with a type mismatch will not be included in the results
	for colName, colType := range ei.Def.ColumnTypes() {
		if val, ok := values[colName]; ok {
			switch colType {
			case dosa.Blob:
				// do nothing with byte arrays
				convertedValues[colName] = val
			case dosa.TUUID:
				if u, ok := val.(dosa.UUID); ok {
					convertedValues[colName] = &u
				}
			case dosa.String:
				if s, ok := val.(string); ok {
					convertedValues[colName] = &s
				}
			case dosa.Int32:
				if i, ok := val.(int32); ok {
					convertedValues[colName] = &i
				}
			case dosa.Int64:
				if i, ok := val.(int64); ok {
					convertedValues[colName] = &i
				}
			case dosa.Double:
				if d, ok := val.(float64); ok {
					convertedValues[colName] = &d
				}
			case dosa.Timestamp:
				if t, ok := val.(time.Time); ok {
					convertedValues[colName] = &t
				}
			case dosa.Bool:
				if b, ok := val.(bool); ok {
					convertedValues[colName] = &b
				}
			default:
				convertedValues[colName] = &val
			}
		}
	}
	return convertedValues
}
source: func (l *MockLedger) NewBlock(channelID string, transactions ...*TxInfo) Block {
	l.Lock()
	defer l.Unlock()
	block := NewBlockWrapper(l.blockProducer.NewBlock(channelID, transactions...))
	l.Store(block)
	return block
}
source: func (c *FakeFlunders) Get(name string, options v1.GetOptions) (result *v1beta1.Flunder, err error) {
	obj, err := c.Fake.
		Invokes(testing.NewGetAction(flundersResource, c.ns, name), &v1beta1.Flunder{})

	if obj == nil {
		return nil, err
	}
	return obj.(*v1beta1.Flunder), err
}
source: func (h *HostStatsCollector) collectLocked() error {
	hs := &HostStats{Timestamp: time.Now().UTC().UnixNano()}

	// Determine up-time
	uptime, err := host.Uptime()
	if err != nil {
		return err
	}
	hs.Uptime = uptime

	// Collect memory stats
	mstats, err := h.collectMemoryStats()
	if err != nil {
		return err
	}
	hs.Memory = mstats

	// Collect cpu stats
	cpus, ticks, err := h.collectCPUStats()
	if err != nil {
		return err
	}
	hs.CPU = cpus
	hs.CPUTicksConsumed = ticks

	// Collect disk stats
	diskStats, err := h.collectDiskStats()
	if err != nil {
		return err
	}
	hs.DiskStats = diskStats

	// Getting the disk stats for the allocation directory
	usage, err := disk.Usage(h.allocDir)
	if err != nil {
		return fmt.Errorf("failed to find disk usage of alloc_dir %q: %v", h.allocDir, err)
	}
	hs.AllocDirStats = h.toDiskStats(usage, nil)

	// Collect devices stats
	deviceStats := h.collectDeviceGroupStats()
	hs.DeviceStats = deviceStats

	// Update the collected status object.
	h.hostStats = hs

	return nil
}
source: func (r Rule) splitPos(path string) int {
	if httpserver.CaseSensitivePath {
		return strings.Index(path, r.SplitPath)
	}
	return strings.Index(strings.ToLower(path), strings.ToLower(r.SplitPath))
}
source: func generateHttpClient(cfg *Configuration, httpClient *http.Client) *http.Client {
	if httpClient == nil {
		httpClient = http.DefaultClient
		if strings.HasPrefix(cfg.Server, "https") && cfg.SkipSslCheck {
			httpClient.Transport = &http.Transport{
				TLSClientConfig: &tls.Config{InsecureSkipVerify: cfg.SkipSslCheck},
			}
		}
	}
	return httpClient
}
source: func NewInjectable(fd int, mtu uint32, capabilities stack.LinkEndpointCapabilities) (tcpip.LinkEndpointID, *InjectableEndpoint) {
	syscall.SetNonblock(fd, true)

	e := &InjectableEndpoint{endpoint: endpoint{
		fd:   fd,
		mtu:  mtu,
		caps: capabilities,
	}}

	return stack.RegisterLinkEndpoint(e), e
}
source: func (g *Generic) Group(provider *http.Client) (string, error) {
	res := map[string]interface{}{}

	r, err := provider.Get(g.APIURL)
	if err != nil {
		return "", err
	}

	defer r.Body.Close()
	if err = json.NewDecoder(r.Body).Decode(&res); err != nil {
		return "", err
	}

	email := ""
	value := res[g.APIKey]
	if e, ok := value.(string); ok {
		email = e
	}

	// If we did not receive an email address, try to lookup the email
	// in a similar way as github
	if email == "" {
		email, err = g.getPrimaryEmail(provider)
		if err != nil {
			return "", err
		}
	}

	domain := strings.Split(email, "@")
	if len(domain) != 2 {
		return "", fmt.Errorf("malformed email address, expected %q to contain @ symbol", email)
	}

	return domain[1], nil
}
source: func (c *ClientContext) Sizes() (uint32, uint32, uint32, uint32, error) {
	return c.sctxt.Sizes()
}
source: func (s *FlushService) Full(full bool) *FlushService {
	s.full = &full
	return s
}
source: func (c *Connection) ObjectsAll(container string, opts *ObjectsOpts) ([]Object, error) {
	objects := make([]Object, 0)
	err := c.ObjectsWalk(container, opts, func(opts *ObjectsOpts) (interface{}, error) {
		newObjects, err := c.Objects(container, opts)
		if err == nil {
			objects = append(objects, newObjects...)
		}
		return newObjects, err
	})
	return objects, err
}
source: func (p *Parser) Words(r io.Reader, fn func(*Word) bool) error {
	p.reset()
	p.f = &File{}
	p.src = r
	p.rune()
	p.next()
	for {
		p.got(_Newl)
		w := p.getWord()
		if w == nil {
			if p.tok != _EOF {
				p.curErr("%s is not a valid word", p.tok)
			}
			return p.err
		}
		if !fn(w) {
			return nil
		}
	}
}
source: func generateListPartsResponse(partsInfo ListPartsInfo, encodingType string) ListPartsResponse {
	listPartsResponse := ListPartsResponse{}
	listPartsResponse.Bucket = partsInfo.Bucket
	listPartsResponse.Key = s3EncodeName(partsInfo.Object, encodingType)
	listPartsResponse.UploadID = partsInfo.UploadID
	listPartsResponse.StorageClass = globalMinioDefaultStorageClass
	listPartsResponse.Initiator.ID = globalMinioDefaultOwnerID
	listPartsResponse.Owner.ID = globalMinioDefaultOwnerID

	listPartsResponse.MaxParts = partsInfo.MaxParts
	listPartsResponse.PartNumberMarker = partsInfo.PartNumberMarker
	listPartsResponse.IsTruncated = partsInfo.IsTruncated
	listPartsResponse.NextPartNumberMarker = partsInfo.NextPartNumberMarker

	listPartsResponse.Parts = make([]Part, len(partsInfo.Parts))
	for index, part := range partsInfo.Parts {
		newPart := Part{}
		newPart.PartNumber = part.PartNumber
		newPart.ETag = "\"" + part.ETag + "\""
		newPart.Size = part.Size
		newPart.LastModified = part.LastModified.UTC().Format(timeFormatAMZLong)
		listPartsResponse.Parts[index] = newPart
	}
	return listPartsResponse
}
source: func GetInt(key string) (int, error) {
	value, err := Get(key)
	if err != nil {
		return 0, err
	}
	if v, ok := value.(int); ok {
		return v, nil
	} else if v, ok := value.(string); ok {
		if i, err := strconv.ParseInt(v, 10, 64); err == nil {
			return int(i), nil
		}
	} else if v, err := GetFloat(key); err == nil {
		if float64(int(v)) == v {
			return int(v), nil
		}
	}
	return 0, &InvalidValue{key, "int"}
}
source: func Tail(arr interface{}) interface{} {
	value := redirectValue(reflect.ValueOf(arr))
	valueType := value.Type()

	kind := value.Kind()

	if kind == reflect.Array || kind == reflect.Slice {
		length := value.Len()

		if length <= 1 {
			return arr
		}

		return value.Slice(1, length).Interface()
	}

	panic(fmt.Sprintf("Type %s is not supported by Initial", valueType.String()))
}
source: func (b *Box) MustString(name string) string {
	str, err := b.String(name)
	if err != nil {
		panic(err)
	}
	return str
}
source: func (a *btcAddress) PrivKey() (*btcec.PrivateKey, error) {
	if a.store.flags.watchingOnly {
		return nil, ErrWatchingOnly
	}

	if !a.flags.hasPrivKey {
		return nil, errors.New("no private key for address")
	}

	// Key store must be unlocked to decrypt the private key.
	if a.store.isLocked() {
		return nil, ErrLocked
	}

	// Unlock address with key store secret.  unlock returns a copy of
	// the clear text private key, and may be used safely even
	// during an address lock.
	privKeyCT, err := a.unlock(a.store.secret)
	if err != nil {
		return nil, err
	}

	return &btcec.PrivateKey{
		PublicKey: *a.pubKey.ToECDSA(),
		D:         new(big.Int).SetBytes(privKeyCT),
	}, nil
}
source: func (plugin *flexVolumePlugin) newUnmounterInternal(volName string, podUID types.UID, mounter mount.Interface, runner exec.Interface) (volume.Unmounter, error) {
	var metricsProvider volume.MetricsProvider
	if plugin.capabilities.SupportsMetrics {
		metricsProvider = volume.NewMetricsStatFS(plugin.host.GetPodVolumeDir(
			podUID, utilstrings.EscapeQualifiedName(plugin.driverName), volName))
	} else {
		metricsProvider = &volume.MetricsNil{}
	}

	return &flexVolumeUnmounter{
		flexVolume: &flexVolume{
			driverName:      plugin.driverName,
			execPath:        plugin.getExecutable(),
			mounter:         mounter,
			plugin:          plugin,
			podUID:          podUID,
			volName:         volName,
			MetricsProvider: metricsProvider,
		},
		runner: runner,
	}, nil
}
source: func DivFloatRegReg(ctx context, datatype OpDataType, dividend, divisor *register, spill bool) string {
	if dividend.width != divisor.width {
		ice("Invalid register width")
	}
	if datatype.op != OP_XMM {
		ice("Unsupported data type for floating point division")
	}
	return instrRegReg(ctx, GetInstr(I_DIV, datatype), divisor, dividend, true)
}
source: func (r *marathonClient) Deployments() ([]*Deployment, error) {
	var deployments []*Deployment
	err := r.apiGet(marathonAPIDeployments, nil, &deployments)
	if err != nil {
		return nil, err
	}
	// Allows loading of deployment steps from the Marathon v1.X API
	// Implements a fix for issue https://github.com/gambol99/go-marathon/issues/153
	for _, deployment := range deployments {
		// Unmarshal pre-v1.X step
		if err := json.Unmarshal(deployment.XXStepsRaw, &deployment.Steps); err != nil {
			deployment.Steps = make([][]*DeploymentStep, 0)
			var steps []*StepActions
			// Unmarshal v1.X Marathon step
			if err := json.Unmarshal(deployment.XXStepsRaw, &steps); err != nil {
				return nil, err
			}
			for stepIndex, step := range steps {
				deployment.Steps = append(deployment.Steps, make([]*DeploymentStep, len(step.Actions)))
				for actionIndex, action := range step.Actions {
					var stepAction string
					if action.Type != "" {
						stepAction = action.Type
					} else {
						stepAction = action.Action
					}
					deployment.Steps[stepIndex][actionIndex] = &DeploymentStep{
						Action: stepAction,
						App:    action.App,
					}
				}
			}
		}
	}
	return deployments, nil
}
source: func Read(source io.Reader) (Etc, error) {
	builder := sml.NewKeyStringValueTreeBuilder()
	err := sml.ReadSML(source, builder)
	if err != nil {
		return nil, errors.Annotate(err, ErrIllegalSourceFormat, errorMessages)
	}
	values, err := builder.Tree()
	if err != nil {
		return nil, errors.Annotate(err, ErrIllegalSourceFormat, errorMessages)
	}
	if err = values.At("etc").Error(); err != nil {
		return nil, errors.Annotate(err, ErrIllegalSourceFormat, errorMessages)
	}
	cfg := &etc{
		values: values,
	}
	if err = cfg.postProcess(); err != nil {
		return nil, errors.Annotate(err, ErrCannotPostProcess, errorMessages)
	}
	return cfg, nil
}
source: func (in *GarbageCollectorControllerConfiguration) DeepCopy() *GarbageCollectorControllerConfiguration {
	if in == nil {
		return nil
	}
	out := new(GarbageCollectorControllerConfiguration)
	in.DeepCopyInto(out)
	return out
}
source: func (c KbfsClient) FSOverallSyncEvent(ctx context.Context, status FolderSyncStatus) (err error) {
	__arg := FSOverallSyncEventArg{Status: status}
	err = c.Cli.Call(ctx, "keybase.1.kbfs.FSOverallSyncEvent", []interface{}{__arg}, nil)
	return
}
source: func (bc *broadcastClient) Send(msg *common.Envelope) error {
	_, err := bc.try(func() (interface{}, error) {
		if bc.shouldStop() {
			return nil, errors.New("closing")
		}
		return bc.trySend(msg)
	})
	return err
}
source: func (fn CookieReaderFunc) ReadCookie(r io.Reader) (CookieJar, error) {
	return fn(r)
}
source: func LeaseExtend(backendIncrement, backendMax time.Duration, systemView logical.SystemView) OperationFunc {
	return func(ctx context.Context, req *logical.Request, data *FieldData) (*logical.Response, error) {
		switch {
		case req.Auth != nil:
			req.Auth.TTL = backendIncrement
			req.Auth.MaxTTL = backendMax
			return &logical.Response{Auth: req.Auth}, nil
		case req.Secret != nil:
			req.Secret.TTL = backendIncrement
			req.Secret.MaxTTL = backendMax
			return &logical.Response{Secret: req.Secret}, nil
		}
		return nil, fmt.Errorf("no lease options for request")
	}
}
source: func (m *ExpirationManager) processRestore(ctx context.Context, leaseID string) error {
	m.restoreRequestLock.RLock()
	defer m.restoreRequestLock.RUnlock()

	// Check if the lease has been seen
	if _, ok := m.restoreLoaded.Load(leaseID); ok {
		return nil
	}

	m.lockLease(leaseID)
	defer m.unlockLease(leaseID)

	// Check again with the lease locked
	if _, ok := m.restoreLoaded.Load(leaseID); ok {
		return nil
	}

	// Load lease and restore expiration timer
	_, err := m.loadEntryInternal(ctx, leaseID, true, false)
	if err != nil {
		return err
	}
	return nil
}
source: func (p *NetPlugin) CreateHostAccPort(portName, globalIP string) (string, error) {
	p.Lock()
	defer p.Unlock()
	return p.NetworkDriver.CreateHostAccPort(portName, globalIP, p.PluginConfig.Instance.HostPvtNW)
}
source: func (context *BaseServiceContext) InitServiceContext(service Service) {
	context.InitBaseContext()
	context.service = service
	context.method = nil
	context.isMissingMethod = false
	context.byRef = false
}
source: func (c KbfsClient) UpgradeTLF(ctx context.Context, __arg UpgradeTLFArg) (err error) {
	err = c.Cli.Call(ctx, "keybase.1.kbfs.upgradeTLF", []interface{}{__arg}, nil)
	return
}
source: func NewChordAsyncResult(groupTasks []*tasks.Signature, chordCallback *tasks.Signature, backend iface.Backend) *ChordAsyncResult {
	asyncResults := make([]*AsyncResult, len(groupTasks))
	for i, task := range groupTasks {
		asyncResults[i] = NewAsyncResult(task, backend)
	}
	return &ChordAsyncResult{
		groupAsyncResults: asyncResults,
		chordAsyncResult:  NewAsyncResult(chordCallback, backend),
		backend:           backend,
	}
}
source: func (s *JobListEntry) SetIsMaster(v bool) *JobListEntry {
	s.IsMaster = &v
	return s
}
source: func (d *Device) sendReq(x xpc.XPC, id int, args xpc.Dict) msg {
	d.sendCmd(x, id, args)
	return <-d.rspc
}
source: func NewChannelEventListener(em event.EventMachine) *ChannelEventListener {
	return &ChannelEventListener{em: em, ids: []uint64{}}
}
source: func (p *Pool) queryLoop() error {
	if err := p.sendNextJobs(p.config.BatchSize); err != nil {
		return err
	}
	for {
		minWait := time.After(p.config.MinWait)
		select {
		case <-p.exit:
			// Close the channel to tell workers to stop executing new jobs
			close(p.jobs)
			return nil
		case <-minWait:
			if err := p.sendNextJobs(p.config.BatchSize); err != nil {
				return err
			}
		}
	}
	return nil
}
source: func (p *Provider) Client(ctx context.Context, t *oauth2.Token) *http.Client {
	if p.NewClient != nil {
		return p.NewClient(ctx, t)
	}
	return p.Config.Client(ctx, t)
}
source: func (c *Client) writeListener() {
	for {
		select {
		case msg := <-c.send:
			websocket.JSON.Send(c.ws, msg)
		case <-c.done:
			// Delete our connection
			c.hub.Unregister(c)

			// Tell reader to stop
			c.done <- true

			// exit process loop
			return
		}
	}
}
source: func ActiveProjects(c context.Context) ([]types.ProjectName, error) {
	return ProjectNames(c, cfgclient.AsService)
}
source:  11%|█         | 555/5000 [00:00<00:05, 842.40it/s]func Convert_v1_GenericWebHookEvent_To_build_GenericWebHookEvent(in *v1.GenericWebHookEvent, out *build.GenericWebHookEvent, s conversion.Scope) error {
	return autoConvert_v1_GenericWebHookEvent_To_build_GenericWebHookEvent(in, out, s)
}
source: func RunWithStdIn(input string, command string, args ...string) (string, error) {
	cmd := stdexec.Command(command, args...)

	if input != "" {
		stdin, err := cmd.StdinPipe()
		if err != nil {
			return "", errors.Annotate(err, "getting stdin pipe")
		}

		go func() {
			defer stdin.Close()
			io.WriteString(stdin, input)
		}()
	}

	out, err := cmd.CombinedOutput()
	output := string(out)
	return output, err
}
source: func (fs *KBFSOpsStandard) Rename(
	ctx context.Context, oldParent Node, oldName string, newParent Node,
	newName string) error {
	timeTrackerDone := fs.longOperationDebugDumper.Begin(ctx)
	defer timeTrackerDone()

	oldFB := oldParent.GetFolderBranch()
	newFB := newParent.GetFolderBranch()

	// only works for nodes within the same topdir
	if oldFB != newFB {
		return RenameAcrossDirsError{}
	}

	ops := fs.getOpsByNode(ctx, oldParent)
	return ops.Rename(ctx, oldParent, oldName, newParent, newName)
}
source: func (s *ISOService) NewCopyIsoParams(id string) *CopyIsoParams {
	p := &CopyIsoParams{}
	p.p = make(map[string]interface{})
	p.p["id"] = id
	return p
}
source: func (c *Contact) PostContactParams() map[string]string {
	m := map[string]string{}

	// Ignore if not defined
	if c.Email != "" {
		m["email"] = c.Email
	}

	if c.Number != "" {
		m["number"] = c.Number
	}

	if c.CountryCode != "" {
		m["countrycode"] = c.CountryCode
	}

	if c.Severity != "" {
		m["severitylevel"] = c.Severity
	}

	if c.Provider != "" {
		m["provider"] = c.Provider
	}

	return m
}
source: func (res *Resource) Open() {
	res.stmu.Lock()
	defer res.stmu.Unlock()

	res.chmu.Lock()
	res.ch = make(chan struct{})
	res.chmu.Unlock()
}
source: func (h *VHostHandler) Handle(useTLS bool, w http.ResponseWriter, r *http.Request) bool {
	h.mu.RLock()
	defer h.mu.RUnlock()

	// do not handle if disabled
	if !h.enabled {
		return false
	}

	// get the next available export
	export := h.exports.Next()
	if export == nil {
		http.Error(w, "endpoint not available", http.StatusNotFound)
		return true
	}

	RouteOriginalURL(r)

	logger := plog.WithFields(log.Fields{
		"application": export.Application,
		"hostip":      export.HostIP,
		"privateip":   export.PrivateIP,
		"request":     r,
	})

	logger.Debug("Proxying endpoint")

	// get the reverse proxy for the export
	rp := GetReverseProxy(useTLS, export)

	// Set up the X-Forwarded-Proto header so that downstream servers know
	// the request originated as HTTPS.
	if _, found := r.Header["X-Forwarded-Proto"]; !found {
		r.Header.Set("X-Forwarded-Proto", "https")
	}

	w.Header().Add("Strict-Transport-Security", "max-age=31536000")
	rp.ServeHTTP(w, r)

	return true
}
source: func (q *TransferQueue) addToAdapter(e lfshttp.Endpoint, pending []*Transfer) <-chan *objectTuple {
	retries := make(chan *objectTuple, len(pending))

	if err := q.ensureAdapterBegun(e); err != nil {
		close(retries)

		q.errorc <- err
		for _, t := range pending {
			q.Skip(t.Size)
			q.wait.Done()
		}

		return retries
	}

	present, missingResults := q.partitionTransfers(pending)

	go func() {
		defer close(retries)

		var results <-chan TransferResult
		if q.dryRun {
			results = q.makeDryRunResults(present)
		} else {
			results = q.adapter.Add(present...)
		}

		for _, res := range missingResults {
			q.handleTransferResult(res, retries)
		}
		for res := range results {
			q.handleTransferResult(res, retries)
		}
	}()

	return retries
}
source: func (e *ModelWatcher) ModelConfig() (*config.Config, error) {
	var result params.ModelConfigResult
	err := e.facade.FacadeCall("ModelConfig", nil, &result)
	if err != nil {
		return nil, errors.Trace(err)
	}
	conf, err := config.New(config.NoDefaults, result.Config)
	if err != nil {
		return nil, errors.Trace(err)
	}
	return conf, nil
}
source: func (t Types) GetByType(tp string) (Type, bool) {
	for _, tt := range t {
		if strings.EqualFold(tt.Type(), tp) {
			return tt, true
		}
	}

	if !strings.Contains(tp, "+") {
		// Try with the main and sub type
		parts := strings.Split(tp, "/")
		if len(parts) == 2 {
			return t.GetByMainSubType(parts[0], parts[1])
		}
	}

	return Type{}, false
}
source: func (s *SerfEventHandler) getRawEventName(name string) string {
	return strings.TrimPrefix(name, s.ServicePrefix+":")
}
source: func (xpath *XPath) ResultAsString() (val string, err error) {
	if xpath.ReturnType() != XPATH_STRING {
		xpath.ResultPtr = C.xmlXPathConvertString(xpath.ResultPtr)
	}
	val = C.GoString((*C.char)(unsafe.Pointer(xpath.ResultPtr.stringval)))
	return
}
source: func interpolationFuncIndex() ast.Function {
	return ast.Function{
		ArgTypes:   []ast.Type{ast.TypeList, ast.TypeString},
		ReturnType: ast.TypeInt,
		Callback: func(args []interface{}) (interface{}, error) {
			haystack := args[0].([]ast.Variable)
			needle := args[1].(string)
			for index, element := range haystack {
				if needle == element.Value {
					return index, nil
				}
			}
			return nil, fmt.Errorf("Could not find '%s' in '%s'", needle, haystack)
		},
	}
}
source: func (cfg *leafNodeCfg) pickNextURL() *url.URL {
	cfg.Lock()
	defer cfg.Unlock()
	// If the current URL is the first in the list and we have more than
	// one URL, then move that one to end of the list.
	if cfg.curURL != nil && len(cfg.urls) > 1 && urlsAreEqual(cfg.curURL, cfg.urls[0]) {
		first := cfg.urls[0]
		copy(cfg.urls, cfg.urls[1:])
		cfg.urls[len(cfg.urls)-1] = first
	}
	cfg.curURL = cfg.urls[0]
	return cfg.curURL
}
source: func (r Account_Address) GetType() (resp datatypes.Account_Address_Type, err error) {
	err = r.Session.DoRequest("SoftLayer_Account_Address", "getType", nil, &r.Options, &resp)
	return
}
source: func NewNotaryServerStore(serverURL string, gun data.GUN, roundTrip http.RoundTripper) (RemoteStore, error) {
	return NewHTTPStore(
		serverURL+"/v2/"+gun.String()+"/_trust/tuf/",
		"",
		"json",
		"key",
		roundTrip,
	)
}
source: func (api *API) SetFirewallRules(args params.FirewallRuleArgs) (params.ErrorResults, error) {
	var errResults params.ErrorResults
	if err := api.checkAdmin(); err != nil {
		return errResults, errors.Trace(err)
	}
	if err := api.check.ChangeAllowed(); err != nil {
		return errResults, errors.Trace(err)
	}

	results := make([]params.ErrorResult, len(args.Args))
	for i, arg := range args.Args {
		logger.Debugf("saving firewall rule %+v", arg)
		err := api.backend.SaveFirewallRule(state.FirewallRule{
			WellKnownService: state.WellKnownServiceType(arg.KnownService),
			WhitelistCIDRs:   arg.WhitelistCIDRS,
		})
		results[i].Error = common.ServerError(err)
	}
	errResults.Results = results
	return errResults, nil
}
source: func (s *roleLister) List(selector labels.Selector) (ret []*v1.Role, err error) {
	err = cache.ListAll(s.indexer, selector, func(m interface{}) {
		ret = append(ret, m.(*v1.Role))
	})
	return ret, err
}
source: func (i DatabaseInventory) CollectionByName(name string) (InventoryCollection, bool) {
	for _, c := range i.Collections {
		if c.Parameters.Name == name {
			return c, true
		}
	}
	return InventoryCollection{}, false
}
source: func GetCapability(key string) *CapabilityMapping {
	for _, capp := range capabilityList {
		if capp.Key == key {
			cpy := *capp
			return &cpy
		}
	}
	return nil
}
source: func GoLineBeginning(buf *Buffer) {
	x := []rune(buf.Document().TextBeforeCursor())
	buf.CursorLeft(len(x))
}
source: func (p *pageState) AllTranslations() page.Pages {
	p.s.h.init.translations.Do()
	return p.allTranslations
}
source: func (c *Emulation) SetPageScaleFactorWithParams(v *EmulationSetPageScaleFactorParams) (*gcdmessage.ChromeResponse, error) {
	return gcdmessage.SendDefaultRequest(c.target, c.target.GetSendCh(), &gcdmessage.ParamRequest{Id: c.target.GetId(), Method: "Emulation.setPageScaleFactor", Params: v})
}
source: func newAddr2Liner(cmd, file string, base uint64) (*addr2Liner, error) {
	if cmd == "" {
		cmd = defaultAddr2line
	}

	j := &addr2LinerJob{
		cmd: exec.Command(cmd, "-aif", "-e", file),
	}

	var err error
	if j.in, err = j.cmd.StdinPipe(); err != nil {
		return nil, err
	}

	outPipe, err := j.cmd.StdoutPipe()
	if err != nil {
		return nil, err
	}

	j.out = bufio.NewReader(outPipe)
	if err := j.cmd.Start(); err != nil {
		return nil, err
	}

	a := &addr2Liner{
		rw:   j,
		base: base,
	}

	return a, nil
}
source: func (r *rpcServer) ListInvoices(ctx context.Context,
	req *lnrpc.ListInvoiceRequest) (*lnrpc.ListInvoiceResponse, error) {

	// If the number of invoices was not specified, then we'll default to
	// returning the latest 100 invoices.
	if req.NumMaxInvoices == 0 {
		req.NumMaxInvoices = 100
	}

	// Next, we'll map the proto request into a format that is understood by
	// the database.
	q := channeldb.InvoiceQuery{
		IndexOffset:    req.IndexOffset,
		NumMaxInvoices: req.NumMaxInvoices,
		PendingOnly:    req.PendingOnly,
		Reversed:       req.Reversed,
	}
	invoiceSlice, err := r.server.chanDB.QueryInvoices(q)
	if err != nil {
		return nil, fmt.Errorf("unable to query invoices: %v", err)
	}

	// Before returning the response, we'll need to convert each invoice
	// into it's proto representation.
	resp := &lnrpc.ListInvoiceResponse{
		Invoices:         make([]*lnrpc.Invoice, len(invoiceSlice.Invoices)),
		FirstIndexOffset: invoiceSlice.FirstIndexOffset,
		LastIndexOffset:  invoiceSlice.LastIndexOffset,
	}
	for i, invoice := range invoiceSlice.Invoices {
		resp.Invoices[i], err = invoicesrpc.CreateRPCInvoice(
			&invoice, activeNetParams.Params,
		)
		if err != nil {
			return nil, err
		}
	}

	return resp, nil
}
source: func (p *LogicalJoin) constructInnerIndexScan(ds *DataSource, idx *model.IndexInfo, filterConds []expression.Expression,
	outerJoinKeys []*expression.Column, us *LogicalUnionScan, rangeInfo string) PhysicalPlan {
	is := PhysicalIndexScan{
		Table:            ds.tableInfo,
		TableAsName:      ds.TableAsName,
		DBName:           ds.DBName,
		Columns:          ds.Columns,
		Index:            idx,
		dataSourceSchema: ds.schema,
		KeepOrder:        false,
		Ranges:           ranger.FullRange(),
		rangeInfo:        rangeInfo,
	}.Init(ds.ctx)

	var rowCount float64
	idxHist, ok := ds.statisticTable.Indices[idx.ID]
	if ok && !ds.statisticTable.Pseudo {
		rowCount = idxHist.AvgCountPerNotNullValue(ds.statisticTable.Count)
	} else {
		rowCount = ds.statisticTable.PseudoAvgCountPerValue()
	}
	is.stats = property.NewSimpleStats(rowCount)
	is.stats.StatsVersion = ds.statisticTable.Version
	if ds.statisticTable.Pseudo {
		is.stats.StatsVersion = statistics.PseudoVersion
	}

	cop := &copTask{
		indexPlan: is,
	}
	if !isCoveringIndex(ds.schema.Columns, is.Index.Columns, is.Table.PKIsHandle) {
		// On this way, it's double read case.
		ts := PhysicalTableScan{Columns: ds.Columns, Table: is.Table}.Init(ds.ctx)
		ts.SetSchema(is.dataSourceSchema)
		cop.tablePlan = ts
	}

	is.initSchema(ds.id, idx, cop.tablePlan != nil)
	indexConds, tblConds := splitIndexFilterConditions(filterConds, idx.Columns, ds.tableInfo)
	path := &accessPath{indexFilters: indexConds, tableFilters: tblConds, countAfterIndex: math.MaxFloat64}
	is.addPushedDownSelection(cop, ds, math.MaxFloat64, path)
	t := finishCopTask(ds.ctx, cop)
	reader := t.plan()
	return p.constructInnerUnionScan(us, reader)
}
source: func New() *Table {
	return &Table{
		Separator:  Separator,
		mtx:        new(sync.RWMutex),
		rightAlign: map[int]bool{},
	}
}
source: func (dialog *Dialog) NewSubdialog() *Dialog {
	return &Dialog{
		depth: dialog.depth,
		isSub: true,
	}
}
source: func Convert_v1_Subject_To_rbac_Subject(in *v1.Subject, out *rbac.Subject, s conversion.Scope) error {
	return autoConvert_v1_Subject_To_rbac_Subject(in, out, s)
}
source: func MaxInt32N(v ...int32) int32 {
	switch len(v) {
	case 0:
		return 0
	case 1:
		return v[0]
	case 2:
		return MaxInt32(v[0], v[1])
	default:
		l := len(v) / 2
		return MaxInt32N(MaxInt32N(v[:l]...), MaxInt32N(v[l:]...))
	}
}
source: func (f *fundingManager) waitUntilChannelOpen(targetChan lnwire.ChannelID,
	quit <-chan struct{}) error {

	f.barrierMtx.RLock()
	barrier, ok := f.newChanBarriers[targetChan]
	f.barrierMtx.RUnlock()
	if ok {
		fndgLog.Tracef("waiting for chan barrier signal for ChanID(%v)",
			targetChan)

		select {
		case <-barrier:
		case <-quit:
			return ErrFundingManagerShuttingDown
		case <-f.quit:
			return ErrFundingManagerShuttingDown
		}

		fndgLog.Tracef("barrier for ChanID(%v) closed", targetChan)
		return nil
	}

	return nil
}
source: func ResolveIgnoreMissing(args map[string][]string, flagSet apiserverflag.NamedFlagSets) []error {
	return apply(args, flagSet, true)
}
source: func recordDuration(start time.Time, name string, ctx *workflowContext) {
	elapsed := time.Since(start)
	ctx.transaction.stepDurations = append(ctx.transaction.stepDurations,
		&workflowStepDuration{
			name:     name,
			duration: elapsed,
		})
}
source: func validateCSIDriverSpec(
	spec *storage.CSIDriverSpec, fldPath *field.Path) field.ErrorList {
	allErrs := field.ErrorList{}
	allErrs = append(allErrs, validateAttachRequired(spec.AttachRequired, fldPath.Child("attachedRequired"))...)
	allErrs = append(allErrs, validatePodInfoOnMount(spec.PodInfoOnMount, fldPath.Child("podInfoOnMount"))...)
	return allErrs
}
source: func (s *Stats) AtomicClone() Stats {
	return Stats{
		TotalItemsRecopied:            atomic.LoadInt64(&s.TotalItemsRecopied),
		TotalItemsAsyncPut:            atomic.LoadInt64(&s.TotalItemsAsyncPut),
		RecopyTransactionCount:        atomic.LoadInt64(&s.RecopyTransactionCount),
		TotalItemsDeletedDuringRecopy: atomic.LoadInt64(&s.TotalItemsDeletedDuringRecopy),
		TotalReadCount:                atomic.LoadInt64(&s.TotalReadCount),
		TotalWriteCount:               atomic.LoadInt64(&s.TotalWriteCount),
		TotalDeleteCount:              atomic.LoadInt64(&s.TotalDeleteCount),
		TotalCycleCount:               atomic.LoadInt64(&s.TotalCycleCount),
		TotalErrorsDuringRecopy:       atomic.LoadInt64(&s.TotalErrorsDuringRecopy),
		TotalReadMovementsSkipped:     atomic.LoadInt64(&s.TotalReadMovementsSkipped),
		TotalReadMovementsAdded:       atomic.LoadInt64(&s.TotalReadMovementsAdded),
	}
}
source: func DirExists(filename string) bool {
	fileInfo, err := os.Stat(filename)
	return err == nil && fileInfo.IsDir()
}
source: func (this *RedisStore) Get(id string) (*Session, error) {
	key := id
	if this.opts.KeyPrefix != "" {
		key = this.opts.KeyPrefix + ":" + id
	}
	b, err := redis.Bytes(this.conn.Do("GET", key))
	if err != nil {
		return nil, err
	}
	var sess Session
	err = json.Unmarshal(b, &sess)
	if err != nil {
		return nil, err
	}
	return &sess, nil
}
source: func (pc *PropertyCollector) WaitForUpdates(ctx *Context, r *types.WaitForUpdates) soap.HasFault {
	body := &methods.WaitForUpdatesBody{}

	res := pc.WaitForUpdatesEx(ctx, &types.WaitForUpdatesEx{
		This:    r.This,
		Version: r.Version,
	})

	if res.Fault() != nil {
		body.Fault_ = res.Fault()
	} else {
		body.Res = &types.WaitForUpdatesResponse{
			Returnval: *res.(*methods.WaitForUpdatesExBody).Res.Returnval,
		}
	}

	return body
}
source: func (m *ExpirationManager) loadEntryInternal(ctx context.Context, leaseID string, restoreMode bool, checkRestored bool) (*leaseEntry, error) {
	ns, err := namespace.FromContext(ctx)
	if err != nil {
		return nil, err
	}

	view := m.leaseView(ns)
	out, err := view.Get(ctx, leaseID)
	if err != nil {
		return nil, errwrap.Wrapf(fmt.Sprintf("failed to read lease entry %s: {{err}}", leaseID), err)
	}
	if out == nil {
		return nil, nil
	}
	le, err := decodeLeaseEntry(out.Value)
	if err != nil {
		return nil, errwrap.Wrapf(fmt.Sprintf("failed to decode lease entry %s: {{err}}", leaseID), err)
	}
	le.namespace = ns

	if restoreMode {
		if checkRestored {
			// If we have already loaded this lease, we don't need to update on
			// load. In the case of renewal and revocation, updatePending will be
			// done after making the appropriate modifications to the lease.
			if _, ok := m.restoreLoaded.Load(leaseID); ok {
				return le, nil
			}
		}

		// Update the cache of restored leases, either synchronously or through
		// the lazy loaded restore process
		m.restoreLoaded.Store(le.LeaseID, struct{}{})

		// Setup revocation timer
		m.updatePending(le, le.ExpireTime.Sub(time.Now()))
	}
	return le, nil
}
source: func (n *IpfsNode) teardown() error {
	log.Debug("core is shutting down...")
	// owned objects are closed in this teardown to ensure that they're closed
	// regardless of which constructor was used to add them to the node.
	var closers []io.Closer

	// NOTE: The order that objects are added(closed) matters, if an object
	// needs to use another during its shutdown/cleanup process, it should be
	// closed before that other object

	if n.FilesRoot != nil {
		closers = append(closers, n.FilesRoot)
	}

	if n.Exchange != nil {
		closers = append(closers, n.Exchange)
	}

	if n.Mounts.Ipfs != nil && !n.Mounts.Ipfs.IsActive() {
		closers = append(closers, mount.Closer(n.Mounts.Ipfs))
	}
	if n.Mounts.Ipns != nil && !n.Mounts.Ipns.IsActive() {
		closers = append(closers, mount.Closer(n.Mounts.Ipns))
	}

	if n.DHT != nil {
		closers = append(closers, n.DHT.Process())
	}

	if n.Blocks != nil {
		closers = append(closers, n.Blocks)
	}

	if n.Bootstrapper != nil {
		closers = append(closers, n.Bootstrapper)
	}

	if n.PeerHost != nil {
		closers = append(closers, n.PeerHost)
	}

	// Repo closed last, most things need to preserve state here
	closers = append(closers, n.Repo)

	var errs []error
	for _, closer := range closers {
		if err := closer.Close(); err != nil {
			errs = append(errs, err)
		}
	}
	if len(errs) > 0 {
		return errs[0]
	}
	return nil
}
source: func (s *SyncedSet) Add(datas ...interface{}) {
	s.Lock()
	defer s.Unlock()
	for _, data := range datas {
		s.set[data] = true
	}
}
source: func Convert_v1_MetricStatus_To_autoscaling_MetricStatus(in *v1.MetricStatus, out *autoscaling.MetricStatus, s conversion.Scope) error {
	return autoConvert_v1_MetricStatus_To_autoscaling_MetricStatus(in, out, s)
}
source: func Register(s *grpc.Server) {
	rpb.RegisterServerReflectionServer(s, &serverReflectionServer{
		s: s,
	})
}
source: func ParseDuration(s string) (d time.Duration, err error) {
	r := strings.NewReader(s)

	switch {
	case strings.HasSuffix(s, "d"):
		var v float64
		_, err = fmt.Fscanf(r, "%fd", &v)
		d = time.Duration(v * float64(24*time.Hour))
	case strings.HasSuffix(s, "w"):
		var v float64
		_, err = fmt.Fscanf(r, "%fw", &v)
		d = time.Duration(v * float64(24*time.Hour*7))
	case strings.HasSuffix(s, "mo"):
		var v float64
		_, err = fmt.Fscanf(r, "%fmo", &v)
		d = time.Duration(v * float64(30*24*time.Hour))
	case strings.HasSuffix(s, "M"):
		var v float64
		_, err = fmt.Fscanf(r, "%fM", &v)
		d = time.Duration(v * float64(30*24*time.Hour))
	default:
		d, err = time.ParseDuration(s)
	}

	return
}
source: func (dsw *desiredStateOfWorld) DeleteSnapshot(snapshotName string) error {
	dsw.Lock()
	defer dsw.Unlock()

	glog.Infof("Deleting snapshot from desired state of world: %s", snapshotName)

	delete(dsw.snapshots, snapshotName)
	return nil
}
source: func (c *Client) GIF(id string) (GIF, error) {
	if strings.ContainsAny(id, "/&?") {
		return GIF{}, fmt.Errorf("Invalid giphy id: `%v`", id)
	}

	req, err := c.NewRequest("/gifs/" + id)
	if err != nil {
		return GIF{}, err
	}

	var gif GIF
	if _, err = c.Do(req, &gif); err != nil {
		return GIF{}, err
	}

	if gif.RawData == nil || gif.RawData[0] == '[' {
		return GIF{}, ErrNoImageFound
	}

	// Check if the first character in Data is a {
	if gif.RawData[0] == '{' {
		var d Data

		err = json.Unmarshal(gif.RawData, &d)
		if err != nil {
			return GIF{}, err
		}

		gif.Data = d

		return gif, nil
	}

	return GIF{}, ErrUnknown
}
source: func ReplicaSetMembers(pool *StatePool) ([]replicaset.Member, error) {
	return replicaset.CurrentMembers(pool.SystemState().MongoSession())
}
source: func (b *bufferedBackend) Shutdown() {
	// Wait until the routine spawned in Run method exits.
	<-b.shutdownCh

	// Wait until all sending routines exit.
	//
	// - When b.shutdownCh is closed, we know that the goroutine in Run has terminated.
	// - This means that processIncomingEvents has terminated.
	// - Which means that b.buffer is closed and cannot accept any new events anymore.
	// - Because processEvents is called synchronously from the Run goroutine, the waitgroup has its final value.
	// Hence wg.Wait will not miss any more outgoing batches.
	b.wg.Wait()

	b.delegateBackend.Shutdown()
}
source: func RemoveFromSlice(slice []string, values ...string) []string {
	output := make([]string, 0, len(slice))

	remove := make(map[string]bool)
	for _, value := range values {
		remove[value] = true
	}

	for _, s := range slice {
		_, ok := remove[s]
		if ok {
			continue
		}
		output = append(output, s)
	}

	return output
}
source: func (section *Section) Keys() []string {
	var keys []string
	for key := range section.values {
		keys = append(keys, key)
	}

	sort.Strings(keys)
	return keys
}
source: func Zeros(r, c uint) *Matrix {
	res := make([][]float32, r)
	for y := 0; y < int(r); y++ {
		res[y] = make([]float32, c)
	}
	return NewMatrix(res)
}
source: func (s *Service) LogDrainList(ctx context.Context, appIdentity string, lr *ListRange) (LogDrainListResult, error) {
	var logDrain LogDrainListResult
	return logDrain, s.Get(ctx, &logDrain, fmt.Sprintf("/apps/%v/log-drains", appIdentity), nil, lr)
}
source: func (w *WIF) String() string {
	// Precalculate size.  Maximum number of bytes before base58 encoding
	// is one byte for the network, 32 bytes of private key, possibly one
	// extra byte if the pubkey is to be compressed, and finally four
	// bytes of checksum.
	encodeLen := 1 + floec.PrivKeyBytesLen + 4
	if w.CompressPubKey {
		encodeLen++
	}

	a := make([]byte, 0, encodeLen)
	a = append(a, w.netID)
	// Pad and append bytes manually, instead of using Serialize, to
	// avoid another call to make.
	a = paddedAppend(floec.PrivKeyBytesLen, a, w.PrivKey.D.Bytes())
	if w.CompressPubKey {
		a = append(a, compressMagic)
	}
	cksum := chainhash.DoubleHashB(a)[:4]
	a = append(a, cksum...)
	return base58.Encode(a)
}
source: func New(name string) Logger {
	l := Logger(&logger{
		level:       levels.DEBUG,
		name:        name,
		enabled:     make(map[levels.LogLevel]bool),
		appender:    appenders.Console(),
		children:    make([]Logger, 0),
		parent:      nil,
		ExitOnFatal: true,
	})
	l.SetLevel(levels.DEBUG)
	return l
}
source: func (session *SafeSession) Find(keyspace, shard string, tabletType topodatapb.TabletType) int64 {
	if session == nil {
		return 0
	}
	session.mu.Lock()
	defer session.mu.Unlock()
	for _, shardSession := range session.ShardSessions {
		if keyspace == shardSession.Target.Keyspace && tabletType == shardSession.Target.TabletType && shard == shardSession.Target.Shard {
			return shardSession.TransactionId
		}
	}
	return 0
}
source: func (p *PathStruct) Get(ctx context.Context, s logical.Storage) (map[string]interface{}, error) {
	entry, err := s.Get(ctx, fmt.Sprintf("struct/%s", p.Name))
	if err != nil {
		return nil, err
	}
	if entry == nil {
		return nil, nil
	}

	var result map[string]interface{}
	if err := jsonutil.DecodeJSON(entry.Value, &result); err != nil {
		return nil, err
	}

	return result, nil
}
source: func CreateDevice(poolName string, deviceID int) error {
	logrus.Debugf("devicemapper: CreateDevice(poolName=%v, deviceID=%v)", poolName, deviceID)
	task, err := TaskCreateNamed(deviceTargetMsg, poolName)
	if task == nil {
		return err
	}

	if err := task.setSector(0); err != nil {
		return fmt.Errorf("devicemapper: Can't set sector %s", err)
	}

	if err := task.setMessage(fmt.Sprintf("create_thin %d", deviceID)); err != nil {
		return fmt.Errorf("devicemapper: Can't set message %s", err)
	}

	dmSawExist = false // reset before the task is run
	if err := task.run(); err != nil {
		// Caller wants to know about ErrDeviceIDExists so that it can try with a different device id.
		if dmSawExist {
			return ErrDeviceIDExists
		}

		return fmt.Errorf("devicemapper: Error running CreateDevice %s", err)

	}
	return nil
}
source: func (tqsc *Controller) GetQueryRules(ruleSource string) *rules.Rules {
	tqsc.mu.Lock()
	defer tqsc.mu.Unlock()
	return tqsc.queryRulesMap[ruleSource]
}
source: func (t *Tracker) watchConsulEvents() {
	// checkTicker is the ticker that triggers us to look at the checks in
	// Consul
	checkTicker := time.NewTicker(consulCheckLookupInterval)
	defer checkTicker.Stop()

	// healthyTimer fires when the checks have been healthy for the
	// MinHealthyTime
	healthyTimer := time.NewTimer(0)
	if !healthyTimer.Stop() {
		select {
		case <-healthyTimer.C:
		default:
		}
	}

	// primed marks whether the healthy timer has been set
	primed := false

	// Store whether the last Consul checks call was successful or not
	consulChecksErr := false

	// allocReg are the registered objects in Consul for the allocation
	var allocReg *consul.AllocRegistration

OUTER:
	for {
		select {
		case <-t.ctx.Done():
			return
		case <-checkTicker.C:
			newAllocReg, err := t.consulClient.AllocRegistrations(t.alloc.ID)
			if err != nil {
				if !consulChecksErr {
					consulChecksErr = true
					t.logger.Warn("error looking up Consul registrations for allocation", "error", err, "alloc_id", t.alloc.ID)
				}
				continue OUTER
			} else {
				consulChecksErr = false
				allocReg = newAllocReg
			}
		case <-healthyTimer.C:
			t.setCheckHealth(true)
		}

		if allocReg == nil {
			continue
		}

		// Store the task registrations
		t.l.Lock()
		for task, reg := range allocReg.Tasks {
			t.taskHealth[task].taskRegistrations = reg
		}
		t.l.Unlock()

		// Detect if all the checks are passing
		passed := true

	CHECKS:
		for _, treg := range allocReg.Tasks {
			for _, sreg := range treg.Services {
				for _, check := range sreg.Checks {
					if check.Status == api.HealthPassing {
						continue
					}

					passed = false
					t.setCheckHealth(false)
					break CHECKS
				}
			}
		}

		if !passed {
			// Reset the timer since we have transitioned back to unhealthy
			if primed {
				if !healthyTimer.Stop() {
					select {
					case <-healthyTimer.C:
					default:
					}
				}
				primed = false
			}
		} else if !primed {
			// Reset the timer to fire after MinHealthyTime
			if !healthyTimer.Stop() {
				select {
				case <-healthyTimer.C:
				default:
				}
			}

			primed = true
			healthyTimer.Reset(t.minHealthyTime)
		}
	}
}
source: func (b *BtcWallet) SendOutputs(outputs []*wire.TxOut,
	feeRate lnwallet.SatPerKWeight) (*wire.MsgTx, error) {

	// Convert our fee rate from sat/kw to sat/kb since it's required by
	// SendOutputs.
	feeSatPerKB := btcutil.Amount(feeRate.FeePerKVByte())

	// Sanity check outputs.
	if len(outputs) < 1 {
		return nil, lnwallet.ErrNoOutputs
	}
	return b.wallet.SendOutputs(outputs, defaultAccount, 1, feeSatPerKB)
}
source: func (s UCS2) Decode() []byte {
	e := unicode.UTF16(unicode.BigEndian, unicode.IgnoreBOM)
	es, _, err := transform.Bytes(e.NewDecoder(), s)
	if err != nil {
		return s
	}
	return es
}
source: func (s *Server) Get(ctx context.Context, q *ApplicationQuery) (*appv1.Application, error) {
	appIf := s.appclientset.ArgoprojV1alpha1().Applications(s.ns)
	a, err := appIf.Get(*q.Name, metav1.GetOptions{})
	if err != nil {
		return nil, err
	}
	if err := s.enf.EnforceErr(ctx.Value("claims"), rbacpolicy.ResourceApplications, rbacpolicy.ActionGet, appRBACName(*a)); err != nil {
		return nil, err
	}
	if q.Refresh != nil {
		refreshType := appv1.RefreshTypeNormal
		if *q.Refresh == string(appv1.RefreshTypeHard) {
			refreshType = appv1.RefreshTypeHard
		}
		_, err = argoutil.RefreshApp(appIf, *q.Name, refreshType)
		if err != nil {
			return nil, err
		}
		a, err = argoutil.WaitForRefresh(ctx, appIf, *q.Name, nil)
		if err != nil {
			return nil, err
		}
	}
	return a, nil
}
source: func (p *Point) Subtract(p2 Point) *Point {
	p.X -= p2.X
	p.Y -= p2.Y
	return p
}
source: func (s *ListSamplesOutput) SetSamples(v []*Sample) *ListSamplesOutput {
	s.Samples = v
	return s
}
source: func (r *Timing) Mean() uint32 {
	sortedDurations := r.SortedDurations()
	var sum time.Duration
	for _, d := range sortedDurations {
		sum += d
	}

	length := int64(len(sortedDurations))
	if length == 0 {
		return 0
	}

	return uint32(sum.Nanoseconds()/length) / 1000000
}
source: func (client *Client) GetServiceBrokers(filters ...Filter) ([]ServiceBroker, Warnings, error) {
	request, err := client.newHTTPRequest(requestOptions{
		RequestName: internal.GetServiceBrokersRequest,
		Query:       ConvertFilterParameters(filters),
	})

	if err != nil {
		return nil, nil, err
	}

	var fullBrokersList []ServiceBroker
	warnings, err := client.paginate(request, ServiceBroker{}, func(item interface{}) error {
		if broker, ok := item.(ServiceBroker); ok {
			fullBrokersList = append(fullBrokersList, broker)
		} else {
			return ccerror.UnknownObjectInListError{
				Expected:   ServiceBroker{},
				Unexpected: item,
			}
		}
		return nil
	})

	return fullBrokersList, warnings, err
}
source: func (c *Cron) Start() {
	if c.running {
		return
	}
	c.running = true
	go c.run()
}
source: func requestToMsgPost(req *http.Request) (*dns.Msg, error) {
	defer req.Body.Close()
	return toMsg(req.Body)
}
source: func Has(in interface{}, key interface{}) bool {
	av := reflect.ValueOf(in)

	switch av.Kind() {
	case reflect.Map:
		kv := reflect.ValueOf(key)
		return av.MapIndex(kv).IsValid()
	case reflect.Slice, reflect.Array:
		l := av.Len()
		for i := 0; i < l; i++ {
			v := av.Index(i).Interface()
			if reflect.DeepEqual(v, key) {
				return true
			}
		}
	}

	return false
}
source: func (s *Scratch) matches(ct cTable, w io.Writer) {
	if s == nil || len(s.dt.single) == 0 {
		return
	}
	dt := s.dt.single[:1<<s.actualTableLog]
	tablelog := s.actualTableLog
	ok := 0
	broken := 0
	for sym, enc := range ct {
		errs := 0
		broken++
		if enc.nBits == 0 {
			for _, dec := range dt {
				if dec.byte == byte(sym) {
					fmt.Fprintf(w, "symbol %x has decoder, but no encoder\n", sym)
					errs++
					break
				}
			}
			if errs == 0 {
				broken--
			}
			continue
		}
		// Unused bits in input
		ub := tablelog - enc.nBits
		top := enc.val << ub
		// decoder looks at top bits.
		dec := dt[top]
		if dec.nBits != enc.nBits {
			fmt.Fprintf(w, "symbol 0x%x bit size mismatch (enc: %d, dec:%d).\n", sym, enc.nBits, dec.nBits)
			errs++
		}
		if dec.byte != uint8(sym) {
			fmt.Fprintf(w, "symbol 0x%x decoder output mismatch (enc: %d, dec:%d).\n", sym, sym, dec.byte)
			errs++
		}
		if errs > 0 {
			fmt.Fprintf(w, "%d errros in base, stopping\n", errs)
			continue
		}
		// Ensure that all combinations are covered.
		for i := uint16(0); i < (1 << ub); i++ {
			vval := top | i
			dec := dt[vval]
			if dec.nBits != enc.nBits {
				fmt.Fprintf(w, "symbol 0x%x bit size mismatch (enc: %d, dec:%d).\n", vval, enc.nBits, dec.nBits)
				errs++
			}
			if dec.byte != uint8(sym) {
				fmt.Fprintf(w, "symbol 0x%x decoder output mismatch (enc: %d, dec:%d).\n", vval, sym, dec.byte)
				errs++
			}
			if errs > 20 {
				fmt.Fprintf(w, "%d errros, stopping\n", errs)
				break
			}
		}
		if errs == 0 {
			ok++
			broken--
		}
	}
	if broken > 0 {
		fmt.Fprintf(w, "%d broken, %d ok\n", broken, ok)
	}
}
source: func (c *Client) registerNode() error {
	node := c.Node()
	req := structs.NodeRegisterRequest{
		Node:         node,
		WriteRequest: structs.WriteRequest{Region: c.Region()},
	}
	var resp structs.NodeUpdateResponse
	if err := c.RPC("Node.Register", &req, &resp); err != nil {
		return err
	}

	// Update the node status to ready after we register.
	c.configLock.Lock()
	node.Status = structs.NodeStatusReady
	c.config.Node.Status = structs.NodeStatusReady
	c.configLock.Unlock()

	c.logger.Info("node registration complete")
	if len(resp.EvalIDs) != 0 {
		c.logger.Debug("evaluations triggered by node registration", "num_evals", len(resp.EvalIDs))
	}

	c.heartbeatLock.Lock()
	defer c.heartbeatLock.Unlock()
	c.lastHeartbeat = time.Now()
	c.heartbeatTTL = resp.HeartbeatTTL
	return nil
}
source: func (e *extension) Input() (string, string) {
	parts := strings.Split(e.InputTypeOverride, ".")
	return parts[len(parts)-1], strings.Join(parts[0:len(parts)-1], ".")
}
source: func (c *ItemConsume) Backup2(t1 LexItem) {
	c.items[1] = t1
	c.peekCount = 2
}
source: func (entry *Entry) Panicln(args ...interface{}) {
	entry.WithField(errorLevelKey, "panic").Entry.Errorln(args...)
	safeRollbarWait(time.Second)
	panic(fmt.Sprint(args...))
}
source: func typeIsNumeric(typ reflect.Type) bool {
	k := typ.Kind()
	switch k {
	case reflect.Int, reflect.Int8, reflect.Int16, reflect.Int32, reflect.Int64, reflect.Uint, reflect.Uint8, reflect.Uint16, reflect.Uint32, reflect.Uint64, reflect.Float32, reflect.Float64:
		return true
	default:
		return false
	}
}
source: func (c *Client) signBlob(ctx context.Context, bb schema.Buildable, sigTime time.Time) (string, error) {
	signer, err := c.Signer()
	if err != nil {
		return "", err
	}
	return bb.Builder().SignAt(ctx, signer, sigTime)
}
source: func InstallExtensions(schema, migrationsDir string, db *sqlx.DB) error {
	extensions, err := getExtensions(migrationsDir)
	if err != nil {
		return err
	}
	for _, extension := range extensions {
		_, err := db.Exec(fmt.Sprintf("CREATE EXTENSION IF NOT EXISTS %v WITH SCHEMA %v", extension, schema))
		if err != nil {
			return err
		}
	}
	return nil
}
source: func (p *Plugin) String() string {
	var str string
	if p.Id != "" {
		str = fmt.Sprintf("%x - %s v.%s", string(p.Id), p.Name, p.Version)
	} else {
		str = fmt.Sprintf("%s v.%s", p.Name, p.Version)
	}
	if p.Id != "" && !p.Enabled {
		str = fmt.Sprintf("%s DISABLED", str)
	}
	return str
}
source: func (c *HyperClient) DeleteService(podID string, services []*types.UserService) error {
	_, err := c.client.ServiceDelete(
		c.ctx,
		&types.ServiceDelRequest{PodID: podID, Services: services},
	)

	if err != nil {
		return err
	}
	return nil
}
source: func compileTemplate(p, base string) error {
	ext := path.Ext(p)
	c, ok := compilers[ext]
	// Ignore file if no template compiler exist for this extension
	if ok {
		t, err := c.Compile(p)
		if err != nil {
			return err
		}
		key, err := filepath.Rel(base, p)
		if err != nil {
			return err
		}
		ghost.LogFn("ghost.templates : storing template for file %s", key)
		templaters[key] = t
	}
	return nil
}
source: func (c *AddPhysicalHostCmd) Run(app subcommands.Application, args []string, env subcommands.Env) int {
	ctx := cli.GetContext(app, c, env)
	// TODO(smut): Validate required fields client-side.
	req := &crimson.CreatePhysicalHostRequest{
		Host: &c.host,
	}
	client := getClient(ctx)
	resp, err := client.CreatePhysicalHost(ctx, req)
	if err != nil {
		errors.Log(ctx, err)
		return 1
	}
	printPhysicalHosts(c.f.tsv, resp)
	return 0
}
source: func (r *Router) ServeHTTP(rw http.ResponseWriter, req *http.Request) {
	r.hrouter.ServeHTTP(rw, req)
}
source: func NewEventsCommand(dockerCli command.Cli) *cobra.Command {
	options := eventsOptions{filter: opts.NewFilterOpt()}

	cmd := &cobra.Command{
		Use:   "events [OPTIONS]",
		Short: "Get real time events from the server",
		Args:  cli.NoArgs,
		RunE: func(cmd *cobra.Command, args []string) error {
			return runEvents(dockerCli, &options)
		},
	}

	flags := cmd.Flags()
	flags.StringVar(&options.since, "since", "", "Show all events created since timestamp")
	flags.StringVar(&options.until, "until", "", "Stream events until this timestamp")
	flags.VarP(&options.filter, "filter", "f", "Filter output based on conditions provided")
	flags.StringVar(&options.format, "format", "", "Format the output using the given Go template")

	return cmd
}
source: func ReferersEqual(o1, o2 *ReferersOption) bool {
	if o1 != nil {
		return o1.Equal(o2)
	}
	if o2 != nil {
		return o2.Equal(o1)
	}
	return true
}
source: func Deserialize(p []byte) (*m.MemInfo, error) {
	var inf m.MemInfo
	err := json.Unmarshal(p, &inf)
	if err != nil {
		return nil, err
	}
	return &inf, nil
}
source: func (WindowsStrategy) configureAutoMount(ctx context.Context, disk string) error {
	// TODO(smut): Mount the specified disk.
	return errors.New("mounting disks is unsupported on Windows")
}
source: func (c *Converter) RegisterIgnoredConversion(from, to interface{}) error {
	typeFrom := reflect.TypeOf(from)
	typeTo := reflect.TypeOf(to)
	if reflect.TypeOf(from).Kind() != reflect.Ptr {
		return fmt.Errorf("expected pointer arg for 'from' param 0, got: %v", typeFrom)
	}
	if typeTo.Kind() != reflect.Ptr {
		return fmt.Errorf("expected pointer arg for 'to' param 1, got: %v", typeTo)
	}
	c.ignoredConversions[typePair{typeFrom.Elem(), typeTo.Elem()}] = struct{}{}
	return nil
}
source: func (s *Session) RequestWithLockedBucket(method, urlStr, contentType string, b []byte, bucket *Bucket, sequence int) (response []byte, err error) {
	if s.Debug {
		log.Printf("API REQUEST %8s :: %s\n", method, urlStr)
		log.Printf("API REQUEST  PAYLOAD :: [%s]\n", string(b))
	}

	req, err := http.NewRequest(method, urlStr, bytes.NewBuffer(b))
	if err != nil {
		bucket.Release(nil)
		return
	}

	// Not used on initial login..
	// TODO: Verify if a login, otherwise complain about no-token
	if s.Token != "" {
		req.Header.Set("authorization", s.Token)
	}

	req.Header.Set("Content-Type", contentType)
	// TODO: Make a configurable static variable.
	req.Header.Set("User-Agent", "DiscordBot (https://github.com/bwmarrin/discordgo, v"+VERSION+")")

	if s.Debug {
		for k, v := range req.Header {
			log.Printf("API REQUEST   HEADER :: [%s] = %+v\n", k, v)
		}
	}

	resp, err := s.Client.Do(req)
	if err != nil {
		bucket.Release(nil)
		return
	}
	defer func() {
		err2 := resp.Body.Close()
		if err2 != nil {
			log.Println("error closing resp body")
		}
	}()

	err = bucket.Release(resp.Header)
	if err != nil {
		return
	}

	response, err = ioutil.ReadAll(resp.Body)
	if err != nil {
		return
	}

	if s.Debug {

		log.Printf("API RESPONSE  STATUS :: %s\n", resp.Status)
		for k, v := range resp.Header {
			log.Printf("API RESPONSE  HEADER :: [%s] = %+v\n", k, v)
		}
		log.Printf("API RESPONSE    BODY :: [%s]\n\n\n", response)
	}

	switch resp.StatusCode {
	case http.StatusOK:
	case http.StatusCreated:
	case http.StatusNoContent:
	case http.StatusBadGateway:
		// Retry sending request if possible
		if sequence < s.MaxRestRetries {

			s.log(LogInformational, "%s Failed (%s), Retrying...", urlStr, resp.Status)
			response, err = s.RequestWithLockedBucket(method, urlStr, contentType, b, s.Ratelimiter.LockBucketObject(bucket), sequence+1)
		} else {
			err = fmt.Errorf("Exceeded Max retries HTTP %s, %s", resp.Status, response)
		}
	case 429: // TOO MANY REQUESTS - Rate limiting
		rl := TooManyRequests{}
		err = json.Unmarshal(response, &rl)
		if err != nil {
			s.log(LogError, "rate limit unmarshal error, %s", err)
			return
		}
		s.log(LogInformational, "Rate Limiting %s, retry in %d", urlStr, rl.RetryAfter)
		s.handleEvent(rateLimitEventType, RateLimit{TooManyRequests: &rl, URL: urlStr})

		time.Sleep(rl.RetryAfter * time.Millisecond)
		// we can make the above smarter
		// this method can cause longer delays than required

		response, err = s.RequestWithLockedBucket(method, urlStr, contentType, b, s.Ratelimiter.LockBucketObject(bucket), sequence)
	case http.StatusUnauthorized:
		if strings.Index(s.Token, "Bot ") != 0 {
			s.log(LogInformational, ErrUnauthorized.Error())
			err = ErrUnauthorized
		}
		fallthrough
	default: // Error condition
		err = newRestError(req, resp, response)
	}

	return
}
source: func (s *PSTNDialIn) SetOneClickPinDelay(v string) *PSTNDialIn {
	s.OneClickPinDelay = &v
	return s
}
source: func RoleScopeFilterByRole(id uuid.UUID) func(db *gorm.DB) *gorm.DB {
	return func(db *gorm.DB) *gorm.DB {
		return db.Where("role_id = ?", id)
	}
}
source: func WithTargetEndpoints(keys ...string) RequestOption {
	return func(ctx context.Client, opts *requestOptions) error {

		var targets []fab.Peer

		for _, url := range keys {

			peerCfg, err := comm.NetworkPeerConfig(ctx.EndpointConfig(), url)
			if err != nil {
				return err
			}

			peer, err := ctx.InfraProvider().CreatePeerFromConfig(peerCfg)
			if err != nil {
				return errors.WithMessage(err, "creating peer from config failed")
			}

			targets = append(targets, peer)
		}

		return WithTargets(targets...)(ctx, opts)
	}
}
source: func (w *unitsWatcher) initial() ([]string, error) {
	initialNames, err := w.getUnits()
	if err != nil {
		return nil, err
	}
	return w.watchUnits(initialNames, nil)
}
source: func checkCandidateBase(l *absurllexer) {
	l.consumeQuote()

	if !bytes.HasPrefix(l.content[l.pos:], relURLPrefix) {
		return
	}

	// check for schemaless URLs
	posAfter := l.pos + relURLPrefixLen
	if posAfter >= len(l.content) {
		return
	}
	r, _ := utf8.DecodeRune(l.content[posAfter:])
	if r == '/' {
		// schemaless: skip
		return
	}
	if l.pos > l.start {
		l.emit()
	}
	l.pos += relURLPrefixLen
	l.w.Write(l.path)
	l.start = l.pos
}
source: func (s *ShareDetails) SetSuccessfulShares(v []*string) *ShareDetails {
	s.SuccessfulShares = v
	return s
}
source: func SliceContainsString(slice []string, str string) bool {
	for _, value := range slice {
		if value == str {
			return true
		}
	}
	return false
}
source: func (sc *StringConstraint) Default(v interface{}) *StringConstraint {
	sc.defaultValue.initialized = true
	sc.defaultValue.value = v
	return sc
}
source: func (s *CostTypes) SetIncludeTax(v bool) *CostTypes {
	s.IncludeTax = &v
	return s
}
source: func (c *Client) DomainList(appIdentity string, lr *ListRange) ([]Domain, error) {
	req, err := c.NewRequest("GET", "/apps/"+appIdentity+"/domains", nil, nil)
	if err != nil {
		return nil, err
	}

	if lr != nil {
		lr.SetHeader(req)
	}

	var domainsRes []Domain
	return domainsRes, c.DoReq(req, &domainsRes)
}
source: func (t *tableCommon) AllocAutoID(ctx sessionctx.Context) (int64, error) {
	rowID, err := t.Allocator(ctx).Alloc(t.tableID)
	if err != nil {
		return 0, err
	}
	if t.meta.ShardRowIDBits > 0 {
		// Use max record ShardRowIDBits to check overflow.
		if OverflowShardBits(rowID, t.meta.MaxShardRowIDBits) {
			// If overflow, the rowID may be duplicated. For examples,
			// t.meta.ShardRowIDBits = 4
			// rowID = 0010111111111111111111111111111111111111111111111111111111111111
			// shard = 01000000000000000000000000000000000000000000000000000000000000000
			// will be duplicated with:
			// rowID = 0100111111111111111111111111111111111111111111111111111111111111
			// shard = 0010000000000000000000000000000000000000000000000000000000000000
			return 0, autoid.ErrAutoincReadFailed
		}
		txnCtx := ctx.GetSessionVars().TxnCtx
		if txnCtx.Shard == nil {
			shard := t.calcShard(txnCtx.StartTS)
			txnCtx.Shard = &shard
		}
		rowID |= *txnCtx.Shard
	}
	return rowID, nil
}
source: func addIssueAndSignCommonFields(fields map[string]*framework.FieldSchema) map[string]*framework.FieldSchema {
	fields["exclude_cn_from_sans"] = &framework.FieldSchema{
		Type:    framework.TypeBool,
		Default: false,
		Description: `If true, the Common Name will not be
included in DNS or Email Subject Alternate Names.
Defaults to false (CN is included).`,
		DisplayName: "Exclude Common Name from Subject Alternative Names (SANs)",
	}

	fields["format"] = &framework.FieldSchema{
		Type:    framework.TypeString,
		Default: "pem",
		Description: `Format for returned data. Can be "pem", "der",
or "pem_bundle". If "pem_bundle" any private
key and issuing cert will be appended to the
certificate pem. Defaults to "pem".`,
		AllowedValues: []interface{}{"pem", "der", "pem_bundle"},
	}

	fields["private_key_format"] = &framework.FieldSchema{
		Type:    framework.TypeString,
		Default: "der",
		Description: `Format for the returned private key.
Generally the default will be controlled by the "format"
parameter as either base64-encoded DER or PEM-encoded DER.
However, this can be set to "pkcs8" to have the returned
private key contain base64-encoded pkcs8 or PEM-encoded
pkcs8 instead. Defaults to "der".`,
		AllowedValues: []interface{}{"", "der", "pem", "pkcs8"},
	}

	fields["ip_sans"] = &framework.FieldSchema{
		Type: framework.TypeCommaStringSlice,
		Description: `The requested IP SANs, if any, in a
comma-delimited list`,
		DisplayName: "IP Subject Alternative Names (SANs)",
	}

	fields["uri_sans"] = &framework.FieldSchema{
		Type: framework.TypeCommaStringSlice,
		Description: `The requested URI SANs, if any, in a
comma-delimited list.`,
		DisplayName: "URI Subject Alternative Names (SANs)",
	}

	fields["other_sans"] = &framework.FieldSchema{
		Type: framework.TypeCommaStringSlice,
		Description: `Requested other SANs, in an array with the format
<oid>;UTF8:<utf8 string value> for each entry.`,
		DisplayName: "Other SANs",
	}

	return fields
} 13%|█▎        | 653/5000 [00:00<00:06, 690.86it/s]
source: func (d *Deleter) DeletePVs() {
	for _, pv := range d.Cache.ListPVs() {
		if pv.Status.Phase != v1.VolumeReleased {
			continue
		}
		name := pv.Name
		switch pv.Spec.PersistentVolumeReclaimPolicy {
		case v1.PersistentVolumeReclaimRetain:
			glog.V(4).Infof("reclaimVolume[%s]: policy is Retain, nothing to do", name)
		case v1.PersistentVolumeReclaimRecycle:
			glog.V(4).Infof("reclaimVolume[%s]: policy is Recycle which is not supported", name)
			d.RuntimeConfig.Recorder.Eventf(pv, v1.EventTypeWarning, "VolumeUnsupportedReclaimPolicy", "Volume has unsupported PersistentVolumeReclaimPolicy: Recycle")
		case v1.PersistentVolumeReclaimDelete:
			glog.V(4).Infof("reclaimVolume[%s]: policy is Delete", name)
			// Cleanup volume
			err := d.deletePV(pv)
			if err != nil {
				mode, modeErr := d.getVolMode(pv)
				if modeErr != nil {
					mode = "unknown"
				}
				deleteType := metrics.DeleteTypeProcess
				if d.shouldRunJob(mode) {
					deleteType = metrics.DeleteTypeJob
				}
				metrics.PersistentVolumeDeleteFailedTotal.WithLabelValues(string(mode), deleteType).Inc()
				cleaningLocalPVErr := fmt.Errorf("Error cleaning PV %q: %v", name, err.Error())
				d.RuntimeConfig.Recorder.Eventf(pv, v1.EventTypeWarning, common.EventVolumeFailedDelete, cleaningLocalPVErr.Error())
				glog.Error(err)
				continue
			}
		default:
			// Unknown PersistentVolumeReclaimPolicy
			d.RuntimeConfig.Recorder.Eventf(pv, v1.EventTypeWarning, "VolumeUnknownReclaimPolicy", "Volume has unrecognized PersistentVolumeReclaimPolicy")
		}
	}
}
source: func remove(na, r *api.GenericResource) bool {
	switch tr := r.Resource.(type) {
	case *api.GenericResource_DiscreteResourceSpec:
		if na.GetDiscreteResourceSpec() == nil {
			return false // Type change, ignore
		}

		na.GetDiscreteResourceSpec().Value -= tr.DiscreteResourceSpec.Value
		if na.GetDiscreteResourceSpec().Value <= 0 {
			return true
		}
	case *api.GenericResource_NamedResourceSpec:
		if na.GetNamedResourceSpec() == nil {
			return false // Type change, ignore
		}

		if tr.NamedResourceSpec.Value != na.GetNamedResourceSpec().Value {
			return false // not the right item, ignore
		}

		return true
	}

	return false
}
source: func PingIgnoreCertificate(surl string) (err error) {
	tr := &http.Transport{
		TLSClientConfig: &tls.Config{InsecureSkipVerify: true},
	}
	client := &http.Client{Transport: tr}
	resp, err := client.Get(surl)
	if err != nil {
		return
	}
	if resp.StatusCode < 200 || resp.StatusCode >= 400 {
		return ErrorPing2.New(nil, surl, resp.StatusCode)
	}
	return
}
source: func (r *Reader) Networks() *Networks {
	s := 4
	if r.Metadata.IPVersion == 6 {
		s = 16
	}
	return &Networks{
		reader: r,
		nodes: []netNode{
			{
				ip: make(net.IP, s),
			},
		},
	}
}
source: func (m *Mocker) RecipientIDs(context.Context, []byte) ([]string, error) {
	return staticPrivateKeyList.Recipients(), nil
}
source: func newAPIsProvider(acls map[string]*pb.APIResource) *aclsProvider {
	aclPolicyRefs := make(map[string]string)

	for key, acl := range acls {
		// If the policy is fully qualified, ie to /Channel/Application/Readers leave it alone
		// otherwise, make it fully qualified referring to /Channel/Application/policyName
		if '/' != acl.PolicyRef[0] {
			aclPolicyRefs[key] = "/" + ChannelGroupKey + "/" + ApplicationGroupKey + "/" + acl.PolicyRef
		} else {
			aclPolicyRefs[key] = acl.PolicyRef
		}
	}

	return &aclsProvider{
		aclPolicyRefs: aclPolicyRefs,
	}
}
source: func (self *tree) Set(key string, value interface{}) Map {
	hash := hashKey(key)
	return setLowLevel(self, hash, hash, key, value)
}
source: func printPodsMultilineWithIndent(w PrefixWriter, initialIndent, title, innerIndent string, pods []corev1.Pod) {
	w.Write(LEVEL_0, "%s%s:%s", initialIndent, title, innerIndent)

	if pods == nil || len(pods) == 0 {
		w.WriteLine("<none>")
		return
	}

	// to print pods in the sorted order
	sort.Slice(pods, func(i, j int) bool {
		cmpKey := func(pod corev1.Pod) string {
			return pod.Name
		}
		return cmpKey(pods[i]) < cmpKey(pods[j])
	})

	for i, pod := range pods {
		if i != 0 {
			w.Write(LEVEL_0, "%s", initialIndent)
			w.Write(LEVEL_0, "%s", innerIndent)
		}
		w.Write(LEVEL_0, "%s\n", pod.Name)
	}
}
source: func (c *Client) VerifyChainBlocksAsync(checkLevel, numBlocks int32) FutureVerifyChainResult {
	cmd := btcjson.NewVerifyChainCmd(&checkLevel, &numBlocks)
	return c.sendCmd(cmd)
}
source: func uncompressRpmPayloadReader(r io.Reader, hdr *RpmHeader) (io.Reader, error) {
	// Check to make sure payload format is a cpio archive. If the tag does
	// not exist, assume archive is cpio.
	if hdr.HasTag(PAYLOADFORMAT) {
		val, err := hdr.GetString(PAYLOADFORMAT)
		if err != nil {
			return nil, err
		}
		if val != "cpio" {
			return nil, fmt.Errorf("Unknown payload format %s", val)
		}
	}

	// Check to see how the payload was compressed. If the tag does not
	// exist, check if it is gzip, if not it is uncompressed.
	var compression string
	if hdr.HasTag(PAYLOADCOMPRESSOR) {
		val, err := hdr.GetString(PAYLOADCOMPRESSOR)
		if err != nil {
			return nil, err
		}
		compression = val
	} else {
		b := make([]byte, 4096)
		_, err := r.Read(b)
		if err != nil {
			return nil, err
		}
		if len(b) > 2 && b[0] == 0x1f && b[1] == 0x8b {
			compression = "gzip"
		} else {
			compression = "uncompressed"
		}
	}

	switch compression {
	case "gzip":
		return gzip.NewReader(r)
	case "bzip2":
		return bzip2.NewReader(r), nil
	case "lzma", "xz":
		return xz.NewReader(r, 0)
	case "uncompressed":
		return r, nil
	default:
		return nil, fmt.Errorf("Unknown compression type %s", compression)
	}
}
source: func (s *StateStore) SchedulerConfig() (uint64, *structs.SchedulerConfiguration, error) {
	tx := s.db.Txn(false)
	defer tx.Abort()

	// Get the scheduler config
	c, err := tx.First("scheduler_config", "id")
	if err != nil {
		return 0, nil, fmt.Errorf("failed scheduler config lookup: %s", err)
	}

	config, ok := c.(*structs.SchedulerConfiguration)
	if !ok {
		return 0, nil, nil
	}

	return config.ModifyIndex, config, nil
}
source: func (c *Client) DeleteIntervalById(id string) (err error) {
	check, err := c.IntervalById(id)
	if err != nil {
		if err == db.ErrNotFound {
			return nil
		}
		return
	}

	interval := models.NewInterval(check)
	conn := c.Pool.Get()
	defer conn.Close()

	_ = conn.Send("MULTI")
	deleteObject(interval, id, conn)

	_, err = conn.Do("EXEC")

	return err
}
source: func MakeAddReferenceArg(tlfID tlf.ID, id ID, context Context) keybase1.AddReferenceArg {
	return keybase1.AddReferenceArg{
		Ref:    makeReference(id, context),
		Folder: tlfID.String(),
	}
}
source: func (wc *watchChan) sync() error {
	opts := []clientv3.OpOption{}
	if wc.recursive {
		opts = append(opts, clientv3.WithPrefix())
	}
	getResp, err := wc.watcher.client.Get(wc.ctx, wc.key, opts...)
	if err != nil {
		return err
	}
	wc.initialRev = getResp.Header.Revision
	for _, kv := range getResp.Kvs {
		wc.sendEvent(parseKV(kv))
	}
	return nil
}
source: func (b *Button) Draw(p *Painter) {
	style := "button"
	if b.IsFocused() {
		style += ".focused"
	}
	p.WithStyle(style, func(p *Painter) {
		lines := strings.Split(b.text, "\n")
		for i, line := range lines {
			p.FillRect(0, i, b.Size().X, 1)
			p.DrawText(0, i, line)
		}
	})
}
source: func MapRemoveByKeyOp(binName string, key interface{}, returnType mapReturnType) *Operation {
	return newCDTCreateOperationValue1(_CDT_MAP_REMOVE_BY_KEY, _MAP_MODIFY, binName, key, returnType)
}
source: func (c *Client) LoadStream(ctx context.Context, in *s.LoadStreamRequest, opts ...grpc.CallOption) (
	*s.LoadStreamResponse, error) {

	resp, err := c.bundleRPC(ctx, opts, &s.BatchRequest_Entry{
		Value: &s.BatchRequest_Entry_LoadStream{LoadStream: in},
	})
	if err != nil {
		return nil, err
	}

	return resp.GetLoadStream(), nil
}
source: func (api *PublicWhisperAPI) DeleteSymKey(ctx context.Context, id string) bool {
	return api.w.DeleteSymKey(id)
}
source: func (trie *Trie) MatchSubtree(key Prefix) (matched bool) {
	_, _, matched, _ = trie.findSubtree(key)
	return
}
source: func (limit *simpleLimiter) Count(n int) error {
	now := time.Now()
	if now.After(limit.timeRead) {
		limit.numRead = 0
		limit.timeRead = now.Add(limit.Frequency)
	}
	limit.numRead += n
	if limit.numRead > limit.Amount {
		return ErrRateExceeded
	}
	return nil
}
source: func (c *DaemonConfig) WorkloadsEnabled() bool {
	for _, w := range c.Workloads {
		if w == "none" {
			return false
		}
	}

	return len(c.Workloads) > 0
}
source: func waitForToken(token *corev1.Secret, serviceAccount *corev1.ServiceAccount, timeout time.Duration, client corev1client.SecretInterface) (*corev1.Secret, error) {
	// there is no provided rounding function, so we use Round(x) === Floor(x + 0.5)
	timeoutSeconds := int64(math.Floor(timeout.Seconds() + 0.5))

	options := metav1.ListOptions{
		FieldSelector:   fields.SelectorFromSet(fields.Set(map[string]string{"metadata.name": token.Name})).String(),
		Watch:           true,
		ResourceVersion: token.ResourceVersion,
		TimeoutSeconds:  &timeoutSeconds,
	}

	watcher, err := client.Watch(options)
	if err != nil {
		return nil, fmt.Errorf("could not begin watch for token: %v", err)
	}

	ctx, cancel := context.WithTimeout(context.Background(), timeout)
	defer cancel()
	event, err := watchtools.UntilWithoutRetry(ctx, watcher, func(event watch.Event) (bool, error) {
		if event.Type == watch.Error {
			return false, fmt.Errorf("encountered error while watching for token: %v", event.Object)
		}

		eventToken, ok := event.Object.(*corev1.Secret)
		if !ok {
			return false, nil
		}

		if eventToken.Name != token.Name {
			return false, nil
		}

		switch event.Type {
		case watch.Modified:
			if sautil.IsServiceAccountToken(eventToken, serviceAccount) {
				return true, nil
			}
		case watch.Deleted:
			return false, errors.New("token was deleted before fulfillment by service account token controller")
		case watch.Added:
			return false, errors.New("unxepected action: token was added after initial creation")
		}
		return false, nil
	})
	if err != nil {
		return nil, err
	}

	return event.Object.(*corev1.Secret), nil
}
source: func readAddrType(conn net.Conn) (int, error) {
	// Read in the type of the remote host.
	addrType, err := readByte(conn)
	if err != nil {
		return 0, trace.Wrap(err)
	}

	// Based off the type, determine how many more bytes to read in for the
	// remote address. For IPv4 it's 4 bytes, for IPv6 it's 16, and for domain
	// names read in another byte to determine the length of the field.
	switch addrType {
	case socks5AddressTypeIPv4:
		return net.IPv4len, nil
	case socks5AddressTypeIPv6:
		return net.IPv6len, nil
	case socks5AddressTypeDomainName:
		len, err := readByte(conn)
		if err != nil {
			return 0, trace.Wrap(err)
		}
		return int(len), nil
	default:
		return 0, trace.BadParameter("unsupported address type: %v", addrType)
	}
}
source: func (c xlsxCalcChainCollection) Filter(fn func(v xlsxCalcChainC) bool) []xlsxCalcChainC {
	results := make([]xlsxCalcChainC, 0)
	for _, v := range c {
		if fn(v) {
			results = append(results, v)
		}
	}
	return results
}
source: func (s *GetDiskSnapshotOutput) SetDiskSnapshot(v *DiskSnapshot) *GetDiskSnapshotOutput {
	s.DiskSnapshot = v
	return s
}
source: func (t *TCB) UpdateStateInbound(tcp header.TCP) Result {
	st := t.handlerInbound(t, tcp)
	if st != ResultDrop {
		t.state = st
	}
	return st
}
source: func newWifiStater(fixtures string) (wifiStater, error) {
	if fixtures != "" {
		return &mockWifiStater{
			fixtures: fixtures,
		}, nil
	}

	return wifi.New()
}
source: func NewConfluentSource() *ConfluentSource {
	src := &ConfluentSource{
		cache: make(map[int32]avro.Schema),
	}
	src.Type = "raw"
	return src
}
source: func (fv FlagValues) Int(name string, defaultValue int) (int, error) {
	value, found := fv[name]
	if !found {
		return defaultValue, nil
	}
	i, err := strconv.Atoi(value)
	if err != nil {
		return 0, fmt.Errorf("flag %q: cannot parse integer from %q", name, value)
	}
	return i, nil
}
source: func NewConnectResult(attempt Attempt, connFactory ConnectionFactory) ConnectResult {
	return ConnectResult{Attempt: attempt, ConnFactory: connFactory}
}
source: func writeRoaringWithLen(r *roaring.Bitmap, w io.Writer,
	reuseBufVarint []byte) (int, error) {
	buf, err := r.ToBytes()
	if err != nil {
		return 0, err
	}

	var tw int

	// write out the length
	n := binary.PutUvarint(reuseBufVarint, uint64(len(buf)))
	nw, err := w.Write(reuseBufVarint[:n])
	tw += nw
	if err != nil {
		return tw, err
	}

	// write out the roaring bytes
	nw, err = w.Write(buf)
	tw += nw
	if err != nil {
		return tw, err
	}

	return tw, nil
}
source: func (res *Resource) AddValidator(validator *Validator) {
	for idx, v := range res.Validators {
		if v.Name == validator.Name {
			res.Validators[idx] = validator
			return
		}
	}

	res.Validators = append(res.Validators, validator)
}
source: func (h *HashMap) Get(k T) (T, bool) {
	hash := h.hash(k)
	for entry := h.table[hash]; entry != nil; entry = entry.next {
		if h.eq(entry.k, k) {
			return entry.v, true
		}
	}
	return nil, false
}
source: func (k *Item) SetSynchronizable(sync Synchronizable) {
	if sync != SynchronizableDefault {
		k.attr[SynchronizableKey] = syncTypeRef[sync]
	} else {
		delete(k.attr, SynchronizableKey)
	}
}
source: func GenerateMountName(mount *MountConfig) string {
	h := fnv.New32a()
	h.Write([]byte(mount.HostDir))
	h.Write([]byte(mount.MountDir))
	return fmt.Sprintf("mount-%x", h.Sum32())
}
source: func NewEndo(w *ombwire.Endorsement, tx *btcutil.Tx, blk *btcutil.Block, net *chaincfg.Params) (*Endorsement, error) {
	// Check Bid is correct length
	if len(w.GetBid()) != 32 {
		return nil, fmt.Errorf("Endo's bid is wrong len")
	}

	author, err := ParseAuthor(tx.MsgTx(), net)
	if err != nil {
		return nil, err
	}

	endo := &Endorsement{
		Block:  blk,
		Tx:     tx.MsgTx(),
		Wire:   w,
		Author: author,
	}

	return endo, nil
}
source: func (s *MemorySession) Delete(key string) error {
	delete(s.data, key)
	return nil
}
source: func (api *AgentToolsAPI) UpdateToolsAvailable() error {
	if !api.authorizer.AuthController() {
		return common.ErrPerm
	}
	return updateToolsAvailability(api.modelGetter, api.newEnviron, api.findTools, api.envVersionUpdate)
}
source: func (c *Client) StopServiceInstance(serviceID string, instanceID int) error {
	req := ServiceInstanceRequest{
		ServiceID:  serviceID,
		InstanceID: instanceID,
	}
	err := c.call("StopServiceInstance", req, new(string))
	return err
}
source: func HashToBig(hash *chainhash.Hash) *big.Int {
	// A Hash is in little-endian, but the big package wants the bytes in
	// big-endian, so reverse them.
	buf := *hash
	blen := len(buf)
	for i := 0; i < blen/2; i++ {
		buf[i], buf[blen-1-i] = buf[blen-1-i], buf[i]
	}

	return new(big.Int).SetBytes(buf[:])
}
source: func (is *identityMapperImpl) Verify(vkID, signature, message []byte) error {
	cert, err := is.Get(vkID)
	if err != nil {
		return err
	}
	return is.mcs.Verify(cert, signature, message)
}
source: func (s *VPNService) NewCreateVpnGatewayParams(vpcid string) *CreateVpnGatewayParams {
	p := &CreateVpnGatewayParams{}
	p.p = make(map[string]interface{})
	p.p["vpcid"] = vpcid
	return p
}
source: func (apic *APICache) GetBlockSummary(height int64) *BlockDataBasic {
	if !apic.IsEnabled() {
		return nil
	}
	cachedBlock := apic.GetCachedBlockByHeight(height)
	if cachedBlock != nil {
		return cachedBlock.summary
	}
	return nil
}
source: func (p *PeriodicDispatch) Tracked() []*structs.Job {
	p.l.RLock()
	defer p.l.RUnlock()
	tracked := make([]*structs.Job, len(p.tracked))
	i := 0
	for _, job := range p.tracked {
		tracked[i] = job
		i++
	}
	return tracked
}
source: func (is InterfaceStruct) Less(i, j int) bool {
	return is.LessF(i, j)
}
source: func NewBlockStore(db dbm.DB) *BlockStore {
	bsjson := LoadBlockStoreStateJSON(db)
	return &BlockStore{
		height: bsjson.Height,
		db:     db,
	}
}
source: func (r *Redis) BLPop(keys []string, timeout int) ([]string, error) {
	args := packArgs("BLPOP", keys, timeout)
	rp, err := r.ExecuteCommand(args...)
	if err != nil {
		return nil, err
	}
	if rp.Multi == nil {
		return nil, nil
	}
	return rp.ListValue()
}
source: func Convert_build_BuildStatusOutputTo_To_v1_BuildStatusOutputTo(in *build.BuildStatusOutputTo, out *v1.BuildStatusOutputTo, s conversion.Scope) error {
	return autoConvert_build_BuildStatusOutputTo_To_v1_BuildStatusOutputTo(in, out, s)
}
source: func (o *DestroyOneDefault) WithPayload(payload *models.Error) *DestroyOneDefault {
	o.Payload = payload
	return o
}
source: func (l Line) Center() Vec {
	return l.A.Add(l.A.To(l.B).Scaled(0.5))
}
source: func CopyFile(src, dst string) error {
	s, err := os.Open(src)
	if err != nil {
		return err
	}
	defer s.Close()
	d, err := os.Create(dst)
	if err != nil {
		return err
	}
	if _, err := io.Copy(d, s); err != nil {
		d.Close()
		return err
	}
	return d.Close()
}
source: func (v *view) ArangoSearchView() (ArangoSearchView, error) {
	if v.viewType != ViewTypeArangoSearch {
		return nil, WithStack(newArangoError(http.StatusConflict, 0, fmt.Sprintf("Type must be '%s', got '%s'", ViewTypeArangoSearch, v.viewType)))
	}
	return &viewArangoSearch{view: *v}, nil
}
source: func NewCmdProjects(fullName string, f kcmdutil.Factory, streams genericclioptions.IOStreams) *cobra.Command {
	o := NewProjectsOptions(fullName, streams)
	cmd := &cobra.Command{
		Use:   "projects",
		Short: "Display existing projects",
		Long:  projectsLong,
		Run: func(cmd *cobra.Command, args []string) {
			kcmdutil.CheckErr(o.Complete(f, cmd, args))
			kcmdutil.CheckErr(o.Validate())
			kcmdutil.CheckErr(o.Run())
		},
	}
	cmd.Flags().BoolVarP(&o.DisplayShort, "short", "q", false, "If true, display only the project names")

	return cmd
}
source: func getFrameworkInfoByFrameworkID(frameworkID string, frameworks []frameworkInfo) *frameworkInfo {
	for _, framework := range frameworks {
		if framework.ID == frameworkID {
			return &framework
		}
	}
	return nil
}
source: func ParseMessage(data []byte, sender net.Addr) (Message, error) {
	address, idx := ReadString(data)
	msg := Message{
		Address: address,
		Sender:  sender,
	}
	data = data[idx:]
	typetags, idx := ReadString(data)
	data = data[idx:]

	// Read all arguments.
	args, err := ReadArguments([]byte(typetags), data)
	if err != nil {
		return Message{}, errors.Wrap(err, "parse message")
	}
	msg.Arguments = args

	return msg, nil
}
source: func (c Core) GetObject(bucketName, objectName string, opts GetObjectOptions) (io.ReadCloser, ObjectInfo, error) {
	return c.getObject(context.Background(), bucketName, objectName, opts)
}
source: func (p *Process) Restart(pos string) error {
	if p.tracedir == "" {
		return proc.ErrNotRecorded
	}

	p.exited = false

	p.common.ClearAllGCache()
	for _, th := range p.threads {
		th.clearBreakpointState()
	}

	p.setCtrlC(false)

	err := p.conn.restart(pos)
	if err != nil {
		return err
	}

	// for some reason we have to send a vCont;c after a vRun to make rr behave
	// properly, because that's what gdb does.
	_, _, err = p.conn.resume(0, nil)
	if err != nil {
		return err
	}

	err = p.updateThreadList(&threadUpdater{p: p})
	if err != nil {
		return err
	}
	p.selectedGoroutine, _ = proc.GetG(p.CurrentThread())

	for addr := range p.breakpoints.M {
		p.conn.setBreakpoint(addr)
	}

	return p.setCurrentBreakpoints()
}
source: func (b *SystemBackend) handleRevoke(ctx context.Context, req *logical.Request, data *framework.FieldData) (*logical.Response, error) {
	// Get all the options
	leaseID := data.Get("lease_id").(string)
	if leaseID == "" {
		leaseID = data.Get("url_lease_id").(string)
	}
	if leaseID == "" {
		return logical.ErrorResponse("lease_id must be specified"),
			logical.ErrInvalidRequest
	}

	ns, err := namespace.FromContext(ctx)
	if err != nil {
		return nil, err
	}
	revokeCtx := namespace.ContextWithNamespace(b.Core.activeContext, ns)
	if data.Get("sync").(bool) {
		// Invoke the expiration manager directly
		if err := b.Core.expiration.Revoke(revokeCtx, leaseID); err != nil {
			b.Backend.Logger().Error("lease revocation failed", "lease_id", leaseID, "error", err)
			return handleErrorNoReadOnlyForward(err)
		}

		return nil, nil
	}

	if err := b.Core.expiration.LazyRevoke(revokeCtx, leaseID); err != nil {
		b.Backend.Logger().Error("lease revocation failed", "lease_id", leaseID, "error", err)
		return handleErrorNoReadOnlyForward(err)
	}

	return logical.RespondWithStatusCode(nil, nil, http.StatusAccepted)
}
source: func Maximum(path, in string, data, max float64, exclusive bool) *errors.Validation {
	if (!exclusive && data > max) || (exclusive && data >= max) {
		return errors.ExceedsMaximum(path, in, max, exclusive)
	}
	return nil
}
source: func (itc *internalTabletConn) VStream(ctx context.Context, target *querypb.Target, startPos string, filter *binlogdatapb.Filter, send func([]*binlogdatapb.VEvent) error) error {
	err := itc.tablet.qsc.QueryService().VStream(ctx, target, startPos, filter, send)
	return tabletconn.ErrorFromGRPC(vterrors.ToGRPC(err))
}
source: func NewSendResponse(apiResponse *api.Response, responseBody []byte) (*SendResponse, error) {
	resp := &SendResponse{
		Response:  apiResponse,
		CacheMeta: &CacheMeta{},
	}

	// If a response body is separately provided we set that as the SendResponse.ResponseBody,
	// otherwise we will do an ioutil.ReadAll to extract the response body from apiResponse.
	switch {
	case len(responseBody) > 0:
		resp.ResponseBody = responseBody
	case apiResponse.Body != nil:
		respBody, err := ioutil.ReadAll(apiResponse.Body)
		if err != nil {
			return nil, err
		}
		// Close the old body
		apiResponse.Body.Close()

		// Re-set the response body after reading from the Reader
		apiResponse.Body = ioutil.NopCloser(bytes.NewReader(respBody))

		resp.ResponseBody = respBody
	}

	return resp, nil
}
source: func Convert_kops_AlwaysAllowAuthorizationSpec_To_v1alpha2_AlwaysAllowAuthorizationSpec(in *kops.AlwaysAllowAuthorizationSpec, out *AlwaysAllowAuthorizationSpec, s conversion.Scope) error {
	return autoConvert_kops_AlwaysAllowAuthorizationSpec_To_v1alpha2_AlwaysAllowAuthorizationSpec(in, out, s)
}
source: func (c *Connection) disconnectVPP() {
	if atomic.CompareAndSwapUint32(&c.vppConnected, 1, 0) {
		c.vppClient.Disconnect()
	}
}
source: func validateUsername(username, allowedUsers string) error {
	if allowedUsers == "" {
		return fmt.Errorf("username not in allowed users list")
	}

	// Role was explicitly configured to allow any username.
	if allowedUsers == "*" {
		return nil
	}

	userList := strings.Split(allowedUsers, ",")
	for _, user := range userList {
		if strings.TrimSpace(user) == username {
			return nil
		}
	}

	return fmt.Errorf("username not in allowed users list")
}
source: func (p *MediaPlaylist) DurationAsInt(yes bool) {
	if yes {
		// duration must be integers if protocol version is less than 3
		version(&p.ver, 3)
	}
	p.durationAsInt = yes
}
source: func (r *policyRepository) FindByName(ctx context.Context, name string) (*policies.Policy, error) {
	r.mtx.RLock()
	defer r.mtx.RUnlock()
	policy, ok := r.policies[policyName(name)]
	if !ok {
		return nil, policies.WithErrNotFound(errors.New("policy resource not found"))
	}
	return policy, nil
}
source: func (s *GrpcServer) startGrpcService() {
	// Start listening for requests
	reflection.Register(s.server)
	logrus.Infof("%s gRPC Server ready on %s", s.name, s.Address())
	waitForServer := make(chan bool)
	s.goServe(waitForServer)
	<-waitForServer
	s.running = true
}
source: func createInterpolatedCommands(config *Config, script string, flattenedEnvVars string) ([]string, error) {
	config.Ctx.Data = &ExecuteCommandTemplate{
		Vars:          flattenedEnvVars,
		Script:        script,
		Command:       script,
		WinRMPassword: getWinRMPassword(config.PackerBuildName),
	}

	interpolatedCmds := make([]string, len(config.ExecuteCommand))
	for i, cmd := range config.ExecuteCommand {
		interpolatedCmd, err := interpolate.Render(cmd, &config.Ctx)
		if err != nil {
			return nil, fmt.Errorf("Error processing command: %s", err)
		}
		interpolatedCmds[i] = interpolatedCmd
	}
	return interpolatedCmds, nil
}
source: func (c Config) ToFile(file string) error {
	if err := validateConfig(c); err != nil {
		return errors.Wrap(err, "config isn't valid")
	}
	b, _ := yaml.Marshal(c)
	if err := ioutil.WriteFile(file, b, 0600); err != nil {
		return errors.Errorf("failed writing file %s: %v", file, err)
	}
	return nil
}
source: func (m *MockCoreV1Interface) ResourceQuotas(arg0 string) v11.ResourceQuotaInterface {
	ret := m.ctrl.Call(m, "ResourceQuotas", arg0)
	ret0, _ := ret[0].(v11.ResourceQuotaInterface)
	return ret0
}
source: func GetAppHashes(p *stage1commontypes.Pod) []types.Hash {
	var names []types.Hash
	for _, a := range p.Manifest.Apps {
		names = append(names, a.Image.ID)
	}

	return names
}
source: func ExtractSynonyms(opts ...interface{}) *opt.SynonymsOption {
	for _, o := range opts {
		if v, ok := o.(*opt.SynonymsOption); ok {
			return v
		}
	}
	return nil
}
source: func (_class VGPUClass) GetVM(sessionID SessionRef, self VGPURef) (_retval VMRef, _err error) {
	_method := "VGPU.get_VM"
	_sessionIDArg, _err := convertSessionRefToXen(fmt.Sprintf("%s(%s)", _method, "session_id"), sessionID)
	if _err != nil {
		return
	}
	_selfArg, _err := convertVGPURefToXen(fmt.Sprintf("%s(%s)", _method, "self"), self)
	if _err != nil {
		return
	}
	_result, _err := _class.client.APICall(_method, _sessionIDArg, _selfArg)
	if _err != nil {
		return
	}
	_retval, _err = convertVMRefToGo(_method + " -> ", _result.Value)
	return
}
source: func (s *CommandStatus) Error() error {
	if s.Status == ok {
		return nil
	}

	return fmt.Errorf("command error on %s: %s",
		s.ReferenceName.String(), s.Status)
}
source: func NewFastHttpContext(instance *FastHTTPServer) *FastHttpContext {
	if instance == nil {
		instance = &FastHTTPServer{MaxMultipartSize: 32 << 20}
	}
	c := &FastHttpContext{
		Request: &FastHttpRequest{header: &FastHttpHeader{isResponse: false},
			Engine: instance},
		Response: &FastHttpResponse{header: &FastHttpHeader{isResponse: true},
			Engine: instance},
	}
	c.Response.header.Source = c.Response
	c.Request.header.Source = c.Request
	return c
}
source: func (e Event) Id() common.Hash {
	types := make([]string, len(e.Inputs))
	i := 0
	for _, input := range e.Inputs {
		types[i] = input.Type.String()
		i++
	}
	return common.BytesToHash(crypto.Keccak256([]byte(fmt.Sprintf("%v(%v)", e.Name, strings.Join(types, ",")))))
}
source: func (c *Conn) ListImages() ([]ImageStatus, error) {
	result := make([][]interface{}, 0)
	if err := c.object.Call(dbusInterface+".ListImages", 0).Store(&result); err != nil {
		return nil, err
	}

	images := []ImageStatus{}
	for _, i := range result {
		image, err := imageFromInterfaces(i)
		if err != nil {
			return nil, err
		}
		images = append(images, *image)
	}

	return images, nil
}
source: func (p *Provider) FetchUser(session goth.Session) (goth.User, error) {
	sess := session.(*Session)
	user := goth.User{
		AccessToken: sess.AccessToken,
		Provider:    p.Name(),
	}

	if user.AccessToken == "" {
		// data is not yet retrieved since accessToken is still empty
		return user, fmt.Errorf("%s has no user information available (yet)", p.providerName)
	}

	u := struct {
		XMLName    xml.Name `xml:"user"`
		ID         string   `xml:"id"`
		Name       string   `xml:"name"`
		RealName   string   `xml:"realname"`
		URL        string   `xml:"url"`
		Country    string   `xml:"country"`
		Age        string   `xml:"age"`
		Gender     string   `xml:"gender"`
		Subscriber string   `xml:"subscriber"`
		PlayCount  string   `xml:"playcount"`
		Playlists  string   `xml:"playlists"`
		Bootstrap  string   `xml:"bootstrap"`
		Registered struct {
			Unixtime string `xml:"unixtime,attr"`
			Time     string `xml:",chardata"`
		} `xml:"registered"`
		Images []struct {
			Size string `xml:"size,attr"`
			URL  string `xml:",chardata"`
		} `xml:"image"`
	}{}

	login := session.(*Session).Login
	err := p.request(false, map[string]string{"method": "user.getinfo", "user": login}, &u)

	if err == nil {
		user.Name = u.RealName
		user.NickName = u.Name
		user.AvatarURL = u.Images[3].URL
		user.UserID = u.ID
		user.Location = u.Country
	}

	return user, err
}
source: func ShowCompletions(c *Context) {
	a := c.App
	if a != nil && a.BashComplete != nil {
		a.BashComplete(c)
	}
}
source: func FindNetprofile(key string) *Netprofile {
	collections.netprofileMutex.Lock()
	defer collections.netprofileMutex.Unlock()

	obj := collections.netprofiles[key]
	if obj == nil {
		return nil
	}

	return obj
}
source: func (l *LogLogger) Logf(format string, v ...interface{}) {
	log.Output(3, fmt.Sprintf(format, v...))
}
source: func connectProxyTransport(sconn ssh.Conn, addr string) (net.Conn, error) {
	channel, _, err := sconn.OpenChannel(chanTransport, nil)
	if err != nil {
		return nil, trace.Wrap(err)
	}

	// Send a special SSH out-of-band request called "teleport-transport"
	// the agent on the other side will create a new TCP/IP connection to
	// 'addr' on its network and will start proxying that connection over
	// this SSH channel.
	ok, err := channel.SendRequest(chanTransportDialReq, true, []byte(addr))
	if err != nil {
		return nil, trace.Wrap(err)
	}
	if !ok {
		defer channel.Close()

		// Pull the error message from the tunnel client (remote cluster)
		// passed to us via stderr.
		errMessage, _ := ioutil.ReadAll(channel.Stderr())
		if errMessage == nil {
			errMessage = []byte("failed connecting to " + addr)
		}
		return nil, trace.Errorf(strings.TrimSpace(string(errMessage)))
	}

	return utils.NewChConn(sconn, channel), nil
}
source: func (buf *Buffer) mvLeftEdge(csbi *consoleScreenBufferInfo) error {
	coords := &coord{y: csbi.cursorPosition.y}

	ret, _, err := setConsoleCursorPosition.Call(buf.Out.Fd(),
		uintptr(*(*int32)(unsafe.Pointer(coords))))
	if ret == 0 {
		return err
	}

	return nil
}
source: func (s tlsSniSolver) CleanUp(domain, token, keyAuth string) error {
	_, acmeDomain, err := acme.TLSSNI01ChallengeCert(keyAuth)
	if err != nil {
		return err
	}
	uncacheCertificate(acmeDomain)
	return nil
}
source: func (s *FlinkApplicationConfigurationDescription) SetJobPlanDescription(v string) *FlinkApplicationConfigurationDescription {
	s.JobPlanDescription = &v
	return s
}
source: func DiffFormatWrite(ctx formatter.Context, changes []container.ContainerChangeResponseItem) error {

	render := func(format func(subContext formatter.SubContext) error) error {
		for _, change := range changes {
			if err := format(&diffContext{c: change}); err != nil {
				return err
			}
		}
		return nil
	}
	return ctx.Write(newDiffContext(), render)
}
source: func ParseThresholdConfig(allocatableConfig []string, evictionHard, evictionSoft, evictionSoftGracePeriod, evictionMinimumReclaim map[string]string) ([]evictionapi.Threshold, error) {
	results := []evictionapi.Threshold{}
	hardThresholds, err := parseThresholdStatements(evictionHard)
	if err != nil {
		return nil, err
	}
	results = append(results, hardThresholds...)
	softThresholds, err := parseThresholdStatements(evictionSoft)
	if err != nil {
		return nil, err
	}
	gracePeriods, err := parseGracePeriods(evictionSoftGracePeriod)
	if err != nil {
		return nil, err
	}
	minReclaims, err := parseMinimumReclaims(evictionMinimumReclaim)
	if err != nil {
		return nil, err
	}
	for i := range softThresholds {
		signal := softThresholds[i].Signal
		period, found := gracePeriods[signal]
		if !found {
			return nil, fmt.Errorf("grace period must be specified for the soft eviction threshold %v", signal)
		}
		softThresholds[i].GracePeriod = period
	}
	results = append(results, softThresholds...)
	for i := range results {
		for signal, minReclaim := range minReclaims {
			if results[i].Signal == signal {
				results[i].MinReclaim = &minReclaim
				break
			}
		}
	}
	for _, key := range allocatableConfig {
		if key == kubetypes.NodeAllocatableEnforcementKey {
			results = addAllocatableThresholds(results)
			break
		}
	}
	return results, nil
}
source: func RandString(a []string) string {
	size := len(a)
	if size == 0 {
		return ""
	}
	return a[rand.Intn(size)]
}
source: func (prog *Program) Write(out io.Writer) error {
	out.Write([]byte(magic))

	gobIdents := func(idents []Ident) []gobIdent {
		res := make([]gobIdent, len(idents))
		for i, id := range idents {
			res[i].Name = id.Name
			res[i].Line = id.Pos.Line
			res[i].Col = id.Pos.Col
		}
		return res
	}

	gobFunc := func(fn *Funcode) gobFunction {
		return gobFunction{
			Id: gobIdent{
				Name: fn.Name,
				Line: fn.Pos.Line,
				Col:  fn.Pos.Col,
			},
			Code:       fn.Code,
			Pclinetab:  fn.pclinetab,
			Locals:     gobIdents(fn.Locals),
			Freevars:   gobIdents(fn.Freevars),
			MaxStack:   fn.MaxStack,
			NumParams:  fn.NumParams,
			HasVarargs: fn.HasVarargs,
			HasKwargs:  fn.HasKwargs,
		}
	}

	gp := &gobProgram{
		Version:   Version,
		Filename:  prog.Toplevel.Pos.Filename(),
		Loads:     gobIdents(prog.Loads),
		Names:     prog.Names,
		Constants: prog.Constants,
		Functions: make([]gobFunction, len(prog.Functions)),
		Globals:   gobIdents(prog.Globals),
		Toplevel:  gobFunc(prog.Toplevel),
	}
	for i, f := range prog.Functions {
		gp.Functions[i] = gobFunc(f)
	}

	return gob.NewEncoder(out).Encode(gp)
}
source: func (scope *Scope) handleBelongsToPreload(field *Field, conditions []interface{}) {
	relation := field.Relationship

	// preload conditions
	preloadDB, preloadConditions := scope.generatePreloadDBWithConditions(conditions)

	// get relations's primary keys
	primaryKeys := scope.getColumnAsArray(relation.ForeignFieldNames, scope.Value)
	if len(primaryKeys) == 0 {
		return
	}

	// find relations
	results := makeSlice(field.Struct.Type)
	scope.Err(preloadDB.Where(fmt.Sprintf("%v IN (%v)", toQueryCondition(scope, relation.AssociationForeignDBNames), toQueryMarks(primaryKeys)), toQueryValues(primaryKeys)...).Find(results, preloadConditions...).Error)

	// assign find results
	var (
		resultsValue       = indirect(reflect.ValueOf(results))
		indirectScopeValue = scope.IndirectValue()
	)

	foreignFieldToObjects := make(map[string][]*reflect.Value)
	if indirectScopeValue.Kind() == reflect.Slice {
		for j := 0; j < indirectScopeValue.Len(); j++ {
			object := indirect(indirectScopeValue.Index(j))
			valueString := toString(getValueFromFields(object, relation.ForeignFieldNames))
			foreignFieldToObjects[valueString] = append(foreignFieldToObjects[valueString], &object)
		}
	}

	for i := 0; i < resultsValue.Len(); i++ {
		result := resultsValue.Index(i)
		if indirectScopeValue.Kind() == reflect.Slice {
			valueString := toString(getValueFromFields(result, relation.AssociationForeignFieldNames))
			if objects, found := foreignFieldToObjects[valueString]; found {
				for _, object := range objects {
					object.FieldByName(field.Name).Set(result)
				}
			}
		} else {
			scope.Err(field.Set(result))
		}
	}
}
source: func (query Query) Offset(offset int) Query {
	query.OffsetResult = offset
	return query
}
source: func (t *Task) Canonicalize(job *Job, tg *TaskGroup) {
	// Ensure that an empty and nil map are treated the same to avoid scheduling
	// problems since we use reflect DeepEquals.
	if len(t.Meta) == 0 {
		t.Meta = nil
	}
	if len(t.Config) == 0 {
		t.Config = nil
	}
	if len(t.Env) == 0 {
		t.Env = nil
	}

	for _, service := range t.Services {
		service.Canonicalize(job.Name, tg.Name, t.Name)
	}

	// If Resources are nil initialize them to defaults, otherwise canonicalize
	if t.Resources == nil {
		t.Resources = DefaultResources()
	} else {
		t.Resources.Canonicalize()
	}

	// Set the default timeout if it is not specified.
	if t.KillTimeout == 0 {
		t.KillTimeout = DefaultKillTimeout
	}

	if t.Vault != nil {
		t.Vault.Canonicalize()
	}

	for _, template := range t.Templates {
		template.Canonicalize()
	}
}
source: func (r *run) importStatus(listNode *importer.Object, st *mastodon.Status) (bool, error) {
	select {
	case <-r.Context().Done():
		return false, r.Context().Err()
	default:
	}

	// We store child nodes by their URI, since the URI is supposed to be an
	// unchanging, globally unique identifier for the status
	statusNode, err := listNode.ChildPathObject(st.URI)
	if err != nil {
		return false, err
	}

	if r.incremental && statusNode.Attr(attrURI) == st.URI {
		return true, nil
	}

	attrs := []string{
		nodeattr.Type, "mastodon:status",
		attrURI, st.URI,
		nodeattr.URL, st.URL,
		nodeattr.Content, st.Content,
		nodeattr.StartDate, schema.RFC3339FromTime(st.CreatedAt),
	}

	if st.SpoilerText != "" {
		attrs = append(attrs, attrSpoilerText, st.SpoilerText)
	}

	filenames := make(map[string]int)

	for i, att := range st.MediaAttachments {
		// All media for a local user will be local
		resp, err := ctxutil.Client(r.Context()).Get(att.URL)
		if err != nil {
			return false, err
		}

		if resp.StatusCode != http.StatusOK {
			return false, fmt.Errorf("failed fetching attachment %s with HTTP status %s", att.URL, resp.Status)
		}

		fileRef, err := schema.WriteFileFromReader(r.Context(), r.Host.Target(), "", resp.Body)
		resp.Body.Close()
		if err != nil {
			return false, err
		}

		filename := path.Base(att.URL)
		filenames[filename]++

		// A status can have several different attachments with the same
		// filename. We add numbers to the path to diffirentiate them if that's
		// the case
		if filenames[filename] > 1 {
			ext := path.Ext(filename)
			filename = fmt.Sprintf("%s%d%s", strings.TrimSuffix(filename, ext), filenames[filename], ext)
		}

		attrs = append(attrs, fmt.Sprintf("camliPath:%v", filename), fileRef.String())

		// The first image gets to be the preview image for the node
		if i == 0 {
			attrs = append(attrs, "camliContentImage", fileRef.String())
		}

		log.Printf("mastodon: adding attachment %s to permanode %s for status %s", fileRef.String(), statusNode.PermanodeRef(), st.URI)

	}

	changed, err := statusNode.SetAttrs2(attrs...)
	if err == nil && changed {
		log.Printf("mastodon: Imported status %s to %s", st.URI, statusNode.PermanodeRef())
	}

	return !changed, err

}
source: func NewContent(
	sites *hugolib.HugoSites, kind, targetPath string) error {
	targetPath = filepath.Clean(targetPath)
	ext := helpers.Ext(targetPath)
	ps := sites.PathSpec
	archetypeFs := ps.BaseFs.SourceFilesystems.Archetypes.Fs
	sourceFs := ps.Fs.Source

	jww.INFO.Printf("attempting to create %q of %q of ext %q", targetPath, kind, ext)

	archetypeFilename, isDir := findArchetype(ps, kind, ext)
	contentPath, s := resolveContentPath(sites, sourceFs, targetPath)

	if isDir {

		langFs := hugofs.NewLanguageFs(s.Language().Lang, sites.LanguageSet(), archetypeFs)

		cm, err := mapArcheTypeDir(ps, langFs, archetypeFilename)
		if err != nil {
			return err
		}

		if cm.siteUsed {
			if err := sites.Build(hugolib.BuildCfg{SkipRender: true}); err != nil {
				return err
			}
		}

		name := filepath.Base(targetPath)
		return newContentFromDir(archetypeFilename, sites, archetypeFs, sourceFs, cm, name, contentPath)
	}

	// Building the sites can be expensive, so only do it if really needed.
	siteUsed := false

	if archetypeFilename != "" {

		var err error
		siteUsed, err = usesSiteVar(archetypeFs, archetypeFilename)
		if err != nil {
			return err
		}
	}

	if siteUsed {
		if err := sites.Build(hugolib.BuildCfg{SkipRender: true}); err != nil {
			return err
		}
	}

	content, err := executeArcheTypeAsTemplate(s, "", kind, targetPath, archetypeFilename)
	if err != nil {
		return err
	}

	if err := helpers.SafeWriteToDisk(contentPath, bytes.NewReader(content), s.Fs.Source); err != nil {
		return err
	}

	jww.FEEDBACK.Println(contentPath, "created")

	editor := s.Cfg.GetString("newContentEditor")
	if editor != "" {
		jww.FEEDBACK.Printf("Editing %s with %q ...\n", targetPath, editor)

		cmd := exec.Command(editor, contentPath)
		cmd.Stdin = os.Stdin
		cmd.Stdout = os.Stdout
		cmd.Stderr = os.Stderr

		return cmd.Run()
	}

	return nil
}
source: func (s *LifecyclePolicyPreviewSummary) SetExpiringImageTotalCount(v int64) *LifecyclePolicyPreviewSummary {
	s.ExpiringImageTotalCount = &v
	return s
}
source: func (m *SpiderMenu) Sort(col int, order walk.SortOrder) error {
	m.sortColumn, m.sortOrder = col, order

	sort.Sort(m)

	return m.SorterBase.Sort(col, order)
}
source: func NewParser(request *http.Request) *Parser {
	return &Parser{
		Method:  request.Method,
		Headers: request.Header,
	}
}
source: func getMonitorParser(conn net.Conn, version listener.Version) (parser eventParserFunc, err error) {
	switch version {
	case listener.Version1_0:
		var (
			meta payload.Meta
			pl   payload.Payload
		)
		// This implements the older API. Always encode a Meta and Payload object,
		// both with full gob type information
		return func() (*payload.Payload, error) {
			if err := payload.ReadMetaPayload(conn, &meta, &pl); err != nil {
				return nil, err
			}
			return &pl, nil
		}, nil

	case listener.Version1_2:
		var (
			pl  payload.Payload
			dec = gob.NewDecoder(conn)
		)
		// This implemenents the newer 1.2 API. Each listener maintains its own gob
		// session, and type information is only ever sent once.
		return func() (*payload.Payload, error) {
			if err := pl.DecodeBinary(dec); err != nil {
				return nil, err
			}
			return &pl, nil
		}, nil

	default:
		return nil, fmt.Errorf("unsupported version %s", version)
	}
}
source: func (iter *SpreadIterator) computeSpreadInfo(tg *structs.TaskGroup) {
	spreadInfos := make(spreadAttributeMap, len(tg.Spreads))
	totalCount := tg.Count

	// Always combine any spread stanzas defined at the job level here
	combinedSpreads := make([]*structs.Spread, 0, len(tg.Spreads)+len(iter.jobSpreads))
	combinedSpreads = append(combinedSpreads, tg.Spreads...)
	combinedSpreads = append(combinedSpreads, iter.jobSpreads...)
	for _, spread := range combinedSpreads {
		si := &spreadInfo{weight: spread.Weight, desiredCounts: make(map[string]float64)}
		sumDesiredCounts := 0.0
		for _, st := range spread.SpreadTarget {
			desiredCount := (float64(st.Percent) / float64(100)) * float64(totalCount)
			si.desiredCounts[st.Value] = desiredCount
			sumDesiredCounts += desiredCount
		}
		// Account for remaining count only if there is any spread targets
		if sumDesiredCounts > 0 && sumDesiredCounts < float64(totalCount) {
			remainingCount := float64(totalCount) - sumDesiredCounts
			si.desiredCounts[implicitTarget] = remainingCount
		}
		spreadInfos[spread.Attribute] = si
		iter.sumSpreadWeights += int32(spread.Weight)
	}
	iter.tgSpreadInfo[tg.Name] = spreadInfos
} 15%|█▌        | 756/5000 [00:00<00:05, 771.74it/s]
source: func dbAddTxIndexEntries(dbTx database.Tx, block *btcutil.Block, blockID uint32) error {
	// The offset and length of the transactions within the serialized
	// block.
	txLocs, err := block.TxLoc()
	if err != nil {
		return err
	}

	// As an optimization, allocate a single slice big enough to hold all
	// of the serialized transaction index entries for the block and
	// serialize them directly into the slice.  Then, pass the appropriate
	// subslice to the database to be written.  This approach significantly
	// cuts down on the number of required allocations.
	offset := 0
	serializedValues := make([]byte, len(block.Transactions())*txEntrySize)
	for i, tx := range block.Transactions() {
		putTxIndexEntry(serializedValues[offset:], blockID, txLocs[i])
		endOffset := offset + txEntrySize
		err := dbPutTxIndexEntry(dbTx, tx.Hash(),
			serializedValues[offset:endOffset:endOffset])
		if err != nil {
			return err
		}
		offset += txEntrySize
	}

	return nil
}
source: func (s *Set) Add(x uint32) {
	v := s.sparse[x]
	if v < uint32(len(s.dense)) && s.dense[v] == x {
		return
	}
	n := len(s.dense)
	s.sparse[x] = uint32(n)
	s.dense = append(s.dense, x)
}
source: func (n *Nodes) Allocations(nodeID string, q *QueryOptions) ([]*Allocation, *QueryMeta, error) {
	var resp []*Allocation
	qm, err := n.client.query("/v1/node/"+nodeID+"/allocations", &resp, q)
	if err != nil {
		return nil, nil, err
	}
	sort.Sort(AllocationSort(resp))
	return resp, qm, nil
}
source: func NotEmpty(fieldName string, value string) error {
	if strings.TrimSpace(value) == "" {
		return NewViolation(fmt.Sprintf("empty string for %v", fieldName))
	}
	return nil
}
source: func NewOrgBackend(b *APIBackend) *OrgBackend {
	return &OrgBackend{
		Logger: b.Logger.With(zap.String("handler", "org")),

		OrganizationService:             b.OrganizationService,
		OrganizationOperationLogService: b.OrganizationOperationLogService,
		UserResourceMappingService:      b.UserResourceMappingService,
		SecretService:                   b.SecretService,
		LabelService:                    b.LabelService,
		UserService:                     b.UserService,
	}
}
source: func WithSpanFilterContext(ctx context.Context, sf *Map) context.Context {
	return context.WithValue(ctx, spanFailures, sf)
}
source: func (f *ControllerClient) DeleteVolume(ctx context.Context, in *csipb.DeleteVolumeRequest, opts ...grpc.CallOption) (*csipb.DeleteVolumeResponse, error) {
	return nil, nil
}
source: func (r *Runhcs) CreateScratch(context context.Context, destpath string) error {
	return r.runOrError(r.command(context, "create-scratch", "--destpath", destpath))
}
source: func (rf *requestForwardingHandler) Handoff(ctx context.Context, shutdownWg *sync.WaitGroup, closeCh chan struct{}, tlsConn *tls.Conn) error {
	if !rf.ha {
		tlsConn.Close()
		return nil
	}

	rf.logger.Debug("got request forwarding connection")

	shutdownWg.Add(2)
	// quitCh is used to close the connection and the second
	// goroutine if the server closes before closeCh.
	quitCh := make(chan struct{})
	go func() {
		select {
		case <-quitCh:
		case <-closeCh:
		case <-rf.stopCh:
		}
		tlsConn.Close()
		shutdownWg.Done()
	}()

	go func() {
		rf.fws.ServeConn(tlsConn, &http2.ServeConnOpts{
			Handler: rf.fwRPCServer,
			BaseConfig: &http.Server{
				ErrorLog: rf.logger.StandardLogger(nil),
			},
		})

		// close the quitCh which will close the connection and
		// the other goroutine.
		close(quitCh)
		shutdownWg.Done()
	}()

	return nil
}
source: func (c *Controller) RunKubernetesNamespaces(ch chan struct{}) {
	wait.Until(func() {
		// Loop the system namespace list, and create them if they do not exist
		for _, ns := range c.SystemNamespaces {
			if err := createNamespaceIfNeeded(c.NamespaceClient, ns); err != nil {
				runtime.HandleError(fmt.Errorf("unable to create required kubernetes system namespace %s: %v", ns, err))
			}
		}
	}, c.SystemNamespacesInterval, ch)
}
source: func (b *Browser) Readlink(link string) (target string, err error) {
	defer translateGitError(&err)
	fi, err := b.Lstat(link)
	if err != nil {
		return "", err
	}
	// If it's not a symlink, error right away.
	if fi.Mode()&os.ModeSymlink == 0 {
		return "", errors.New("not a symlink")
	}

	return b.readLink(link)
}
source: func (s *Stream) Close() error {
	closeStream := false
	s.stateLock.Lock()
	switch s.state {
	// Opened means we need to signal a close
	case streamSYNSent:
		fallthrough
	case streamSYNReceived:
		fallthrough
	case streamEstablished:
		s.state = streamLocalClose
		goto SEND_CLOSE

	case streamLocalClose:
	case streamRemoteClose:
		s.state = streamClosed
		closeStream = true
		goto SEND_CLOSE

	case streamClosed:
	case streamReset:
	default:
		panic("unhandled state")
	}
	s.stateLock.Unlock()
	return nil
SEND_CLOSE:
	s.stateLock.Unlock()
	s.sendClose()
	s.notifyWaiting()
	if closeStream {
		s.session.closeStream(s.id)
	}
	return nil
}
source: func migrateConfigV4ToV5() {
	if !isMcConfigExists() {
		return
	}
	mcCfgV4, e := quick.LoadConfig(mustGetMcConfigPath(), nil, newConfigV4())
	fatalIf(probe.NewError(e), "Unable to load mc config V4.")

	// update to newer version
	if mcCfgV4.Version() != "4" {
		return
	}

	cfgV5 := newConfigV5()
	for k, v := range mcCfgV4.Data().(*configV4).Aliases {
		cfgV5.Aliases[k] = v
	}
	for host, hostCfgV4 := range mcCfgV4.Data().(*configV4).Hosts {
		cfgV5.Hosts[host] = hostConfigV5{
			AccessKeyID:     hostCfgV4.AccessKeyID,
			SecretAccessKey: hostCfgV4.SecretAccessKey,
			API:             "v4", // Rename from .Signature to .API
		}
	}

	mcNewCfgV5, e := quick.NewConfig(cfgV5, nil)
	fatalIf(probe.NewError(e), "Unable to initialize quick config for config version `5`.")

	e = mcNewCfgV5.Save(mustGetMcConfigPath())
	fatalIf(probe.NewError(e), "Unable to save config version `5`.")

	console.Infof("Successfully migrated %s from version `4` to version `5`.\n", mustGetMcConfigPath())
}
source: func nonzero(v interface{}, param string) error {
	st := reflect.ValueOf(v)
	valid := true
	switch st.Kind() {
	case reflect.String:
		valid = len(st.String()) != 0
	case reflect.Ptr, reflect.Interface:
		valid = !st.IsNil()
	case reflect.Slice, reflect.Map, reflect.Array:
		valid = st.Len() != 0
	case reflect.Int, reflect.Int8, reflect.Int16, reflect.Int32, reflect.Int64:
		valid = st.Int() != 0
	case reflect.Uint, reflect.Uint8, reflect.Uint16, reflect.Uint32, reflect.Uint64, reflect.Uintptr:
		valid = st.Uint() != 0
	case reflect.Float32, reflect.Float64:
		valid = st.Float() != 0
	case reflect.Bool:
		valid = st.Bool()
	case reflect.Invalid:
		valid = false // always invalid
	case reflect.Struct:
		valid = true // always valid since only nil pointers are empty
	default:
		return ErrUnsupported
	}

	if !valid {
		return ErrZeroValue
	}
	return nil
}
source: func Documentation(getPtrNames bool) (map[string]interface{}, error) {
	handlerDocs, err := handlerService.Docs(getPtrNames)
	if err != nil {
		return nil, err
	}
	remoteDocs, err := remoteService.Docs(getPtrNames)
	if err != nil {
		return nil, err
	}
	return map[string]interface{}{
		"handlers": handlerDocs,
		"remotes":  remoteDocs,
	}, nil
}
source: func (ss *SecretSyncer) HasActiveDevice(includeTypesSet DeviceTypeSet) (bool, error) {
	devs, err := ss.ActiveDevices(includeTypesSet)
	if err != nil {
		return false, err
	}
	return len(devs) > 0, nil
}
source: func (l *LogParserPlugin) Stop() {
	l.Lock()
	defer l.Unlock()

	for _, t := range l.tailers {
		err := t.Stop()

		//message for a stopped tailer
		log.Printf("D! tail dropped for file: %v", t.Filename)

		if err != nil {
			log.Printf("E! Error stopping tail on file %s\n", t.Filename)
		}
		t.Cleanup()
	}
	close(l.done)
	l.wg.Wait()
}
source: func (engine *Engine) Table(tableNameOrBean interface{}) *Session {
	session := engine.NewSession()
	session.isAutoClose = true
	return session.Table(tableNameOrBean)
}
source: func (l *Lifecycle) AddKillFunc(f func()) {
	l.m.Lock()
	defer l.m.Unlock()
	l.killFuncs = append(l.killFuncs, f)
}
source: func (db *DB) Stats() Stats {
	db.statlock.RLock()
	defer db.statlock.RUnlock()
	return db.stats
}
source: func (c *jobsV1) Create(job *extensions.Job) (result *extensions.Job, err error) {
	result = &extensions.Job{}
	err = c.r.Post().Namespace(c.ns).Resource("jobs").Body(job).Do().Into(result)
	return
}
source: func DefaultOnError(err error, w http.ResponseWriter, r *http.Request) {
	log.Printf("[httpgzip] %v", err)
}
source: func fetchManifest(ctx context.Context, repo distribution.Repository, ref reference.Named) (types.ImageManifest, error) {
	manifest, err := getManifest(ctx, repo, ref)
	if err != nil {
		return types.ImageManifest{}, err
	}

	switch v := manifest.(type) {
	// Removed Schema 1 support
	case *schema2.DeserializedManifest:
		imageManifest, err := pullManifestSchemaV2(ctx, ref, repo, *v)
		if err != nil {
			return types.ImageManifest{}, err
		}
		return imageManifest, nil
	case *manifestlist.DeserializedManifestList:
		return types.ImageManifest{}, errors.Errorf("%s is a manifest list", ref)
	}
	return types.ImageManifest{}, errors.Errorf("%s is not a manifest", ref)
}
source: func (l *Link) TrackOffset() time.Duration {
	var offsetMs C.int
	C.sp_link_as_track_and_offset(l.sp_link, &offsetMs)
	return time.Duration(offsetMs) / time.Millisecond
}
source: func MAC48Address(input string) string {
	h := md5.New()
	h.Write([]byte(input))
	result := h.Sum(nil)

	var c []string
	c = append(c, toHex(result[0]))
	c = append(c, toHex(result[1]))
	c = append(c, toHex(result[2]))
	c = append(c, toHex(result[3]))
	c = append(c, toHex(result[4]))
	c = append(c, toHex(result[5]))

	return strings.ToUpper(strings.Join(c, ":"))
}
source: func (namespace *HostComputeNamespace) Create() (*HostComputeNamespace, error) {
	logrus.Debugf("hcn::HostComputeNamespace::Create id=%s", namespace.Id)

	jsonString, err := json.Marshal(namespace)
	if err != nil {
		return nil, err
	}

	logrus.Debugf("hcn::HostComputeNamespace::Create JSON: %s", jsonString)
	namespace, hcnErr := createNamespace(string(jsonString))
	if hcnErr != nil {
		return nil, hcnErr
	}
	return namespace, nil
}
source: func (in *EndpointSubset) DeepCopy() *EndpointSubset {
	if in == nil {
		return nil
	}
	out := new(EndpointSubset)
	in.DeepCopyInto(out)
	return out
}
source: func (s *store) GetDigestLock(d digest.Digest) (Locker, error) {
	return GetLockfile(filepath.Join(s.digestLockRoot, d.String()))
}
source: func inversionsCount(array, buffer []int) int {
	if len(array) <= 1 {
		return 0
	}
	cleft := inversionsCount(buffer[:len(array)/2], array[:len(array)/2])
	cright := inversionsCount(buffer[len(array)/2:], array[len(array)/2:])
	ccross := inversionsCombine(array[:len(array)/2], array[len(array)/2:], buffer)
	return cleft + ccross + cright
}
source: func NewGroupsMembersListArg(Group *GroupSelector) *GroupsMembersListArg {
	s := new(GroupsMembersListArg)
	s.Group = Group
	s.Limit = 1000
	return s
}
source: func AddAdapter(name string, adapter AdapterPod) {
	lock.Lock()
	adapters[name] = adapter
	lock.Unlock()
}
source: func (s *UsergroupsService) Enable(usergroup string) *UsergroupsEnableCall {
	var call UsergroupsEnableCall
	call.service = s
	call.usergroup = usergroup
	return &call
}
source: func New(server string) *Account {
	return &Account{
		server: server,
		auth:   auth.Public,
		ctx: wrap.Wrap(&apex.Logger{
			Handler: cli.New(os.Stdout),
		}),
		headers: map[string]string{},
	}
}
source: func (s *UserService) NewCreateUserParams(account string, email string, firstname string, lastname string, password string, username string) *CreateUserParams {
	p := &CreateUserParams{}
	p.p = make(map[string]interface{})
	p.p["account"] = account
	p.p["email"] = email
	p.p["firstname"] = firstname
	p.p["lastname"] = lastname
	p.p["password"] = password
	p.p["username"] = username
	return p
}
source: func HasClipTimeout(ctx context.Context) bool {
	_, ok := ctx.Value(ctxKeyClipTimeout).(int)
	return ok
}
source: func (m *ModelStatus) MachineInstance(machineID string) (status.StatusInfo, error) {
	return m.getStatus(machineGlobalInstanceKey(machineID), "instance")
}
source: func (p PortRange) String() string {
	proto := strings.ToLower(p.Protocol)
	if proto == "icmp" {
		return fmt.Sprintf("%s (%q)", proto, p.UnitName)
	}
	return fmt.Sprintf("%d-%d/%s (%q)", p.FromPort, p.ToPort, proto, p.UnitName)
}
source: func (lk *consulLock) renewSession() {
	for {
		err := lk.client.Session().RenewPeriodic(lk.ttl, lk.sessionID, nil, lk.stopChan)
		if err == nil || lk.IsReleased() {
			// If lock was released, exit this go routine
			return
		}

		// Create new consul session
		err = lk.createSession()
		if err != nil {
			log.Errorf("Error Creating session for lock %s. Err: %v", lk.keyName, err)
		}
	}

}
source: func (directions Directions) Dump(format string) (data []byte, err error) {
	resp, err := http.Get(directions.URL(format))
	if err != nil {
		return
	}
	defer resp.Body.Close()
	data, err = ioutil.ReadAll(resp.Body)
	return
}
source: func ParamsActionExecutionResultsToStateActionResults(arg params.ActionExecutionResult) (state.ActionResults, error) {
	var status state.ActionStatus
	switch arg.Status {
	case params.ActionCancelled:
		status = state.ActionCancelled
	case params.ActionCompleted:
		status = state.ActionCompleted
	case params.ActionFailed:
		status = state.ActionFailed
	case params.ActionPending:
		status = state.ActionPending
	default:
		return state.ActionResults{}, errors.Errorf("unrecognized action status '%s'", arg.Status)
	}
	return state.ActionResults{
		Status:  status,
		Results: arg.Results,
		Message: arg.Message,
	}, nil
}
source: func (s *RouterService) StopRouter(p *StopRouterParams) (*StopRouterResponse, error) {
	resp, err := s.cs.newRequest("stopRouter", p.toURLValues())
	if err != nil {
		return nil, err
	}

	var r StopRouterResponse
	if err := json.Unmarshal(resp, &r); err != nil {
		return nil, err
	}

	// If we have a async client, we need to wait for the async result
	if s.cs.async {
		b, err := s.cs.GetAsyncJobResult(r.JobID, s.cs.timeout)
		if err != nil {
			if err == AsyncTimeoutErr {
				return &r, err
			}
			return nil, err
		}

		b, err = getRawValue(b)
		if err != nil {
			return nil, err
		}

		if err := json.Unmarshal(b, &r); err != nil {
			return nil, err
		}
	}

	return &r, nil
}
source: func (sc serviceCommand) Execute() (string, int, error) {
	if sc.AdminState == contract.Locked {
		LoggingClient.Error(sc.Name + " is in admin locked state")

		return "", DefaultErrorCode, ErrDeviceLocked{}
	}

	LoggingClient.Info("Issuing" + sc.Request.Method + " command to: " + sc.Request.URL.String())
	resp, reqErr := sc.HttpCaller.Do(sc.Request)
	if reqErr != nil {
		LoggingClient.Error(reqErr.Error())
		return "", http.StatusInternalServerError, reqErr

	}

	buf := new(bytes.Buffer)
	_, readErr := buf.ReadFrom(resp.Body)

	if readErr != nil {
		return "", DefaultErrorCode, readErr
	}
	return buf.String(), resp.StatusCode, nil
}
source: func (s *LocalStore) SaveCertificates(certificates []*Certificate) error {
	storedData, err := s.get()
	if err != nil {
		return err
	}

	storedData.Certificates = certificates
	s.SaveDataChan <- storedData

	return nil
}
source: func (cs *ConsensusState) ReplayFile(file string, console bool) error {

	if cs.IsRunning() {
		return errors.New("cs is already running, cannot replay")
	}
	if cs.wal != nil {
		return errors.New("cs wal is open, cannot replay")
	}

	cs.startForReplay()

	// ensure all new step events are regenerated as expected

	ctx := context.Background()
	newStepSub, err := cs.eventBus.Subscribe(ctx, subscriber, types.EventQueryNewRoundStep)
	if err != nil {
		return errors.Errorf("failed to subscribe %s to %v", subscriber, types.EventQueryNewRoundStep)
	}
	defer cs.eventBus.Unsubscribe(ctx, subscriber, types.EventQueryNewRoundStep)

	// just open the file for reading, no need to use wal
	fp, err := os.OpenFile(file, os.O_RDONLY, 0600)
	if err != nil {
		return err
	}

	pb := newPlayback(file, fp, cs, cs.state.Copy())
	defer pb.fp.Close() // nolint: errcheck

	var nextN int // apply N msgs in a row
	var msg *TimedWALMessage
	for {
		if nextN == 0 && console {
			nextN = pb.replayConsoleLoop()
		}

		msg, err = pb.dec.Decode()
		if err == io.EOF {
			return nil
		} else if err != nil {
			return err
		}

		if err := pb.cs.readReplayMessage(msg, newStepSub); err != nil {
			return err
		}

		if nextN > 0 {
			nextN--
		}
		pb.count++
	}
}
source: func isFieldPK(field *r.StructField) (isPK bool) {
	result := false
	pk := field.Tag.Get("pk")
	if len(pk) > 0 {
		result = true
	}
	return result
}
source: func (x *XC) Initialized(ctx context.Context) error {
	if x == nil {
		return fmt.Errorf("XC not initialized")
	}
	if x.pubring == nil {
		return fmt.Errorf("pubring not initialized")
	}
	if x.secring == nil {
		return fmt.Errorf("secring not initialized")
	}
	if x.client == nil {
		return fmt.Errorf("client not initialized")
	}
	if err := x.client.Ping(ctx); err != nil {
		return fmt.Errorf("agent not running")
	}
	return nil
}
source: func Save(config *api.Config, cmd *cobra.Command) {
	c := Config{
		BuilderImage: config.BuilderImage,
		Source:       config.Source.String(),
		Tag:          config.Tag,
		Flags:        make(map[string]string),
	}
	cmd.Flags().Visit(func(f *pflag.Flag) {
		if f.Name == "env" {
			for i, env := range config.Environment {
				c.Flags[fmt.Sprintf("%s-%d", f.Name, i)] = fmt.Sprintf("%s=%s", env.Name, env.Value)
			}
		} else {
			c.Flags[f.Name] = f.Value.String()
		}
	})
	data, err := json.Marshal(c)
	if err != nil {
		glog.V(1).Infof("Unable to serialize to %s: %v", DefaultConfigPath, err)
		return
	}
	if err := ioutil.WriteFile(DefaultConfigPath, data, 0644); err != nil {
		glog.V(1).Infof("Unable to save %s: %v", DefaultConfigPath, err)
	}
	return
}
source: func (c *Connection) SetID(i int) {
	c.Lock()
	defer c.Unlock()
	c.id = i
}
source: func parseAndSetDebugLevels(debugLevel string) error {
	// When the specified string doesn't have any delimiters, treat it as
	// the log level for all subsystems.
	if !strings.Contains(debugLevel, ",") && !strings.Contains(debugLevel, "=") {
		// Validate debug log level.
		if !validLogLevel(debugLevel) {
			str := "The specified debug level [%v] is invalid"
			return fmt.Errorf(str, debugLevel)
		}

		// Change the logging level for all subsystems.
		setLogLevels(debugLevel)

		return nil
	}

	// Split the specified string into subsystem/level pairs while detecting
	// issues and update the log levels accordingly.
	for _, logLevelPair := range strings.Split(debugLevel, ",") {
		if !strings.Contains(logLevelPair, "=") {
			str := "The specified debug level contains an invalid " +
				"subsystem/level pair [%v]"
			return fmt.Errorf(str, logLevelPair)
		}

		// Extract the specified subsystem and log level.
		fields := strings.Split(logLevelPair, "=")
		subsysID, logLevel := fields[0], fields[1]

		// Validate subsystem.
		if _, exists := subsystemLoggers[subsysID]; !exists {
			str := "The specified subsystem [%v] is invalid -- " +
				"supported subsystems %v"
			return fmt.Errorf(str, subsysID, supportedSubsystems())
		}

		// Validate log level.
		if !validLogLevel(logLevel) {
			str := "The specified debug level [%v] is invalid"
			return fmt.Errorf(str, logLevel)
		}

		setLogLevel(subsysID, logLevel)
	}

	return nil
}
source: func (mi *MemoryIndex) GetCommitDataByIndex(i int) (*CommitData, error) {
	if int(i) >= len(mi.commitData) {
		return nil, plumbing.ErrObjectNotFound
	}

	commitData := mi.commitData[i]

	// Map parent hashes to parent indexes
	if commitData.ParentIndexes == nil {
		parentIndexes := make([]int, len(commitData.ParentHashes))
		for i, parentHash := range commitData.ParentHashes {
			var err error
			if parentIndexes[i], err = mi.GetIndexByHash(parentHash); err != nil {
				return nil, err
			}
		}
		commitData.ParentIndexes = parentIndexes
	}

	return commitData, nil
}
source: func (d *domainClient) GetStackTrace(ctx context.Context, args *GetStackTraceArgs) (reply *GetStackTraceReply, err error) {
	reply = new(GetStackTraceReply)
	if args != nil {
		err = rpcc.Invoke(ctx, "Debugger.getStackTrace", args, reply, d.conn)
	} else {
		err = rpcc.Invoke(ctx, "Debugger.getStackTrace", nil, reply, d.conn)
	}
	if err != nil {
		err = &internal.OpError{Domain: "Debugger", Op: "GetStackTrace", Err: err}
	}
	return
}
source: func filterMorphism(filt []shape.ValueFilter) morphism {
	return morphism{
		Reversal: func(ctx *pathContext) (morphism, *pathContext) { return filterMorphism(filt), ctx },
		Apply: func(in shape.Shape, ctx *pathContext) (shape.Shape, *pathContext) {
			return shape.AddFilters(in, filt...), ctx
		},
	}
}
source: func (db *DB) RetrieveWinnersByHash(hash string) ([]string, uint32, error) {
	var winners string
	var height uint32
	err := db.QueryRow(db.getWinnersByHashSQL, hash).Scan(&height, &winners)
	if err != nil {
		return nil, 0, err
	}
	return splitToArray(winners), height, err
}
source: func (s *HyperParameterTuningJobWarmStartConfig) SetParentHyperParameterTuningJobs(v []*ParentHyperParameterTuningJob) *HyperParameterTuningJobWarmStartConfig {
	s.ParentHyperParameterTuningJobs = v
	return s
}
source: func (m *MockEnviron) AllInstances(arg0 context.ProviderCallContext) ([]instances.Instance, error) {
	ret := m.ctrl.Call(m, "AllInstances", arg0)
	ret0, _ := ret[0].([]instances.Instance)
	ret1, _ := ret[1].(error)
	return ret0, ret1
}
source: func (val AnnotationValue) Validate(_ interface{}) error {
	if annotationValueRegex.Match([]byte(val)) {
		return nil
	}

	return errInvalidAnnotationValue
}
source: func (gce *Cloud) CurrentNodeName(hostname string) (types.NodeName, error) {
	return types.NodeName(hostname), nil
}
source: func WriteByteOffs(fp sophie.FsPath, buffer []byte, keyOffs, keyEnds, valOffs, valEnds []int) error {
	if len(keyOffs) != len(keyEnds) || len(keyOffs) != len(valOffs) || len(keyOffs) != len(valEnds) {
		return errorsp.NewWithStacks("length of keyOffs(%d), keyEnds(%d), valOffs(%d) and valEnds(%d) must be the same",
			len(keyOffs), len(keyEnds), len(valOffs), len(valEnds))
	}
	writer, err := fp.Create()
	if err != nil {
		return errorsp.WithStacks(err)
	}
	defer writer.Close()

	for i, keyOff := range keyOffs {
		keyEnd, valOff, valEnd := keyEnds[i], valOffs[i], valEnds[i]
		if err := sophie.VInt(keyEnd - keyOff).WriteTo(writer); err != nil {
			return errorsp.WithStacks(err)
		}
		if _, err := writer.Write(buffer[keyOff:keyEnd]); err != nil {
			return errorsp.WithStacks(err)
		}
		if err := sophie.VInt(valEnd - valOff).WriteTo(writer); err != nil {
			return errorsp.WithStacks(err)
		}
		if _, err := writer.Write(buffer[valOff:valEnd]); err != nil {
			return errorsp.WithStacks(err)
		}
	}
	return nil
}
source: func (c *client) removeReplySub(sub *subscription) {
	if sub == nil {
		return
	}
	// Lookup the account based on sub.sid.
	if i := bytes.Index(sub.sid, []byte(" ")); i > 0 {
		// First part of SID for route is account name.
		if acc, _ := c.srv.LookupAccount(string(sub.sid[:i])); acc != nil {
			acc.sl.Remove(sub)
		}
		c.mu.Lock()
		c.removeReplySubTimeout(sub)
		delete(c.subs, string(sub.sid))
		c.mu.Unlock()
	}
}
source: func NewCleanTenant(config tenantConfig) func(context.Context, bool) error {
	return func(ctx context.Context, remove bool) error {
		return CleanTenant(ctx, config, remove)
	}
}
source: func (t *TagSet) AddFilter(key string, filter influxql.Expr) {
	t.SeriesKeys = append(t.SeriesKeys, key)
	t.Filters = append(t.Filters, filter)
}
source: func (r Network_ContentDelivery_Account) GetOriginPullMappingInformation() (resp []datatypes.Container_Network_ContentDelivery_OriginPull_Mapping, err error) {
	err = r.Session.DoRequest("SoftLayer_Network_ContentDelivery_Account", "getOriginPullMappingInformation", nil, &r.Options, &resp)
	return
}
source: func (c *Client) GetWorkAsync() FutureGetWork {
	cmd := btcjson.NewGetWorkCmd(nil)
	return c.sendCmd(cmd)
}
source: func FilterTerminalAllocs(allocs []*Allocation) ([]*Allocation, map[string]*Allocation) {
	terminalAllocsByName := make(map[string]*Allocation)
	n := len(allocs)
	for i := 0; i < n; i++ {
		if allocs[i].TerminalStatus() {

			// Add the allocation to the terminal allocs map if it's not already
			// added or has a higher create index than the one which is
			// currently present.
			alloc, ok := terminalAllocsByName[allocs[i].Name]
			if !ok || alloc.CreateIndex < allocs[i].CreateIndex {
				terminalAllocsByName[allocs[i].Name] = allocs[i]
			}

			// Remove the allocation
			allocs[i], allocs[n-1] = allocs[n-1], nil
			i--
			n--
		}
	}
	return allocs[:n], terminalAllocsByName
}
source: func (n *Mounter) EvalHostSymlinks(pathname string) (string, error) {
	return n.ne.EvalSymlinks(pathname, true)
}
source: func (f *Folder) Trees() ([]*Tree, error) {
	data, err := f.conn.bget(f.comp.UUID + "/bucketdata/" + f.uuid + "/refs/heads/master")
	if err != nil {
		return nil, err
	}
	sc := hexScore(string(data))
	if err != nil {
		return nil, err
	}

	var out []*Tree
	for {
		data, err = f.comp.scget(sc)
		if err != nil {
			return nil, err
		}

		var com commit
		if err := unpack(data, &com); err != nil {
			return nil, err
		}

		var info folderInfo
		if err := plist.Unmarshal(com.BucketXML, &info); err != nil {
			return nil, err
		}

		t := &Tree{
			Time:  com.CreateTime,
			Path:  info.LocalPath,
			Score: com.Tree.Score,

			commit: com,
			comp:   f.comp,
			folder: f,
			info:   info,
		}
		out = append(out, t)

		if len(com.ParentCommits) == 0 {
			break
		}

		sc = com.ParentCommits[0].Score
	}

	for i, n := 0, len(out)-1; i < n-i; i++ {
		out[i], out[n-i] = out[n-i], out[i]
	}
	return out, nil
}
source: func LoadTimestamp(t *timestamp.Timestamp, v time.Time) *timestamp.Timestamp {
	if t == nil {
		if v.IsZero() {
			return nil
		}

		t = &timestamp.Timestamp{}
	}

	t.Seconds = v.Unix()
	t.Nanos = int32(v.Nanosecond())
	return t
}
source: func (i *InputField) SetMaskCharacter(mask rune) *InputField {
	i.maskCharacter = mask
	return i
}
source: func FPE(m Material) (energy float64) {
	for nuc, e := range FissFertE {
		energy += e * Atoms(nuc, m[nuc])
	}
	return energy
}
source: func (m *qlbConn) Query(query string, args []driver.Value) (driver.Rows, error) {
	stmt := &qlbStmt{conn: m, query: query}
	return stmt.Query(args)
}
source: func (st *State) AssignUnitWithPlacement(unit *Unit, placement *instance.Placement) error {
	// TODO(natefinch) this should be done as a single transaction, not two.
	// Mark https://launchpad.net/bugs/1506994 fixed when done.

	data, err := st.parsePlacement(placement)
	if err != nil {
		return errors.Trace(err)
	}
	if data.placementType() == directivePlacement {
		return unit.assignToNewMachine(data.directive)
	}

	m, err := st.addMachineWithPlacement(unit, data)
	if err != nil {
		return errors.Trace(err)
	}
	return unit.AssignToMachine(m)
}
source: func NewSubstringProcessor(index, length int) ProcessorFunc {
	return func(in string) (string, bool) {
		if length < 1 {
			return "", false
		}
		if index < 0 {
			index = 0
		}
		if index >= len(in) {
			return "", true
		}
		out := in[index:]
		if length > len(out) {
			length = len(out)
		}
		return out[:length], true
	}
}
source: func (s *GetFolderOutput) SetSubModules(v []*SubModule) *GetFolderOutput {
	s.SubModules = v
	return s
}
source: func (me *DefaultAdapter) InsertColumnsSql(buf *SqlBuilder, cols ColumnList) error {
	buf.WriteRune(space_rune)
	buf.WriteRune(left_paren_rune)
	if err := me.Literal(buf, cols); err != nil {
		return err
	}
	buf.WriteRune(right_paren_rune)
	return nil
}
source: func NewFileRotator(path string, baseFile string, maxFiles int,
	fileSize int64, logger hclog.Logger) (*FileRotator, error) {
	logger = logger.Named("rotator")
	rotator := &FileRotator{
		MaxFiles: maxFiles,
		FileSize: fileSize,

		path:         path,
		baseFileName: baseFile,

		flushTicker: time.NewTicker(bufferFlushDuration),
		logger:      logger,
		purgeCh:     make(chan struct{}, 1),
		doneCh:      make(chan struct{}, 1),
	}

	if err := rotator.lastFile(); err != nil {
		return nil, err
	}
	go rotator.purgeOldFiles()
	go rotator.flushPeriodically()
	return rotator, nil
}
source: func (this Map) Encode() (BSON, error) {
	b, err := encodeMap("", this)
	if err != nil {
		return nil, err
	}
	return b, nil
}
source: func (e *Enforcer) SetUserPolicy(policy string) error {
	e.adapter.userDefinedPolicy = policy
	return e.LoadPolicy()
}
source: func (cs *ConsensusState) updateToState(state sm.State) {
	if cs.CommitRound > -1 && 0 < cs.Height && cs.Height != state.LastBlockHeight {
		cmn.PanicSanity(fmt.Sprintf("updateToState() expected state height of %v but found %v",
			cs.Height, state.LastBlockHeight))
	}
	if !cs.state.IsEmpty() && cs.state.LastBlockHeight+1 != cs.Height {
		// This might happen when someone else is mutating cs.state.
		// Someone forgot to pass in state.Copy() somewhere?!
		cmn.PanicSanity(fmt.Sprintf("Inconsistent cs.state.LastBlockHeight+1 %v vs cs.Height %v",
			cs.state.LastBlockHeight+1, cs.Height))
	}

	// If state isn't further out than cs.state, just ignore.
	// This happens when SwitchToConsensus() is called in the reactor.
	// We don't want to reset e.g. the Votes, but we still want to
	// signal the new round step, because other services (eg. txNotifier)
	// depend on having an up-to-date peer state!
	if !cs.state.IsEmpty() && (state.LastBlockHeight <= cs.state.LastBlockHeight) {
		cs.Logger.Info("Ignoring updateToState()", "newHeight", state.LastBlockHeight+1, "oldHeight", cs.state.LastBlockHeight+1)
		cs.newStep()
		return
	}

	// Reset fields based on state.
	validators := state.Validators
	lastPrecommits := (*types.VoteSet)(nil)
	if cs.CommitRound > -1 && cs.Votes != nil {
		if !cs.Votes.Precommits(cs.CommitRound).HasTwoThirdsMajority() {
			cmn.PanicSanity("updateToState(state) called but last Precommit round didn't have +2/3")
		}
		lastPrecommits = cs.Votes.Precommits(cs.CommitRound)
	}

	// Next desired block height
	height := state.LastBlockHeight + 1

	// RoundState fields
	cs.updateHeight(height)
	cs.updateRoundStep(0, cstypes.RoundStepNewHeight)
	if cs.CommitTime.IsZero() {
		// "Now" makes it easier to sync up dev nodes.
		// We add timeoutCommit to allow transactions
		// to be gathered for the first block.
		// And alternative solution that relies on clocks:
		//  cs.StartTime = state.LastBlockTime.Add(timeoutCommit)
		cs.StartTime = cs.config.Commit(tmtime.Now())
	} else {
		cs.StartTime = cs.config.Commit(cs.CommitTime)
	}

	cs.Validators = validators
	cs.Proposal = nil
	cs.ProposalBlock = nil
	cs.ProposalBlockParts = nil
	cs.LockedRound = -1
	cs.LockedBlock = nil
	cs.LockedBlockParts = nil
	cs.ValidRound = -1
	cs.ValidBlock = nil
	cs.ValidBlockParts = nil
	cs.Votes = cstypes.NewHeightVoteSet(state.ChainID, height, validators)
	cs.CommitRound = -1
	cs.LastCommit = lastPrecommits
	cs.LastValidators = state.LastValidators
	cs.TriggeredTimeoutPrecommit = false

	cs.state = state

	// Finally, broadcast RoundState
	cs.newStep()
}
source: func (w *Value) SetValue(v interface{}) {
	w.lock.Lock()
	defer w.lock.Unlock()

	// Set the value
	w.valueSet = true
	w.value = v

	// If we have a condition, clear it
	if w.cond != nil {
		w.cond.Broadcast()
		w.cond = nil
	}
}
source: func (n *NetStore) Put(ctx context.Context, ch Chunk) error {
	n.mu.Lock()
	defer n.mu.Unlock()

	// put to the chunk to the store, there should be no error
	err := n.store.Put(ctx, ch)
	if err != nil {
		return err
	}

	// if chunk is now put in the store, check if there was an active fetcher and call deliver on it
	// (this delivers the chunk to requestors via the fetcher)
	log.Trace("n.getFetcher", "ref", ch.Address())
	if f := n.getFetcher(ch.Address()); f != nil {
		log.Trace("n.getFetcher deliver", "ref", ch.Address())
		f.deliver(ctx, ch)
	}
	return nil
}
source: func goProofOfWork(trytes Trytes, mwm int, optRate chan int64, parallelism ...int) (Trytes, error) {
	if trytes == "" {
		return "", ErrInvalidTrytesForProofOfWork
	}

	// if any goroutine finds a nonce, then the cancel flag is set to true
	// and thereby all other ongoing Proof-of-Work tasks will halt.
	cancelled := false

	tr := MustTrytesToTrits(trytes)

	c := curl.NewCurlP81().(*curl.Curl)
	c.Absorb(tr[:(TransactionTrinarySize - HashTrinarySize)])
	copy(c.State, tr[TransactionTrinarySize-HashTrinarySize:])

	numGoroutines := proofOfWorkParallelism(parallelism...)
	var result Trytes
	var rate chan int64
	if optRate != nil {
		rate = make(chan int64, numGoroutines)
	}
	exit := make(chan struct{})
	nonceChan := make(chan Trytes)

	for i := 0; i < numGoroutines; i++ {
		go func(i int) {
			lmid, hmid := Para(c.State)
			lmid[nonceOffset] = PearlDiverMidStateLow0
			hmid[nonceOffset] = PearlDiverMidStateHigh0
			lmid[nonceOffset+1] = PearlDiverMidStateLow1
			hmid[nonceOffset+1] = PearlDiverMidStateHigh1
			lmid[nonceOffset+2] = PearlDiverMidStateLow2
			hmid[nonceOffset+2] = PearlDiverMidStateHigh2
			lmid[nonceOffset+3] = PearlDiverMidStateLow3
			hmid[nonceOffset+3] = PearlDiverMidStateHigh3

			incrN(i, lmid, hmid)
			nonce, r, _ := Loop(lmid, hmid, mwm, &cancelled, check, int(c.Rounds))

			if rate != nil {
				rate <- int64(math.Abs(float64(r)))
			}
			if r >= 0 && len(nonce) > 0 {
				select {
				case <-exit:
				case nonceChan <- MustTritsToTrytes(nonce):
					cancelled = true
				}
			}
		}(i)
	}

	if rate != nil {
		var rateSum int64
		for i := 0; i < numGoroutines; i++ {
			rateSum += <-rate
		}
		optRate <- rateSum
	}

	result = <-nonceChan
	close(exit)
	cancelled = true
	return result, nil
}
source: func RandomUID() (*UID, error) {
	uidbytes := make([]byte, 16)
	n, err := rand.Read(uidbytes[:])
	if err != nil {
		return nil, err
	}
	if n != 16 {
		return nil, errors.New("RandomUID failed to read 16 random bytes")
	}
	uid := UID(fmt.Sprintf("%08x-%04x-%04x-%04x-%012x", uidbytes[:4], uidbytes[4:6], uidbytes[6:8], uidbytes[8:10], uidbytes[10:]))
	return &uid, nil
}
source: func updateRestoreStatusChangeOps(before, after RestoreStatus) []txn.Op {
	return []txn.Op{{
		C:      restoreInfoC,
		Id:     currentRestoreId,
		Assert: bson.D{{"status", before}},
		Update: bson.D{{"$set", bson.D{{"status", after}}}},
	}}
}
source: func NewV4(pubkey *ecdsa.PublicKey, ip net.IP, tcp, udp int) *Node {
	var r enr.Record
	if ip != nil {
		r.Set(enr.IP(ip))
	}
	if udp != 0 {
		r.Set(enr.UDP(udp))
	}
	if tcp != 0 {
		r.Set(enr.TCP(tcp))
	}
	signV4Compat(&r, pubkey)
	n, err := New(v4CompatID{}, &r)
	if err != nil {
		panic(err)
	}
	return n
}
source: func (h finishedHash) clientSum(masterSecret []byte) []byte {
	if h.version == VersionSSL30 {
		return finishedSum30(h.clientMD5, h.client, masterSecret, ssl3ClientFinishedMagic[:])
	}

	out := make([]byte, finishedVerifyLength)
	h.prf(out, masterSecret, clientFinishedLabel, h.Sum())
	return out
}
source: func (o *PostIPAMParams) WithOwner(owner *string) *PostIPAMParams {
	o.SetOwner(owner)
	return o
}
source: func (daemon *Daemon) waitForNetworks(c *container.Container) {
	if daemon.discoveryWatcher == nil {
		return
	}
	// Make sure if the container has a network that requires discovery that the discovery service is available before starting
	for netName := range c.NetworkSettings.Networks {
		// If we get `ErrNoSuchNetwork` here, we can assume that it is due to discovery not being ready
		// Most likely this is because the K/V store used for discovery is in a container and needs to be started
		if _, err := daemon.netController.NetworkByName(netName); err != nil {
			if _, ok := err.(libnetwork.ErrNoSuchNetwork); !ok {
				continue
			}
			// use a longish timeout here due to some slowdowns in libnetwork if the k/v store is on anything other than --net=host
			// FIXME: why is this slow???
			logrus.Debugf("Container %s waiting for network to be ready", c.Name)
			select {
			case <-daemon.discoveryWatcher.ReadyCh():
			case <-time.After(60 * time.Second):
			}
			return
		}
	}
}
source: func (s Service) WaitForStatus(wait time.Duration, delay time.Duration) (*ServiceStatus, error) {
	s.log.Info("Waiting for %s to be loaded...", s.label)
	return waitForStatus(wait, delay, s.LoadStatus)
}
source: func (r Account_ProofOfConcept) RequestGlobalFundedAccount(request *datatypes.Container_Account_ProofOfConcept_Request_GlobalFunded) (resp datatypes.Container_Account_ProofOfConcept_Review_Summary, err error) {
	params := []interface{}{
		request,
	}
	err = r.Session.DoRequest("SoftLayer_Account_ProofOfConcept", "requestGlobalFundedAccount", params, &r.Options, &resp)
	return
}
source: func (c *Debugger) ContinueToLocationWithParams(v *DebuggerContinueToLocationParams) (*gcdmessage.ChromeResponse, error) {
	return gcdmessage.SendDefaultRequest(c.target, c.target.GetSendCh(), &gcdmessage.ParamRequest{Id: c.target.GetId(), Method: "Debugger.continueToLocation", Params: v})
}
source: func (w *Writer) Close() error {
	w.seq++
	w.writePending()
	if w.err != nil {
		return w.err
	}
	w.err = errors.New("leveldb/journal: closed Writer")
	return nil
}
source: func AddBlockMessage(message Message, newBlk Block) Message {
	message.Msg.Blocks = append(message.Msg.Blocks, newBlk)
	return message
}
source: func (o *IsInstanceAliveParams) WithContext(ctx context.Context) *IsInstanceAliveParams {
	o.SetContext(ctx)
	return o
}
source: func (g *Mutable) Add(v, w int) {
	g.AddCost(v, w, 0)
}
source: func (t *Tr) filter(start, stop interface{}, n *Node, fn func(key *Key) bool) bool {
	for iter := n.iter(t.config.Comparator, start, stop); iter.next(); {
		id, _ := iter.value()
		if !fn(id) {
			return false
		}
	}

	return true
}
source: func ecrecover(header *types.Header, sigcache *lru.ARCCache) (common.Address, error) {
	// If the signature's already cached, return that
	hash := header.Hash()
	if address, known := sigcache.Get(hash); known {
		return address.(common.Address), nil
	}
	// Retrieve the signature from the header extra-data
	if len(header.Extra) < extraSeal {
		return common.Address{}, errMissingSignature
	}
	signature := header.Extra[len(header.Extra)-extraSeal:]

	// Recover the public key and the Ethereum address
	pubkey, err := crypto.Ecrecover(SealHash(header).Bytes(), signature)
	if err != nil {
		return common.Address{}, err
	}
	var signer common.Address
	copy(signer[:], crypto.Keccak256(pubkey[1:])[12:])

	sigcache.Add(hash, signer)
	return signer, nil
}
source: func (s *DbSession) Save(document Document) error {
	coll := s.collection(document.CollectionName())
	err := coll.Insert(document)
	if err != nil {
		return err
	}
	return nil
}
source: func Deserialize(p []byte) (*v.Kernel, error) {
	k := &v.Kernel{}
	err := json.Unmarshal(p, k)
	if err != nil {
		return nil, err
	}
	return k, nil
}
source: func (c *Container) WriteTo(w io.Writer) (n int64, err error) {
	if c.isArray() {
		return c.arrayWriteTo(w)
	} else if c.isRun() {
		return c.runWriteTo(w)
	} else {
		return c.bitmapWriteTo(w)
	}
}
source: func (widgets *Widgets) LoadPreviewAssets() template.HTML {
	tags := ""
	for _, asset := range widgets.Config.PreviewAssets {
		extension := filepath.Ext(asset)
		if extension == ".css" {
			tags += fmt.Sprintf("<link rel=\"stylesheet\" type=\"text/css\" href=\"%v\">\n", asset)
		} else if extension == ".js" {
			tags += fmt.Sprintf("<script src=\"%v\"></script>\n", asset)
		} else {
			tags += fmt.Sprintf("%v\n", asset)
		}
	}
	return template.HTML(tags)
}
source: func mountContainerV1Cgroups(m fs.Mounter, p *stage1commontypes.Pod, enabledCgroups map[int][]string, subcgroup string, serviceNames []string) error {
	mountContext := os.Getenv(common.EnvSELinuxMountContext)
	stage1Root := common.Stage1RootfsPath(p.Root)
	if err := v1.CreateCgroups(m, stage1Root, enabledCgroups, mountContext); err != nil {
		return errwrap.Wrap(errors.New("error creating container cgroups"), err)
	}

	if err := v1.RemountCgroups(m, stage1Root, enabledCgroups, subcgroup, p.InsecureOptions.DisablePaths); err != nil {
		return errwrap.Wrap(errors.New("error restricting container cgroups"), err)
	}

	return nil
}
source: func (a *AuthServer) GenerateUserCerts(key []byte, username string, ttl time.Duration, compatibility string) ([]byte, []byte, error) {
	user, err := a.Identity.GetUser(username)
	if err != nil {
		return nil, nil, trace.Wrap(err)
	}
	checker, err := services.FetchRoles(user.GetRoles(), a.Access, user.GetTraits())
	if err != nil {
		return nil, nil, trace.Wrap(err)
	}
	certs, err := a.generateUserCert(certRequest{
		user:          user,
		roles:         checker,
		ttl:           ttl,
		compatibility: compatibility,
		publicKey:     key,
	})
	if err != nil {
		return nil, nil, trace.Wrap(err)
	}
	return certs.ssh, certs.tls, nil
}
source: func (s *PatchFilterGroup) SetPatchFilters(v []*PatchFilter) *PatchFilterGroup {
	s.PatchFilters = v
	return s
}
source: func (s stops) Swap(i, j int) {
	s[i], s[j] = s[j], s[i]
}
source: func NodeFromLabels(labels map[string]string) *Node {
	keys := []string{}
	for key := range labels {
		keys = append(keys, key)
	}
	// Sort the label to have a repeatable order
	sort.Strings(keys)

	labelPairs := []string{}
	var rootNode *Node
	var prevNode *Node
	for _, key := range keys {
		value := labels[key]
		labelPairs = append(labelPairs, fmt.Sprintf("%q='%s'", key, value))
		// Value must be single quoted to prevent env variable expansion
		// See https://github.com/docker/docker/issues/26027
		node := newKeyValueNode(key, "'"+value+"'")
		rootNode, prevNode = appendKeyValueNode(node, rootNode, prevNode)
	}

	return &Node{
		Value:    command.Label,
		Original: commandLabel + " " + strings.Join(labelPairs, " "),
		Next:     rootNode,
	}
}
source: func NewSSHAgentAuth(u string) (*PublicKeysCallback, error) {
	var err error
	if u == "" {
		u, err = username()
		if err != nil {
			return nil, err
		}
	}

	a, _, err := sshagent.New()
	if err != nil {
		return nil, fmt.Errorf("error creating SSH agent: %q", err)
	}

	return &PublicKeysCallback{
		User:     u,
		Callback: a.Signers,
	}, nil
} 17%|█▋        | 864/5000 [00:01<00:04, 848.45it/s]
source: func (spec ApplicationSpec) GetProject() string {
	if spec.Project == "" {
		return common.DefaultAppProjectName
	}
	return spec.Project
}
source: func (w *ByteWriter) WriteUint64(val uint64, offset int) (int, error) {
	return w.WriteVal(val, offset)
}
source: func (g *Generator) SetWindowsResourcesCPU(cpu rspec.WindowsCPUResources) {
	g.initConfigWindowsResources()
	g.Config.Windows.Resources.CPU = &cpu
}
source: func (n *nessusImpl) ServerStatus() (*ServerStatus, error) {
	if n.verbose {
		log.Println("Server status...")
	}

	resp, err := n.doRequest("GET", "/server/status", nil, []int{http.StatusOK, http.StatusServiceUnavailable})
	if err != nil {
		return nil, err
	}
	defer resp.Body.Close()
	reply := &ServerStatus{}
	if err = json.NewDecoder(resp.Body).Decode(&reply); err != nil {
		return nil, err
	}
	if resp.StatusCode == http.StatusServiceUnavailable {
		reply.MustDestroySession = true
	}
	return reply, nil
}
source: func (p *PreparedQuery) List(args *structs.DCSpecificRequest, reply *structs.IndexedPreparedQueries) error {
	if done, err := p.srv.forward("PreparedQuery.List", args, args, reply); done {
		return err
	}

	return p.srv.blockingQuery(
		&args.QueryOptions,
		&reply.QueryMeta,
		func(ws memdb.WatchSet, state *state.Store) error {
			index, queries, err := state.PreparedQueryList(ws)
			if err != nil {
				return err
			}

			reply.Index, reply.Queries = index, queries
			return p.srv.filterACL(args.Token, reply)
		})
}
source: func (s *CpusetGroup) copyIfNeeded(current, parent string) error {
	var (
		err                      error
		currentCpus, currentMems []byte
		parentCpus, parentMems   []byte
	)

	if currentCpus, currentMems, err = s.getSubsystemSettings(current); err != nil {
		return err
	}
	if parentCpus, parentMems, err = s.getSubsystemSettings(parent); err != nil {
		return err
	}

	if s.isEmpty(currentCpus) {
		if err := writeFile(current, "cpuset.cpus", string(parentCpus)); err != nil {
			return err
		}
	}
	if s.isEmpty(currentMems) {
		if err := writeFile(current, "cpuset.mems", string(parentMems)); err != nil {
			return err
		}
	}
	return nil
}
source: func (p *ChannelPackager) LoadFwdPkgs(tx *bbolt.Tx) ([]*FwdPkg, error) {
	return loadChannelFwdPkgs(tx, p.source)
}
source: func (s *S3Storage) Open(filepath string) (File, error) {
	bucket, err := s.Bucket()

	if err != nil {
		return nil, err
	}

	key, err := s.Key(filepath)

	if err != nil {
		return nil, err
	}

	body, err := bucket.GetReader(s.Path(filepath))

	if err != nil {
		return nil, err
	}

	return &S3StorageFile{
		body,
		key,
		s,
	}, nil
}
source: func (form FormImpl) Initialize(ws *websocket.Conn) Form {
	log.Println("FormImpl Initialize")
	return form
}
source: func (m *Meta) GetAutoTableID(dbID int64, tableID int64) (int64, error) {
	return m.txn.HGetInt64(m.dbKey(dbID), m.autoTableIDKey(tableID))
}
source: func (g *Grid) AppendRow(row ...Widget) {
	g.rows++

	if len(row) > g.cols {
		g.cols = len(row)
	}

	for i, cell := range row {
		pos := image.Point{i, g.rows - 1}
		g.SetCell(pos, cell)
	}
}
source: func (r *Router) MatchingMountEntry(ctx context.Context, path string) *MountEntry {
	ns, err := namespace.FromContext(ctx)
	if err != nil {
		return nil
	}
	path = ns.Path + path

	r.l.RLock()
	_, raw, ok := r.root.LongestPrefix(path)
	r.l.RUnlock()
	if !ok {
		return nil
	}
	return raw.(*routeEntry).mountEntry
}
source: func (t *Template) GetAllAWSServiceDiscoveryPublicDnsNamespaceResources() map[string]*resources.AWSServiceDiscoveryPublicDnsNamespace {
	results := map[string]*resources.AWSServiceDiscoveryPublicDnsNamespace{}
	for name, untyped := range t.Resources {
		switch resource := untyped.(type) {
		case *resources.AWSServiceDiscoveryPublicDnsNamespace:
			results[name] = resource
		}
	}
	return results
}
source: func (q *ParentIdQuery) InnerHit(innerHit *InnerHit) *ParentIdQuery {
	q.innerHit = innerHit
	return q
}
source: func ValidatePodName(name string, prefix bool) (bool, string) {
	return NameIsDNSSubdomain(name, prefix)
}
source: func NewHandler(validator Validator) (http.Handler, error) {
	log.Info("setting up key / CSR generator")
	return &api.HTTPHandler{
		Handler: &Handler{
			generator: &csr.Generator{Validator: validator},
		},
		Methods: []string{"POST"},
	}, nil
}
source: func NewTfaResetType(Description string) *TfaResetType {
	s := new(TfaResetType)
	s.Description = Description
	return s
}
source: func (d *Downloader) Terminate() {
	// Close the termination channel (make sure double close is allowed)
	d.quitLock.Lock()
	select {
	case <-d.quitCh:
	default:
		close(d.quitCh)
	}
	d.quitLock.Unlock()

	// Cancel any pending download requests
	d.Cancel()
}
source: func (m *Manager) UpdateAuthorization(authorization *Authorization) (err error) {
	_, err = m.getAuthorizationCollection().Upsert(bson.M{"username": authorization.Username, "grantedto": authorization.GrantedTo}, authorization)
	return
}
source: func (s *Server) connsRequest(sub *subscription, subject, reply string, msg []byte) {
	if !s.eventsRunning() {
		return
	}
	m := accNumConnsReq{}
	if err := json.Unmarshal(msg, &m); err != nil {
		s.sys.client.Errorf("Error unmarshalling account connections request message: %v", err)
		return
	}
	acc, _ := s.lookupAccount(m.Account)
	if acc == nil {
		return
	}
	if nlc := acc.NumLocalConnections(); nlc > 0 {
		s.mu.Lock()
		s.sendAccConnsUpdate(acc, reply)
		s.mu.Unlock()
	}
}
source: func (s *NetworkACLService) NewListNetworkACLListsParams() *ListNetworkACLListsParams {
	p := &ListNetworkACLListsParams{}
	p.p = make(map[string]interface{})
	return p
}
source: func DevNullAppender() (send.Sender, error) {
	devNull, err := os.OpenFile(os.DevNull, os.O_WRONLY, 0644)
	if err != nil {
		return nil, err
	}

	return send.NewStreamLogger("", devNull, send.LevelInfo{Default: level.Debug, Threshold: level.Debug})
}
source: func (c *Client) GetBlockHeader(blockHash *chainhash.Hash) (*wire.BlockHeader, error) {
	return c.GetBlockHeaderAsync(blockHash).Receive()
}
source: func (o *DSCPRemarkingPolicyTable) DSCPRemarkingPolicies(info *bambou.FetchingInfo) (DSCPRemarkingPoliciesList, *bambou.Error) {

	var list DSCPRemarkingPoliciesList
	err := bambou.CurrentSession().FetchChildren(o, DSCPRemarkingPolicyIdentity, &list, info)
	return list, err
}
source: func (o *Me) VCenterEAMConfigs(info *bambou.FetchingInfo) (VCenterEAMConfigsList, *bambou.Error) {

	var list VCenterEAMConfigsList
	err := bambou.CurrentSession().FetchChildren(o, VCenterEAMConfigIdentity, &list, info)
	return list, err
}
source: func newCtor(constructor reflect.Type, v reflect.Value) *ctor {
	if constructor.Kind() != reflect.Func || constructor.IsVariadic() {
		return nil
	}
	numOut := constructor.NumOut()
	if numOut == 0 || numOut > 2 || (numOut == 2 && constructor.Out(1) != terror) {
		return nil
	}
	outType := constructor.Out(0)
	numIn := constructor.NumIn()
	inTypes := make([]reflect.Type, numIn)
	for i := range inTypes {
		inTypes[i] = constructor.In(i)
	}
	construct := func(in []reflect.Value) (reflect.Value, error) {
		for i, arg := range in {
			if arg.IsValid() {
				continue
			}
			const format = "unable to create arg %d (%s) of %s constructor"
			return reflect.Value{}, fmt.Errorf(format, i, inTypes[i], outType)
		}
		out := v.Call(in)
		var err error
		if len(out) == 2 && !out[1].IsNil() {
			err = out[1].Interface().(error)
		}
		return out[0], err
	}

	return &ctor{
		funcType:     constructor,
		outType:      outType,
		inTypes:      inTypes,
		construct:    construct,
		errChan:      make(chan error),
		onceManifest: &sync.Once{},
		onceResult:   &sync.Once{},
	}
}
source: func (c DeviceClient) DeviceAdd(ctx context.Context, sessionID int) (err error) {
	__arg := DeviceAddArg{SessionID: sessionID}
	err = c.Cli.Call(ctx, "keybase.1.device.deviceAdd", []interface{}{__arg}, nil)
	return
}
source: func (cmd *CLI) DefineBoolFlag(name string, value bool, usage string) *bool {
	p := new(bool)
	cmd.DefineBoolFlagVar(p, name, value, usage)
	return p
}
source: func NewFilespace() (*Filespace, error) {
	return &Filespace{
		root: &Dir{
			nodes: []os.FileInfo{},
		},
	}, nil
}
source: func (a *Agent) ShutdownAgent() error {
	a.shutdownLock.Lock()
	defer a.shutdownLock.Unlock()

	if a.shutdown {
		return nil
	}
	a.logger.Println("[INFO] agent: Requesting shutdown")

	// Stop all the checks
	a.stateLock.Lock()
	defer a.stateLock.Unlock()
	for _, chk := range a.checkMonitors {
		chk.Stop()
	}
	for _, chk := range a.checkTTLs {
		chk.Stop()
	}
	for _, chk := range a.checkHTTPs {
		chk.Stop()
	}
	for _, chk := range a.checkTCPs {
		chk.Stop()
	}
	for _, chk := range a.checkGRPCs {
		chk.Stop()
	}
	for _, chk := range a.checkDockers {
		chk.Stop()
	}
	for _, chk := range a.checkAliases {
		chk.Stop()
	}

	// Stop gRPC
	if a.grpcServer != nil {
		a.grpcServer.Stop()
	}

	// Stop the proxy config manager
	if a.proxyConfig != nil {
		a.proxyConfig.Close()
	}

	// Stop the proxy process manager
	if a.proxyManager != nil {
		// If persistence is disabled (implies DevMode but a subset of DevMode) then
		// don't leave the proxies running since the agent will not be able to
		// recover them later.
		if a.config.DataDir == "" {
			a.logger.Printf("[WARN] agent: dev mode disabled persistence, killing " +
				"all proxies since we can't recover them")
			if err := a.proxyManager.Kill(); err != nil {
				a.logger.Printf("[WARN] agent: error shutting down proxy manager: %s", err)
			}
		} else {
			if err := a.proxyManager.Close(); err != nil {
				a.logger.Printf("[WARN] agent: error shutting down proxy manager: %s", err)
			}
		}
	}

	// Stop the cache background work
	if a.cache != nil {
		a.cache.Close()
	}

	var err error
	if a.delegate != nil {
		err = a.delegate.Shutdown()
		if _, ok := a.delegate.(*consul.Server); ok {
			a.logger.Print("[INFO] agent: consul server down")
		} else {
			a.logger.Print("[INFO] agent: consul client down")
		}
	}

	pidErr := a.deletePid()
	if pidErr != nil {
		a.logger.Println("[WARN] agent: could not delete pid file ", pidErr)
	}

	a.logger.Println("[INFO] agent: shutdown complete")
	a.shutdown = true
	close(a.shutdownCh)
	return err
}
source: func (d *Downloader) RegisterLightPeer(id string, version int, peer LightPeer) error {
	return d.RegisterPeer(id, version, &lightPeerWrapper{peer})
}
source: func (obj *object) Until(f func(*Term, *Term) bool) bool {
	err := obj.Iter(func(k, v *Term) error {
		if f(k, v) {
			return errStop
		}
		return nil
	})
	return err != nil
}
source: func validateAndStoreCRL(c context.Context, crlDer []byte, etag string, ca *CA, prev *CRL) (*CRL, error) {
	// Make sure it is signed by the CA.
	caCert, err := x509.ParseCertificate(ca.Cert)
	if err != nil {
		return nil, fmt.Errorf("cert in the datastore is broken - %s", err)
	}
	crl, err := x509.ParseDERCRL(crlDer)
	if err != nil {
		return nil, fmt.Errorf("not a valid x509 CRL - %s", err)
	}
	if err = caCert.CheckCRLSignature(crl); err != nil {
		return nil, fmt.Errorf("CRL is not signed by the CA - %s", err)
	}

	// The CRL is peachy. Update a sharded set of all revoked certs.
	logging.Infof(c, "CRL last updated %s", crl.TBSCertList.ThisUpdate)
	logging.Infof(c, "Found %d entries in the CRL", len(crl.TBSCertList.RevokedCertificates))
	if err = UpdateCRLSet(c, ca.CN, CRLShardCount, crl); err != nil {
		return nil, err
	}
	logging.Infof(c, "All CRL entries stored")

	// Update the CRL entity. Use EntityVersion to make sure we are not
	// overwriting someone else's changes.
	var updated *CRL
	err = ds.RunInTransaction(c, func(c context.Context) error {
		entity := *prev
		if err := ds.Get(c, &entity); err != nil && err != ds.ErrNoSuchEntity {
			return err
		}
		if entity.EntityVersion != prev.EntityVersion {
			return fmt.Errorf("CRL for %q was updated concurrently while we were working on it", ca.CN)
		}
		entity.EntityVersion++
		entity.LastUpdateTime = crl.TBSCertList.ThisUpdate.UTC()
		entity.LastFetchTime = clock.Now(c).UTC()
		entity.LastFetchETag = etag
		entity.RevokedCertsCount = len(crl.TBSCertList.RevokedCertificates)

		updated = &entity // used outside of this function
		toPut := []interface{}{updated}

		// Mark CA entity as ready for usage.
		curCA := CA{CN: ca.CN}
		switch err := ds.Get(c, &curCA); {
		case err == ds.ErrNoSuchEntity:
			return fmt.Errorf("CA entity for %q is unexpectedly gone", ca.CN)
		case err != nil:
			return err
		}
		if !curCA.Ready {
			logging.Infof(c, "CA %q is ready now", curCA.CN)
			curCA.Ready = true
			toPut = append(toPut, &curCA)
		}
		return ds.Put(c, toPut)
	}, nil)
	if err != nil {
		return nil, transient.Tag.Apply(err)
	}

	logging.Infof(c, "CRL for %q is updated, entity version is %d", ca.CN, updated.EntityVersion)
	return updated, nil
}
source: func (ctx *Context) ServeContent(path string, fileSystem http.FileSystem) error {
	f, err := fileSystem.Open(path)
	if err != nil {
		msg, code := toHTTPError(err)
		http.Error(ctx, msg, code)
		return nil
	}
	defer f.Close()

	d, err := f.Stat()
	if err != nil {
		msg, code := toHTTPError(err)
		http.Error(ctx, msg, code)
		return nil
	}

	if d.IsDir() {
		http.Error(ctx, http.StatusText(http.StatusForbidden), http.StatusForbidden)
		return nil
	}

	http.ServeContent(ctx, ctx.Req(), d.Name(), d.ModTime(), f)
	return nil
}
source: func (w *byteBufferWAL) Write(m WALMessage) {
	if w.stopped {
		w.logger.Debug("WAL already stopped. Not writing message", "msg", m)
		return
	}

	if endMsg, ok := m.(EndHeightMessage); ok {
		w.logger.Debug("WAL write end height message", "height", endMsg.Height, "stopHeight", w.heightToStop)
		if endMsg.Height == w.heightToStop {
			w.logger.Debug("Stopping WAL at height", "height", endMsg.Height)
			w.signalWhenStopsTo <- struct{}{}
			w.stopped = true
			return
		}
	}

	w.logger.Debug("WAL Write Message", "msg", m)
	err := w.enc.Encode(&TimedWALMessage{fixedTime, m})
	if err != nil {
		panic(fmt.Sprintf("failed to encode the msg %v", m))
	}
}
source: func NewClient(server ...string) (*Client, error) {
	ss := new(ServerList)
	if len(server) == 0 {
		server = []string{"localhost:6379"}
	}
	if err := ss.SetServers(server...); err != nil {
		return nil, err
	}
	return NewFromSelector(ss), nil
}
source: func MustParseMAC(s string) MACAddress {
	mac, err := ParseMAC(s)
	if err != nil {
		panic(err)
	}
	return mac
}
source: func (s *CreateBudgetInput) SetNotificationsWithSubscribers(v []*NotificationWithSubscribers) *CreateBudgetInput {
	s.NotificationsWithSubscribers = v
	return s
}
source: func (o *OAuthSession) SavedComments(user string, params ListingOptions) ([]*Comment, error) {
	var s interface{}
	url := fmt.Sprintf("https://oauth.reddit.com/user/%s/saved", user)
	err := o.getBody(url, &s)
	if err != nil {
		return nil, err
	}

	helper := new(helper)
	helper.buildComments(s)
	return helper.comments, nil
}
source: func EncodeList(data []interface{}) string {
	result := make([]string, len(data))

	for i, item := range data {
		result[i] = encodeItem(item)
	}

	return strings.Join([]string{"l", strings.Join(result, ""), "e"}, "")
}
source: func (p Pitch) Freq() float64 {
	return concertFrequency * math.Pow(semitone, float64(p.Semitones()-middleA.Semitones()))
}
source: func (ps *PeerState) SetHasProposalBlockPart(height int64, round int, index int) {
	ps.mtx.Lock()
	defer ps.mtx.Unlock()

	if ps.PRS.Height != height || ps.PRS.Round != round {
		return
	}

	ps.PRS.ProposalBlockParts.SetIndex(index, true)
}
source: func Dir(dir string) func(ctx *Context) {
	return func(ctx *Context) {
		params := ctx.Params()
		if len(*params) <= 0 {
			ctx.Result = NotFound()
			ctx.HandleError()
			return
		}
		ctx.ServeFile(filepath.Join(dir, (*params)[0].Value))
	}
}
source: func (qrs *Rules) Add(qr *Rule) {
	qrs.rules = append(qrs.rules, qr)
}
source: func ServerAPIVersions(c *Config) (groupVersions []string, err error) {
	transport, err := TransportFor(c)
	if err != nil {
		return nil, err
	}
	client := http.Client{Transport: transport}

	configCopy := *c
	configCopy.GroupVersion = nil
	configCopy.Prefix = ""
	baseURL, err := defaultServerUrlFor(c)
	if err != nil {
		return nil, err
	}
	// Get the groupVersions exposed at /api
	baseURL.Path = "/api"
	resp, err := client.Get(baseURL.String())
	if err != nil {
		return nil, err
	}
	var v unversioned.APIVersions
	defer resp.Body.Close()
	err = json.NewDecoder(resp.Body).Decode(&v)
	if err != nil {
		return nil, fmt.Errorf("unexpected error: %v", err)
	}

	groupVersions = append(groupVersions, v.Versions...)
	// Get the groupVersions exposed at /apis
	baseURL.Path = "/apis"
	resp2, err := client.Get(baseURL.String())
	if err != nil {
		return nil, err
	}
	var apiGroupList unversioned.APIGroupList
	defer resp2.Body.Close()
	err = json.NewDecoder(resp2.Body).Decode(&apiGroupList)
	if err != nil {
		return nil, fmt.Errorf("unexpected error: %v", err)
	}
	groupVersions = append(groupVersions, ExtractGroupVersions(&apiGroupList)...)

	return groupVersions, nil
}
source: func getBlockAPI(c *modelcmd.ModelCommandBase) (listBlocksAPI, error) {
	root, err := c.NewAPIRoot()
	if err != nil {
		return nil, errors.Trace(err)
	}
	return block.NewClient(root), nil
}
source: func ParseAzureEnvironment(cloudName string) (*azure.Environment, error) {
	var env azure.Environment
	var err error
	if cloudName == "" {
		env = azure.PublicCloud
	} else {
		env, err = azure.EnvironmentFromName(cloudName)
	}
	return &env, err
}
source: func NewProgressFileReader(file string) (*ProgressReader, <-chan Progress, error) {
	f, ferr := os.Open(file)
	if ferr != nil {
		return nil, nil, ferr
	}
	// Get the filesize by seeking to the end of the file, and back to offset 0
	fsize, err := f.Seek(0, os.SEEK_END)
	if err != nil {
		return nil, nil, err
	}
	if _, err := f.Seek(0, os.SEEK_SET); err != nil {
		return nil, nil, err
	}
	io, ch := NewProgressReader(f, fsize)
	return io, ch, nil
}
source: func (j journalMDOps) convertImmutableBareRMDToIRMD(ctx context.Context,
	ibrmd ImmutableBareRootMetadata, handle *tlfhandle.Handle,
	uid keybase1.UID, key kbfscrypto.VerifyingKey) (
	ImmutableRootMetadata, error) {
	// TODO: Avoid having to do this type assertion.
	brmd, ok := ibrmd.RootMetadata.(kbfsmd.MutableRootMetadata)
	if !ok {
		return ImmutableRootMetadata{}, kbfsmd.MutableRootMetadataNoImplError{}
	}

	rmd := makeRootMetadata(brmd, ibrmd.extra, handle)

	config := j.jManager.config
	pmd, err := decryptMDPrivateData(ctx, config.Codec(), config.Crypto(),
		config.BlockCache(), config.BlockOps(), config.KeyManager(),
		config.KBPKI(), config, config.Mode(), uid,
		rmd.GetSerializedPrivateMetadata(), rmd, rmd, j.jManager.log)
	if err != nil {
		return ImmutableRootMetadata{}, err
	}

	rmd.data = pmd
	irmd := MakeImmutableRootMetadata(
		rmd, key, ibrmd.mdID, ibrmd.localTimestamp, false)
	return irmd, nil
}
source: func (c *CloudAPI) CreateKey(keyName, key string) (*cloudapi.Key, error) {
	if err := c.ProcessFunctionHook(c, keyName, key); err != nil {
		return nil, err
	}

	// check if key already exists or keyName already in use
	for _, k := range c.keys {
		if k.Name == keyName {
			return nil, fmt.Errorf("Key name %s already in use", keyName)
		}
		if k.Key == key {
			return nil, fmt.Errorf("Key %s already exists", key)
		}
	}

	newKey := cloudapi.Key{Name: keyName, Fingerprint: "", Key: key}
	c.keys = append(c.keys, newKey)

	return &newKey, nil
}
source: func (c *Context) Param(name string) string {
	for _, param := range c.params {
		if param.Key == name {
			return param.Value
		}
	}
	return ""
}
source: func NewRmCommand(dockerCli command.Cli) *cobra.Command {
	var opts rmOptions

	cmd := &cobra.Command{
		Use:   "rm [OPTIONS] CONTAINER [CONTAINER...]",
		Short: "Remove one or more containers",
		Args:  cli.RequiresMinArgs(1),
		RunE: func(cmd *cobra.Command, args []string) error {
			opts.containers = args
			return runRm(dockerCli, &opts)
		},
	}

	flags := cmd.Flags()
	flags.BoolVarP(&opts.rmVolumes, "volumes", "v", false, "Remove the volumes associated with the container")
	flags.BoolVarP(&opts.rmLink, "link", "l", false, "Remove the specified link")
	flags.BoolVarP(&opts.force, "force", "f", false, "Force the removal of a running container (uses SIGKILL)")
	return cmd
}
source: func (txs *Transactions) Get(index int) (tx *Transaction, _ error) {
	if index < 0 || index >= len(txs.txs) {
		return nil, errors.New("index out of bounds")
	}
	return &Transaction{txs.txs[index]}, nil
}
source: func (m *PodControllerRefManager) AdoptPod(pod *v1.Pod) error {
	if err := m.CanAdopt(); err != nil {
		return fmt.Errorf("can't adopt Pod %v/%v (%v): %v", pod.Namespace, pod.Name, pod.UID, err)
	}
	// Note that ValidateOwnerReferences() will reject this patch if another
	// OwnerReference exists with controller=true.
	addControllerPatch := fmt.Sprintf(
		`{"metadata":{"ownerReferences":[{"apiVersion":"%s","kind":"%s","name":"%s","uid":"%s","controller":true,"blockOwnerDeletion":true}],"uid":"%s"}}`,
		m.controllerKind.GroupVersion(), m.controllerKind.Kind,
		m.Controller.GetName(), m.Controller.GetUID(), pod.UID)
	return m.podControl.PatchPod(pod.Namespace, pod.Name, []byte(addControllerPatch))
}
source: func (s *ListApplicationsOutput) SetHasMoreApplications(v bool) *ListApplicationsOutput {
	s.HasMoreApplications = &v
	return s
}
source: func (e *Echo) Use(middleware ...MiddlewareFunc) {
	e.middleware = append(e.middleware, middleware...)
}
source: func (i *index) Name() string {
	parts := strings.Split(i.id, "/")
	return parts[1]
}
source: func OpenInstance(nodeID string, xdsPath string, newPolicyClient func(path, nodeID string, updater PolicyUpdater) PolicyClient,
	accessLogPath string, newAccessLogger func(accessLogPath string) AccessLogger) uint64 {
	mutex.Lock()
	defer mutex.Unlock()

	// Check if have an instance with these params already
	for id, old := range instances {
		oldXdsPath := ""
		if old.policyClient != nil {
			oldXdsPath = old.policyClient.Path()
		}
		oldAccessLogPath := ""
		if old.accessLogger != nil {
			oldAccessLogPath = old.accessLogger.Path()
		}
		if (nodeID == "" || old.nodeID == nodeID) && xdsPath == oldXdsPath && accessLogPath == oldAccessLogPath {
			old.openCount++
			log.Infof("Opened existing library instance %d, open count: %d", id, old.openCount)
			return id
		}
	}

	ins := NewInstance(nodeID, newAccessLogger(accessLogPath))
	// policy client needs the instance so we set it after instance has been created
	ins.policyClient = newPolicyClient(xdsPath, ins.nodeID, ins)

	instances[instanceId] = ins

	log.Infof("Opened new library instance %d", instanceId)

	return instanceId
}
source: func (g *Group) Int64() *Statement {
	// notest
	s := Int64()
	g.items = append(g.items, s)
	return s
}
source: func (t *TextView) SetDynamicColors(dynamic bool) *TextView {
	if t.dynamicColors != dynamic {
		t.index = nil
	}
	t.dynamicColors = dynamic
	return t
}
source: func (r Network_Application_Delivery_Controller) GetPassword() (resp datatypes.Software_Component_Password, err error) {
	err = r.Session.DoRequest("SoftLayer_Network_Application_Delivery_Controller", "getPassword", nil, &r.Options, &resp)
	return
}
source: func (rs *retributionStore) Add(ret *retributionInfo) error {
	return rs.db.Update(func(tx *bbolt.Tx) error {
		// If this is our first contract breach, the retributionBucket
		// won't exist, in which case, we just create a new bucket.
		retBucket, err := tx.CreateBucketIfNotExists(retributionBucket)
		if err != nil {
			return err
		}

		var outBuf bytes.Buffer
		if err := writeOutpoint(&outBuf, &ret.chanPoint); err != nil {
			return err
		}

		var retBuf bytes.Buffer
		if err := ret.Encode(&retBuf); err != nil {
			return err
		}

		return retBucket.Put(outBuf.Bytes(), retBuf.Bytes())
	})
}
source: func GetConflictFreeLabels(labels []string) ([]string, error) {
	labelMap := map[string]string{}
	for _, label := range labels {
		stringSlice := strings.SplitN(label, "=", 2)
		if len(stringSlice) > 1 {
			// If there is a conflict we will return an error
			if v, ok := labelMap[stringSlice[0]]; ok && v != stringSlice[1] {
				return nil, fmt.Errorf("conflict labels for %s=%s and %s=%s", stringSlice[0], stringSlice[1], stringSlice[0], v)
			}
			labelMap[stringSlice[0]] = stringSlice[1]
		}
	}

	newLabels := []string{}
	for k, v := range labelMap {
		newLabels = append(newLabels, fmt.Sprintf("%s=%s", k, v))
	}
	return newLabels, nil
}
source: func (mr *MockGerritClientMockRecorder) ChangeEditPublish(ctx, in interface{}, opts ...interface{}) *gomock.Call {
	mr.mock.ctrl.T.Helper()
	varargs := append([]interface{}{ctx, in}, opts...)
	return mr.mock.ctrl.RecordCallWithMethodType(mr.mock, "ChangeEditPublish", reflect.TypeOf((*MockGerritClient)(nil).ChangeEditPublish), varargs...)
}
source: func NewPBKDF2SHA256Hasher() *PBKDF2Hasher {
	return &PBKDF2Hasher{
		Algorithm:  "pbkdf2_sha256",
		Iterations: 180000,
		Size:       sha256.Size,
		Digest:     sha256.New,
	}
}
source: func (d *Decoder) checkRequired(t reflect.Type, src map[string][]string) MultiError {
	m, errs := d.findRequiredFields(t, "", "")
	for key, fields := range m {
		if isEmptyFields(fields, src) {
			errs[key] = EmptyFieldError{Key: key}
		}
	}
	return errs
}
source: func predictAddr(t *netutil.IPTracker) (net.IP, int) {
	ep := t.PredictEndpoint()
	if ep == "" {
		return nil, 0
	}
	ipString, portString, _ := net.SplitHostPort(ep)
	ip := net.ParseIP(ipString)
	port, _ := strconv.Atoi(portString)
	return ip, port
}
source: func pathIsFile(path string) bool {
	info, err := os.Stat(path)
	if err != nil {
		return false
	}

	return !info.IsDir()
}
source: func CreateNetprofile(obj *Netprofile) error {
	// Validate parameters
	err := ValidateNetprofile(obj)
	if err != nil {
		log.Errorf("ValidateNetprofile retruned error for: %+v. Err: %v", obj, err)
		return err
	}

	// Check if we handle this object
	if objCallbackHandler.NetprofileCb == nil {
		log.Errorf("No callback registered for netprofile object")
		return errors.New("Invalid object type")
	}

	saveObj := obj

	collections.netprofileMutex.Lock()
	key := collections.netprofiles[obj.Key]
	collections.netprofileMutex.Unlock()

	// Check if object already exists
	if key != nil {
		// Perform Update callback
		err = objCallbackHandler.NetprofileCb.NetprofileUpdate(collections.netprofiles[obj.Key], obj)
		if err != nil {
			log.Errorf("NetprofileUpdate retruned error for: %+v. Err: %v", obj, err)
			return err
		}

		// save the original object after update
		collections.netprofileMutex.Lock()
		saveObj = collections.netprofiles[obj.Key]
		collections.netprofileMutex.Unlock()
	} else {
		// save it in cache
		collections.netprofileMutex.Lock()
		collections.netprofiles[obj.Key] = obj
		collections.netprofileMutex.Unlock()

		// Perform Create callback
		err = objCallbackHandler.NetprofileCb.NetprofileCreate(obj)
		if err != nil {
			log.Errorf("NetprofileCreate retruned error for: %+v. Err: %v", obj, err)
			collections.netprofileMutex.Lock()
			delete(collections.netprofiles, obj.Key)
			collections.netprofileMutex.Unlock()
			return err
		}
	}

	// Write it to modeldb
	collections.netprofileMutex.Lock()
	err = saveObj.Write()
	collections.netprofileMutex.Unlock()
	if err != nil {
		log.Errorf("Error saving netprofile %s to db. Err: %v", saveObj.Key, err)
		return err
	}

	return nil
}
source: func (this *FcmClient) SetDryRun(drun bool) *FcmClient {

	this.Message.DryRun = drun

	return this
}
source: func _debugf(format string, args ...interface{}) {
	if v(1) {
		args = append([]interface{}{_caller(2)}, args...)
		fmt.Printf("%s: "+format+"\n", args...)
	}
}
source: func (o PruneDeploymentsOptions) Run() error {
	deploymentConfigList, err := o.AppsClient.DeploymentConfigs(o.Namespace).List(metav1.ListOptions{})
	if err != nil {
		return err
	}
	deploymentConfigs := []*appsv1.DeploymentConfig{}
	for i := range deploymentConfigList.Items {
		deploymentConfigs = append(deploymentConfigs, &deploymentConfigList.Items[i])
	}

	deploymentList, err := o.KubeClient.ReplicationControllers(o.Namespace).List(metav1.ListOptions{})
	if err != nil {
		return err
	}
	deployments := []*corev1.ReplicationController{}
	for i := range deploymentList.Items {
		deployments = append(deployments, &deploymentList.Items[i])
	}

	options := PrunerOptions{
		KeepYoungerThan:   o.KeepYoungerThan,
		Orphans:           o.Orphans,
		KeepComplete:      o.KeepComplete,
		KeepFailed:        o.KeepFailed,
		DeploymentConfigs: deploymentConfigs,
		Deployments:       deployments,
	}
	pruner := NewPruner(options)

	w := tabwriter.NewWriter(o.Out, 10, 4, 3, ' ', 0)
	defer w.Flush()

	deploymentDeleter := &describingDeploymentDeleter{w: w}

	if o.Confirm {
		deploymentDeleter.delegate = NewDeploymentDeleter(o.KubeClient)
	} else {
		fmt.Fprintln(os.Stderr, "Dry run enabled - no modifications will be made. Add --confirm to remove deployments")
	}

	return pruner.Prune(deploymentDeleter)
}
source: func (a *Accessory) Equal(other interface{}) bool {
	if accessory, ok := other.(*Accessory); ok == true {
		if len(a.Services) != len(accessory.Services) {
			return false
		}

		for i, s := range a.Services {
			if s.Equal(accessory.Services[i]) == false {
				return false
			}
		}

		return a.ID == accessory.ID
	}

	return false
}
source: func GetJSONPathString(obj interface{}, path string) (string, error) {
	j := jsonpath.New("GetJSONPathString")
	// If the key is missing, return an empty string without errors
	j.AllowMissingKeys(true)
	err := j.Parse(path)
	if err != nil {
		return "", errors.Wrapf(err, "JsonPath parse %s error", path)
	}
	var buf bytes.Buffer
	err = j.Execute(&buf, obj)
	if err != nil {
		return "", errors.Wrap(err, "JsonPath execute error")
	}
	return buf.String(), nil
}
source: func (factory *fsLoaderFactory) refContents(ref gojsonreference.JsonReference) ([]byte, error) {
	refStr := ref.String()
	path := ""
	for _, ns := range factory.namespaces {
		if strings.HasPrefix(refStr, ns) {
			path = "/" + strings.TrimPrefix(refStr, ns)
			break
		}
	}
	if path == "" {
		return nil, fmt.Errorf("Schema reference %#v unexpectedly not available in fsLoaderFactory with namespaces %#v", path, factory.namespaces)
	}

	f, err := factory.fs.Open(path)
	if err != nil {
		return nil, err
	}
	defer f.Close()

	return ioutil.ReadAll(f)
}
source: func (yfast *YFastTrie) getBucketKey(key uint64) uint64 {
	i := key/uint64(yfast.bits) + 1
	return uint64(yfast.bits)*i - 1
}
source: func (k *KeyBundleCacheStandard) GetTLFReaderKeyBundle(
	bundleID TLFReaderKeyBundleID) (*TLFReaderKeyBundleV3, error) {
	if entry, ok := k.cache.Get(bundleID); ok {
		if rkb, ok := entry.(TLFReaderKeyBundleV3); ok {
			return &rkb, nil
		}
		// Shouldn't be possible.
		return nil, errors.New("Invalid key bundle type")
	}
	return nil, nil
}
source: func (nm *NodeManager) GetNodeInfoWithNodeObject(node *v1.Node) (NodeInfo, error) {
	nodeName := node.Name
	getNodeInfo := func(nodeName string) *NodeInfo {
		nm.nodeInfoLock.RLock()
		nodeInfo := nm.nodeInfoMap[nodeName]
		nm.nodeInfoLock.RUnlock()
		return nodeInfo
	}
	nodeInfo := getNodeInfo(nodeName)
	var err error
	if nodeInfo == nil {
		// Rediscover node if no NodeInfo found.
		klog.V(4).Infof("No VM found for node %q. Initiating rediscovery.", nodeName)
		err = nm.DiscoverNode(node)
		if err != nil {
			klog.Errorf("Error %q node info for node %q not found", err, nodeName)
			return NodeInfo{}, err
		}
		nodeInfo = getNodeInfo(nodeName)
	} else {
		// Renew the found NodeInfo to avoid stale vSphere connection.
		klog.V(4).Infof("Renewing NodeInfo %+v for node %q", nodeInfo, nodeName)
		nodeInfo, err = nm.renewNodeInfo(nodeInfo, true)
		if err != nil {
			klog.Errorf("Error %q occurred while renewing NodeInfo for %q", err, nodeName)
			return NodeInfo{}, err
		}
		nm.addNodeInfo(nodeName, nodeInfo)
	}
	return *nodeInfo, nil
}
source: func (conn *Connection) DoScan(cmd string, args ...interface{}) (int, *ResultSet, error) {
	result, err := conn.Do(cmd, args...)
	if err != nil {
		return 0, nil, err
	}
	return result.Scanned()
}
source: func getDockerDetailsData(path string, osOpen osOpenFunc) (resources.DockerImageDetails, error) {
	f, err := osOpen(path)
	if err == nil {
		defer f.Close()
		details, err := unMarshalDockerDetails(f)
		if err != nil {
			return details, errors.Trace(err)
		}
		return details, nil
	} else if err := resources.ValidateDockerRegistryPath(path); err == nil {
		return resources.DockerImageDetails{
			RegistryPath: path,
		}, nil
	}
	return resources.DockerImageDetails{}, errors.NotValidf("filepath or registry path: %s", path)

}
source: func (p *RequestParams) Upsert(param string, paramType *reflect.StructField) {
	if p == nil {
		return
	}
	t := *p
	for i, reqparam := range t {
		if reqparam.FieldName == param {
			if paramType != nil {
				t[i].FieldType = *paramType
			}
			return
		}
	}
	reqparam := RequestParam{
		FieldName: param,
	}
	if paramType != nil {
		reqparam.FieldType = *paramType
	}
	*p = append(t, reqparam)
}
source: func (db *DB) mmap(minsz int) error {
	db.mmaplock.Lock()
	defer db.mmaplock.Unlock()

	info, err := db.file.Stat()
	if err != nil {
		return fmt.Errorf("mmap stat error: %s", err)
	} else if int(info.Size()) < db.pageSize*2 {
		return fmt.Errorf("file size too small")
	}

	// Ensure the size is at least the minimum size.
	var size = int(info.Size())
	if size < minsz {
		size = minsz
	}
	size, err = db.mmapSize(size)
	if err != nil {
		return err
	}

	// Dereference all mmap references before unmapping.
	if db.rwtx != nil {
		db.rwtx.root.dereference()
	}

	// Unmap existing data before continuing.
	if err := db.munmap(); err != nil {
		return err
	}

	// Memory-map the data file as a byte slice.
	if err := mmap(db, size); err != nil {
		return err
	}

	// Save references to the meta pages.
	db.meta0 = db.page(0).meta()
	db.meta1 = db.page(1).meta()

	// Validate the meta pages. We only return an error if both meta pages fail
	// validation, since meta0 failing validation means that it wasn't saved
	// properly -- but we can recover using meta1. And vice-versa.
	err0 := db.meta0.validate()
	err1 := db.meta1.validate()
	if err0 != nil && err1 != nil {
		return err0
	}

	return nil
}
source: func (*ProtoMarshaller) Unmarshal(data []byte, value interface{}) error {
	message, ok := value.(proto.Message)
	if !ok {
		return errors.New("unable to unmarshal non proto field")
	}
	return proto.Unmarshal(data, message)
}
source: func NormalizeAddresses(addrs []string, defaultPort string) ([]string, error) {
	var (
		normalized = make([]string, 0, len(addrs))
		seenSet    = make(map[string]struct{})
	)

	for _, addr := range addrs {
		normalizedAddr, err := NormalizeAddress(addr, defaultPort)
		if err != nil {
			return nil, err
		}
		_, seen := seenSet[normalizedAddr]
		if !seen {
			normalized = append(normalized, normalizedAddr)
			seenSet[normalizedAddr] = struct{}{}
		}
	}

	return normalized, nil
}
source: func (c *PCPCounterVector) Inc(inc int64, instance string) error {
	c.mutex.Lock()
	defer c.mutex.Unlock()

	if inc < 0 {
		return errors.New("increment cannot be negative")
	}

	if inc == 0 {
		return nil
	}

	v, err := c.valInstance(instance)
	if err != nil {
		return err
	}

	return c.setInstance(v.(int64)+inc, instance)
}
source: func (mc *MetricsConfiguration) ReportInterval() time.Duration {
	if mc.RootScope != nil && mc.RootScope.ReportingInterval != 0 {
		return mc.RootScope.ReportingInterval
	}
	return defaultReportingInterval
}
source: func (dc PeerDeliverClient) DeliverFiltered(ctx context.Context, opts ...grpc.CallOption) (ccapi.Deliver, error) {
	df, err := dc.Client.DeliverFiltered(ctx, opts...)
	return df, err
}
source: func (c *Client) Group(id, action, target int32) (*GroupNode, error) {
	msg := osc.Message{
		Address: groupNewAddress,
		Arguments: osc.Arguments{
			osc.Int(id),
			osc.Int(action),
			osc.Int(target),
		},
	}
	if err := c.oscConn.Send(msg); err != nil {
		return nil, err
	}
	return newGroup(c, id), nil
}
source: func (ts *Server) GetVSchema(ctx context.Context, keyspace string) (*vschemapb.Keyspace, error) {
	nodePath := path.Join(KeyspacesPath, keyspace, VSchemaFile)
	data, _, err := ts.globalCell.Get(ctx, nodePath)
	if err != nil {
		return nil, err
	}
	var vs vschemapb.Keyspace
	err = proto.Unmarshal(data, &vs)
	if err != nil {
		return nil, vterrors.Wrapf(err, "bad vschema data: %q", data)
	}
	return &vs, nil
}
source: func NewUnboundedBuffer(mem, file int64) Buffer {
	return NewMulti(New(mem), NewPartition(NewFilePool(file, os.TempDir())))
}
source: func NewDecoder(rd io.Reader) Decoder {
	dec := gob.NewDecoder(rd)
	return func(r *Result) error { return dec.Decode(r) }
}
source: func (f *FileStore) LastModified() time.Time {
	f.mu.RLock()
	defer f.mu.RUnlock()

	return f.lastModified
}
source: func (st *State) WatchVolumes(scope names.Tag) (watcher.StringsWatcher, error) {
	return st.watchStorageEntities("WatchVolumes", scope)
}
source: func MinCyclePeriod(d time.Duration) detector.Option {
	return func(di interface{}) detector.Option {
		md := di.(*MasterDetector)
		old := md.minDetectorCyclePeriod
		md.minDetectorCyclePeriod = d
		return MinCyclePeriod(old)
	}
}
source: func (base *Base) Walk(ctx context.Context, path string, f storagedriver.WalkFn) error {
	ctx, done := dcontext.WithTrace(ctx)
	defer done("%s.Walk(%q)", base.Name(), path)

	if !storagedriver.PathRegexp.MatchString(path) && path != "/" {
		return storagedriver.InvalidPathError{Path: path, DriverName: base.StorageDriver.Name()}
	}

	return base.setDriverName(base.StorageDriver.Walk(ctx, path, f))
}
source: func (m *managerImpl) IsUnderMemoryPressure() bool {
	m.RLock()
	defer m.RUnlock()
	return hasNodeCondition(m.nodeConditions, v1.NodeMemoryPressure)
}
source: func (c *pidCollector) collectPids(stopCh chan interface{}, pidGetter allPidGetter) {
	// Fire the timer right away when the executor starts from there on the pids
	// are collected every scan interval
	timer := time.NewTimer(0)
	defer timer.Stop()
	for {
		select {
		case <-timer.C:
			pids, err := pidGetter()
			if err != nil {
				c.logger.Debug("error collecting pids", "error", err)
			}
			c.pidLock.Lock()

			// Adding pids which are not being tracked
			for pid, np := range pids {
				if _, ok := c.pids[pid]; !ok {
					c.pids[pid] = np
				}
			}
			// Removing pids which are no longer present
			for pid := range c.pids {
				if _, ok := pids[pid]; !ok {
					delete(c.pids, pid)
				}
			}
			c.pidLock.Unlock()
			timer.Reset(pidScanInterval)
		case <-stopCh:
			return
		}
	}
}
source: func newEvalState() *evalState {
	return &evalState{
		status: structs.EvalStatusPending,
		allocs: make(map[string]*allocState),
	}
}
source: func New(host, authtoken string) (*TCP, error) {
	client := &TCP{
		host:     host,
		messages: make(chan mist.Message),
		token:    authtoken,
	}

	return client, client.connect()
}
source: func NewToplistRegion(region string) (ToplistRegion, error) {
	if len(region) != 2 {
		return 0, errors.New("spotify: invalid toplist region")
	}
	region = strings.ToUpper(region)
	r := int(region[0])<<8 | int(region[1])
	return ToplistRegion(r), nil
}
source: func (s *ImageStoreService) NewAddImageStoreParams(provider string) *AddImageStoreParams {
	p := &AddImageStoreParams{}
	p.p = make(map[string]interface{})
	p.p["provider"] = provider
	return p
}
source: func (conn *ProtoConnection) Watch(msgClb func(messaging.ProtoMessage), topics ...string) error {
	return conn.ConsumeTopic(msgClb, topics...)
}
source: func (oc *ObjectComprehension) Copy() *ObjectComprehension {
	cpy := *oc
	cpy.Body = oc.Body.Copy()
	cpy.Key = oc.Key.Copy()
	cpy.Value = oc.Value.Copy()
	return &cpy
}
source: func (t *Template) GetAllAWSConfigConfigurationRecorderResources() map[string]*resources.AWSConfigConfigurationRecorder {
	results := map[string]*resources.AWSConfigConfigurationRecorder{}
	for name, untyped := range t.Resources {
		switch resource := untyped.(type) {
		case *resources.AWSConfigConfigurationRecorder:
			results[name] = resource
		}
	}
	return results
}
source: func ParseSignature(s string) (sig Signature, err error) {
	if len(s) == 0 {
		return
	}
	if len(s) > 255 {
		return Signature{""}, SignatureError{s, "too long"}
	}
	sig.str = s
	for err == nil && len(s) != 0 {
		err, s = validSingle(s, 0)
	}
	if err != nil {
		sig = Signature{""}
	}

	return
}
source: func certPool(caFile string, exclusivePool bool) (*x509.CertPool, error) {
	// If we should verify the server, we need to load a trusted ca
	var (
		certPool *x509.CertPool
		err      error
	)
	if exclusivePool {
		certPool = x509.NewCertPool()
	} else {
		certPool, err = SystemCertPool()
		if err != nil {
			return nil, fmt.Errorf("failed to read system certificates: %v", err)
		}
	}
	pem, err := ioutil.ReadFile(caFile)
	if err != nil {
		return nil, fmt.Errorf("could not read CA certificate %q: %v", caFile, err)
	}
	if !certPool.AppendCertsFromPEM(pem) {
		return nil, fmt.Errorf("failed to append certificates from PEM file: %q", caFile)
	}
	return certPool, nil
}
source: func StackExists(stackNameOrID string, awsSession *session.Session, logger *logrus.Logger) (bool, error) {
	cf := cloudformation.New(awsSession)

	describeStacksInput := &cloudformation.DescribeStacksInput{
		StackName: aws.String(stackNameOrID),
	}
	describeStacksOutput, err := cf.DescribeStacks(describeStacksInput)
	logger.WithFields(logrus.Fields{
		"DescribeStackOutput": describeStacksOutput,
	}).Debug("DescribeStackOutput results")

	exists := false
	if err != nil {
		logger.WithFields(logrus.Fields{
			"DescribeStackOutputError": err,
		}).Debug("DescribeStackOutput")

		// If the stack doesn't exist, then no worries
		if strings.Contains(err.Error(), "does not exist") {
			exists = false
		} else {
			return false, err
		}
	} else {
		exists = true
	}
	return exists, nil
}
source: func (s *subscriber) Report() map[string]interface{} {
	s.mutex.Lock()
	defer s.mutex.Unlock()
	result := map[string]interface{}{
		"source": s.config.Origin,
	}
	targets := make(map[string]interface{})
	for target, remote := range s.servers {
		targets[target] = remote.Report()
	}
	if len(targets) > 0 {
		result["targets"] = targets
	}
	return result

}
source: func (r Root) FullText() string {
	var buf bytes.Buffer

	var f func(*html.Node)
	f = func(n *html.Node) {
		if n.Type == html.TextNode {
			buf.WriteString(n.Data)
		}
		if n.Type == html.ElementNode {
			f(n.FirstChild)
		}
		if n.NextSibling != nil {
			f(n.NextSibling)
		}
	}

	f(r.Pointer.FirstChild)

	return buf.String()
}
source: func (c *Context) getStore() Store {
	store, ok := c.Request.Context().Value(Key).(Store)
	if !ok {
		panic("invalid request context")
	}
	return store
}
source: func interfaceToArray(input interface{}) interface{} {
	var (
		result  interface{}
		coords  []float64
		coords2 [][]float64
		coords3 [][][]float64
		coords4 [][][][]float64
	)
	switch it := input.(type) {
	case []float64, [][]float64, [][][]float64, [][][][]float64:
		result = it
	case []interface{}:
		for inx := 0; inx < len(it); inx++ {
			switch curr1 := it[inx].(type) {
			case float64:
				coords = append(coords, curr1)
				result = coords
			case []interface{}:
				switch curr2 := interfaceToArray(curr1).(type) {
				case []float64:
					coords2 = append(coords2, curr2)
					result = coords2
				case [][]float64:
					coords3 = append(coords3, curr2)
					result = coords3
				case [][][]float64:
					coords4 = append(coords4, curr2)
					result = coords4
				}
			}
		}
	}
	return result
}
source: func (d *Dispute) UnmarshalJSON(data []byte) error {
	if id, ok := ParseID(data); ok {
		d.ID = id
		return nil
	}

	type dispute Dispute
	var v dispute
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}

	*d = Dispute(v)
	return nil
}
source: func (m MilliSatoshi) ToSatoshis() btcutil.Amount {
	return btcutil.Amount(uint64(m) / mSatScale)
} 20%|█▉        | 990/5000 [00:01<00:04, 957.88it/s]
source: func (e *Engine) becomeBackup() {
	if err := e.ncc.Dial(); err != nil {
		log.Fatalf("Failed to connect to NCC: %v", err)
	}
	defer e.ncc.Close()

	e.syncClient.enable()
	e.hcManager.disable()
	e.notifier.SetSource(config.SourcePeer)

	if err := e.lbInterface.Down(); err != nil {
		log.Fatalf("Failed to bring LB interface down: %v", err)
	}

	// TODO(jsing): Once peer synchronisation is implemented, make this
	// a time-based expiration that commences once communication with the
	// peer is lost.
	e.hcManager.expire()
}
source: func (pgb *ChainDB) ticketsByTPWindows(heightArr, soloArr, pooledArr []uint64) ([]uint64,
	[]uint64, []uint64, error) {
	ctx, cancel := context.WithTimeout(pgb.ctx, pgb.queryTimeout)
	defer cancel()

	var err error
	heightArr, soloArr, pooledArr, err = retrieveTicketByOutputCount(ctx, pgb.db,
		pgb.chainParams.StakeDiffWindowSize, outputCountByTicketPoolWindow,
		heightArr, soloArr, pooledArr)
	if err != nil {
		err = fmt.Errorf("ticketsByTPWindows: %v", pgb.replaceCancelError(err))
	}

	return heightArr, soloArr, pooledArr, err
}
source: func PackToFunc(srcPath, destPath string, fn func(fullName string, fi os.FileInfo) error, includeDir ...bool) error {
	isIncludeDir := false
	if len(includeDir) > 0 && includeDir[0] {
		isIncludeDir = true
	}

	return packTo(srcPath, destPath, fn, isIncludeDir)
}
source: func CheckStorable(inDoc interface{}) error {
	// Normalise document to bson.M
	bytes, err := bson.Marshal(inDoc)
	if err != nil {
		return errors.Annotate(err, "marshalling")
	}
	var doc bson.M
	if err := bson.Unmarshal(bytes, &doc); err != nil {
		return errors.Annotate(err, "unmarshalling")
	}
	// Check it.
	return errors.Trace(checkDoc(doc))
}
source: func (in *CiliumNetworkPolicyNodeStatus) DeepCopy() *CiliumNetworkPolicyNodeStatus {
	if in == nil {
		return nil
	}
	out := new(CiliumNetworkPolicyNodeStatus)
	in.DeepCopyInto(out)
	return out
}
source: func (ev *EnvVars) Restore() {
	for key, value := range ev.vars {
		if err := os.Setenv(key, value); err != nil {
			msg := fmt.Sprintf("cannot reset environment variable %q: %v", key, err)
			ev.assert.Fail(msg)
		}
	}
}
source: func (n *Node) Stop() error {
	n.lock.Lock()
	defer n.lock.Unlock()

	// Short circuit if the node's not running
	if n.server == nil {
		return ErrNodeStopped
	}

	// Terminate the API, services and the p2p server.
	n.stopWS()
	n.stopHTTP()
	n.stopIPC()
	n.rpcAPIs = nil
	failure := &StopError{
		Services: make(map[reflect.Type]error),
	}
	for kind, service := range n.services {
		if err := service.Stop(); err != nil {
			failure.Services[kind] = err
		}
	}
	n.server.Stop()
	n.services = nil
	n.server = nil

	// Release instance directory lock.
	if n.instanceDirLock != nil {
		if err := n.instanceDirLock.Release(); err != nil {
			n.log.Error("Can't release datadir lock", "err", err)
		}
		n.instanceDirLock = nil
	}

	// unblock n.Wait
	close(n.stop)

	// Remove the keystore if it was created ephemerally.
	var keystoreErr error
	if n.ephemeralKeystore != "" {
		keystoreErr = os.RemoveAll(n.ephemeralKeystore)
	}

	if len(failure.Services) > 0 {
		return failure
	}
	if keystoreErr != nil {
		return keystoreErr
	}
	return nil
}
source: func (r *RepositoryContent) GetTarget() string {
	if r == nil || r.Target == nil {
		return ""
	}
	return *r.Target
}
source: func (h *Highlighter) getClass(tok token.Token) string {
	switch {
	case tok.IsKeyword():
		return h.KeywordClass
	case tok.IsLiteral():
		if tok == token.IDENT {
			return h.IdentClass
		} else {
			return h.LiteralClass
		}
	case tok.IsOperator():
		return h.OperatorClass
	case tok == token.COMMENT:
		return h.CommentClass
	case tok == token.ILLEGAL:
		break
	default:
		panic(fmt.Sprintf("unknown token type: %v", tok))
	}
	return ""
}
source: func ParseGetBlockRes(res keybase1.GetBlockRes, resErr error) (
	buf []byte, serverHalf kbfscrypto.BlockCryptKeyServerHalf, err error) {
	if resErr != nil {
		return nil, kbfscrypto.BlockCryptKeyServerHalf{}, resErr
	}
	serverHalf, err = kbfscrypto.ParseBlockCryptKeyServerHalf(res.BlockKey)
	if err != nil {
		return nil, kbfscrypto.BlockCryptKeyServerHalf{}, err
	}
	return res.Buf, serverHalf, nil
}
source: func reapIntents(intents map[string]nodeIntent, now time.Time, timeout time.Duration) {
	for node, intent := range intents {
		if now.Sub(intent.WallTime) > timeout {
			delete(intents, node)
		}
	}
}
source: func cmdAppend(args commandArgs, c *Conn) {
	if !c.assertAuthenticated(args.ID()) {
		return
	}

	mailboxName := args.Arg(appendArgMailbox)
	mailbox, err := c.User.MailboxByName(mailboxName)
	if err != nil {
		c.writeResponse(args.ID(), "NO could not get mailbox")
		return
	}

	length, err := strconv.ParseUint(args.Arg(appendArgLength), 10, 64)
	if err != nil || length == 0 {
		c.writeResponse(args.ID(), "BAD invalid length for message literal")
		return
	}

	flagString := args.Arg(appendArgFlags)
	flags := types.Flags(0)
	if flagString != "" {
		flags = types.FlagsFromString(flagString)
	}

	// Tell client to send the mail message
	c.writeResponse("+", "go ahead, feed me your message")

	// Read in the whole message
	messageData, err := c.ReadFixedLength(int(length))
	if err != nil {
		return
	}

	msg := mailbox.NewMessage()
	rawMsg, err := types.MessageFromBytes(messageData)
	if err != nil {
		c.writeResponse(args.ID(), "NO "+err.Error())
		return
	}
	msg = msg.SetHeaders(rawMsg.Headers)
	msg = msg.SetBody(rawMsg.Body)
	msg = msg.OverwriteFlags(flags)

	msg, err = msg.Save()
	if err != nil {
		c.writeResponse(args.ID(), "NO "+err.Error())
		return
	}

	c.writeResponse(args.ID(), "OK APPEND completed")
}
source: func NewClaimsHeader(opts ...Option) *ClaimsHeader {

	c := &ClaimsHeader{}

	for _, opt := range opts {
		opt(c)
	}

	return c
}
source: func Convert_coordination_LeaseList_To_v1_LeaseList(in *coordination.LeaseList, out *v1.LeaseList, s conversion.Scope) error {
	return autoConvert_coordination_LeaseList_To_v1_LeaseList(in, out, s)
}
source: func NewWriter(simple bool, buf ...byte) (w *Writer) {
	w = new(Writer)
	w.buf = buf
	w.Simple = simple
	return
}
source: func (o *GetStatusParams) WithTimeout(timeout time.Duration) *GetStatusParams {
	o.SetTimeout(timeout)
	return o
}
source: func (api *API) Schema(ctx context.Context) []*IndexInfo {
	span, _ := tracing.StartSpanFromContext(ctx, "API.Schema")
	defer span.Finish()
	return api.holder.limitedSchema()
}
source: func (m GridMapper) ID(xyi ...interface{}) (rowIDs []int64, err error) {
	x := xyi[0].(float64)
	y := xyi[1].(float64)
	externalID := m.Xres * m.Yres

	// bounds check
	if x < m.Xmin || x > m.Xmax || y < m.Ymin || y > m.Ymax {
		if m.allowExternal {
			return []int64{externalID}, nil
		}
		return []int64{0}, fmt.Errorf("point (%v, %v) out of range", x, y)
	}

	// compute x bin
	xInt := int64(float64(m.Xres) * (x - m.Xmin) / (m.Xmax - m.Xmin))
	// compute y bin
	yInt := int64(float64(m.Yres) * (y - m.Ymin) / (m.Ymax - m.Ymin))

	rowID := (m.Yres * xInt) + yInt
	return []int64{rowID}, nil

}
source: func (d *DirtyBlockCacheStandard) Get(
	_ context.Context, _ tlf.ID, ptr BlockPointer, branch BranchName) (
	Block, error) {
	block := func() Block {
		dirtyID := dirtyBlockID{
			id:       ptr.ID,
			refNonce: ptr.RefNonce,
			branch:   branch,
		}
		d.lock.RLock()
		defer d.lock.RUnlock()
		return d.cache[dirtyID]
	}()
	if block != nil {
		return block, nil
	}

	return nil, NoSuchBlockError{ptr.ID}
}
source: func MarshalAuthorizedKey(key PublicKey) []byte {
	b := &bytes.Buffer{}
	b.WriteString(key.Type())
	b.WriteByte(' ')
	e := base64.NewEncoder(base64.StdEncoding, b)
	e.Write(key.Marshal())
	e.Close()
	b.WriteByte('\n')
	return b.Bytes()
}
source: func LoadPreKeyRecord(serialized []byte) (*PreKeyRecord, error) {
	record := &PreKeyRecord{Pkrs: &protobuf.PreKeyRecordStructure{}}
	err := proto.Unmarshal(serialized, record.Pkrs)
	if err != nil {
		return nil, err
	}
	return record, nil
}
source: func (e *expectations) Clear(namespace, ingressName string) {
	e.lock.Lock()
	defer e.lock.Unlock()
	key := queueKey{namespace: namespace, name: ingressName}
	delete(e.expect, key)
}
source: func URLFloat(r *http.Request, key, validation string) (float64, error) {
	p := strings.TrimSpace(chi.URLParam(r, key))
	if len(p) == 0 {
		return 0, ErrNoURLParam
	}

	i, err := strconv.ParseFloat(p, 64)
	if err != nil {
		return 0, err
	}

	if len(validation) == 0 {
		return i, nil
	}
	return i, Validate.VarCtx(r.Context(), &i, validation)
}
source: func (ctx *RoleBindingRestrictionContext) labelSetForUser(subject rbac.Subject) (labels.Set, error) {
	if subject.Kind != rbac.UserKind {
		return labels.Set{}, fmt.Errorf("not a user: %q", subject.Name)
	}

	labelSet, ok := ctx.userToLabelSet[subject.Name]
	if ok {
		return labelSet, nil
	}

	user, err := ctx.userClient.Users().Get(subject.Name, metav1.GetOptions{})
	if err != nil {
		return labels.Set{}, err
	}

	ctx.userToLabelSet[subject.Name] = labels.Set(user.Labels)

	return ctx.userToLabelSet[subject.Name], nil
}
source: func (c Command) ReplySignature(d Domain) string {
	var args []string
	for _, arg := range c.Returns {
		name := arg.Name(d)
		if name == "range" || name == "type" {
			name = name[0 : len(name)-1]
		}

		typ := arg.GoType("cdp", d)
		if arg.Optional && !strings.HasPrefix(typ, "[]") {
			typ = "*" + typ
		}
		args = append(args, name+" "+typ)
	}
	return strings.Join(args, ", ")
}
source: func (v ByteView) Len() int {
	if v.b != nil {
		return len(v.b)
	}
	return len(v.s)
}
source: func (m *MultiResolver) getResolveValidator(name string) ([]ResolveValidator, error) {
	rs := m.resolvers[""]
	tld := path.Ext(name)
	if tld != "" {
		tld = tld[1:]
		rstld, ok := m.resolvers[tld]
		if ok {
			return rstld, nil
		}
	}
	if len(rs) == 0 {
		return rs, NewNoResolverError(tld)
	}
	return rs, nil
}
source: func (r Network_Storage_Allowed_Host_Hardware) GetAssignedIscsiVolumes() (resp []datatypes.Network_Storage, err error) {
	err = r.Session.DoRequest("SoftLayer_Network_Storage_Allowed_Host_Hardware", "getAssignedIscsiVolumes", nil, &r.Options, &resp)
	return
}
source: func NewWindowed(n int, minValue, maxValue int64, sigfigs int) *WindowedHistogram {
	w := WindowedHistogram{
		idx: -1,
		h:   make([]Histogram, n),
		m:   New(minValue, maxValue, sigfigs),
	}

	for i := range w.h {
		w.h[i] = *New(minValue, maxValue, sigfigs)
	}
	w.Rotate()

	return &w
}
source: func GetFalseNegatives(class string, c ConfusionMatrix) float64 {
	ret := 0.0
	for k := range c[class] {
		if k == class {
			continue
		}
		ret += float64(c[class][k])
	}
	return ret
}
source: func LowerCaseWithUnderscores(name string) string {
	newName := []rune{}
	for i, c := range name {
		if i == 0 {
			newName = append(newName, unicode.ToLower(c))
		} else {
			if unicode.IsUpper(c) {
				newName = append(newName, '_')
				newName = append(newName, unicode.ToLower(c))
			} else {
				newName = append(newName, c)
			}
		}
	}
	return string(newName)
}
source: func (n *Node) Copy(c *Node) {
	n.State = c.State
	n.Priority = c.Priority
	n.Host.Copy(&c.Host)
	n.VserversEnabled = c.VserversEnabled
}
source: func (ra *RegistrationAuthorityImpl) recheckCAA(ctx context.Context, authzs []*core.Authorization) error {
	ra.stats.Inc("recheck_caa", 1)
	ra.stats.Inc("recheck_caa_authzs", int64(len(authzs)))
	ch := make(chan error, len(authzs))
	for _, authz := range authzs {
		go func(authz *core.Authorization) {
			name := authz.Identifier.Value

			// If an authorization has multiple valid challenges,
			// the type of the first valid challenge is used for
			// the purposes of CAA rechecking.
			var method string
			for _, challenge := range authz.Challenges {
				if challenge.Status == core.StatusValid {
					method = challenge.Type
					break
				}
			}
			if method == "" {
				ch <- berrors.InternalServerError(
					"Internal error determining validation method for authorization ID %v (%v)",
					authz.ID, name,
				)
				return
			}

			resp, err := ra.caa.IsCAAValid(ctx, &vaPB.IsCAAValidRequest{
				Domain:           &name,
				ValidationMethod: &method,
				AccountURIID:     &authz.RegistrationID,
			})
			if err != nil {
				ra.log.AuditErrf("Rechecking CAA: %s", err)
				err = berrors.InternalServerError(
					"Internal error rechecking CAA for authorization ID %v (%v)",
					authz.ID, name,
				)
			} else if resp.Problem != nil {
				err = berrors.CAAError(*resp.Problem.Detail)
			}
			ch <- err
		}(authz)
	}
	var caaFailures []string
	for _ = range authzs {
		if err := <-ch; berrors.Is(err, berrors.CAA) {
			caaFailures = append(caaFailures, err.Error())
		} else if err != nil {
			return err
		}
	}
	if len(caaFailures) > 0 {
		return berrors.CAAError("Rechecking CAA: %v", strings.Join(caaFailures, ", "))
	}
	return nil
}
source: func (r Reply) Lines() []string {
	var lines []string

	if len(r.lines) == 0 {
		l := strconv.Itoa(r.Status)
		lines = append(lines, l+"\n")
		return lines
	}

	for i, line := range r.lines {
		l := ""
		if i == len(r.lines)-1 {
			l = strconv.Itoa(r.Status) + " " + line + "\r\n"
		} else {
			l = strconv.Itoa(r.Status) + "-" + line + "\r\n"
		}
		lines = append(lines, l)
	}

	return lines
}
source: func (jcm *joinChannelMessage) AnchorPeersOf(org api.OrgIdentityType) []api.AnchorPeer {
	return jcm.members2AnchorPeers[string(org)]
}
source: func (s *Server) OnConnect(f func(*Client)) {
	s.eventHub.Subscribe(clientConnected, func(e hub.Event) {
		go f(e.(connectionEvent).Client)
	})
}
source: func HTTP2Transporter(config *tls.Config) Transporter {
	if config == nil {
		config = &tls.Config{InsecureSkipVerify: true}
	}
	return &http2Transporter{
		clients:   make(map[string]*http.Client),
		tlsConfig: config,
	}
}
source: func safeWriteToFile(t SafeWriter, mode os.FileMode, log Log) error {
	filename := t.GetFilename()
	if filename == "" {
		return fmt.Errorf("No filename")
	}
	log.Debugf("Writing to %s", filename)
	tempFilename, tempFile, err := openTempFile(filename+"-", "", mode)
	log.Debugf("Temporary file generated: %s", tempFilename)
	if err != nil {
		return err
	}
	_, err = t.WriteTo(tempFile)
	if err != nil {
		log.Errorf("Error writing temporary file %s: %s", tempFilename, err)
		_ = tempFile.Close()
		_ = os.Remove(tempFilename)
		return err
	}
	err = tempFile.Close()
	if err != nil {
		log.Errorf("Error closing temporary file %s: %s", tempFilename, err)
		_ = os.Remove(tempFilename)
		return err
	}
	err = os.Rename(tempFilename, filename)
	if err != nil {
		log.Errorf("Error renaming temporary file %s to %s: %s", tempFilename, filename, err)
		_ = os.Remove(tempFilename)
		return err
	}
	log.Debugf("Wrote to %s", filename)
	return nil
}
source: func ResetLine(str string) (out string) {
	return applyTransform(str, func(idx int, line string) string {
		return fmt.Sprintf("%s%s", RESET_LINE, line)
	})
}
source: func (g *genDeepCopy) deepCopyableInterfaces(c *generator.Context, t *types.Type) ([]*types.Type, bool, error) {
	ts, err := g.deepCopyableInterfacesInner(c, t)
	if err != nil {
		return nil, false, err
	}

	set := map[string]*types.Type{}
	for _, t := range ts {
		set[t.String()] = t
	}

	result := []*types.Type{}
	for _, t := range set {
		result = append(result, t)
	}

	TypeSlice(result).Sort() // we need a stable sorting because it determines the order in generation

	nonPointerReceiver, err := extractNonPointerInterfaces(t)
	if err != nil {
		return nil, false, err
	}

	return result, nonPointerReceiver, nil
}
source: func API2CharmResource(apiInfo params.CharmResource) (charmresource.Resource, error) {
	var res charmresource.Resource

	rtype, err := charmresource.ParseType(apiInfo.Type)
	if err != nil {
		return res, errors.Trace(err)
	}

	origin, err := charmresource.ParseOrigin(apiInfo.Origin)
	if err != nil {
		return res, errors.Trace(err)
	}

	fp, err := resource.DeserializeFingerprint(apiInfo.Fingerprint)
	if err != nil {
		return res, errors.Trace(err)
	}

	res = charmresource.Resource{
		Meta: charmresource.Meta{
			Name:        apiInfo.Name,
			Type:        rtype,
			Path:        apiInfo.Path,
			Description: apiInfo.Description,
		},
		Origin:      origin,
		Revision:    apiInfo.Revision,
		Fingerprint: fp,
		Size:        apiInfo.Size,
	}

	if err := res.Validate(); err != nil {
		return res, errors.Trace(err)
	}
	return res, nil
}
source: func (pgb *ChainDB) InitUtxoCache(utxos []dbtypes.UTXO) {
	pgb.utxoCache.Reinit(utxos)
}
source: func (id ID) Type() Type {
	t, err := id.SafeType()
	if err != nil {
		panic(err)
	}
	return t
}
source: func NewDNSProviderConfig(config *Config) (*DNSProvider, error) {
	if config == nil {
		return nil, errors.New("fastdns: the configuration of the DNS provider is nil")
	}

	if config.ClientToken == "" || config.ClientSecret == "" || config.AccessToken == "" || config.Host == "" {
		return nil, fmt.Errorf("fastdns: credentials are missing")
	}

	return &DNSProvider{config: config}, nil
}
source: func (f FakeLister) List(api.ListOptions) (*api.PodList, error) {
	return f.PodList, f.Err
}
source: func (b *backend) secretIDAccessorEntry(ctx context.Context, s logical.Storage, secretIDAccessor, roleSecretIDPrefix string) (*secretIDAccessorStorageEntry, error) {
	if secretIDAccessor == "" {
		return nil, fmt.Errorf("missing secretIDAccessor")
	}

	var result secretIDAccessorStorageEntry

	// Create index entry, mapping the accessor to the token ID
	salt, err := b.Salt(ctx)
	if err != nil {
		return nil, err
	}
	accessorPrefix := secretIDAccessorPrefix
	if roleSecretIDPrefix == secretIDLocalPrefix {
		accessorPrefix = secretIDAccessorLocalPrefix
	}
	entryIndex := accessorPrefix + salt.SaltID(secretIDAccessor)

	accessorLock := b.secretIDAccessorLock(secretIDAccessor)
	accessorLock.RLock()
	defer accessorLock.RUnlock()

	if entry, err := s.Get(ctx, entryIndex); err != nil {
		return nil, err
	} else if entry == nil {
		return nil, nil
	} else if err := entry.DecodeJSON(&result); err != nil {
		return nil, err
	}

	return &result, nil
}
source: func (c *Charge) UnmarshalJSON(data []byte) error {
	if id, ok := ParseID(data); ok {
		c.ID = id
		return nil
	}

	type charge Charge
	var v charge
	if err := json.Unmarshal(data, &v); err != nil {
		return err
	}

	*c = Charge(v)
	return nil
}
source: func (s *UpdateSmsChannelInput) SetSMSChannelRequest(v *SMSChannelRequest) *UpdateSmsChannelInput {
	s.SMSChannelRequest = v
	return s
}
source: func (fw *Firewaller) reconcileInstances() error {
	for _, machined := range fw.machineds {
		m, err := machined.machine()
		if params.IsCodeNotFound(err) {
			if err := fw.forgetMachine(machined); err != nil {
				return err
			}
			continue
		}
		if err != nil {
			return err
		}
		instanceId, err := m.InstanceId()
		if errors.IsNotProvisioned(err) {
			logger.Errorf("Machine not yet provisioned: %v", err)
			continue
		}
		if err != nil {
			return err
		}
		envInstances, err := fw.environInstances.Instances(fw.cloudCallContext, []instance.Id{instanceId})
		if err == environs.ErrNoInstances {
			return nil
		}
		if err != nil {
			return err
		}
		machineId := machined.tag.Id()

		fwInstance, ok := envInstances[0].(instances.InstanceFirewaller)
		if !ok {
			return nil
		}

		initialRules, err := fwInstance.IngressRules(fw.cloudCallContext, machineId)
		if err != nil {
			return err
		}

		// Check which ports to open or to close.
		toOpen, toClose := diffRanges(initialRules, machined.ingressRules)
		if len(toOpen) > 0 {
			logger.Infof("opening instance port ranges %v for %q",
				toOpen, machined.tag)
			if err := fwInstance.OpenPorts(fw.cloudCallContext, machineId, toOpen); err != nil {
				// TODO(mue) Add local retry logic.
				return err
			}
		}
		if len(toClose) > 0 {
			logger.Infof("closing instance port ranges %v for %q",
				toClose, machined.tag)
			if err := fwInstance.ClosePorts(fw.cloudCallContext, machineId, toClose); err != nil {
				// TODO(mue) Add local retry logic.
				return err
			}
		}
	}
	return nil
}
source: func MustFloat(input interface{}) float64 {
	output, err := Float(input)
	if err != nil {
		panic(err)
	}
	return output
}
source: func (i Info) Generator() template.HTML {
	return template.HTML(fmt.Sprintf(`<meta name="generator" content="Hugo %s" />`, CurrentVersion.String()))
}
source: func Infof(msg string, args ...interface{}) {
	if level >= InfoLevel {
		InfoLog.Printf(msg, args...)
	}
}
source: func (db *DB) LDump(key []byte) ([]byte, error) {
	v, err := db.LRange(key, 0, -1)
	if err != nil {
		return nil, err
	} else if len(v) == 0 {
		return nil, err
	}

	return rdb.Dump(rdb.List(v))
}
source: func (m *MockService) ThumbnailRepo() repo.Thumbnail {
	ret := m.ctrl.Call(m, "ThumbnailRepo")
	ret0, _ := ret[0].(repo.Thumbnail)
	return ret0
}
source: func (cli *NetworkCli) CmdNetworkInfo(chain string, args ...string) error {
	cmd := cli.Subcmd(chain, "info", "NETWORK", "Displays detailed information on a network", false)
	cmd.Require(flag.Exact, 1)
	err := cmd.ParseFlags(args, true)
	if err != nil {
		return err
	}

	id, err := lookupNetworkID(cli, cmd.Arg(0))
	if err != nil {
		return err
	}

	obj, _, err := readBody(cli.call("GET", "/networks/"+id, nil, nil))
	if err != nil {
		return err
	}
	networkResource := &networkResource{}
	if err := json.NewDecoder(bytes.NewReader(obj)).Decode(networkResource); err != nil {
		return err
	}
	fmt.Fprintf(cli.out, "Network Id: %s\n", networkResource.ID)
	fmt.Fprintf(cli.out, "Name: %s\n", networkResource.Name)
	fmt.Fprintf(cli.out, "Type: %s\n", networkResource.Type)
	if networkResource.Services != nil {
		for _, serviceResource := range networkResource.Services {
			fmt.Fprintf(cli.out, "  Service Id: %s\n", serviceResource.ID)
			fmt.Fprintf(cli.out, "\tName: %s\n", serviceResource.Name)
		}
	}

	return nil
}
source: func NewAWSService() AWSService {
	s := session.New(&aws.Config{Region: &awsRegion})

	return &RealAWSService{
		elbc: elb.New(s),
		r53c: route53.New(s),
		ec2:  ec2.New(s),
	}
}
source: func NewHandlerWrapper(b *ratelimit.Bucket, wait bool) server.HandlerWrapper {
	fn := limit(b, wait, "go.micro.server")

	return func(h server.HandlerFunc) server.HandlerFunc {
		return func(ctx context.Context, req server.Request, rsp interface{}) error {
			if err := fn(); err != nil {
				return err
			}
			return h(ctx, req, rsp)
		}
	}
}
source: func RequestNewChannels(devEUI lorawan.EUI64, maxChannels int, currentChannels, wantedChannels map[int]band.Channel) *storage.MACCommandBlock {
	var out []lorawan.MACCommand

	// sort by channel index
	var wantedChannelNumbers []int
	for i := range wantedChannels {
		wantedChannelNumbers = append(wantedChannelNumbers, i)
	}
	sort.Ints(wantedChannelNumbers)

	for _, i := range wantedChannelNumbers {
		wanted := wantedChannels[i]
		current, ok := currentChannels[i]
		if !ok || current.Frequency != wanted.Frequency || current.MinDR != wanted.MinDR || current.MaxDR != wanted.MaxDR {
			out = append(out, lorawan.MACCommand{
				CID: lorawan.NewChannelReq,
				Payload: &lorawan.NewChannelReqPayload{
					ChIndex: uint8(i),
					Freq:    uint32(wanted.Frequency),
					MinDR:   uint8(wanted.MinDR),
					MaxDR:   uint8(wanted.MaxDR),
				},
			})
		}
	}

	if len(out) > maxChannels {
		out = out[0:maxChannels]
	}

	if len(out) == 0 {
		return nil
	}

	return &storage.MACCommandBlock{
		CID:         lorawan.NewChannelReq,
		MACCommands: storage.MACCommands(out),
	}
}
source: func Convert_v1_FlexPersistentVolumeSource_To_core_FlexPersistentVolumeSource(in *v1.FlexPersistentVolumeSource, out *core.FlexPersistentVolumeSource, s conversion.Scope) error {
	return autoConvert_v1_FlexPersistentVolumeSource_To_core_FlexPersistentVolumeSource(in, out, s)
}
source: func Convert_config_SourceStrategyDefaultsConfig_To_v1_SourceStrategyDefaultsConfig(in *config.SourceStrategyDefaultsConfig, out *v1.SourceStrategyDefaultsConfig, s conversion.Scope) error {
	return autoConvert_config_SourceStrategyDefaultsConfig_To_v1_SourceStrategyDefaultsConfig(in, out, s)
}
source: func (c *collector) Remove(t runtime.Task) {
	if c.ns == nil {
		return
	}
	c.mu.Lock()
	defer c.mu.Unlock()
	delete(c.tasks, taskID(t.ID(), t.Namespace()))
}
source: func (p *Process) ClearBreakpoint(addr uint64) (*proc.Breakpoint, error) {
	if p.exited {
		return nil, &proc.ErrProcessExited{Pid: p.conn.pid}
	}
	return p.breakpoints.Clear(addr, func(bp *proc.Breakpoint) error {
		return p.conn.clearBreakpoint(bp.Addr)
	})
}
source: func (s *Session) removeEventHandlerInstance(t string, ehi *eventHandlerInstance) {
	s.handlersMu.Lock()
	defer s.handlersMu.Unlock()

	handlers := s.handlers[t]
	for i := range handlers {
		if handlers[i] == ehi {
			s.handlers[t] = append(handlers[:i], handlers[i+1:]...)
		}
	}

	onceHandlers := s.onceHandlers[t]
	for i := range onceHandlers {
		if onceHandlers[i] == ehi {
			s.onceHandlers[t] = append(onceHandlers[:i], handlers[i+1:]...)
		}
	}
}
source: func (g gjsonLabels) Has(label string) bool {
	return gjson.GetBytes(g.json, label).Exists()
}
source: func (v *VoiceConnection) Close() {

	v.log(LogInformational, "called")

	v.Lock()
	defer v.Unlock()

	v.Ready = false
	v.speaking = false

	if v.close != nil {
		v.log(LogInformational, "closing v.close")
		close(v.close)
		v.close = nil
	}

	if v.udpConn != nil {
		v.log(LogInformational, "closing udp")
		err := v.udpConn.Close()
		if err != nil {
			v.log(LogError, "error closing udp connection, %s", err)
		}
		v.udpConn = nil
	}

	if v.wsConn != nil {
		v.log(LogInformational, "sending close frame")

		// To cleanly close a connection, a client should send a close
		// frame and wait for the server to close the connection.
		v.wsMutex.Lock()
		err := v.wsConn.WriteMessage(websocket.CloseMessage, websocket.FormatCloseMessage(websocket.CloseNormalClosure, ""))
		v.wsMutex.Unlock()
		if err != nil {
			v.log(LogError, "error closing websocket, %s", err)
		}

		// TODO: Wait for Discord to actually close the connection.
		time.Sleep(1 * time.Second)

		v.log(LogInformational, "closing websocket")
		err = v.wsConn.Close()
		if err != nil {
			v.log(LogError, "error closing websocket, %s", err)
		}

		v.wsConn = nil
	}
}
source: func (b *AESGCMBarrier) Initialize(ctx context.Context, key []byte) error {
	// Verify the key size
	min, max := b.KeyLength()
	if len(key) < min || len(key) > max {
		return fmt.Errorf("key size must be %d or %d", min, max)
	}

	// Check if already initialized
	if alreadyInit, err := b.Initialized(ctx); err != nil {
		return err
	} else if alreadyInit {
		return ErrBarrierAlreadyInit
	}

	// Generate encryption key
	encrypt, err := b.GenerateKey()
	if err != nil {
		return errwrap.Wrapf("failed to generate encryption key: {{err}}", err)
	}

	// Create a new keyring, install the keys
	keyring := NewKeyring()
	keyring = keyring.SetMasterKey(key)
	keyring, err = keyring.AddKey(&Key{
		Term:    1,
		Version: 1,
		Value:   encrypt,
	})
	if err != nil {
		return errwrap.Wrapf("failed to create keyring: {{err}}", err)
	}
	return b.persistKeyring(ctx, keyring)
}
source: func (fs *FilteringSink) Store(location BlockLocation, data []byte) error {
	fs.totalReqs++

	if fs.Filter.Has(location) {
		fs.allowedReqs++
		return fs.Sink.Store(location, data)
	}

	// when filtered, just discard the block
	return nil
}
source: func NewLogger(config Config) (Logger, error) {
	switch config.Name {
	case Console:
		return NewConsoleLogger(config)
	case Syslog:
		return NewSysLogger(config)
	case UDPLog:
		return NewUDPLogger(config)
	}
	return nil, fmt.Errorf("unknown logger: %v", config)
}
source: func cleanApp(c *model.CommandConfig) (err error) {
	appPkg, err := build.Import(c.ImportPath, "", build.FindOnly)
	if err != nil {
		utils.Logger.Fatal("Abort: Failed to find import path:", "error", err)
	}

	purgeDirs := []string{
		filepath.Join(appPkg.Dir, "app", "tmp"),
		filepath.Join(appPkg.Dir, "app", "routes"),
	}

	for _, dir := range purgeDirs {
		fmt.Println("Removing:", dir)
		err = os.RemoveAll(dir)
		if err != nil {
			utils.Logger.Error("Failed to clean dir", "error", err)
			return
		}
	}
	return err
}
source: func (ds *DiskStorage) StorageGeneration() (initTime time.Time, random string, err error) {
	return ds.gen.StorageGeneration()
}
source: func (w *DeploymentStream) Publish(status twelvefactor.Status) error {
	return w.Status(status.Message)
}
source: func GetNetworkDescriptions(n *networking.Networking) []NetDescriber {
	var nds []NetDescriber
	for _, an := range n.GetActiveNetworks() {
		nds = append(nds, an)
	}
	return nds
}
source: func (client *Client) CreateUser(uaaUserID string) (User, Warnings, error) {
	type userRequestBody struct {
		GUID string `json:"guid"`
	}

	bodyBytes, err := json.Marshal(userRequestBody{
		GUID: uaaUserID,
	})
	if err != nil {
		return User{}, nil, err
	}

	request, err := client.newHTTPRequest(requestOptions{
		RequestName: internal.PostUserRequest,
		Body:        bytes.NewReader(bodyBytes),
	})
	if err != nil {
		return User{}, nil, err
	}

	var user User
	response := cloudcontroller.Response{
		DecodeJSONResponseInto: &user,
	}

	err = client.connection.Make(request, &response)
	if err != nil {
		return User{}, response.Warnings, err
	}

	return user, response.Warnings, nil
}
source: func (b *Bucket) DeleteBucket(key []byte) error {
	if b.tx.db == nil {
		return ErrTxClosed
	} else if !b.Writable() {
		return ErrTxNotWritable
	}

	// Move cursor to correct position.
	c := b.Cursor()
	k, _, flags := c.seek(key)

	// Return an error if bucket doesn't exist or is not a bucket.
	if !bytes.Equal(key, k) {
		return ErrBucketNotFound
	} else if (flags & bucketLeafFlag) == 0 {
		return ErrIncompatibleValue
	}

	// Recursively delete all child buckets.
	child := b.Bucket(key)
	err := child.ForEach(func(k, v []byte) error {
		if v == nil {
			if err := child.DeleteBucket(k); err != nil {
				return fmt.Errorf("delete bucket: %s", err)
			}
		}
		return nil
	})
	if err != nil {
		return err
	}

	// Remove cached copy.
	delete(b.buckets, string(key))

	// Release all bucket pages to freelist.
	child.nodes = nil
	child.rootNode = nil
	child.free()

	// Delete the node if we have a matching key.
	c.node().del(key)

	return nil
}
source: func Convert_v1alpha2_LyftVPCNetworkingSpec_To_kops_LyftVPCNetworkingSpec(in *LyftVPCNetworkingSpec, out *kops.LyftVPCNetworkingSpec, s conversion.Scope) error {
	return autoConvert_v1alpha2_LyftVPCNetworkingSpec_To_kops_LyftVPCNetworkingSpec(in, out, s)
}
source: func (in *HTTPIngressRuleValue) DeepCopy() *HTTPIngressRuleValue {
	if in == nil {
		return nil
	}
	out := new(HTTPIngressRuleValue)
	in.DeepCopyInto(out)
	return out
}
source: func (fbs *FilterByShard) ReplaceTablet(old, new *topodatapb.Tablet, name string) {
	if fbs.isIncluded(old) && fbs.isIncluded(new) {
		fbs.tr.ReplaceTablet(old, new, name)
	}
}
source: func (t Term) Append(args ...interface{}) Term {
	return constructMethodTerm(t, "Append", p.Term_APPEND, args, map[string]interface{}{})
}
source: func isOperator(token string) bool {
	for _, v := range operators {
		if v == token {
			return true
		}
	}
	return false
}
source: func (addr *ResourceAddress) ModuleInstanceAddr() addrs.ModuleInstance {
	path := make(addrs.ModuleInstance, len(addr.Path))
	for i, name := range addr.Path {
		path[i] = addrs.ModuleInstanceStep{Name: name}
	}
	return path
}
source: func (s *DescribeWorkspacesConnectionStatusOutput) SetWorkspacesConnectionStatus(v []*WorkspaceConnectionStatus) *DescribeWorkspacesConnectionStatusOutput {
	s.WorkspacesConnectionStatus = v
	return s
}
source: func (frame *FrameContext) ExecuteUntilPC(instructions []byte) {
	frame.buf.Truncate(0)
	frame.buf.Write(instructions)

	// We only need to execute the instructions until
	// ctx.loc > ctx.address (which is the address we
	// are currently at in the traced process).
	for frame.address >= frame.loc && frame.buf.Len() > 0 {
		executeDwarfInstruction(frame)
	}
}
source: func ValidateIPNetFromString(subnet string, minAddrs int64, fldPath *field.Path) field.ErrorList {
	allErrs := field.ErrorList{}
	_, svcSubnet, err := net.ParseCIDR(subnet)
	if err != nil {
		allErrs = append(allErrs, field.Invalid(fldPath, subnet, "couldn't parse subnet"))
		return allErrs
	}
	numAddresses := ipallocator.RangeSize(svcSubnet)
	if numAddresses < minAddrs {
		allErrs = append(allErrs, field.Invalid(fldPath, subnet, "subnet is too small"))
	}
	return allErrs
}
source: func datasetSize(block uint64) uint64 {
	epoch := int(block / epochLength)
	if epoch < maxEpoch {
		return datasetSizes[epoch]
	}
	return calcDatasetSize(epoch)
}
source: func parseSrcDestArgs(g *libkb.GlobalContext, ctx *cli.Context, name string) ([]keybase1.Path, keybase1.Path, error) {
	nargs := len(ctx.Args())

	var srcType, destType keybase1.PathType
	var srcPaths []keybase1.Path
	var destPath keybase1.Path

	if nargs < 2 {
		return srcPaths, destPath, errors.New(name + " requires one or more source arguments and a destination argument")
	}
	for i, src := range ctx.Args() {
		rev := int64(0)
		timeString := ""
		relTimeString := ""
		if i != nargs-1 {
			// All source paths use the same revision.
			rev = int64(ctx.Int("rev"))
			timeString = ctx.String("time")
			relTimeString = getRelTime(ctx)
		}
		argPath, err := makeSimpleFSPathWithArchiveParams(
			src, rev, timeString, relTimeString)
		if err != nil {
			return nil, keybase1.Path{}, err
		}
		tempPathType, err := argPath.PathType()
		if err != nil {
			return srcPaths, destPath, err
		}
		// Make sure all source paths are the same type
		if i == 0 {
			srcType = tempPathType
		} else if i == nargs-1 {
			destPath = argPath
			destType = tempPathType
			break
		} else if tempPathType != srcType {
			return srcPaths, destPath, errors.New(name + " requires all sources to be the same type")
		}
		srcPaths = append(srcPaths, argPath)
	}

	if srcType == keybase1.PathType_LOCAL && destType == keybase1.PathType_LOCAL {
		return srcPaths, destPath, errors.New(name + " requires KBFS source and/or destination")
	}
	return srcPaths, destPath, nil
}
source: func (m *MediaTypeDefinition) IterateViews(it ViewIterator) error {
	o := m.Views
	// gather names and sort them
	names := make([]string, len(o))
	i := 0
	for n := range o {
		names[i] = n
		i++
	}
	sort.Strings(names)
	// iterate
	for _, n := range names {
		if err := it(o[n]); err != nil {
			return err
		}
	}
	return nil
}
source: func (s *State) MemberRemove(member *Member) error {
	if s == nil {
		return ErrNilState
	}

	guild, err := s.Guild(member.GuildID)
	if err != nil {
		return err
	}

	s.Lock()
	defer s.Unlock()

	members, ok := s.memberMap[member.GuildID]
	if !ok {
		return ErrStateNotFound
	}

	_, ok = members[member.User.ID]
	if !ok {
		return ErrStateNotFound
	}
	delete(members, member.User.ID)

	for i, m := range guild.Members {
		if m.User.ID == member.User.ID {
			guild.Members = append(guild.Members[:i], guild.Members[i+1:]...)
			return nil
		}
	}

	return ErrStateNotFound
}
source: func MakeHelp(c AutoHelp) string {
	usageText := c.Usage()

	// If the length of Usage() is zero, then assume this is a hidden
	// command.
	if len(usageText) == 0 {
		return ""
	}

	descriptionText := wordwrap.WrapString(c.Description(), 60)
	descrLines := strings.Split(descriptionText, "\n")
	prefixedLines := make([]string, len(descrLines))
	for i := range descrLines {
		prefixedLines[i] = "  " + descrLines[i]
	}
	descriptionText = strings.Join(prefixedLines, "\n")

	c.InitOpts()
	flags := []*flag.Flag{}
	c.VisitAllFlags(func(f *flag.Flag) {
		flags = append(flags, f)
	})
	optionsText := OptionsHelpOutput(flags)

	var helpOutput string
	switch {
	case len(optionsText) == 0 && len(descriptionText) == 0:
		helpOutput = usageText
	case len(optionsText) == 0:
		helpOutput = fmt.Sprintf(`Usage: %s

%s`,
			usageText, descriptionText)
	case len(descriptionText) == 0 && len(optionsText) > 0:
		helpOutput = fmt.Sprintf(`Usage: %s

Options:

%s`,
			usageText, optionsText)
	default:
		helpOutput = fmt.Sprintf(`Usage: %s

%s

Options:

%s`,
			usageText, descriptionText, optionsText)
	}

	return strings.TrimSpace(helpOutput)
}
source: func (s *Stmt) Select(dest interface{}, args ...interface{}) error {
	return Select(&qStmt{s}, dest, "", args...)
}
source: func (wr *Wrangler) ExecuteHook(ctx context.Context, tabletAlias *topodatapb.TabletAlias, hook *hk.Hook) (hookResult *hk.HookResult, err error) {
	if strings.Contains(hook.Name, "/") {
		return nil, fmt.Errorf("hook name cannot have a '/' in it")
	}
	ti, err := wr.ts.GetTablet(ctx, tabletAlias)
	if err != nil {
		return nil, err
	}
	return wr.ExecuteTabletHook(ctx, ti.Tablet, hook)
}
source: func NewFileMoveDetails(RelocateActionDetails []*RelocateAssetReferencesLogInfo) *FileMoveDetails {
	s := new(FileMoveDetails)
	s.RelocateActionDetails = RelocateActionDetails
	return s
}
source: func BucketTimesIn(bucketName []byte) DBConfiguration {
	return func(c *CyclePDB) error {
		c.bucketTimesIn = bucketName
		return nil
	}
}
source: func (q *Queue) List(positions ...int) ([]interface{}, error) {
	q.Lock()
	defer q.Unlock()
	result := make([]interface{}, len(positions))
	for i, pos := range positions {
		element, err := q.get(pos)
		if err != nil {
			return nil, err
		}
		result[i] = element
	}
	return result, nil
}
source: func (n *node) add(key string, data interface{}, order int) int {
	matched := 0

	// find the common prefix
	for ; matched < len(key) && matched < len(n.key); matched++ {
		if key[matched] != n.key[matched] {
			break
		}
	}

	if matched == len(n.key) {
		if matched == len(key) {
			// the node key is the same as the key: make the current node as data node
			// if the node is already a data node, ignore the new data since we only care the first matched node
			if n.data == nil {
				n.data = data
				n.order = order
			}
			return n.pindex + 1
		}

		// the node key is a prefix of the key: create a child node
		newKey := key[matched:]

		// try adding to a static child
		if child := n.children[newKey[0]]; child != nil {
			if pn := child.add(newKey, data, order); pn >= 0 {
				return pn
			}
		}
		// try adding to a param child
		for _, child := range n.pchildren {
			if pn := child.add(newKey, data, order); pn >= 0 {
				return pn
			}
		}

		return n.addChild(newKey, data, order)
	}

	if matched == 0 || !n.static {
		// no common prefix, or partial common prefix with a non-static node: should skip this node
		return -1
	}

	// the node key shares a partial prefix with the key: split the node key
	n1 := &node{
		static:    true,
		key:       n.key[matched:],
		data:      n.data,
		order:     n.order,
		minOrder:  n.minOrder,
		pchildren: n.pchildren,
		children:  n.children,
		pindex:    n.pindex,
		pnames:    n.pnames,
	}

	n.key = key[0:matched]
	n.data = nil
	n.pchildren = make([]*node, 0)
	n.children = make([]*node, 256)
	n.children[n1.key[0]] = n1

	return n.add(key, data, order)
}
source: func LoadFontFace(path string, points float64) (font.Face, error) {
	fontBytes, err := ioutil.ReadFile(path)
	if err != nil {
		return nil, err
	}
	f, err := truetype.Parse(fontBytes)
	if err != nil {
		return nil, err
	}
	face := truetype.NewFace(f, &truetype.Options{
		Size: points,
		// Hinting: font.HintingFull,
	})
	return face, nil
}
source: func (prop Prop) Check(parameters *TestParameters) *TestResult {
	iterations := math.Ceil(float64(parameters.MinSuccessfulTests) / float64(parameters.Workers))
	sizeStep := float64(parameters.MaxSize-parameters.MinSize) / (iterations * float64(parameters.Workers))

	genParameters := GenParameters{
		MinSize:        parameters.MinSize,
		MaxSize:        parameters.MaxSize,
		MaxShrinkCount: parameters.MaxShrinkCount,
		Rng:            parameters.Rng,
	}
	runner := &runner{
		parameters: parameters,
		worker: func(workerIdx int, shouldStop shouldStop) *TestResult {
			var n int
			var d int

			isExhaused := func() bool {
				return n+d > parameters.MinSuccessfulTests &&
					1.0+float64(parameters.Workers*n)*parameters.MaxDiscardRatio < float64(d)
			}

			for !shouldStop() && n < int(iterations) {
				size := float64(parameters.MinSize) + (sizeStep * float64(workerIdx+(parameters.Workers*(n+d))))
				propResult := prop(genParameters.WithSize(int(size)))

				switch propResult.Status {
				case PropUndecided:
					d++
					if isExhaused() {
						return &TestResult{
							Status:    TestExhausted,
							Succeeded: n,
							Discarded: d,
						}
					}
				case PropTrue:
					n++
				case PropProof:
					n++
					return &TestResult{
						Status:    TestProved,
						Succeeded: n,
						Discarded: d,
						Labels:    propResult.Labels,
						Args:      propResult.Args,
					}
				case PropFalse:
					return &TestResult{
						Status:    TestFailed,
						Succeeded: n,
						Discarded: d,
						Labels:    propResult.Labels,
						Args:      propResult.Args,
					}
				case PropError:
					return &TestResult{
						Status:     TestError,
						Succeeded:  n,
						Discarded:  d,
						Labels:     propResult.Labels,
						Error:      propResult.Error,
						ErrorStack: propResult.ErrorStack,
						Args:       propResult.Args,
					}
				}
			}

			if isExhaused() {
				return &TestResult{
					Status:    TestExhausted,
					Succeeded: n,
					Discarded: d,
				}
			}
			return &TestResult{
				Status:    TestPassed,
				Succeeded: n,
				Discarded: d,
			}
		},
	}

	return runner.runWorkers()
}
source: func (crud *repo) FindByPublicId(publicId string) (profile service.Entity, err error) {
	if err = dbconn.DB.Where("public_id = ?", publicId).First(&profile).Error; err != nil {
		return service.Entity{}, err
	}
	return profile, nil
}
source: func (i *DocumentIndex) IsOrgAccessor(userID influxdb.ID, orgID influxdb.ID) error {
	f := influxdb.UserResourceMappingFilter{
		UserID:       userID,
		ResourceType: influxdb.OrgsResourceType,
		ResourceID:   orgID,
	}

	if i.writable {
		f.UserType = influxdb.Owner
	}

	ms, err := i.service.findUserResourceMappings(i.ctx, i.tx, f)
	if err != nil {
		return err
	}

	for _, m := range ms {
		switch m.UserType {
		case influxdb.Owner, influxdb.Member:
			return nil
		default:
			continue
		}
	}

	return &influxdb.Error{
		Code: influxdb.EUnauthorized,
		Msg:  "user is not org member",
	}
}
source: func eventHasNonBlobPayloadMembers(s *Shape) bool {
	num := len(s.MemberRefs)
	for _, ref := range s.MemberRefs {
		if ref.IsEventHeader || (ref.IsEventPayload && (ref.Shape.Type == "blob" || ref.Shape.Type == "string")) {
			num--
		}
	}
	return num > 0
}
source: func (in *RuleWithOperations) DeepCopy() *RuleWithOperations {
	if in == nil {
		return nil
	}
	out := new(RuleWithOperations)
	in.DeepCopyInto(out)
	return out
}
source: func ViterbiSplit(input string, c *Corpus) []string {
	s := strings.ToLower(input)
	probabilities := []float64{1.0}
	lasts := []int{0}

	runes := []int{}
	for i := range s {
		runes = append(runes, i)
	}
	runes = append(runes, len(s)+1)

	for i := range s {
		probs := make([]float64, 0)
		ls := make([]int, 0)

		// m := maxInt(0, i-c.maxWordLength)

		for j, r := range runes {
			if r > i {
				break
			}

			p, ok := c.WordProb(s[r : i+1])
			if !ok {
				// http://stackoverflow.com/questions/195010/how-can-i-split-multiple-joined-words#comment48879458_481773
				p = (math.Log(float64(1)/float64(c.totalFreq)) - float64(c.maxWordLength) - float64(1)) * float64(i-r) // note it should be i-r not j-i as per the SO post
			}
			prob := probabilities[j] * p

			probs = append(probs, prob)
			ls = append(ls, r)
		}

		maxProb := -math.SmallestNonzeroFloat64
		maxK := -1 << 63
		for j, p := range probs {
			if p > maxProb {
				maxProb = p
				maxK = ls[j]
			}
		}
		probabilities = append(probabilities, maxProb)
		lasts = append(lasts, maxK)
	}

	words := make([]string, 0)
	i := utf8.RuneCountInString(s)

	for i > 0 {
		start := lasts[i]
		words = append(words, s[start:i])
		i = start
	}

	// reverse it
	for i, j := 0, len(words)-1; i < j; i, j = i+1, j-1 {
		words[i], words[j] = words[j], words[i]
	}

	return words
}
source: func (hook *FluentHook) getTagAndDel(entry *logrus.Entry, data logrus.Fields) string {
	// use static tag from
	if hook.tag != nil {
		return *hook.tag
	}

	tagField, ok := data[TagField]
	if !ok {
		return entry.Message
	}

	tag, ok := tagField.(string)
	if !ok {
		return entry.Message
	}

	// remove tag from data fields
	delete(data, TagField)
	return tag
}
source: func (s *Schema) IsUniqueKey(col *Column) bool {
	for _, key := range s.Keys {
		if len(key) == 1 && key[0].Equal(nil, col) {
			return true
		}
	}
	return false
}
source: func TLSCertInfo(cert *tls.Certificate) string {
	x509cert, err := x509.ParseCertificate(cert.Certificate[0])
	if err != nil {
		return err.Error()
	}
	return CertInfo(x509cert)
}
source: func (t *Client) EnsureTable(datasetName string, tableName string, schemaObject interface{}) (*bigquery.Table, error) {
	ctx := t.ctx
	dataset := t.client.Dataset(datasetName)
	table := dataset.Table(tableName)

	schema, err := bigquery.InferSchema(schemaObject)
	if err != nil {
		return table, err
	}
	setSchemaOptional(&schema)

	if _, err = table.Metadata(ctx); err != nil {
		if gerr, ok := err.(*googleapi.Error); ok && gerr.Code == 404 {
			return table, table.Create(ctx, &bigquery.TableMetadata{Schema: schema})
		}
		return table, err
	}
	return table, nil
}
source: func Convert_image_ImageLayer_To_v1_ImageLayer(in *image.ImageLayer, out *v1.ImageLayer, s conversion.Scope) error {
	return autoConvert_image_ImageLayer_To_v1_ImageLayer(in, out, s)
}
source: func (g *GPG) Encrypt(ctx context.Context, plaintext []byte, recipients []string) ([]byte, error) {
	ciphertext := &bytes.Buffer{}
	ents := g.recipientsToEntities(recipients)
	wc, err := openpgp.Encrypt(ciphertext, ents, nil, nil, nil)
	if err != nil {
		return nil, errors.Wrapf(err, "failed to encrypt")
	}
	if _, err := io.Copy(wc, bytes.NewReader(plaintext)); err != nil {
		return nil, errors.Wrapf(err, "failed to write plaintext to encoder")
	}
	if err := wc.Close(); err != nil {
		return nil, errors.Wrapf(err, "failed to finalize encryption")
	}
	return ciphertext.Bytes(), nil
}
source: func (rs *RenderSystem) EntityExists(basic *ecs.BasicEntity) int {
	for index, entity := range rs.entities {
		if entity.ID() == basic.ID() {
			return index
		}
	}

	return -1
}
source: func (dct *DjangoContentType) Delete(db XODB) error {
	var err error

	// if doesn't exist, bail
	if !dct._exists {
		return nil
	}

	// if deleted, bail
	if dct._deleted {
		return nil
	}

	// sql query
	const sqlstr = `DELETE FROM public.django_content_type WHERE id = $1`

	// run query
	XOLog(sqlstr, dct.ID)
	_, err = db.Exec(sqlstr, dct.ID)
	if err != nil {
		return err
	}

	// set deleted
	dct._deleted = true

	return nil
}
source: func (p *LogicalJoin) pushDownTopNToChild(topN *LogicalTopN, idx int) LogicalPlan {
	if topN == nil {
		return p.children[idx].pushDownTopN(nil)
	}

	for _, by := range topN.ByItems {
		cols := expression.ExtractColumns(by.Expr)
		for _, col := range cols {
			if p.children[1-idx].Schema().Contains(col) {
				return p.children[idx].pushDownTopN(nil)
			}
		}
	}

	newTopN := LogicalTopN{
		Count:   topN.Count + topN.Offset,
		ByItems: make([]*ByItems, len(topN.ByItems)),
	}.Init(topN.ctx)
	for i := range topN.ByItems {
		newTopN.ByItems[i] = topN.ByItems[i].Clone()
	}
	return p.children[idx].pushDownTopN(newTopN)
}
source: func (m *ModelManagerAPI) DumpModelsDB(args params.Entities) params.MapResults {
	results := params.MapResults{
		Results: make([]params.MapResult, len(args.Entities)),
	}
	for i, entity := range args.Entities {
		dumped, err := m.dumpModelDB(entity)
		if err != nil {
			results.Results[i].Error = common.ServerError(err)
			continue
		}
		results.Results[i].Result = dumped
	}
	return results
}
source: func Lt(lhs Expression, rhs Expression) BoolExpression {
	return newBoolExpression(lhs, rhs, []byte("<"))
}
source: func (mc *cache) Discard(ids []string) {
	mc.mu.Lock()
	defer mc.mu.Unlock()
	for _, id := range ids {
		if mr := mc.inQueue[id]; mr != nil {
			// The row is still in the queue somewhere. Mark
			// it as defunct. It will be "garbage collected" later.
			mr.defunct = true
		}
		delete(mc.inQueue, id)
		delete(mc.inFlight, id)
	}
}
source: func (t *Template) GetAWSDMSReplicationSubnetGroupWithName(name string) (*resources.AWSDMSReplicationSubnetGroup, error) {
	if untyped, ok := t.Resources[name]; ok {
		switch resource := untyped.(type) {
		case *resources.AWSDMSReplicationSubnetGroup:
			return resource, nil
		}
	}
	return nil, fmt.Errorf("resource %q of type AWSDMSReplicationSubnetGroup not found", name)
}
source: func (m *RollPitchYawRatesThrustSetpoint) Decode(buf []byte) {
	data := bytes.NewBuffer(buf)
	binary.Read(data, binary.LittleEndian, &m.TIME_BOOT_MS)
	binary.Read(data, binary.LittleEndian, &m.ROLL_RATE)
	binary.Read(data, binary.LittleEndian, &m.PITCH_RATE)
	binary.Read(data, binary.LittleEndian, &m.YAW_RATE)
	binary.Read(data, binary.LittleEndian, &m.THRUST)
}
source: func (p *DB) findGE(key []byte, prev bool) (int, bool) {
	node := 0
	h := p.maxHeight - 1
	for {
		next := p.nodeData[node+nNext+h]
		cmp := 1
		if next != 0 {
			o := p.nodeData[next]
			cmp = p.cmp.Compare(p.kvData[o:o+p.nodeData[next+nKey]], key)
		}
		if cmp < 0 {
			// Keep searching in this list
			node = next
		} else {
			if prev {
				p.prevNode[h] = node
			} else if cmp == 0 {
				return next, true
			}
			if h == 0 {
				return next, cmp == 0
			}
			h--
		}
	}
}
source: func (c *Context) Usage() {
	c.cmd.Flags.Usage()
	if len(c.cmd.children) > 0 {
		fmt.Print("\nCommands:\n\n")
		w := tabwriter.NewWriter(os.Stdout, 0, 0, 3, ' ', 0)
		for name, child := range c.cmd.children {
			fmt.Fprintln(w, "  "+name+"\t"+child.Desc)
		}
		w.Flush()
	}
}
source: func (dl *ConsoleLogger) Critical(message interface{}, params ...interface{}) {
	dl.logger.Criticalf(fmt.Sprintf("%s %s", caller(), fmt.Sprint(message)), params...)
}
source: func (r User_Customer_External_Binding) GetNote() (resp string, err error) {
	err = r.Session.DoRequest("SoftLayer_User_Customer_External_Binding", "getNote", nil, &r.Options, &resp)
	return
}
source: func (m *MockVolumeDriver) CloudMigrateStart(arg0 *api.CloudMigrateStartRequest) (*api.CloudMigrateStartResponse, error) {
	ret := m.ctrl.Call(m, "CloudMigrateStart", arg0)
	ret0, _ := ret[0].(*api.CloudMigrateStartResponse)
	ret1, _ := ret[1].(error)
	return ret0, ret1
}
source: func (b *BatchProvider) NewChain(table, chain string) error {
	b.Lock()
	defer b.Unlock()

	if _, ok := b.batchTables[table]; !ok {
		return b.ipt.NewChain(table, chain)
	}

	if _, ok := b.rules[table]; !ok {
		b.rules[table] = map[string][]string{}
	}
	b.rules[table][chain] = []string{}

	return nil
}
source: func (in *Fields) DeepCopy() *Fields {
	if in == nil {
		return nil
	}
	out := new(Fields)
	in.DeepCopyInto(out)
	return out
} 22%|██▏       | 1095/5000 [00:01<00:05, 683.40it/s]
source: func Targets(ctx context.Context) ([]*target.Info, error) {
	// Don't rely on Run, as that needs to be able to call Targets, and we
	// don't want cyclic func calls.
	c := FromContext(ctx)
	if c == nil || c.Allocator == nil {
		return nil, ErrInvalidContext
	}
	if c.Browser == nil {
		browser, err := c.Allocator.Allocate(ctx, c.browserOpts...)
		if err != nil {
			return nil, err
		}
		c.Browser = browser
	}
	return target.GetTargets().Do(cdp.WithExecutor(ctx, c.Browser))
}
source: func VerifyCSR(csr *x509.CertificateRequest, maxNames int, keyPolicy *goodkey.KeyPolicy, pa core.PolicyAuthority, forceCNFromSAN bool, regID int64) error {
	normalizeCSR(csr, forceCNFromSAN)
	key, ok := csr.PublicKey.(crypto.PublicKey)
	if !ok {
		return invalidPubKey
	}
	if err := keyPolicy.GoodKey(key); err != nil {
		return fmt.Errorf("invalid public key in CSR: %s", err)
	}
	if !goodSignatureAlgorithms[csr.SignatureAlgorithm] {
		return unsupportedSigAlg
	}
	if err := csr.CheckSignature(); err != nil {
		return invalidSig
	}
	if len(csr.EmailAddresses) > 0 {
		return invalidEmailPresent
	}
	if len(csr.IPAddresses) > 0 {
		return invalidIPPresent
	}
	if len(csr.DNSNames) == 0 && csr.Subject.CommonName == "" {
		return invalidNoDNS
	}
	if len(csr.Subject.CommonName) > maxCNLength {
		return fmt.Errorf("CN was longer than %d bytes", maxCNLength)
	}
	if len(csr.DNSNames) > maxNames {
		return fmt.Errorf("CSR contains more than %d DNS names", maxNames)
	}
	badNames := []string{}
	for _, name := range csr.DNSNames {
		ident := core.AcmeIdentifier{
			Type:  core.IdentifierDNS,
			Value: name,
		}
		var err error
		if err = pa.WillingToIssueWildcard(ident); err != nil {
			badNames = append(badNames, fmt.Sprintf("%q", name))
		}
	}
	if len(badNames) > 0 {
		return fmt.Errorf("policy forbids issuing for: %s", strings.Join(badNames, ", "))
	}
	return nil
}
source: func (w *AtomicWriter) removeUserVisiblePaths(paths sets.String) error {
	ps := string(os.PathSeparator)
	var lasterr error
	for p := range paths {
		// only remove symlinks from the volume root directory (i.e. items that don't contain '/')
		if strings.Contains(p, ps) {
			continue
		}
		if err := os.Remove(filepath.Join(w.targetDir, p)); err != nil {
			klog.Errorf("%s: error pruning old user-visible path %s: %v", w.logContext, p, err)
			lasterr = err
		}
	}

	return lasterr
}
source: func DecodeRxBufferHeader(b []byte) RxBuffer {
	return RxBuffer{
		Offset:   binary.LittleEndian.Uint64(b[postedOffset:]),
		Size:     binary.LittleEndian.Uint32(b[postedSize:]),
		ID:       binary.LittleEndian.Uint64(b[postedID:]),
		UserData: binary.LittleEndian.Uint64(b[postedUserData:]),
	}
}
source: func (s *ZoneService) NewDeleteZoneParams(id string) *DeleteZoneParams {
	p := &DeleteZoneParams{}
	p.p = make(map[string]interface{})
	p.p["id"] = id
	return p
}
source: func NewENSRegistryCaller(address common.Address, caller bind.ContractCaller) (*ENSRegistryCaller, error) {
	contract, err := bindENSRegistry(address, caller, nil, nil)
	if err != nil {
		return nil, err
	}
	return &ENSRegistryCaller{contract: contract}, nil
}
source: func (sl *DiskSessionLogger) PostSessionSlice(slice SessionSlice) error {
	sl.Lock()
	defer sl.Unlock()

	for i := range slice.Chunks {
		_, err := sl.writeChunk(slice.SessionID, slice.Chunks[i])
		if err != nil {
			return trace.Wrap(err)
		}
	}
	return sl.flush()
}
source: func (cs *StreamManager) LockProtectedGroup(g *Group) {
	cs.LockProtectedEntries(g.Entries)
	cs.LockProtectedGroups(g.Groups)
}
source: func DialConfig(url string, config Config) (*Connection, error) {
	var err error
	var conn net.Conn

	uri, err := ParseURI(url)
	if err != nil {
		return nil, err
	}

	if config.SASL == nil {
		config.SASL = []Authentication{uri.PlainAuth()}
	}

	if config.Vhost == "" {
		config.Vhost = uri.Vhost
	}

	addr := net.JoinHostPort(uri.Host, strconv.FormatInt(int64(uri.Port), 10))

	dialer := config.Dial
	if dialer == nil {
		dialer = DefaultDial(defaultConnectionTimeout)
	}

	conn, err = dialer("tcp", addr)
	if err != nil {
		return nil, err
	}

	if uri.Scheme == "amqps" {
		if config.TLSClientConfig == nil {
			config.TLSClientConfig = new(tls.Config)
		}

		// If ServerName has not been specified in TLSClientConfig,
		// set it to the URI host used for this connection.
		if config.TLSClientConfig.ServerName == "" {
			config.TLSClientConfig.ServerName = uri.Host
		}

		client := tls.Client(conn, config.TLSClientConfig)
		if err := client.Handshake(); err != nil {

			conn.Close()
			return nil, err
		}

		conn = client
	}

	return Open(conn, config)
}
source: func (c *Compiler) checkSafetyRuleHeads() {

	for _, name := range c.sorted {
		m := c.Modules[name]
		WalkRules(m, func(r *Rule) bool {
			safe := r.Body.Vars(safetyCheckVarVisitorParams)
			safe.Update(r.Head.Args.Vars())
			unsafe := r.Head.Vars().Diff(safe)
			for v := range unsafe {
				if !v.IsGenerated() {
					c.err(NewError(UnsafeVarErr, r.Loc(), "var %v is unsafe", v))
				}
			}
			return false
		})
	}
}
source: func (d *driver) LocalDevices(
	ctx types.Context,
	opts *types.LocalDevicesOpts) (*types.LocalDevices, error) {

	buckets, err := d.getMountedBuckets(ctx)
	if err != nil {
		return nil, err
	}
	return &types.LocalDevices{Driver: s3fs.Name, DeviceMap: buckets}, nil
}
source: func (taskChain *TaskChain) generate(dtasks Dogtasks, task string) error {

	t, found := dtasks.Tasks[task]
	if !found {
		return fmt.Errorf("Task %q does not exist", task)
	}

	// Cycle detection
	for i := 0; i < len(taskChain.Tasks); i++ {
		if taskChain.Tasks[i].Name == task {
			if len(taskChain.Tasks[i].Pre) > 0 || len(taskChain.Tasks[i].Post) > 0 {
				return ErrCycleInTaskChain
			}
		}
	}

	// Iterate over pre-tasks
	if err := addToChain(taskChain, dtasks, t.Pre); err != nil {
		return err
	}

	// Add current task to chain
	taskChain.Tasks = append(taskChain.Tasks, *t)

	// Iterate over post-tasks
	if err := addToChain(taskChain, dtasks, t.Post); err != nil {
		return err
	}
	return nil
}
source: func (l *ossObjects) PutObjectPart(ctx context.Context, bucket, object, uploadID string, partID int, r *minio.PutObjReader, opts minio.ObjectOptions) (pi minio.PartInfo, err error) {
	data := r.Reader
	bkt, err := l.Client.Bucket(bucket)
	if err != nil {
		logger.LogIf(ctx, err)
		return pi, ossToObjectError(err, bucket, object)
	}

	imur := oss.InitiateMultipartUploadResult{
		Bucket:   bucket,
		Key:      object,
		UploadID: uploadID,
	}
	size := data.Size()
	up, err := bkt.UploadPart(imur, data, size, partID)
	if err != nil {
		logger.LogIf(ctx, err)
		return pi, ossToObjectError(err, bucket, object)
	}

	return minio.PartInfo{
		Size: size,
		ETag: minio.ToS3ETag(up.ETag),
		// NOTE(timonwong): LastModified is not supported
		PartNumber: up.PartNumber,
	}, nil
}
source: func (e *EventSubscriber) loop() {
	defer close(e.Events)
	for {
		select {
		case <-e.stop:
			return
		case event := <-e.queue:
			e.Events <- event
		}
	}
}
source: func (d *Decoder) skipToNextFrame() (fh FrameHeader, readN int, err error) {
	if d == nil {
		return nil, readN, errors.New("nil decoder")
	}
	buf := make([]byte, 1)
	lookAheadBuf := make([]byte, 1)
	var n int
	for {
		n, err = d.r.Read(buf)
		readN += n
		if err != nil {
			return nil, readN, err
		}
		readN++
		if buf[0] == 0xFF {
			if _, err := d.r.Read(lookAheadBuf); err != nil {
				return nil, readN, err
			}
			readN++
			if lookAheadBuf[0]&0xE0 == 0xE0 {
				buf = []byte{0xff, lookAheadBuf[0], 0, 0}
				n, err := d.r.Read(buf[2:])
				if err != nil {
					return nil, readN + n, err
				}
				if n != 2 {
					return nil, readN + n, io.ErrUnexpectedEOF
				}
				readN += 2
			}
			return buf, readN, err
		}
	}
}
source: func MerkleDepth(nodeCount uint64) (depth uint64) {
	depth = 0

	for binaryTreeSize(0, depth) < nodeCount {
		depth++
	}

	return depth + 1
}
source: func NewErrorParsingURL(u string, e error) ErrorParsingURL {
	return ErrorParsingURL{uri: u, err: e}
}
source: func (l ServiceLockNode) Path() string {
	return path.Join("/pools", l.PoolID, "/services", l.ServiceID)
}
source: func (Encoder) AppendInt64(dst []byte, val int64) []byte {
	major := majorTypeUnsignedInt
	contentVal := val
	if val < 0 {
		major = majorTypeNegativeInt
		contentVal = -val - 1
	}
	if contentVal <= additionalMax {
		lb := byte(contentVal)
		dst = append(dst, byte(major|lb))
	} else {
		dst = appendCborTypePrefix(dst, major, uint64(contentVal))
	}
	return dst
}
source: func FindKopsVersionSpec(versions []KopsVersionSpec, version semver.Version) *KopsVersionSpec {
	for i := range versions {
		v := &versions[i]
		if v.Range != "" {
			versionRange, err := semver.ParseRange(v.Range)
			if err != nil {
				glog.Warningf("unable to parse range in channel version spec: %q", v.Range)
				continue
			}
			if !versionRange(version) {
				glog.V(8).Infof("version range %q does not apply to version %q; skipping", v.Range, version)
				continue
			}
		}
		return v
	}

	return nil
}
source: func MakeNtfnChans() {
	// If we're monitoring for blocks OR collecting block data, these channels
	// are necessary to handle new block notifications. Otherwise, leave them
	// as nil so that both a send (below) blocks and a receive (in
	// blockConnectedHandler) block. default case makes non-blocking below.
	// quit channel case manages blockConnectedHandlers.
	//NtfnChans.ConnectChan = make(chan *chainhash.Hash, blockConnChanBuffer)

	// WiredDB channel for connecting new blocks
	NtfnChans.ConnectChanWiredDB = make(chan *chainhash.Hash, blockConnChanBuffer)

	// Stake DB channel for connecting new blocks - BLOCKING!
	//NtfnChans.ConnectChanStakeDB = make(chan *chainhash.Hash)

	NtfnChans.ConnectChanDcrpgDB = make(chan *chainhash.Hash, blockConnChanBuffer)

	// Reorg data channels
	NtfnChans.ReorgChanBlockData = make(chan *txhelpers.ReorgData)
	NtfnChans.ReorgChanWiredDB = make(chan *txhelpers.ReorgData)
	NtfnChans.ReorgChanStakeDB = make(chan *txhelpers.ReorgData)
	NtfnChans.ReorgChanDcrpgDB = make(chan *txhelpers.ReorgData)

	// To update app status
	NtfnChans.UpdateStatusNodeHeight = make(chan uint32, blockConnChanBuffer)
	NtfnChans.UpdateStatusDBHeight = make(chan uint32, blockConnChanBuffer)

	// watchaddress
	// if len(cfg.WatchAddresses) > 0 {
	// // recv/SpendTxBlockChan come with connected blocks
	// 	NtfnChans.RecvTxBlockChan = make(chan *txhelpers.BlockWatchedTx, blockConnChanBuffer)
	// 	NtfnChans.SpendTxBlockChan = make(chan *txhelpers.BlockWatchedTx, blockConnChanBuffer)
	// 	NtfnChans.RelevantTxMempoolChan = make(chan *dcrutil.Tx, relevantMempoolTxChanBuffer)
	// }

	// New mempool tx chan for general purpose mempool monitor/collector/saver.
	NtfnChans.NewTxChan = make(chan *dcrjson.TxRawResult, newTxChanBuffer)

	NtfnChans.InsightNewTxChan = make(chan *insight.NewTx, expNewTxChanBuffer)
	NtfnChans.ReorgChartsCache = make(chan *txhelpers.ReorgData)
}
source: func RoundUp(t time.Time, d TimeDelta) time.Time {
	// works only because all TimeDeltas are more than 1.5 times as large as the next lower
	shift := d.Seconds()
	shift += shift / 2
	t = d.RoundDown(t)
	t = t.Add(time.Duration(shift) * time.Second)
	t = d.RoundDown(t)
	DebugLogger.Printf("RoundUp( %s, %s ) --> %s ", t.Format("2006-01-02 15:04:05 (Mon)"), d.String(),
		t.Format("2006-01-02 15:04:05 (Mon)"))
	return t
}
source: func (c *TagsCollection) Foreach(callback TagForeachCallback) error {
	data := tagForeachData{
		callback: callback,
		err:      nil,
	}

	handle := pointerHandles.Track(&data)
	defer pointerHandles.Untrack(handle)

	runtime.LockOSThread()
	defer runtime.UnlockOSThread()

	err := C._go_git_tag_foreach(c.repo.ptr, handle)
	runtime.KeepAlive(c)
	if err == C.GIT_EUSER {
		return data.err
	}
	if err < 0 {
		return MakeGitError(err)
	}

	return nil
}
source: func (d *compressor) writeBlockSkip(tok tokens, index int, eof bool) error {
	if index > 0 || eof {
		if d.blockStart <= index {
			window := d.window[d.blockStart:index]
			// If we removed less than a 64th of all literals
			// we huffman compress the block.
			if int(tok.n) > len(window)-int(tok.n>>6) {
				d.w.writeBlockHuff(eof, window)
			} else {
				// Write a dynamic huffman block.
				d.w.writeBlockDynamic(tok.tokens[:tok.n], eof, window)
			}
		} else {
			d.w.writeBlock(tok.tokens[:tok.n], eof, nil)
		}
		d.blockStart = index
		return d.w.err
	}
	return nil
}
source: func New(dir, passphrase string) (*Config, error) {
	if dir == "" || dir == "." {
		return nil, fmt.Errorf("dir must not be empty")
	}
	fn := filepath.Join(dir, filename)

	c := &Config{
		filename:   fn,
		passphrase: passphrase,
	}

	if !fsutil.IsFile(fn) {
		err := save(c.filename, c.passphrase, map[string]string{})
		return c, err
	}

	_, err := c.Get("")
	if err != nil {
		return nil, errors.Wrapf(err, "failed to open existing secrects config %s: %s", fn, err)
	}
	return c, nil
}
source: func (m *MockServerInfoSource) StartTime() time.Time {
	ret := m.ctrl.Call(m, "StartTime")
	ret0, _ := ret[0].(time.Time)
	return ret0
}
source: func MakeCallSiteFileLogger(fileName string, depth int) (Sender, error) {
	s, err := MakeFileLogger(fileName)
	if err != nil {
		return nil, err
	}

	if err := s.SetFormatter(MakeCallSiteFormatter(depth)); err != nil {
		return nil, err
	}

	return s, nil
}
source: func (p *parser) parseCurrentToken() {
	if p.tok.Type == SelfClosingTagToken {
		p.hasSelfClosingToken = true
		p.tok.Type = StartTagToken
	}

	consumed := false
	for !consumed {
		if p.inForeignContent() {
			consumed = parseForeignContent(p)
		} else {
			consumed = p.im(p)
		}
	}

	if p.hasSelfClosingToken {
		// This is a parse error, but ignore it.
		p.hasSelfClosingToken = false
	}
}
source: func (osCat OSCategory) ListRequest() (ListCommand, error) {
	req := &ListOSCategories{
		Name: osCat.Name,
		ID:   osCat.ID,
	}

	return req, nil
}
source: func (_class PoolClass) DisableExternalAuth(sessionID SessionRef, pool PoolRef, config map[string]string) (_err error) {
	_method := "pool.disable_external_auth"
	_sessionIDArg, _err := convertSessionRefToXen(fmt.Sprintf("%s(%s)", _method, "session_id"), sessionID)
	if _err != nil {
		return
	}
	_poolArg, _err := convertPoolRefToXen(fmt.Sprintf("%s(%s)", _method, "pool"), pool)
	if _err != nil {
		return
	}
	_configArg, _err := convertStringToStringMapToXen(fmt.Sprintf("%s(%s)", _method, "config"), config)
	if _err != nil {
		return
	}
	_, _err =  _class.client.APICall(_method, _sessionIDArg, _poolArg, _configArg)
	return
}
source: func buildReplicatorPlan(filter *binlogdatapb.Filter, tableKeys map[string][]string, copyState map[string]*sqltypes.Result) (*ReplicatorPlan, error) {
	plan := &ReplicatorPlan{
		VStreamFilter: &binlogdatapb.Filter{},
		TargetTables:  make(map[string]*TablePlan),
		TablePlans:    make(map[string]*TablePlan),
		tableKeys:     tableKeys,
	}
nextTable:
	for tableName := range tableKeys {
		lastpk, ok := copyState[tableName]
		if ok && lastpk == nil {
			// Don't replicate uncopied tables.
			continue
		}
		for _, rule := range filter.Rules {
			switch {
			case strings.HasPrefix(rule.Match, "/"):
				expr := strings.Trim(rule.Match, "/")
				result, err := regexp.MatchString(expr, tableName)
				if err != nil {
					return nil, err
				}
				if !result {
					continue
				}
				sendRule := &binlogdatapb.Rule{
					Match:  tableName,
					Filter: buildQuery(tableName, rule.Filter),
				}
				plan.VStreamFilter.Rules = append(plan.VStreamFilter.Rules, sendRule)
				tablePlan := &TablePlan{
					TargetName: tableName,
					SendRule:   sendRule,
				}
				plan.TargetTables[tableName] = tablePlan
				plan.TablePlans[tableName] = tablePlan
				continue nextTable
			case rule.Match == tableName:
				tablePlan, err := buildTablePlan(rule, tableKeys, lastpk)
				if err != nil {
					return nil, err
				}
				if _, ok := plan.TablePlans[tablePlan.SendRule.Match]; ok {
					continue
				}
				plan.VStreamFilter.Rules = append(plan.VStreamFilter.Rules, tablePlan.SendRule)
				plan.TargetTables[tableName] = tablePlan
				plan.TablePlans[tablePlan.SendRule.Match] = tablePlan
				continue nextTable
			}
		}
	}
	return plan, nil
}
source: func (endpoint *ApplicationEndpoint) Find(endpoints []ApplicationEndpoint) *ApplicationEndpoint {
	// Yes, this is brute-force linear search, but in practice the lists should be small, few 10s at most
	endpointID := endpoint.GetID()
	for _, entry := range endpoints {
		if entry.GetID() == endpointID {
			return &entry
		}
	}
	return nil
}
source: func (b *basicBatcher) IsDisposed() bool {
	b.lock.Lock()
	disposed := b.disposed
	b.lock.Unlock()
	return disposed
}
source: func deleteObject(remover models.Remover, id string, conn redis.Conn) {
	_ = conn.Send("DEL", id)

	for _, cmd := range remover.Remove() {
		switch cmd.Command {
		case "ZREM":
		case "SREM":
		case "HDEL":
			_ = conn.Send(cmd.Command, cmd.Hash, cmd.Key)
		}
	}
}
source: func (o *querySet) Exist() bool {
	cnt, _ := o.orm.alias.DbBaser.Count(o.orm.db, o, o.mi, o.cond, o.orm.alias.TZ)
	return cnt > 0
}
source: func AuthorizedWithOrgID(a Authorizer, orgID ID) func(ID, DocumentIndex) error {
	switch t := a.(type) {
	case *Authorization:
		return TokenAuthorizedWithOrgID(t, orgID)
	}

	return func(id ID, idx DocumentIndex) error {
		if err := idx.IsOrgAccessor(a.GetUserID(), orgID); err != nil {
			return err
		}

		return idx.AddDocumentOwner(id, "org", orgID)
	}
}
source: func (ca *CompositeAction) AddExec(a Action) {
	ca.Add(a)
	ca.actions[len(ca.actions)-1].Apply()
}
source: func NewMul(Variable node.Node, Expression node.Node) *Mul {
	return &Mul{
		FreeFloating: nil,
		Left:         Variable,
		Right:        Expression,
	}
}
source: func (s *statefulSetLister) StatefulSets(namespace string) StatefulSetNamespaceLister {
	return statefulSetNamespaceLister{indexer: s.indexer, namespace: namespace}
}
source: func InnerText(n *html.Node) string {
	var output func(*bytes.Buffer, *html.Node)
	output = func(buf *bytes.Buffer, n *html.Node) {
		switch n.Type {
		case html.TextNode:
			buf.WriteString(n.Data)
			return
		case html.CommentNode:
			return
		}
		for child := n.FirstChild; child != nil; child = child.NextSibling {
			output(buf, child)
		}
	}

	var buf bytes.Buffer
	output(&buf, n)
	return buf.String()
}
source: func (a *ACLTokens) Delete(accessorID string, q *WriteOptions) (*WriteMeta, error) {
	if accessorID == "" {
		return nil, fmt.Errorf("missing accessor ID")
	}
	wm, err := a.client.delete("/v1/acl/token/"+accessorID, nil, q)
	if err != nil {
		return nil, err
	}
	return wm, nil
}
source: func (z *Writer) Write(p []byte) (int, error) {
	if z.err != nil {
		return 0, z.err
	}
	var n int
	// Write the GZIP header lazily.
	if !z.wroteHeader {
		z.wroteHeader = true
		z.buf[0] = gzipID1
		z.buf[1] = gzipID2
		z.buf[2] = gzipDeflate
		z.buf[3] = 0
		if z.Extra != nil {
			z.buf[3] |= 0x04
		}
		if z.Name != "" {
			z.buf[3] |= 0x08
		}
		if z.Comment != "" {
			z.buf[3] |= 0x10
		}
		le.PutUint32(z.buf[4:8], uint32(z.ModTime.Unix()))
		if z.level == BestCompression {
			z.buf[8] = 2
		} else if z.level == BestSpeed {
			z.buf[8] = 4
		} else {
			z.buf[8] = 0
		}
		z.buf[9] = z.OS
		n, z.err = z.w.Write(z.buf[:10])
		if z.err != nil {
			return n, z.err
		}
		if z.Extra != nil {
			z.err = z.writeBytes(z.Extra)
			if z.err != nil {
				return n, z.err
			}
		}
		if z.Name != "" {
			z.err = z.writeString(z.Name)
			if z.err != nil {
				return n, z.err
			}
		}
		if z.Comment != "" {
			z.err = z.writeString(z.Comment)
			if z.err != nil {
				return n, z.err
			}
		}
		if z.compressor == nil {
			z.compressor, _ = flate.NewWriter(z.w, z.level)
		}
	}
	z.size += uint32(len(p))
	z.digest = crc32.Update(z.digest, crc32.IEEETable, p)
	n, z.err = z.compressor.Write(p)
	return n, z.err
}
source: func (s *Snapshot) SetNodeSnapshots(v []*NodeSnapshot) *Snapshot {
	s.NodeSnapshots = v
	return s
}
source: func Eprintf(format string, a ...interface{}) (n int, err error) {
	return fmt.Fprintf(os.Stderr, format, a...)
}
source: func (s *GetSamplingTargetsOutput) SetUnprocessedStatistics(v []*UnprocessedStatistics) *GetSamplingTargetsOutput {
	s.UnprocessedStatistics = v
	return s
}
source: func (profile *UserProfile) SetFieldsMap(m map[string]UserProfileCustomField) {
	profile.Fields.SetMap(m)
}
source: func ValidNodeStatus(status string) bool {
	switch status {
	case NodeStatusInit, NodeStatusReady, NodeStatusDown:
		return true
	default:
		return false
	}
}
source: func (f *FlowMod) WriteTo(w io.Writer) (int64, error) {
	return encoding.WriteTo(w, f.Cookie, f.CookieMask, f.Table,
		f.Command, f.IdleTimeout, f.HardTimeout, f.Priority,
		f.Buffer, f.OutPort, f.OutGroup, f.Flags, pad2{},
		&f.Match, &f.Instructions,
	)
}
source: func (p *Init) Checkpoint(ctx context.Context, r *CheckpointConfig) error {
	p.mu.Lock()
	defer p.mu.Unlock()

	return p.initState.Checkpoint(ctx, r)
}
source: func isIdentityAuthorizedByPrincipalSet(channel string, evaluator principalEvaluator, principalSet policies.PrincipalSet, identity api.PeerIdentityType) bool {
	// We look for a principal which authorizes the identity
	// among all principals in the principalSet
	for _, principal := range principalSet {
		err := evaluator.SatisfiesPrincipal(channel, identity, principal)
		if err != nil {
			continue
		}
		// Else, err is nil, so we found a principal which authorized
		// the given identity.
		return true
	}
	return false
}
source: func (v ModuleID) String() string {
	x := (int32)(v)
	return fmt.Sprint(x)
}
source: func (p Port) Proto() string {
	parts := strings.Split(string(p), "/")
	if len(parts) == 1 {
		return "tcp"
	}
	return parts[1]
}
source: func (s *AwsSecurityFindingFilters) SetProductName(v []*StringFilter) *AwsSecurityFindingFilters {
	s.ProductName = v
	return s
}
source: func NewHandle(store kv.Storage) *Handle {
	h := &Handle{
		store: store,
	}
	return h
}
source: func (gr *GoReq) Timeout(timeout time.Duration) *GoReq {
	gr.Transport.Dial = func(network, addr string) (net.Conn, error) {
		conn, err := net.DialTimeout(network, addr, timeout)
		if err != nil {
			gr.Errors = append(gr.Errors, err)
			return nil, err
		}
		conn.SetDeadline(time.Now().Add(timeout))
		return conn, nil
	}
	return gr
}
source: func NewSize(size int) (*Cipher, error) {
    var err error
    var internal cipherInternal

    switch size {
    case 256:
        internal, err = newThreefish256(nil, nil)
    case 512:
        internal, err = newThreefish512(nil, nil)
    case 1024:
        internal, err = newThreefish1024(nil, nil)
    default:
        return nil, KeySizeError(size)
    }
    return &Cipher{size, internal}, err
}
source: func (t *Table) ProjectBindings(bs []string) error {
	t.mu.Lock()
	defer t.mu.Unlock()
	if len(t.Data) == 0 || len(t.mbs) == 0 {
		return nil
	}
	for _, b := range bs {
		if !t.mbs[b] {
			return fmt.Errorf("cannot project against unknown binding %s; known bindinds are %v", b, t.AvailableBindings)
		}
	}
	t.AvailableBindings = []string{}
	t.mbs = make(map[string]bool)
	t.unsafeAddBindings(bs)
	return nil
}
source: func (s *ListRecordsOutput) SetDatasetDeletedAfterRequestedSyncCount(v bool) *ListRecordsOutput {
	s.DatasetDeletedAfterRequestedSyncCount = &v
	return s
}
source: func (c Client) Get(id string, params *stripe.TerminalLocationParams) (*stripe.TerminalLocation, error) {
	path := stripe.FormatURLPath("/v1/terminal/locations/%s", id)
	location := &stripe.TerminalLocation{}
	err := c.B.Call(http.MethodGet, path, c.Key, params, location)
	return location, err
}
source: func (h *SMTPAPIHeader) JSONString() (string, error) {
	headers, e := json.Marshal(h)
	return escapeUnicode(string(headers)), e
}
source: func (F *Frisby) AddFile(filename string) *Frisby {
	file, err := os.Open(filename)
	if err != nil {
		F.Errs = append(F.Errs, err)
	} else {
		fileField := request.FileField{
			FieldName: defaultFileKey,
			FileName:  filepath.Base(filename),
			File:      file}
		F.Req.Files = append(F.Req.Files, fileField)
	}
	return F
}
source: func (r *bucketLocationCache) Get(bucketName string) (location string, ok bool) {
	r.RLock()
	defer r.RUnlock()
	location, ok = r.items[bucketName]
	return
}
source: func (p *LogicalProjection) tryToGetChildProp(prop *property.PhysicalProperty) (*property.PhysicalProperty, bool) {
	newProp := &property.PhysicalProperty{TaskTp: property.RootTaskType, ExpectedCnt: prop.ExpectedCnt}
	newCols := make([]property.Item, 0, len(prop.Items))
	for _, col := range prop.Items {
		idx := p.schema.ColumnIndex(col.Col)
		switch expr := p.Exprs[idx].(type) {
		case *expression.Column:
			newCols = append(newCols, property.Item{Col: expr, Desc: col.Desc})
		case *expression.ScalarFunction:
			return nil, false
		}
	}
	newProp.Items = newCols
	return newProp, true
}
source: func (c oauthClient) AddMemberToListViaUserID(userID uint, listID uint, muted bool) (wl.Membership, error) {
	if userID == 0 {
		return wl.Membership{}, errors.New("userID must be > 0")
	}

	if listID == 0 {
		return wl.Membership{}, errors.New("listID must be > 0")
	}

	url := fmt.Sprintf("%s/memberships", c.apiURL)
	body := []byte(
		fmt.Sprintf(
			`{"user_id":%d,"list_id":%d,"muted":%t}`,
			userID,
			listID,
			muted,
		),
	)

	req, err := c.newPostRequest(url, body)
	if err != nil {
		return wl.Membership{}, err
	}

	resp, err := c.do(req)
	if err != nil {
		return wl.Membership{}, err
	}

	if resp.StatusCode != http.StatusCreated {
		return wl.Membership{}, fmt.Errorf("Unexpected response code %d - expected %d", resp.StatusCode, http.StatusCreated)
	}

	membership := wl.Membership{}
	err = json.NewDecoder(resp.Body).Decode(&membership)
	if err != nil {
		return wl.Membership{}, err
	}

	return membership, nil
}
source: func (buf *TrackedBuffer) WriteNode(node SQLNode) *TrackedBuffer {
	buf.Myprintf("%v", node)
	return buf
}
source: func (c *Client) NewReleasesOpt(opt *Options) (albums *SimpleAlbumPage, err error) {
	spotifyURL := c.baseURL + "browse/new-releases"
	if opt != nil {
		v := url.Values{}
		if opt.Country != nil {
			v.Set("country", *opt.Country)
		}
		if opt.Limit != nil {
			v.Set("limit", strconv.Itoa(*opt.Limit))
		}
		if opt.Offset != nil {
			v.Set("offset", strconv.Itoa(*opt.Offset))
		}
		if params := v.Encode(); params != "" {
			spotifyURL += "?" + params
		}
	}

	var objmap map[string]*json.RawMessage
	err = c.get(spotifyURL, &objmap)
	if err != nil {
		return nil, err
	}

	var result SimpleAlbumPage
	err = json.Unmarshal(*objmap["albums"], &result)
	if err != nil {
		return nil, err
	}

	return &result, nil
}
source: func (s *Channel) SetShuffleConfig(v *ShuffleConfig) *Channel {
	s.ShuffleConfig = v
	return s
}
source: func (e ExamplepbNumericEnum) UnmarshalJSON(b []byte) error {
	return unmarshalJSONEnum(b, pbexamplepb.NumericEnum_value)
}
source: func (se *Engine) broadcast(created, altered, dropped []string) {
	s := make(map[string]*Table, len(se.tables))
	for k, v := range se.tables {
		s[k] = v
	}
	for _, f := range se.notifiers {
		f(s, created, altered, dropped)
	}
}
source: func GetTableIndexKeyRange(tableID, indexID int64) (startKey, endKey []byte) {
	startKey = EncodeIndexSeekKey(tableID, indexID, nil)
	endKey = EncodeIndexSeekKey(tableID, indexID, []byte{255})
	return
}
source: func (is *InfoSyncer) storeServerInfo(ctx context.Context) error {
	if is.etcdCli == nil {
		return nil
	}
	infoBuf, err := json.Marshal(is.info)
	if err != nil {
		return errors.Trace(err)
	}
	str := string(hack.String(infoBuf))
	err = ddl.PutKVToEtcd(ctx, is.etcdCli, keyOpDefaultRetryCnt, is.serverInfoPath, str, clientv3.WithLease(is.session.Lease()))
	return err
}
source: func (v *volumeClient) Restore(volumeID string, snapID string) error {
	response := &api.VolumeResponse{}
	req := v.c.Post().Resource(snapPath + "/restore").Instance(volumeID)
	req.QueryOption(api.OptSnapID, snapID)

	if err := req.Do().Unmarshal(response); err != nil {
		return err
	}
	if response.Error != "" {
		return errors.New(response.Error)
	}
	return nil
}
source: func unboundRunner(cmdName string, Timeout internal.Duration, UseSudo bool, Server string, ThreadAsTag bool) (*bytes.Buffer, error) {
	cmdArgs := []string{"stats_noreset"}

	if Server != "" {
		host, port, err := net.SplitHostPort(Server)
		if err != nil { // No port was specified
			host = Server
			port = ""
		}

		// Unbound control requires an IP address, and we want to be nice to the user
		resolver := net.Resolver{}
		ctx, lookUpCancel := context.WithTimeout(context.Background(), Timeout.Duration)
		defer lookUpCancel()
		serverIps, err := resolver.LookupIPAddr(ctx, host)
		if err != nil {
			return nil, fmt.Errorf("error looking up ip for server: %s: %s", Server, err)
		}
		if len(serverIps) == 0 {
			return nil, fmt.Errorf("error no ip for server: %s: %s", Server, err)
		}
		server := serverIps[0].IP.String()
		if port != "" {
			server = server + "@" + port
		}

		cmdArgs = append([]string{"-s", server}, cmdArgs...)
	}

	cmd := exec.Command(cmdName, cmdArgs...)

	if UseSudo {
		cmdArgs = append([]string{cmdName}, cmdArgs...)
		cmd = exec.Command("sudo", cmdArgs...)
	}

	var out bytes.Buffer
	cmd.Stdout = &out
	err := internal.RunTimeout(cmd, Timeout.Duration)
	if err != nil {
		return &out, fmt.Errorf("error running unbound-control: %s (%s %v)", err, cmdName, cmdArgs)
	}

	return &out, nil
}
source: func (f *FileSystem) logsImpl(ctx context.Context, follow, plain bool, offset int64,
	origin, task, logType string,
	fs allocdir.AllocDirFS, frames chan<- *sframer.StreamFrame) error {

	// Create the framer
	framer := sframer.NewStreamFramer(frames, streamHeartbeatRate, streamBatchWindow, streamFrameSize)
	framer.Run()
	defer framer.Destroy()

	// Path to the logs
	logPath := filepath.Join(allocdir.SharedAllocName, allocdir.LogDirName)

	// nextIdx is the next index to read logs from
	var nextIdx int64
	switch origin {
	case "start":
		nextIdx = 0
	case "end":
		nextIdx = math.MaxInt64
		offset *= -1
	default:
		return invalidOrigin
	}

	for {
		// Logic for picking next file is:
		// 1) List log files
		// 2) Pick log file closest to desired index
		// 3) Open log file at correct offset
		// 3a) No error, read contents
		// 3b) If file doesn't exist, goto 1 as it may have been rotated out
		entries, err := fs.List(logPath)
		if err != nil {
			return fmt.Errorf("failed to list entries: %v", err)
		}

		// If we are not following logs, determine the max index for the logs we are
		// interested in so we can stop there.
		maxIndex := int64(math.MaxInt64)
		if !follow {
			_, idx, _, err := findClosest(entries, maxIndex, 0, task, logType)
			if err != nil {
				return err
			}
			maxIndex = idx
		}

		logEntry, idx, openOffset, err := findClosest(entries, nextIdx, offset, task, logType)
		if err != nil {
			return err
		}

		var eofCancelCh chan error
		exitAfter := false
		if !follow && idx > maxIndex {
			// Exceeded what was there initially so return
			return nil
		} else if !follow && idx == maxIndex {
			// At the end
			eofCancelCh = make(chan error)
			close(eofCancelCh)
			exitAfter = true
		} else {
			eofCancelCh = blockUntilNextLog(ctx, fs, logPath, task, logType, idx+1)
		}

		p := filepath.Join(logPath, logEntry.Name)
		err = f.streamFile(ctx, openOffset, p, 0, fs, framer, eofCancelCh)

		// Check if the context is cancelled
		select {
		case <-ctx.Done():
			return nil
		default:
		}

		if err != nil {
			// Check if there was an error where the file does not exist. That means
			// it got rotated out from under us.
			if os.IsNotExist(err) {
				continue
			}

			// Check if the connection was closed
			if err == syscall.EPIPE {
				return nil
			}

			return fmt.Errorf("failed to stream %q: %v", p, err)
		}

		if exitAfter {
			return nil
		}

		// defensively check to make sure StreamFramer hasn't stopped
		// running to avoid tight loops with goroutine leaks as in
		// #3342
		select {
		case <-framer.ExitCh():
			return nil
		default:
		}

		// Since we successfully streamed, update the overall offset/idx.
		offset = int64(0)
		nextIdx = idx + 1
	}
}
source: func IsRecordNotFoundError(err error) bool {
	if errs, ok := err.(Errors); ok {
		for _, err := range errs {
			if err == ErrRecordNotFound {
				return true
			}
		}
	}
	return err == ErrRecordNotFound
}
source: func ListImports(importPath, rootPath, vendorPath, srcPath, tags string, isTest bool) ([]string, error) {
	oldGOPATH := os.Getenv("GOPATH")
	sep := ":"
	if runtime.GOOS == "windows" {
		sep = ";"
	}

	ctxt := build.Default
	ctxt.BuildTags = strings.Split(tags, " ")
	ctxt.GOPATH = vendorPath + sep + oldGOPATH
	if setting.Debug {
		log.Debug("Import/root path: %s : %s", importPath, rootPath)
		log.Debug("Context GOPATH: %s", ctxt.GOPATH)
		log.Debug("Source path: %s", srcPath)
	}
	pkg, err := ctxt.Import(importPath, srcPath, build.AllowBinary)
	if err != nil {
		if _, ok := err.(*build.NoGoError); !ok {
			return nil, fmt.Errorf("fail to get imports(%s): %v", importPath, err)
		}
		log.Warn("Getting imports: %v", err)
	}

	rawImports := pkg.Imports
	numImports := len(rawImports)
	if isTest {
		rawImports = append(rawImports, pkg.TestImports...)
		numImports = len(rawImports)
	}
	imports := make([]string, 0, numImports)
	for _, name := range rawImports {
		if IsGoRepoPath(name) {
			continue
		} else if strings.HasPrefix(name, rootPath) {
			moreImports, err := ListImports(name, rootPath, vendorPath, srcPath, tags, isTest)
			if err != nil {
				return nil, err
			}
			imports = append(imports, moreImports...)
			continue
		}
		if setting.Debug {
			log.Debug("Found dependency: %s", name)
		}
		imports = append(imports, name)
	}
	return imports, nil
}
source: func PackWithOrder(w io.Writer, data interface{}, order binary.ByteOrder) error {
	return PackWithOptions(w, data, &Options{Order: order})
}
source: func (s *OrderableDBInstanceOption) SetMaxIopsPerDbInstance(v int64) *OrderableDBInstanceOption {
	s.MaxIopsPerDbInstance = &v
	return s
}
source: func (c *Connection) Container(container string) (info Container, headers Headers, err error) {
	var resp *http.Response
	resp, headers, err = c.storage(RequestOpts{
		Container:  container,
		Operation:  "HEAD",
		ErrorMap:   ContainerErrorMap,
		NoResponse: true,
	})
	if err != nil {
		return
	}
	// Parse the headers into the struct
	info.Name = container
	if info.Bytes, err = getInt64FromHeader(resp, "X-Container-Bytes-Used"); err != nil {
		return
	}
	if info.Count, err = getInt64FromHeader(resp, "X-Container-Object-Count"); err != nil {
		return
	}
	return
}
source: func (b OpenshiftControllerClientBuilder) OpenshiftTemplateClientOrDie(name string) templateclient.Interface {
	client, err := b.OpenshiftTemplateClient(name)
	if err != nil {
		klog.Fatal(err)
	}
	return client
}
source: func (m *OverloadAction) Validate() error {
	if m == nil {
		return nil
	}

	if len(m.GetName()) < 1 {
		return OverloadActionValidationError{
			field:  "Name",
			reason: "value length must be at least 1 bytes",
		}
	}

	if len(m.GetTriggers()) < 1 {
		return OverloadActionValidationError{
			field:  "Triggers",
			reason: "value must contain at least 1 item(s)",
		}
	}

	for idx, item := range m.GetTriggers() {
		_, _ = idx, item

		{
			tmp := item

			if v, ok := interface{}(tmp).(interface{ Validate() error }); ok {

				if err := v.Validate(); err != nil {
					return OverloadActionValidationError{
						field:  fmt.Sprintf("Triggers[%v]", idx),
						reason: "embedded message failed validation",
						cause:  err,
					}
				}
			}
		}

	}

	return nil
}
source: func (m *MetaClient) AddRoleUsers(ctx context.Context, name string, users []string) error {
	// No permissions to add, so, role is in the right state
	if len(users) == 0 {
		return nil
	}

	a := &RoleAction{
		Action: "add-users",
		Role: &Role{
			Name:  name,
			Users: users,
		},
	}
	return m.Post(ctx, "/role", a, nil)
}
source: func (t *Template) GetAllAWSEventsEventBusPolicyResources() map[string]*resources.AWSEventsEventBusPolicy {
	results := map[string]*resources.AWSEventsEventBusPolicy{}
	for name, untyped := range t.Resources {
		switch resource := untyped.(type) {
		case *resources.AWSEventsEventBusPolicy:
			results[name] = resource
		}
	}
	return results
}
source: func SortByChartName(list []*rspb.Release) {
	s := &sorter{list: list}
	s.less = func(i, j int) bool {
		chi := s.list[i].Chart
		chj := s.list[j].Chart

		ni := ""
		if chi != nil && chi.Metadata != nil {
			ni = chi.Metadata.Name
		}

		nj := ""
		if chj != nil && chj.Metadata != nil {
			nj = chj.Metadata.Name
		}

		return ni < nj
	}
	sort.Sort(s)
}
source: func WithNoColor(ctx context.Context, bv bool) context.Context {
	return context.WithValue(ctx, ctxKeyNoColor, bv)
}
source: func (b *BigIP) DeleteGTMWideIP(fullPath string, recordType GTMType) error {
	return b.delete(uriGtm, uriWideIp, string(recordType), fullPath)
}
source: func (h Handler) Prepend(cmd common.SetRequest) error {
	return h.handleAppendPrependCommon(cmd, common.RequestPrepend)
}
source: func (r *Reply) Array() ([]*Reply, error) {
	if r.Type() == ReplyNil {
		return nil, ErrNil
	}
	if r.Type() != ReplyArray {
		return nil, ErrType
	}
	return r.arrayValue, nil
}
source: func (c *Cache) Size() int64 {
	c.Lock()
	defer c.Unlock()
	return c.size
}
source: func (g *Generator) loadPackage(path string) (*loader.PackageInfo, error) {
	pkg := g.Program.Package(path)
	if pkg != nil {
		return pkg, nil
	}

	return nil, fmt.Errorf("failed to load package %q", path)
}
source: func (_class VBDClass) GetMode(sessionID SessionRef, self VBDRef) (_retval VbdMode, _err error) {
	_method := "VBD.get_mode"
	_sessionIDArg, _err := convertSessionRefToXen(fmt.Sprintf("%s(%s)", _method, "session_id"), sessionID)
	if _err != nil {
		return
	}
	_selfArg, _err := convertVBDRefToXen(fmt.Sprintf("%s(%s)", _method, "self"), self)
	if _err != nil {
		return
	}
	_result, _err := _class.client.APICall(_method, _sessionIDArg, _selfArg)
	if _err != nil {
		return
	}
	_retval, _err = convertEnumVbdModeToGo(_method + " -> ", _result.Value)
	return
}
source: func (s *OvsElementService) ConfigureOvsElement(p *ConfigureOvsElementParams) (*OvsElementResponse, error) {
	resp, err := s.cs.newRequest("configureOvsElement", p.toURLValues())
	if err != nil {
		return nil, err
	}

	var r OvsElementResponse
	if err := json.Unmarshal(resp, &r); err != nil {
		return nil, err
	}

	// If we have a async client, we need to wait for the async result
	if s.cs.async {
		b, err := s.cs.GetAsyncJobResult(r.JobID, s.cs.timeout)
		if err != nil {
			if err == AsyncTimeoutErr {
				return &r, err
			}
			return nil, err
		}

		b, err = getRawValue(b)
		if err != nil {
			return nil, err
		}

		if err := json.Unmarshal(b, &r); err != nil {
			return nil, err
		}
	}

	return &r, nil
}
source: func (h ddlHistoryJobHandler) ServeHTTP(w http.ResponseWriter, req *http.Request) {
	if limitID := req.FormValue(qLimit); len(limitID) > 0 {
		lid, err := strconv.Atoi(limitID)

		if err != nil {
			writeError(w, err)
			return
		}

		if lid < 1 {
			writeError(w, errors.New("ddl history limit must be greater than 1"))
			return
		}

		jobs, err := h.getAllHistoryDDL()
		if err != nil {
			writeError(w, errors.New("ddl history not found"))
			return
		}

		jobsLen := len(jobs)
		if jobsLen > lid {
			start := jobsLen - lid
			jobs = jobs[start:]
		}

		writeData(w, jobs)
		return
	}
	jobs, err := h.getAllHistoryDDL()
	if err != nil {
		writeError(w, errors.New("ddl history not found"))
		return
	}
	writeData(w, jobs)
}
source: func (self *StringTypeDef) UnmarshalJSON(b []byte) error {
	var m rawStringTypeDef
	err := json.Unmarshal(b, &m)
	if err == nil {
		o := StringTypeDef(m)
		*self = o
		err = self.Validate()
	}
	return err
}
source: func (s *Volume) SetDockerVolumeConfiguration(v *DockerVolumeConfiguration) *Volume {
	s.DockerVolumeConfiguration = v
	return s
}
source: func (t *Task) EffectiveCron() string {
	if t.Cron != "" {
		return t.Cron
	}
	if t.Every != "" {
		return "@every " + t.Every
	}
	return ""
}
source: func (m *MockInterface) SettingsV1alpha1() v1alpha12.SettingsV1alpha1Interface {
	ret := m.ctrl.Call(m, "SettingsV1alpha1")
	ret0, _ := ret[0].(v1alpha12.SettingsV1alpha1Interface)
	return ret0
}
source: func MkdirAll(path string, perm os.FileMode, user *ChownOpt, tm *time.Time) error {
	// Fast path: if we can tell whether path is a directory or file, stop with success or error.
	dir, err := os.Stat(path)
	if err == nil {
		if dir.IsDir() {
			return nil
		}
		return &os.PathError{Op: "mkdir", Path: path, Err: syscall.ENOTDIR}
	}

	// Slow path: make sure parent exists and then call Mkdir for path.
	i := len(path)
	for i > 0 && os.IsPathSeparator(path[i-1]) { // Skip trailing path separator.
		i--
	}

	j := i
	for j > 0 && !os.IsPathSeparator(path[j-1]) { // Scan backward over element.
		j--
	}

	if j > 1 {
		// Create parent.
		err = MkdirAll(fixRootDirectory(path[:j-1]), perm, user, tm)
		if err != nil {
			return err
		}
	}

	dir, err1 := os.Lstat(path)
	if err1 == nil && dir.IsDir() {
		return nil
	}

	// Parent now exists; invoke Mkdir and use its result.
	err = os.Mkdir(path, perm)
	if err != nil {
		// Handle arguments like "foo/." by
		// double-checking that directory doesn't exist.
		dir, err1 := os.Lstat(path)
		if err1 == nil && dir.IsDir() {
			return nil
		}
		return err
	}

	if err := Chown(path, user); err != nil {
		return err
	}

	if err := Utimes(path, tm); err != nil {
		return err
	}

	return nil
}
source: func (rr *RoundRobin) Open(factory Factory) {
	rr.mu.Lock()
	defer rr.mu.Unlock()
	rr.factory = factory
}
source: func discoverTypesInPath(path, typeID, typeName string) ([]plugin, error) {
	pluginTypes := []plugin{}

	dirs, err := listDirectories(path)
	if err != nil {
		return pluginTypes, err
	}

	for _, dir := range dirs {
		fset := token.NewFileSet()
		goPackages, err := parser.ParseDir(fset, dir, nil, parser.AllErrors)
		if err != nil {
			return pluginTypes, fmt.Errorf("Failed parsing directory %s: %s", dir, err)
		}

		for _, goPackage := range goPackages {
			ast.PackageExports(goPackage)
			ast.Inspect(goPackage, func(n ast.Node) bool {
				switch x := n.(type) {
				case *ast.FuncDecl:
					// If we get a function then we will check the function name
					// against typeName and the function return type (Results)
					// against typeID.
					//
					// There may be more than one return type but in the target
					// case there should only be one. Also the return type is a
					// ast.SelectorExpr which means we have multiple nodes.
					// We'll read all of them as ast.Ident (identifier), join
					// them via . to get a string like terraform.ResourceProvider
					// and see if it matches our expected typeID
					//
					// This is somewhat verbose but prevents us from identifying
					// the wrong types if the function name is amiguous or if
					// there are other subfolders added later.
					if x.Name.Name == typeName && len(x.Type.Results.List) == 1 {
						node := x.Type.Results.List[0].Type
						typeIdentifiers := []string{}
						ast.Inspect(node, func(m ast.Node) bool {
							switch y := m.(type) {
							case *ast.Ident:
								typeIdentifiers = append(typeIdentifiers, y.Name)
							}
							// We need all of the identifiers to join so we
							// can't break early here.
							return true
						})
						if strings.Join(typeIdentifiers, ".") == typeID {
							derivedName := deriveName(path, dir)
							pluginTypes = append(pluginTypes, plugin{
								Package:    goPackage.Name,
								PluginName: derivedName,
								ImportName: deriveImport(x.Name.Name, derivedName),
								TypeName:   x.Name.Name,
								Path:       dir,
							})
						}
					}
				case *ast.TypeSpec:
					// In the simpler case we will simply check whether the type
					// declaration has the name we were looking for.
					if x.Name.Name == typeID {
						derivedName := deriveName(path, dir)
						pluginTypes = append(pluginTypes, plugin{
							Package:    goPackage.Name,
							PluginName: derivedName,
							ImportName: deriveImport(x.Name.Name, derivedName),
							TypeName:   x.Name.Name,
							Path:       dir,
						})
						// The AST stops parsing when we return false. Once we
						// find the symbol we want we can stop parsing.
						return false
					}
				}
				return true
			})
		}
	}

	return pluginTypes, nil
}
source: func (mp MemberMapping) ServerCertificates() StringSet {
	res := make(StringSet)
	for _, member := range mp {
		res[string(member.ServerTLSCert)] = struct{}{}
	}
	return res
}
source: func Confirm(remoteip, response string) (result bool, err error) {
	resp, err := check(remoteip, response)
	result = resp.Success
	return
}
source: func (h *Host) NewObject() (*Object, error) {
	ctx := context.TODO() // TODO: move the NewObject method to some "ImportRun" type with a context field?
	pn, err := h.upload(ctx, schema.NewUnsignedPermanode())
	if err != nil {
		return nil, err
	}
	// No need to do a describe query against it: we know it's
	// empty (has no claims against it yet).
	return &Object{h: h, pn: pn}, nil
}
source: func (a *acceptBuildConfigs) Accept(from interface{}) bool {
	obj, _, err := objectMetaData(from)
	if err != nil {
		return false
	}
	gvk, _, err := a.typer.ObjectKinds(obj)
	if err != nil {
		return false
	}
	gk := gvk[0].GroupKind()
	return build.Kind("BuildConfig") == gk || image.Kind("ImageStream") == gk
}
source: func (c *Client) RemoveAll(path string) error {
	rs, err := c.req("DELETE", path, nil, nil)
	if err != nil {
		return newPathError("Remove", path, 400)
	}
	err = rs.Body.Close()
	if err != nil {
		return err
	}

	if rs.StatusCode == 200 || rs.StatusCode == 204 || rs.StatusCode == 404 {
		return nil
	}

	return newPathError("Remove", path, rs.StatusCode)
}
source: func (c *command) run() []byte {
	cmd := exec.Command(c.program, c.args...)
	var stdout, stderr bytes.Buffer
	cmd.Stdout = &stdout
	cmd.Stderr = &stderr
	err := cmd.Run()
	out := stdout.Bytes()
	if err != nil {
		log.Fatalf("Could not run %v: %v: %v: %v", c, err, string(out), stderr.String())
	}
	return out
}
source: func RunUntilSuccess(n int, f func() bool, retryInterval time.Duration) bool {
	for i := 0; i < n; i++ {
		if f() {
			return true
		}

		time.Sleep(retryInterval)
	}

	return false
}
source: func MaxReceiveMessages(max int64) broker.SubscribeOption {
	return func(o *broker.SubscribeOptions) {
		if o.Context == nil {
			o.Context = context.Background()
		}
		o.Context = context.WithValue(o.Context, maxMessagesKey{}, max)
	}
}
source: func relativePath(file, relativeTo string) string {
	// stdin: return the current working directory if possible.
	if relativeTo == "-" {
		if cwd, err := os.Getwd(); err == nil {
			return filepath.Join(cwd, file)
		}
	}

	// If the given file is already an absolute path, just return it.
	// Otherwise, the returned path will be relative to the given relativeTo
	// path.
	if filepath.IsAbs(file) {
		return file
	}

	abs, err := filepath.Abs(filepath.Join(path.Dir(relativeTo), file))
	if err != nil {
		logrus.Errorf("Failed to get absolute directory: %s", err)
		return file
	}
	return abs
}
source: func (s *Server) newServer(proto, addr string) ([]*HTTPServer, error) {
	var (
		err error
		ls  []net.Listener
	)
	switch proto {
	case "fd":
		ls, err = listenFD(addr, s.cfg.TLSConfig)
		if err != nil {
			return nil, err
		}
	case "tcp":
		l, err := s.initTCPSocket(addr)
		if err != nil {
			return nil, err
		}
		ls = append(ls, l)
	case "unix":
		l, err := sockets.NewUnixSocket(addr, s.cfg.SocketGroup)
		if err != nil {
			return nil, fmt.Errorf("can't create unix socket %s: %v", addr, err)
		}
		ls = append(ls, l)
	default:
		return nil, fmt.Errorf("Invalid protocol format: %q", proto)
	}
	var res []*HTTPServer
	for _, l := range ls {
		res = append(res, &HTTPServer{
			&http.Server{
				Addr: addr,
			},
			l,
		})
	}
	return res, nil
}
source: func NewClaimSeqnoProvider(mctx libkb.MetaContext, walletState *WalletState) (seqnoProvider *ClaimSeqnoProvider, unlock func()) {
	walletState.SeqnoLock()
	return &ClaimSeqnoProvider{
		mctx:        mctx,
		walletState: walletState,
	}, walletState.SeqnoUnlock
}
source: func (s *MemorySession) AllPackets(dir Direction) ([]packet.Generic, error) {
	return s.storeForDirection(dir).All(), nil
}
source: func (s *PublicEthereumAPI) GasPrice(ctx context.Context) (*hexutil.Big, error) {
	price, err := s.b.SuggestPrice(ctx)
	return (*hexutil.Big)(price), err
}
source: func (k *kubernetesMethod) readJWT() (string, error) {
	// load configured token path if set, default to serviceAccountFile
	tokenFilePath := serviceAccountFile
	if k.tokenPath != "" {
		tokenFilePath = k.tokenPath
	}

	data := k.jwtData
	// k.jwtData should only be non-nil in tests
	if data == nil {
		f, err := os.Open(tokenFilePath)
		if err != nil {
			return "", err
		}
		data = f
	}
	defer data.Close()

	contentBytes, err := ioutil.ReadAll(data)
	if err != nil {
		return "", err
	}

	return strings.TrimSpace(string(contentBytes)), nil
}
source: func New() *Mux {
	return &Mux{
		root:    make(map[string]*node),
		Timeout: 10 * time.Second,
		Opened:  func(m *Mux) {},
		Closed:  func(m *Mux) {},
		Timed:   false,
		Log:     func(li ...interface{}) {},
		active: connections{
			conns: make(map[net.Conn]struct{}),
		},
		idle: connections{
			conns: make(map[net.Conn]struct{}),
		},
	}
}
source: func RegisterPrefix(pref string, ns string) {
	Register(Namespace{Prefix: pref, Full: ns})
}
source: func (r *PrevRevisions) ListKeys() (ret []string) {
	r.mu.RLock()
	for key := range r.revisions {
		ret = append(ret, key)
	}
	r.mu.RUnlock()
	return ret
}
source: func (sbc *SandboxConn) VStream(ctx context.Context, target *querypb.Target, startPos string, filter *binlogdatapb.Filter, send func([]*binlogdatapb.VEvent) error) error {
	return fmt.Errorf("not implemented in test")
}
source: func (t TimeSinceEpoch) Time() time.Time {
	ts := float64(t) / 1
	secs := int64(ts)
	nsecs := int64((ts - float64(secs)) * 1000000000)
	return time.Unix(secs, nsecs)
}
source: func (w *Wallet) DumpPrivKeys() ([]string, error) {
	var privkeys []string
	err := walletdb.View(w.db, func(tx walletdb.ReadTx) error {
		addrmgrNs := tx.ReadBucket(waddrmgrNamespaceKey)
		// Iterate over each active address, appending the private key to
		// privkeys.
		return w.Manager.ForEachActiveAddress(addrmgrNs, func(addr btcutil.Address) error {
			ma, err := w.Manager.Address(addrmgrNs, addr)
			if err != nil {
				return err
			}

			// Only those addresses with keys needed.
			pka, ok := ma.(waddrmgr.ManagedPubKeyAddress)
			if !ok {
				return nil
			}

			wif, err := pka.ExportPrivKey()
			if err != nil {
				// It would be nice to zero out the array here. However,
				// since strings in go are immutable, and we have no
				// control over the caller I don't think we can. :(
				return err
			}
			privkeys = append(privkeys, wif.String())
			return nil
		})
	})
	return privkeys, err
}
source: func (s *TrainingSpecification) SetTrainingImageDigest(v string) *TrainingSpecification {
	s.TrainingImageDigest = &v
	return s
}
source: func (b *BloomFilter) FillRatio() float64 {
	sum := uint32(0)
	for i := uint(0); i < b.buckets.Count(); i++ {
		sum += b.buckets.Get(i)
	}
	return float64(sum) / float64(b.m)
}
source: func onMessage(cm gcm.CcsMessage) error {
	toylog.Infoln("Message, from:", cm.From, "with:", cm.Data)
	// Echo the message with a tag.
	cm.Data["echoed"] = true
	m := gcm.HttpMessage{To: cm.From, Data: cm.Data}
	r, err := gcm.SendHttp(*serverKey, m)
	if err != nil {
		toylog.Errorln("Error sending message.", err)
		return err
	}
	toylog.Infof("Sent message. %+v -> %+v", m, r)
	return nil
}
source: func (m *HeaderCtxFlag) ServeHTTPC(ctx context.Context, rw http.ResponseWriter, r *http.Request, next ContextHandler) {
	debugStr := m.FlagStr()
	if debugStr != "" && m.HeaderName != "" {
		if r.Header.Get(m.HeaderName) == debugStr {
			ctx = m.WithFlag(ctx)
		} else if r.URL.Query().Get(m.HeaderName) == debugStr {
			ctx = m.WithFlag(ctx)
		}
	}
	next.ServeHTTPC(ctx, rw, r)
}
source: func Complex64() gopter.Gen {
	return gopter.CombineGens(
		Float32(),
		Float32(),
	).Map(func(values []interface{}) complex64 {
		return complex(values[0].(float32), values[1].(float32))
	}).WithShrinker(Complex64Shrinker)
}
source: func (s *StoragePoolService) NewEnableStorageMaintenanceParams(id string) *EnableStorageMaintenanceParams {
	p := &EnableStorageMaintenanceParams{}
	p.p = make(map[string]interface{})
	p.p["id"] = id
	return p
}
source: func InvokeUnaryHandler(
	i UnaryInvokeRequest,
) (err error) {
	defer func() {
		if r := recover(); r != nil {
			err = handlePanic(Unary, i.Logger, r, i.Request.ToRequestMeta())
		}
	}()

	err = i.Handler.Handle(i.Context, i.Request, i.ResponseWriter)

	// The handler stopped work on context deadline.
	if err == context.DeadlineExceeded && err == i.Context.Err() {
		deadline, _ := i.Context.Deadline()
		err = yarpcerrors.Newf(
			yarpcerrors.CodeDeadlineExceeded,
			"call to procedure %q of service %q from caller %q timed out after %v",
			i.Request.Procedure, i.Request.Service, i.Request.Caller, deadline.Sub(i.StartTime))
	}
	return err
} 25%|██▍       | 1226/5000 [00:01<00:04, 818.02it/s]
source: func (qzs *queryzRow) RowsPQ() string {
	val := float64(qzs.Rows) / float64(qzs.Count)
	return fmt.Sprintf("%.6f", val)
}
source: func (b *IndexBuilder) AddFile(name string, content []byte) error {
	return b.Add(Document{Name: name, Content: content})
}
source: func ToASCII(r rune) rune {
	a, ok := UnicodeToASCII[r]
	if ok {
		return a
	}
	return r
}
source: func vcsMetadata(path string) (map[string]string, error) {
	vcs, err := vcsDetect(path)
	if err != nil {
		return nil, fmt.Errorf("error detecting VCS: %s", err)
	}

	if vcs.Metadata != nil {
		return vcs.Metadata(path)
	}

	return nil, nil
}
source: func InitFileAndConsole(fullpath string, toStderrLevel logger.Level) error {
	fileOpts := makeFileOpts(fullpath)
	consoleOpts := makeConsoleOpts(toStderrLevel)
	p := provider.NewMixProvider(provider.NewFile(fileOpts), provider.NewConsole(consoleOpts))
	return InitWithProvider(p)
}
source: func (s *Restore) Session(sess *structs.Session) error {
	// Insert the session.
	if err := s.tx.Insert("sessions", sess); err != nil {
		return fmt.Errorf("failed inserting session: %s", err)
	}

	// Insert the check mappings.
	for _, checkID := range sess.Checks {
		mapping := &sessionCheck{
			Node:    sess.Node,
			CheckID: checkID,
			Session: sess.ID,
		}
		if err := s.tx.Insert("session_checks", mapping); err != nil {
			return fmt.Errorf("failed inserting session check mapping: %s", err)
		}
	}

	// Update the index.
	if err := indexUpdateMaxTxn(s.tx, sess.ModifyIndex, "sessions"); err != nil {
		return fmt.Errorf("failed updating index: %s", err)
	}

	return nil
}
source: func (sbc *SandboxConn) MessageStream(ctx context.Context, target *querypb.Target, name string, callback func(*sqltypes.Result) error) (err error) {
	if err := sbc.getError(); err != nil {
		return err
	}
	r := sbc.getNextResult()
	if r == nil {
		return nil
	}
	callback(r)
	return nil
}
source: func reporterConfigFromEnv() (*ReporterConfig, error) {
	rc := &ReporterConfig{}

	if e := os.Getenv(envReporterMaxQueueSize); e != "" {
		if value, err := strconv.ParseInt(e, 10, 0); err == nil {
			rc.QueueSize = int(value)
		} else {
			return nil, errors.Wrapf(err, "cannot parse env var %s=%s", envReporterMaxQueueSize, e)
		}
	}

	if e := os.Getenv(envReporterFlushInterval); e != "" {
		if value, err := time.ParseDuration(e); err == nil {
			rc.BufferFlushInterval = value
		} else {
			return nil, errors.Wrapf(err, "cannot parse env var %s=%s", envReporterFlushInterval, e)
		}
	}

	if e := os.Getenv(envReporterLogSpans); e != "" {
		if value, err := strconv.ParseBool(e); err == nil {
			rc.LogSpans = value
		} else {
			return nil, errors.Wrapf(err, "cannot parse env var %s=%s", envReporterLogSpans, e)
		}
	}

	if e := os.Getenv(envEndpoint); e != "" {
		u, err := url.ParseRequestURI(e)
		if err != nil {
			return nil, errors.Wrapf(err, "cannot parse env var %s=%s", envEndpoint, e)
		}
		rc.CollectorEndpoint = u.String()
		user := os.Getenv(envUser)
		pswd := os.Getenv(envPassword)
		if user != "" && pswd == "" || user == "" && pswd != "" {
			return nil, errors.Errorf("you must set %s and %s env vars together", envUser, envPassword)
		}
		rc.User = user
		rc.Password = pswd
	} else {
		host := jaeger.DefaultUDPSpanServerHost
		if e := os.Getenv(envAgentHost); e != "" {
			host = e
		}

		port := jaeger.DefaultUDPSpanServerPort
		if e := os.Getenv(envAgentPort); e != "" {
			if value, err := strconv.ParseInt(e, 10, 0); err == nil {
				port = int(value)
			} else {
				return nil, errors.Wrapf(err, "cannot parse env var %s=%s", envAgentPort, e)
			}
		}
		rc.LocalAgentHostPort = fmt.Sprintf("%s:%d", host, port)
	}

	return rc, nil
}
source: func (s *DbSession) FindByRef(ref *mgo.DBRef, document Document) error {
	q := s.Session.DB(s.db.Config.DBName).FindRef(ref)
	if err := q.One(document); err != nil {
		if err.Error() != mgo.ErrNotFound.Error() {
			log.Printf("Error fetching %s. Error: %s\n", document.CollectionName(), err)
		}

		return err
	}
	return nil
}
source: func WithTimeoutForNonLongRunningRequests(handler http.Handler, longRunning apirequest.LongRunningRequestCheck, timeout time.Duration) http.Handler {
	if longRunning == nil {
		return handler
	}
	timeoutFunc := func(req *http.Request) (*http.Request, <-chan time.Time, func(), *apierrors.StatusError) {
		// TODO unify this with apiserver.MaxInFlightLimit
		ctx := req.Context()

		requestInfo, ok := apirequest.RequestInfoFrom(ctx)
		if !ok {
			// if this happens, the handler chain isn't setup correctly because there is no request info
			return req, time.After(timeout), func() {}, apierrors.NewInternalError(fmt.Errorf("no request info found for request during timeout"))
		}

		if longRunning(req, requestInfo) {
			return req, nil, nil, nil
		}

		ctx, cancel := context.WithCancel(ctx)
		req = req.WithContext(ctx)

		postTimeoutFn := func() {
			cancel()
			metrics.Record(req, requestInfo, metrics.APIServerComponent, "", http.StatusGatewayTimeout, 0, 0)
		}
		return req, time.After(timeout), postTimeoutFn, apierrors.NewTimeoutError(fmt.Sprintf("request did not complete within %s", timeout), 0)
	}
	return WithTimeout(handler, timeoutFunc)
}
source: func (l *MockLedger) Register(consumer Consumer) {
	l.Lock()
	defer l.Unlock()
	l.consumers = append(l.consumers, consumer)
}
source: func verifyCIDRRoleSecretIDSubset(secretIDCIDRs []string, roleBoundCIDRList []string) error {
	if len(secretIDCIDRs) != 0 {
		// If there are no CIDR blocks on the role, then the subset
		// requirement would be satisfied
		if len(roleBoundCIDRList) != 0 {
			subset, err := cidrutil.SubsetBlocks(roleBoundCIDRList, secretIDCIDRs)
			if !subset || err != nil {
				return errwrap.Wrapf(fmt.Sprintf("failed to verify subset relationship between CIDR blocks on the role %q and CIDR blocks on the secret ID %q: {{err}}", roleBoundCIDRList, secretIDCIDRs), err)
			}
		}
	}

	return nil
}
source: func Convert_security_PodSecurityPolicySelfSubjectReviewSpec_To_v1_PodSecurityPolicySelfSubjectReviewSpec(in *security.PodSecurityPolicySelfSubjectReviewSpec, out *v1.PodSecurityPolicySelfSubjectReviewSpec, s conversion.Scope) error {
	return autoConvert_security_PodSecurityPolicySelfSubjectReviewSpec_To_v1_PodSecurityPolicySelfSubjectReviewSpec(in, out, s)
}
source: func (s *DescribeCacheEngineVersionsOutput) SetCacheEngineVersions(v []*CacheEngineVersion) *DescribeCacheEngineVersionsOutput {
	s.CacheEngineVersions = v
	return s
}
source: func (gw *realEPManager) removeMapPath(path string) {
	if err := os.RemoveAll(path); err != nil {
		log.WithError(err).WithField(logfields.Path, path).Warn("Error while deleting stale map file")
	} else {
		log.WithField(logfields.Path, path).Info("Removed stale bpf map")
	}
}
source: func Panic(err error) {
	if err != nil {
		if _, ok := StackTrace(err); !ok {
			err = &wrappedError{
				err:   err,
				stack: callers(),
			}
		}

		panic(err)
	}
}
source: func (r *FileRef) OnAfterClose(cb func()) {
	r.m.Lock()
	r.afterCloseCallbacks = append(r.afterCloseCallbacks, cb)
	r.m.Unlock()
}
source: func (h *Hasher) Write(b []byte) (int, error) {
	l := len(b)
	if l == 0 || l > h.pool.Size {
		return 0, nil
	}
	t := h.getTree()
	secsize := 2 * h.pool.SegmentSize
	// calculate length of missing bit to complete current open section
	smax := secsize - t.offset
	// if at the beginning of chunk or middle of the section
	if t.offset < secsize {
		// fill up current segment from buffer
		copy(t.section[t.offset:], b)
		// if input buffer consumed and open section not complete, then
		// advance offset and return
		if smax == 0 {
			smax = secsize
		}
		if l <= smax {
			t.offset += l
			return l, nil
		}
	} else {
		// if end of a section
		if t.cursor == h.pool.SegmentCount*2 {
			return 0, nil
		}
	}
	// read full sections and the last possibly partial section from the input buffer
	for smax < l {
		// section complete; push to tree asynchronously
		go h.writeSection(t.cursor, t.section, true, false)
		// reset section
		t.section = make([]byte, secsize)
		// copy from input buffer at smax to right half of section
		copy(t.section, b[smax:])
		// advance cursor
		t.cursor++
		// smax here represents successive offsets in the input buffer
		smax += secsize
	}
	t.offset = l - smax + secsize
	return l, nil
}
source: func (c *Carbon) AddMinutes(m int) *Carbon {
	d := time.Duration(m) * time.Minute

	return NewCarbon(c.Add(d))
}
source: func (c ClientBuildClient) Patch(namespace, name string, patch []byte) (*buildv1.Build, error) {
	return c.Client.BuildV1().Builds(namespace).Patch(name, types.StrategicMergePatchType, patch)
}
source: func (s *ListRecordsOutput) SetDatasetSyncCount(v int64) *ListRecordsOutput {
	s.DatasetSyncCount = &v
	return s
}
source: func (in *NonResourceAttributes) DeepCopy() *NonResourceAttributes {
	if in == nil {
		return nil
	}
	out := new(NonResourceAttributes)
	in.DeepCopyInto(out)
	return out
}
source: func (s *State) IsDead() bool {
	s.Lock()
	res := s.Dead
	s.Unlock()
	return res
}
source: func incCsum16(start, old, new uint16) uint16 {

	start = start ^ 0xffff
	old = old ^ 0xffff

	csum := uint32(start) + uint32(old) + uint32(new)
	for (csum >> 16) > 0 {
		csum = (csum & 0xffff) + ((csum >> 16) & 0xffff)
	}
	csum = csum ^ 0xffff
	return uint16(csum)
}
source: func newTokenLimiter(bandwidth, workers int) *tokenLimiter {
	burst := 100 * kbToBytes * workers // 100 KB of burst per worker
	return &tokenLimiter{burst: burst, rateLimiter: rate.NewLimiter(rate.Limit(bandwidth*mbToKB*kbToBytes)/byteToBits, burst), nowFunc: time.Now}
}
source: func (t *TimeSeries) Permissions(ctx context.Context) chronograf.Permissions {
	return t.PermissionsF(ctx)
}
source: func (s Style) WriteToRenderer(r Renderer) {
	r.SetClassName(s.GetClassName())
	r.SetStrokeColor(s.GetStrokeColor())
	r.SetStrokeWidth(s.GetStrokeWidth())
	r.SetStrokeDashArray(s.GetStrokeDashArray())
	r.SetFillColor(s.GetFillColor())
	r.SetFont(s.GetFont())
	r.SetFontColor(s.GetFontColor())
	r.SetFontSize(s.GetFontSize())

	r.ClearTextRotation()
	if s.GetTextRotationDegrees() != 0 {
		r.SetTextRotation(util.Math.DegreesToRadians(s.GetTextRotationDegrees()))
	}
}
source: func Init(ctx types.Context, config gofig.Config) error {

	serverName, ok := context.Server(ctx)
	if !ok {
		panic("ctx is missing ServerName")
	}

	ctx.Info("initializing server services")

	sc := &serviceContainer{
		taskService:     &globalTaskService{name: "global-task-service"},
		storageServices: map[string]types.StorageService{},
	}

	if err := sc.Init(ctx, config); err != nil {
		return err
	}

	servicesByServerRWL.Lock()
	defer servicesByServerRWL.Unlock()
	servicesByServer[serverName] = sc

	return nil
}
source: func deriveCloneBounds(src *Bounds) *Bounds {
	if src == nil {
		return nil
	}
	dst := new(Bounds)
	deriveDeepCopy(dst, src)
	return dst
}
source: func NewTargetFile(fileDir, fileName, fileExt string, permissions os.FileMode) TargetFile {
	return TargetFile{
		fileDir,
		fileName,
		fileExt,
		fmt.Sprintf("%s/%s%s", fileDir, fileName, fileExt),
		permissions,
	}
}
source: func (i *IATA) MarshalBinary() ([]byte, error) {
	// 4 bytes: IAID
	// N bytes: options slice byte count
	b := buffer.New(nil)

	b.WriteBytes(i.IAID[:])
	opts, err := i.Options.MarshalBinary()
	if err != nil {
		return nil, err
	}
	b.WriteBytes(opts)

	return b.Data(), nil
}
source: func (h *Head) compactable() bool {
	return h.MaxTime()-h.MinTime() > h.chunkRange/2*3
}
source: func (n *NodeDrainer) handleMigratedAllocs(allocs []*structs.Allocation) {
	// Determine the set of nodes that were effected
	nodes := make(map[string]struct{})
	for _, alloc := range allocs {
		nodes[alloc.NodeID] = struct{}{}
	}

	var done []string
	var remainingAllocs []*structs.Allocation

	// For each node, check if it is now done
	n.l.RLock()
	for node := range nodes {
		draining, ok := n.nodes[node]
		if !ok {
			continue
		}

		isDone, err := draining.IsDone()
		if err != nil {
			n.logger.Error("error checking if node is done draining", "node_id", node, "error", err)
			continue
		}

		if !isDone {
			continue
		}

		done = append(done, node)

		remaining, err := draining.RemainingAllocs()
		if err != nil {
			n.logger.Error("node is done draining but encountered an error getting remaining allocs", "node_id", node, "error", err)
			continue
		}

		remainingAllocs = append(remainingAllocs, remaining...)
	}
	n.l.RUnlock()

	// Stop any running system jobs on otherwise done nodes
	if len(remainingAllocs) > 0 {
		future := structs.NewBatchFuture()
		n.drainAllocs(future, remainingAllocs)
		if err := future.Wait(); err != nil {
			n.logger.Error("failed to drain remaining allocs from done nodes", "num_allocs", len(remainingAllocs), "error", err)
		}
	}

	// Create the node event
	event := structs.NewNodeEvent().
		SetSubsystem(structs.NodeEventSubsystemDrain).
		SetMessage(NodeDrainEventComplete)

	// Submit the node transitions in a sharded form to ensure a reasonable
	// Raft transaction size.
	for _, nodes := range partitionIds(defaultMaxIdsPerTxn, done) {
		if _, err := n.raft.NodesDrainComplete(nodes, event); err != nil {
			n.logger.Error("failed to unset drain for nodes", "error", err)
		}
	}
}
source: func (p *Pipeline) TransformContext(transformers ...ContextTransformer) *Pipeline {
	return &Pipeline{
		prior:       p,
		transformer: filterNilEvent(transformContext(transformers...)),
	}
}
source: func BuildCanonicalPathForTlfName(t tlf.Type, tlfName tlf.CanonicalName) string {
	return BuildCanonicalPathForTlfType(t, string(tlfName))
}
source: func (s *replicaSetLister) GetPodReplicaSets(pod *v1.Pod) ([]*apps.ReplicaSet, error) {
	if len(pod.Labels) == 0 {
		return nil, fmt.Errorf("no ReplicaSets found for pod %v because it has no labels", pod.Name)
	}

	list, err := s.ReplicaSets(pod.Namespace).List(labels.Everything())
	if err != nil {
		return nil, err
	}

	var rss []*apps.ReplicaSet
	for _, rs := range list {
		if rs.Namespace != pod.Namespace {
			continue
		}
		selector, err := metav1.LabelSelectorAsSelector(rs.Spec.Selector)
		if err != nil {
			return nil, fmt.Errorf("invalid selector: %v", err)
		}

		// If a ReplicaSet with a nil or empty selector creeps in, it should match nothing, not everything.
		if selector.Empty() || !selector.Matches(labels.Set(pod.Labels)) {
			continue
		}
		rss = append(rss, rs)
	}

	if len(rss) == 0 {
		return nil, fmt.Errorf("could not find ReplicaSet for pod %s in namespace %s with labels: %v", pod.Name, pod.Namespace, pod.Labels)
	}

	return rss, nil
}
source: func (s *Benchmark) Timeouts() uint64 {
	s.RLock()
	defer s.RUnlock()
	return s.timeouts
}
source: func NewFromPointers(points []geo.Pointer) *Quadtree {
	if len(points) == 0 {
		// This is kind of meaningless but is what will happen
		// if using an empty pointset above.
		return New(geo.NewBound(0, 0, 0, 0))
	}

	b := geo.NewBoundFromPoints(points[0].Point(), points[0].Point())
	for _, p := range points {
		b.Extend(p.Point())
	}

	q := New(b, len(points))

	for _, p := range points {
		q.Insert(p)
	}

	return q
}
source: func (handle *MemifPacketHandle) WritePacketData(data []byte) (err error) {
	handle.writeMu.Lock()
	defer handle.writeMu.Unlock()

	if handle.stop {
		err = io.EOF
		return
	}

	count, err := handle.memif.TxBurst(handle.queueId, []RawPacketData{data})

	if err != nil {
		return
	}

	if count == 0 {
		err = io.EOF
	}

	return
}
source: func (m *Manager) GetClientLabels(clientID string) (labels []string, err error) {
	results := []struct{ Label string }{}
	err = m.getClientsCollection().Find(bson.M{"clientid": clientID}).Select(bson.M{"label": 1}).All(&results)
	labels = make([]string, len(results), len(results))
	for i, value := range results {
		labels[i] = value.Label
	}
	return
}
source: func (u *Unit) SetPassword(password string) error {
	var result params.ErrorResults
	args := params.EntityPasswords{
		Changes: []params.EntityPassword{
			{Tag: u.tag.String(), Password: password},
		},
	}
	err := u.st.facade.FacadeCall("SetPasswords", args, &result)
	if err != nil {
		return err
	}
	return result.OneError()
}
source: func (i IndexFile) Get(name, version string) (*ChartVersion, error) {
	vs, ok := i.Entries[name]
	if !ok {
		return nil, ErrNoChartName
	}
	if len(vs) == 0 {
		return nil, ErrNoChartVersion
	}

	var constraint *semver.Constraints
	if len(version) == 0 {
		constraint, _ = semver.NewConstraint("*")
	} else {
		var err error
		constraint, err = semver.NewConstraint(version)
		if err != nil {
			return nil, err
		}
	}

	// when customer input exact version, check whether have exact match one first
	if len(version) != 0 {
		for _, ver := range vs {
			if version == ver.Version {
				return ver, nil
			}
		}
	}

	for _, ver := range vs {
		test, err := semver.NewVersion(ver.Version)
		if err != nil {
			continue
		}

		if constraint.Check(test) {
			return ver, nil
		}
	}
	return nil, fmt.Errorf("No chart version found for %s-%s", name, version)
}
source: func (tracker *DefaultImportTracker) PathOf(localName string) (string, bool) {
	name, ok := tracker.nameToPath[localName]
	return name, ok
}
source: func (nc *Conn) isDraining() bool {
	return nc.status == DRAINING_SUBS || nc.status == DRAINING_PUBS
}
source: func (l logf) Debugf(s string, args ...interface{}) {
	l.log.Debug(s, args...)
}
source: func Indent(spaces, str cty.Value) (cty.Value, error) {
	return IndentFunc.Call([]cty.Value{spaces, str})
}
source: func NewCmdBuildHook(fullName string, f kcmdutil.Factory, streams genericclioptions.IOStreams) *cobra.Command {
	o := NewBuildHookOptions(streams)
	cmd := &cobra.Command{
		Use:     "build-hook BUILDCONFIG --post-commit [--command] [--script] -- CMD",
		Short:   "Update a build hook on a build config",
		Long:    buildHookLong,
		Example: fmt.Sprintf(buildHookExample, fullName),
		Run: func(cmd *cobra.Command, args []string) {
			kcmdutil.CheckErr(o.Complete(f, cmd, args))
			kcmdutil.CheckErr(o.Validate())
			kcmdutil.CheckErr(o.Run())
		},
	}
	usage := "to use to edit the resource"
	kcmdutil.AddFilenameOptionFlags(cmd, &o.FilenameOptions, usage)
	cmd.Flags().StringVarP(&o.Selector, "selector", "l", o.Selector, "Selector (label query) to filter build configs")
	cmd.Flags().BoolVar(&o.All, "all", o.All, "If true, select all build configs in the namespace")
	cmd.Flags().BoolVar(&o.PostCommit, "post-commit", o.PostCommit, "If true, set the post-commit build hook on a build config")
	cmd.Flags().BoolVar(&o.Entrypoint, "command", o.Entrypoint, "If true, set the entrypoint of the hook container to the given command")
	cmd.Flags().StringVar(&o.Script, "script", o.Script, "Specify a script to run for the build-hook")
	cmd.Flags().BoolVar(&o.Remove, "remove", o.Remove, "If true, remove the build hook.")
	cmd.Flags().BoolVar(&o.Local, "local", o.Local, "If true, set image will NOT contact api-server but run locally.")

	o.PrintFlags.AddFlags(cmd)
	kcmdutil.AddDryRunFlag(cmd)

	return cmd
}
source: func NewPilosaProxy(host string, client *http.Client) *pilosaProxy {
	return &pilosaProxy{
		host:   host,
		client: client,
	}
}
source: func maybeNotFound(err *params.Error) error {
	if err == nil || !params.IsCodeNotFound(err) {
		return err
	}
	return errors.NewNotFound(err, "")
}
source: func deleteCommands(dp models.DeviceProfile, w http.ResponseWriter) error {
	for _, command := range dp.CoreCommands {
		err := dbClient.DeleteCommandById(command.Id)
		if err != nil {
			http.Error(w, err.Error(), http.StatusServiceUnavailable)
			return err
		}
	}

	return nil
}
source: func checkProposalsOnlyDifferByTimestamp(lastSignBytes, newSignBytes []byte) (time.Time, bool) {
	var lastProposal, newProposal types.CanonicalProposal
	if err := cdc.UnmarshalBinaryLengthPrefixed(lastSignBytes, &lastProposal); err != nil {
		panic(fmt.Sprintf("LastSignBytes cannot be unmarshalled into proposal: %v", err))
	}
	if err := cdc.UnmarshalBinaryLengthPrefixed(newSignBytes, &newProposal); err != nil {
		panic(fmt.Sprintf("signBytes cannot be unmarshalled into proposal: %v", err))
	}

	lastTime := lastProposal.Timestamp
	// set the times to the same value and check equality
	now := tmtime.Now()
	lastProposal.Timestamp = now
	newProposal.Timestamp = now
	lastProposalBytes, _ := cdc.MarshalBinaryLengthPrefixed(lastProposal)
	newProposalBytes, _ := cdc.MarshalBinaryLengthPrefixed(newProposal)

	return lastTime, bytes.Equal(newProposalBytes, lastProposalBytes)
}
source: func (c *Client) GetCFilterAsync(blockHash *chainhash.Hash,
	filterType wire.FilterType) FutureGetCFilterResult {
	hash := ""
	if blockHash != nil {
		hash = blockHash.String()
	}

	cmd := btcjson.NewGetCFilterCmd(hash, filterType)
	return c.sendCmd(cmd)
}
source: func (c *ConnectionManager) ApplyAll(f ApplyFn) {
	c.Lock()
	defer c.Unlock()
	for k, v := range c.lookup {
		if !f(k, v.transporter) {
			break
		}
	}
}
source: func New(conf Config, staticKeysAndValues ...interface{}) Logger {
	var prefix string
	var flags int
	var formatter formatLogEvent
	staticArgs := make(map[string]string, 0)

	format := SanitizeFormat(conf.Format)
	if format == JsonFormat {
		formatter = formatLogEventAsJson

		// Don't mess up the json by letting logger print these:
		prefix = ""
		flags = 0

		// Instead put them into the staticArgs
		if defaultPrefix != "" {
			staticArgs["prefix"] = defaultPrefix
		}
	} else if format == KeyValueFormat {
		formatter = formatLogEvent(formatLogEventAsKeyValue)
	} else {
		formatter = formatLogEvent(formatLogEventAsPlainText)
		prefix = defaultPrefix
		flags = defaultFlags
	}

	// Set 'ID' config as a static field, but before reading the varargs suplied
	// fields, so that they can override the config.
	if conf.ID != "" {
		staticArgs["golog_id"] = conf.ID
	}

	if len(staticKeysAndValues)%2 == 1 {
		// If there are an odd number of staticKeysAndValue, then there's probably one
		// missing, which means we'd interpret a value as a key, which can be bad for
		// logs-as-data, like metrics on staticKeys or elasticsearch. But, instead of
		// throwing the corrupt data out, serialize it into a string, which both
		// keeps the info, and maintains key-value integrity.
		staticKeysAndValues = []interface{}{"corruptStaticFields", flattenKeyValues(staticKeysAndValues)}
	}

	// Do this after handling prefix, so that individual loggers can override
	// external env variable.
	currentKey := ""
	for i, arg := range staticKeysAndValues {
		if i%2 == 0 {
			currentKey = fmt.Sprintf("%v", arg)
		} else {
			staticArgs[currentKey] = fmt.Sprintf("%v", arg)
		}
	}

	return &logger{
		stackTrace: defaultStackTrace,

		level: defaultLevel,

		formatLogEvent: formatter,
		staticArgs:     staticArgs,

		// don't touch the default logger on 'log' package
		// cache args to make a logger, in case it's changes with SetOutput()
		prefix: prefix,
		flags:  flags,
		l:      log.New(defaultOutput, prefix, flags),
	}
}
source: func newLeafNodeCfg(remote *RemoteLeafOpts) *leafNodeCfg {
	cfg := &leafNodeCfg{
		RemoteLeafOpts: remote,
		urls:           make([]*url.URL, 0, 4),
	}
	// Start with the one that is configured. We will add to this
	// array when receiving async leafnode INFOs.
	cfg.urls = append(cfg.urls, cfg.URL)
	return cfg
}
source: func (b *StringBuilder) WriteByte(c byte) error {
	b.copyCheck()
	b.buf = append(b.buf, c)
	return nil
}
source: func (pf *PortForwarder) handleConnection(conn net.Conn, port ForwardedPort) {
	defer conn.Close()

	glog.Infof("Handling connection for %d", port.Local)

	requestID := pf.nextRequestID()

	// create error stream
	headers := http.Header{}
	headers.Set(api.StreamType, api.StreamTypeError)
	headers.Set(api.PortHeader, fmt.Sprintf("%d", port.Remote))
	headers.Set(api.PortForwardRequestIDHeader, strconv.Itoa(requestID))
	errorStream, err := pf.streamConn.CreateStream(headers)
	if err != nil {
		util.HandleError(fmt.Errorf("error creating error stream for port %d -> %d: %v", port.Local, port.Remote, err))
		return
	}
	// we're not writing to this stream
	errorStream.Close()

	errorChan := make(chan error)
	go func() {
		message, err := ioutil.ReadAll(errorStream)
		switch {
		case err != nil:
			errorChan <- fmt.Errorf("error reading from error stream for port %d -> %d: %v", port.Local, port.Remote, err)
		case len(message) > 0:
			errorChan <- fmt.Errorf("an error occurred forwarding %d -> %d: %v", port.Local, port.Remote, string(message))
		}
		close(errorChan)
	}()

	// create data stream
	headers.Set(api.StreamType, api.StreamTypeData)
	dataStream, err := pf.streamConn.CreateStream(headers)
	if err != nil {
		util.HandleError(fmt.Errorf("error creating forwarding stream for port %d -> %d: %v", port.Local, port.Remote, err))
		return
	}

	localError := make(chan struct{})
	remoteDone := make(chan struct{})

	go func() {
		// Copy from the remote side to the local port.
		if _, err := io.Copy(conn, dataStream); err != nil && !strings.Contains(err.Error(), "use of closed network connection") {
			util.HandleError(fmt.Errorf("error copying from remote stream to local connection: %v", err))
		}

		// inform the select below that the remote copy is done
		close(remoteDone)
	}()

	go func() {
		// inform server we're not sending any more data after copy unblocks
		defer dataStream.Close()

		// Copy from the local port to the remote side.
		if _, err := io.Copy(dataStream, conn); err != nil && !strings.Contains(err.Error(), "use of closed network connection") {
			util.HandleError(fmt.Errorf("error copying from local connection to remote stream: %v", err))
			// break out of the select below without waiting for the other copy to finish
			close(localError)
		}
	}()

	// wait for either a local->remote error or for copying from remote->local to finish
	select {
	case <-remoteDone:
	case <-localError:
	}

	// always expect something on errorChan (it may be nil)
	err = <-errorChan
	if err != nil {
		util.HandleError(err)
	}
}
source: func Convert_apps_DaemonSetList_To_v1beta2_DaemonSetList(in *apps.DaemonSetList, out *v1beta2.DaemonSetList, s conversion.Scope) error {
	return autoConvert_apps_DaemonSetList_To_v1beta2_DaemonSetList(in, out, s)
}
source: func (i *PendingItem) Error() error {
	i.lock.Lock()
	defer i.lock.Unlock()
	return i.err
}
source: func Status(serviceName string,
	serviceDescription string,
	redact bool,
	logger *logrus.Logger) error {
	return errors.New("Status not supported for this binary")
}
source: func (r renderer) CodeSpan(out *bytes.Buffer, text []byte) {
	out.Write([]byte("`"))
	out.Write(text)
	out.Write([]byte("`"))
}
source: func (k *kubernetesClient) PrepareForBootstrap(ctx environs.BootstrapContext, controllerName string) error {
	alreadyExistErr := errors.NewAlreadyExists(nil,
		fmt.Sprintf(`a controller called %q already exists on this k8s cluster.
Please bootstrap again and choose a different controller name.`, controllerName),
	)

	k.namespace = DecideControllerNamespace(controllerName)

	// ensure no existing namespace has the same name.
	_, err := k.getNamespaceByName(k.namespace)
	if err == nil {
		return alreadyExistErr
	}
	if !errors.IsNotFound(err) {
		return errors.Trace(err)
	}
	// Good, no existing namespace has the same name.
	// Now, try to find if there is any existing controller running in this cluster.
	// Note: we have to do this check before we are confident to support multi controllers running in same k8s cluster.

	_, err = k.listNamespacesByAnnotations(k.annotations)
	if err == nil {
		return alreadyExistErr
	}
	if !errors.IsNotFound(err) {
		return errors.Trace(err)
	}
	// All good, no existing controller found on the cluster.
	// The namespace will be set to controller-name in newcontrollerStack.

	// do validation on storage class.
	_, err = k.validateOperatorStorage()
	return errors.Trace(err)
}
source: func NewGetPropertiesArgs(objectID RemoteObjectID) *GetPropertiesArgs {
	args := new(GetPropertiesArgs)
	args.ObjectID = objectID
	return args
}
source: func (st *State) Relation(relationTag names.RelationTag) (*Relation, error) {
	result, err := st.relation(relationTag, st.unitTag)
	if err != nil {
		return nil, err
	}
	return &Relation{
		id:        result.Id,
		tag:       relationTag,
		life:      result.Life,
		suspended: result.Suspended,
		st:        st,
		otherApp:  result.OtherApplication,
	}, nil
}
source: func (scaler *JobScaler) ScaleSimple(namespace, name string, preconditions *ScalePrecondition, newSize uint) error {
	job, err := scaler.c.Jobs(namespace).Get(name)
	if err != nil {
		return ScaleError{ScaleGetFailure, "Unknown", err}
	}
	if preconditions != nil {
		if err := preconditions.ValidateJob(job); err != nil {
			return err
		}
	}
	parallelism := int(newSize)
	job.Spec.Parallelism = &parallelism
	if _, err := scaler.c.Jobs(namespace).Update(job); err != nil {
		if errors.IsInvalid(err) {
			return ScaleError{ScaleUpdateInvalidFailure, job.ResourceVersion, err}
		}
		return ScaleError{ScaleUpdateFailure, job.ResourceVersion, err}
	}
	return nil
}
source: func WaitUntilVolumeAttached(ctx aws.Context, conn *ec2.EC2, volumeId string) error {
	volumeInput := ec2.DescribeVolumesInput{
		VolumeIds: []*string{&volumeId},
	}

	err := WaitForVolumeToBeAttached(conn,
		ctx,
		&volumeInput,
		getWaiterOptions()...)
	return err
}
source: func ParseVersionsFile(r io.Reader) (VersionsFile, error) {
	res := VersionsFile{}

	lineNo := 0
	makeError := func(fmtStr string, args ...interface{}) error {
		args = append([]interface{}{lineNo}, args...)
		return fmt.Errorf("failed to parse versions file (line %d): "+fmtStr, args...)
	}

	const (
		stWaitingPkg = "a package name"
		stWaitingVer = "a package version"
		stWaitingIID = "an instance ID"
		stWaitingNL  = "a new line"
	)
	state := stWaitingPkg
	pkg := ""
	ver := ""
	iid := ""

	scanner := bufio.NewScanner(r)
	for scanner.Scan() {
		lineNo++

		line := strings.TrimSpace(scanner.Text())

		// Comments are grammatically insignificant (unlike empty lines), so skip
		// the completely.
		if len(line) > 0 && line[0] == '#' {
			continue
		}

		switch state {
		case stWaitingPkg:
			if line == "" {
				continue // can have more than one empty line between triples
			}
			pkg = line
			if err := common.ValidatePackageName(pkg); err != nil {
				return nil, makeError("%s", err)
			}
			state = stWaitingVer

		case stWaitingVer:
			if line == "" {
				return nil, makeError("expecting a version name, not a new line")
			}
			ver = line
			if err := common.ValidateInstanceVersion(ver); err != nil {
				return nil, makeError("%s", err)
			}
			state = stWaitingIID

		case stWaitingIID:
			if line == "" {
				return nil, makeError("expecting an instance ID, not a new line")
			}
			iid = line
			if err := common.ValidateInstanceID(iid, common.AnyHash); err != nil {
				return nil, makeError("%s", err)
			}
			if err := res.AddVersion(pkg, ver, iid); err != nil {
				panic(err) // impossible, everything has been validated already
			}
			pkg, ver, iid = "", "", ""
			state = stWaitingNL

		case stWaitingNL:
			if line == "" {
				state = stWaitingPkg
				continue
			}
			return nil, makeError("expecting an empty line between each version definition triple")
		}
	}

	if state != stWaitingPkg && state != stWaitingNL {
		return nil, makeError("unexpected EOF, expecting %s", state)
	}

	if err := scanner.Err(); err != nil {
		return nil, err
	}
	return res, nil
}
source: func groupKeyFor(key lease.Key) groupKey {
	return groupKey{
		namespace: key.Namespace,
		modelUUID: key.ModelUUID,
	}
}
source: func NewDispatchTouchEventArgs(typ string, touchPoints []TouchPoint) *DispatchTouchEventArgs {
	args := new(DispatchTouchEventArgs)
	args.Type = typ
	args.TouchPoints = touchPoints
	return args
}
source: func (d *decoder) init(in *bitReader, dt []decSymbol, tableLog uint8) {
	d.dt = dt
	d.br = in
	d.state = uint16(in.getBits(tableLog))
}
source: func Create(client *flickr.FlickrClient, title, description, primaryPhotoId string) (*PhotosetResponse, error) {
	client.Init()
	client.HTTPVerb = "POST"
	client.Args.Set("method", "flickr.photosets.create")
	client.Args.Set("title", title)
	client.Args.Set("description", description)
	client.Args.Set("primary_photo_id", primaryPhotoId)

	client.OAuthSign()

	response := &PhotosetResponse{}
	err := flickr.DoPost(client, response)
	return response, err
}
source: func (f *RelationalModelDefinition) Underscore() string {
	runes := []rune(f.ModelName)
	length := len(runes)

	var out []rune
	for i := 0; i < length; i++ {
		if i > 0 && unicode.IsUpper(runes[i]) && ((i+1 < length && unicode.IsLower(runes[i+1])) || unicode.IsLower(runes[i-1])) {
			out = append(out, '_')
		}
		out = append(out, unicode.ToLower(runes[i]))
	}

	return string(out)
}
source: func SerializeDataSet(c types.Cell) *pb.MetricsDataSet {
	d := pb.MetricsDataSet{}
	d.MetricName = proto.String(metricNamePrefix + c.Name)
	d.FieldDescriptor = field.SerializeDescriptor(c.Fields)
	d.Description = proto.String(c.Description)

	if c.ValueType.IsCumulative() {
		d.StreamKind = pb.StreamKind_CUMULATIVE.Enum()
	} else {
		d.StreamKind = pb.StreamKind_GAUGE.Enum()
	}

	switch c.ValueType {
	case types.NonCumulativeIntType, types.CumulativeIntType:
		d.ValueType = pb.ValueType_INT64.Enum()
	case types.NonCumulativeFloatType, types.CumulativeFloatType:
		d.ValueType = pb.ValueType_DOUBLE.Enum()
	case types.NonCumulativeDistributionType, types.CumulativeDistributionType:
		d.ValueType = pb.ValueType_DISTRIBUTION.Enum()
	case types.StringType:
		d.ValueType = pb.ValueType_STRING.Enum()
	case types.BoolType:
		d.ValueType = pb.ValueType_BOOL.Enum()
	}

	if c.Units.IsSpecified() {
		d.Annotations.Unit = proto.String(string(c.Units))
	}
	return &d
}
source: func (m *kubeGenericRuntimeManager) ListImages() ([]kubecontainer.Image, error) {
	var images []kubecontainer.Image

	allImages, err := m.imageService.ListImages(nil)
	if err != nil {
		klog.Errorf("ListImages failed: %v", err)
		return nil, err
	}

	for _, img := range allImages {
		images = append(images, kubecontainer.Image{
			ID:          img.Id,
			Size:        int64(img.Size_),
			RepoTags:    img.RepoTags,
			RepoDigests: img.RepoDigests,
		})
	}

	return images, nil
}
source: func (t *Transaction) Delete(c *Collection, id string, deleted *bool) {
	if c == nil {
		t.setError(newNilCollectionError("Delete"))
		return
	}
	// Delete any field indexes
	// This must happen first, because it relies on reading the old field values
	// from the hash for string indexes (if any)
	t.deleteFieldIndexes(c, id)
	var handler ReplyHandler
	if deleted == nil {
		handler = nil
	} else {
		handler = NewScanBoolHandler(deleted)
	}
	// Delete the main hash
	t.Command("DEL", redis.Args{c.Name() + ":" + id}, handler)
	// Remvoe the id from the index of all models for the given type
	t.Command("SREM", redis.Args{c.IndexKey(), id}, nil)
}
source: func (s *ServerRPC) PodRemove(ctx context.Context, req *types.PodRemoveRequest) (*types.PodRemoveResponse, error) {
	if req.PodID == "" {
		return nil, fmt.Errorf("PodRemove failed PodID is required for PodRemove")
	}

	code, cause, err := s.daemon.RemovePod(req.PodID)
	if err != nil {
		return nil, fmt.Errorf("s.daemon.RemovePod error: %v", err)
	}

	return &types.PodRemoveResponse{
		Cause: cause,
		Code:  int32(code),
	}, nil
}
source: func (n *NetStore) FetchFunc(ctx context.Context, ref Address) func(context.Context) error {
	chunk, fetch, _ := n.get(ctx, ref)
	if chunk != nil {
		return nil
	}
	return func(ctx context.Context) error {
		_, err := fetch(ctx)
		return err
	}
}
source: func NewCmdLinkSecret(name, fullName string, f kcmdutil.Factory, streams genericclioptions.IOStreams) *cobra.Command {
	o := NewLinkSecretOptions(streams)

	cmd := &cobra.Command{
		Use:     fmt.Sprintf("%s serviceaccounts-name secret-name [another-secret-name]...", name),
		Short:   "Link secrets to a ServiceAccount",
		Long:    linkSecretLong,
		Example: fmt.Sprintf(linkSecretExample, fullName),
		PreRun: func(cmd *cobra.Command, args []string) {
			if len(os.Args) > 1 && os.Args[1] == "add" {
				printDeprecationWarning("secrets add", "secrets link")
			}
		},
		Run: func(c *cobra.Command, args []string) {
			if err := o.Complete(f, args); err != nil {
				kcmdutil.CheckErr(kcmdutil.UsageErrorf(c, err.Error()))
			}

			if err := o.Validate(); err != nil {
				kcmdutil.CheckErr(kcmdutil.UsageErrorf(c, err.Error()))
			}

			if err := o.LinkSecrets(); err != nil {
				kcmdutil.CheckErr(err)
			}

		},
	}

	cmd.Flags().StringSliceVar(&o.typeFlags, "for", []string{"mount"}, "type of secret to link: mount or pull")

	return cmd
}
source: func parseURL(urlString string) (*url.URL, error) {
	url, parseErr := url.Parse(urlString)
	if parseErr != nil {
		return nil, parseErr
	}
	if url == nil {
		return nil, fmt.Errorf("No URL")
	}
	return url, nil
}
source: func (eBase *elementBase) hasMixinSels() bool {
	for _, mi := range eBase.mixins {
		if sels, _ := mi.selsParams(); len(sels) > 0 {
			return true
		}
	}

	return false
}
source: func (c *CipherReader) Read(p []byte) (n int, err error) {
	n, err = c.r.Read(p)
	ws.Cipher(p[:n], c.mask, c.pos)
	c.pos += n
	return
}
source: func ExtractTag(path string) string {
	match := tagExp.FindStringSubmatch(path)
	// match is []string{"whole match", "submatch"} when successful

	if len(match) != 2 {
		return ""
	}
	return match[1]
}
source: func AddIp(ip, iface string) error {
	link, err := netlink.LinkByName(iface)
	if err != nil {
		return err
	}

	addr, err := netlink.ParseAddr(ip)
	if err != nil {
		return err
	}

	return netlink.AddrAdd(link, addr)
}
source: func (rule *overlappingFieldsCanBeMergedRule) collectConflictsBetween(conflicts []conflict, parentFieldsAreMutuallyExclusive bool,
	fieldsInfo1 *fieldsAndFragmentNames,
	fieldsInfo2 *fieldsAndFragmentNames) []conflict {
	// A field map is a keyed collection, where each key represents a response
	// name and the value at that key is a list of all fields which provide that
	// response name. For any response name which appears in both provided field
	// maps, each field from the first field map must be compared to every field
	// in the second field map to find potential conflicts.
	for _, responseName := range fieldsInfo1.fieldsOrder {
		fields1, ok1 := fieldsInfo1.fieldMap[responseName]
		fields2, ok2 := fieldsInfo2.fieldMap[responseName]
		if !ok1 || !ok2 {
			continue
		}
		for i := 0; i < len(fields1); i++ {
			for k := 0; k < len(fields2); k++ {
				conflict := rule.findConflict(parentFieldsAreMutuallyExclusive, responseName, fields1[i], fields2[k])
				if conflict != nil {
					conflicts = append(conflicts, *conflict)
				}
			}
		}
	}
	return conflicts
}
source: func (b *OptionsBuilder) BuildOptions(o interface{}) error {
	cs, ok := o.(*kops.ClusterSpec)
	if !ok {
		return errors.New("expected a ClusterSpec object")
	}

	if cs.NodeAuthorization != nil {
		na := cs.NodeAuthorization
		// NodeAuthorizerSpec
		if na.NodeAuthorizer != nil {
			if na.NodeAuthorizer.Authorizer == "" {
				switch kops.CloudProviderID(cs.CloudProvider) {
				case kops.CloudProviderAWS:
					na.NodeAuthorizer.Authorizer = "aws"
				default:
					na.NodeAuthorizer.Authorizer = "alwaysallow"
				}
			}
			if na.NodeAuthorizer.Image == "" {
				na.NodeAuthorizer.Image = GetNodeAuthorizerImage()
			}
			if na.NodeAuthorizer.Port == 0 {
				na.NodeAuthorizer.Port = DefaultPort
			}
			if na.NodeAuthorizer.Timeout == nil {
				na.NodeAuthorizer.Timeout = DefaultTimeout
			}
			if na.NodeAuthorizer.TokenTTL == nil {
				na.NodeAuthorizer.TokenTTL = DefaultTokenTTL
			}
			if na.NodeAuthorizer.NodeURL == "" {
				na.NodeAuthorizer.NodeURL = fmt.Sprintf("https://node-authorizer-internal.%s:%d", b.Context.ClusterName, na.NodeAuthorizer.Port)
			}
			if na.NodeAuthorizer.Features == nil {
				features := []string{"verify-registration", "verify-ip"}

				switch kops.CloudProviderID(cs.CloudProvider) {
				case kops.CloudProviderAWS:
					features = append(features, "verify-signature")
				}
				na.NodeAuthorizer.Features = &features
			}
		}
	}

	return nil
}
source: func (client *AuroraDNSClient) GetZones() ([]zones.ZoneRecord, error) {
	logrus.Debugf("GetZones")
	response, err := client.requestor.Request("zones", "GET", []byte(""))

	if err != nil {
		logrus.Errorf("Failed to get zones: %s", err)
		return nil, err
	}

	var respData []zones.ZoneRecord
	err = json.Unmarshal(response, &respData)
	if err != nil {
		logrus.Errorf("Failed to unmarshall response: %s", err)
		return nil, err
	}

	logrus.Debugf("Unmarshalled response: %+v", respData)
	return respData, nil
}
source: func (p *MempoolMonitor) LastBlockHeight() int64 {
	p.mtx.RLock()
	defer p.mtx.RUnlock()
	return p.lastBlock.Height
}
source: func SetLogLevel(lv level) {
	if logLv != lv {
		logLv = lv
		if logLv <= DEBUG {
			lgr.SetFlags(log.LstdFlags | log.Lshortfile)
		} else {
			lgr.SetFlags(log.LstdFlags)
		}
	}
}
source: func (list *List) PrintResult(result string) int {
	var bytes int

	bytes = list.PrintHead()

	list.colors.Highlight.Set()
	printBytes, _ := list.Print(" ", result)
	color.Unset()

	return bytes + printBytes + list.Println()
}
source: func (n *LevelLogger) Fatalln(v ...interface{}) {
	if !n.Enabled() {
		return
	}
	n.mu.RLock()
	n.logger.Output(callDepth, fmt.Sprintln(v...))
	n.mu.RUnlock()
	os.Exit(1)
}
source: func (cmd *CLI) Param(name string) values.Value {
	value, ok := cmd.Params()[name]
	if !ok {
		panic(fmt.Sprintf("param not defined %v", name))
	}
	return value
}
source: func InitCoverage(name string) {
	// We read the coverage destination in from the KUBE_COVERAGE_FILE env var,
	// or if it's empty we just use a default in /tmp
	coverageFile = os.Getenv("KUBE_COVERAGE_FILE")
	if coverageFile == "" {
		coverageFile = "/tmp/k8s-" + name + ".cov"
	}
	fmt.Println("Dumping coverage information to " + coverageFile)

	flushInterval := 5 * time.Second
	requestedInterval := os.Getenv("KUBE_COVERAGE_FLUSH_INTERVAL")
	if requestedInterval != "" {
		if duration, err := time.ParseDuration(requestedInterval); err == nil {
			flushInterval = duration
		} else {
			panic("Invalid KUBE_COVERAGE_FLUSH_INTERVAL value; try something like '30s'.")
		}
	}

	// Set up the unit test framework with the required arguments to activate test coverage.
	flag.CommandLine.Parse([]string{"-test.coverprofile", tempCoveragePath()})

	// Begin periodic logging
	go wait.Forever(FlushCoverage, flushInterval)
}
source: func (c *WorkItemLinkController) Delete(ctx *app.DeleteWorkItemLinkContext) error {
	currentUserIdentityID, err := login.ContextIdentity(ctx)
	if err != nil {
		return jsonapi.JSONErrorResponse(ctx, errors.NewUnauthorizedError(err.Error()))
	}
	authorized, err := c.checkIfUserIsSpaceCollaboratorOrWorkItemCreator(ctx, ctx.LinkID, *currentUserIdentityID)
	if err != nil {
		return jsonapi.JSONErrorResponse(ctx, err)
	}
	if !authorized {
		return jsonapi.JSONErrorResponse(ctx, errors.NewForbiddenError("user is not authorized to delete the link"))
	}
	err = application.Transactional(c.db, func(appl application.Application) error {
		return appl.WorkItemLinks().Delete(ctx.Context, ctx.LinkID, *currentUserIdentityID)
	})
	if err != nil {
		return jsonapi.JSONErrorResponse(ctx, err)
	}
	return ctx.OK([]byte{})
}
source: func (l *Logger) logAll(opt *levelOptions, s string) {
	// Skip everything if logger is disabled
	if !l.Active {
		return
	}
	// Log to all receivers
	for _, r := range l.Receivers {
		r.log(opt, s)
	}
}
source: func NewEVMInterpreter(evm *EVM, cfg Config) *EVMInterpreter {
	// We use the STOP instruction whether to see
	// the jump table was initialised. If it was not
	// we'll set the default jump table.
	if !cfg.JumpTable[STOP].valid {
		switch {
		case evm.ChainConfig().IsConstantinople(evm.BlockNumber):
			cfg.JumpTable = constantinopleInstructionSet
		case evm.ChainConfig().IsByzantium(evm.BlockNumber):
			cfg.JumpTable = byzantiumInstructionSet
		case evm.ChainConfig().IsHomestead(evm.BlockNumber):
			cfg.JumpTable = homesteadInstructionSet
		default:
			cfg.JumpTable = frontierInstructionSet
		}
	}

	return &EVMInterpreter{
		evm:      evm,
		cfg:      cfg,
		gasTable: evm.ChainConfig().GasTable(evm.BlockNumber),
	}
}
source: func (c *Cluster) Register(node Node) error {
	if node.Address == "" {
		return errors.New("Invalid address")
	}
	node.defTLSConfig = c.tlsConfig
	err := c.runHooks(HookEventBeforeNodeRegister, &node)
	if err != nil {
		return err
	}
	return c.storage().StoreNode(node)
}
source: func (addr *Address) ProviderID() network.Id {
	return network.Id(addr.doc.ProviderID)
}
source: func addScriptStagingVolume(pod *apiv1.Pod) {
	volName := "argo-staging"
	stagingVol := apiv1.Volume{
		Name: volName,
		VolumeSource: apiv1.VolumeSource{
			EmptyDir: &apiv1.EmptyDirVolumeSource{},
		},
	}
	pod.Spec.Volumes = append(pod.Spec.Volumes, stagingVol)

	for i, initCtr := range pod.Spec.InitContainers {
		if initCtr.Name == common.InitContainerName {
			volMount := apiv1.VolumeMount{
				Name:      volName,
				MountPath: common.ExecutorStagingEmptyDir,
			}
			initCtr.VolumeMounts = append(initCtr.VolumeMounts, volMount)
			pod.Spec.InitContainers[i] = initCtr
			break
		}
	}
	found := false
	for i, ctr := range pod.Spec.Containers {
		if ctr.Name == common.MainContainerName {
			volMount := apiv1.VolumeMount{
				Name:      volName,
				MountPath: common.ExecutorStagingEmptyDir,
			}
			ctr.VolumeMounts = append(ctr.VolumeMounts, volMount)
			pod.Spec.Containers[i] = ctr
			found = true
			break
		}
	}
	if !found {
		panic("Unable to locate main container")
	}
}
source: func (environProvider) Validate(cfg, old *config.Config) (*config.Config, error) {
	newCfg, err := newConfig(cfg, old)
	if err != nil {
		return nil, errors.Annotate(err, "invalid config")
	}
	return newCfg.config, nil
}
source: func (m *Machine) Units() ([]*Unit, error) {
	m.mu.Lock()
	defer m.mu.Unlock()

	result := make([]*Unit, 0)
	for unitName, unit := range m.model.units {
		if unit.details.MachineId == m.details.Id {
			result = append(result, unit)
		}
		if unit.details.Subordinate {
			principalUnit, found := m.model.units[unit.details.Principal]
			if !found {
				return result, errors.NotFoundf("principal unit %q for subordinate %s", unit.details.Principal, unitName)
			}
			if principalUnit.details.MachineId == m.details.Id {
				result = append(result, unit)
			}
		}
	}
	return result, nil
}
source: func (daemon *Daemon) ConnectToNetwork(container *container.Container, idOrName string, endpointConfig *networktypes.EndpointSettings) error {
	if endpointConfig == nil {
		endpointConfig = &networktypes.EndpointSettings{}
	}
	container.Lock()
	defer container.Unlock()

	if !container.Running {
		if container.RemovalInProgress || container.Dead {
			return errRemovalContainer(container.ID)
		}

		n, err := daemon.FindNetwork(idOrName)
		if err == nil && n != nil {
			if err := daemon.updateNetworkConfig(container, n, endpointConfig, true); err != nil {
				return err
			}
		} else {
			container.NetworkSettings.Networks[idOrName] = &network.EndpointSettings{
				EndpointSettings: endpointConfig,
			}
		}
	} else {
		if err := daemon.connectToNetwork(container, idOrName, endpointConfig, true); err != nil {
			return err
		}
	}

	return container.CheckpointTo(daemon.containersReplica)
}
source: func (r Resource) Validate(bucketName string) error {
	if !r.IsValid() {
		return fmt.Errorf("invalid resource")
	}

	if !wildcard.Match(r.BucketName, bucketName) {
		return fmt.Errorf("bucket name does not match")
	}

	return nil
}
source: func NewGeoBoundingBoxQuery(tlLat, tlLon, brLat, brLon float64) *GeoBoundingBoxQuery {
	q := &GeoBoundingBoxQuery{newFtsQueryBase()}
	q.options["top_left"] = []float64{tlLon, tlLat}
	q.options["bottom_right"] = []float64{brLon, brLat}
	return q
}
source: func (c *Chunk) GetRow(idx int) Row {
	return Row{c: c, idx: idx}
}
source: func (s *oracleVolumeSource) fetchVolumeStatus(name, desiredStatus string) (complete bool, err error) {
	details, err := s.api.StorageVolumeDetails(name)
	if err != nil {
		return false, errors.Trace(err)
	}

	if details.Status == ociCommon.VolumeError {
		return false, errors.Errorf("volume entered error state: %q", details.Status_detail)
	}
	return string(details.Status) == desiredStatus, nil
}
source: func (store *store) AddDigest(ref reference.Canonical, id digest.Digest, force bool) error {
	return store.addReference(ref, id, force)
}
source: func (e *Env) Scan(g *Graph, s []byte, limit int64) [][]string {
	alloc := limit
	if 10000 < alloc {
		alloc = 10000
	}
	acc := make([][]string, 0, alloc)
	g.Do(SPO, &Triple{[]byte(s), nil, nil, nil}, nil,
		func(t *Triple) bool {
			acc = append(acc, t.Strings())
			limit--
			if limit == 0 {
				return false
			}
			return true
		})
	return acc
}
source: func (o *PostNodesIdentifierWorkflowsParams) WithIdentifier(identifier string) *PostNodesIdentifierWorkflowsParams {
	o.Identifier = identifier
	return o
}
source: func (enc *Encoder) ObjectKey(key string, v MarshalerJSONObject) {
	if enc.hasKeys {
		if !enc.keyExists(key) {
			return
		}
	}
	if v.IsNil() {
		enc.grow(2 + len(key))
		r := enc.getPreviousRune()
		if r != '{' {
			enc.writeByte(',')
		}
		enc.writeByte('"')
		enc.writeStringEscape(key)
		enc.writeBytes(objKeyObj)
		enc.writeByte('}')
		return
	}
	enc.grow(5 + len(key))
	r := enc.getPreviousRune()
	if r != '{' {
		enc.writeByte(',')
	}
	enc.writeByte('"')
	enc.writeStringEscape(key)
	enc.writeBytes(objKeyObj)

	var origHasKeys = enc.hasKeys
	var origKeys = enc.keys
	enc.hasKeys = false
	enc.keys = nil

	v.MarshalJSONObject(enc)

	enc.hasKeys = origHasKeys
	enc.keys = origKeys

	enc.writeByte('}')
}
source: func (sk *SecretKey) deriveKey(password *[]byte) error {
	key, err := scrypt.Key(*password, sk.Parameters.Salt[:],
		sk.Parameters.N,
		sk.Parameters.R,
		sk.Parameters.P,
		len(sk.Key))
	if err != nil {
		return err
	}
	copy(sk.Key[:], key)
	zero.Bytes(key)

	// I'm not a fan of forced garbage collections, but scrypt allocates a
	// ton of memory and calling it back to back without a GC cycle in
	// between means you end up needing twice the amount of memory.  For
	// example, if your scrypt parameters are such that you require 1GB and
	// you call it twice in a row, without this you end up allocating 2GB
	// since the first GB probably hasn't been released yet.
	debug.FreeOSMemory()

	return nil
}
source: func (s *Server) verifyAccountClaims(claimJWT string) (*jwt.AccountClaims, string, error) {
	if accClaims, err := jwt.DecodeAccountClaims(claimJWT); err != nil {
		return nil, _EMPTY_, err
	} else {
		vr := jwt.CreateValidationResults()
		accClaims.Validate(vr)
		if vr.IsBlocking(true) {
			return nil, _EMPTY_, ErrAccountValidation
		}
		return accClaims, claimJWT, nil
	}
}
source: func (d *dockerClient) GetAllInfraContainersPID() (map[string]int, error) {
	timeoutCtx, cancel := ctx.WithTimeout(ctx.Background(), 10*time.Second)
	defer cancel()

	cList, err := Client().workloadIDsList(timeoutCtx)
	if err != nil {
		log.WithError(err).Error("Failed to retrieve the container list")
		return nil, err
	}
	pids := map[string]int{}
	for _, contID := range cList {
		cJSON, err := d.ContainerInspect(context.Background(), contID)
		if err != nil {
			continue
		}
		if cJSON.Config == nil || !utils.IsInfraContainer(cJSON.Config.Labels) {
			continue
		}
		if cJSON.State == nil || !cJSON.State.Running {
			continue
		}
		pids[cJSON.ID] = cJSON.State.Pid
	}

	return pids, nil
}
source: func (f *StringSliceFlag) Apply(set *flag.FlagSet) {
	f.set = set
	f.StringSliceFlag.Apply(set)
}
source: func (t *Template) GetAllAWSEC2VPNGatewayRoutePropagationResources() map[string]*resources.AWSEC2VPNGatewayRoutePropagation {
	results := map[string]*resources.AWSEC2VPNGatewayRoutePropagation{}
	for name, untyped := range t.Resources {
		switch resource := untyped.(type) {
		case *resources.AWSEC2VPNGatewayRoutePropagation:
			results[name] = resource
		}
	}
	return results
}
source: func (c *Context) keyboard() (chatKeyboard, error) {

	udata, _ := c.User.getData()
	chatID := c.Chat.ID

	for _, kb := range udata.KeyboardPerChat {
		if kb.ChatID == chatID && kb.BotID == c.Bot().ID {
			return kb, nil
		}

	}

	cdata, _ := c.Chat.getData()

	for _, kb := range cdata.KeyboardPerBot {
		if kb.ChatID == chatID && kb.BotID == c.Bot().ID {
			return kb, nil
		}
	}

	return chatKeyboard{}, nil
}
source: func (s *FirewallService) ListPaloAltoFirewalls(p *ListPaloAltoFirewallsParams) (*ListPaloAltoFirewallsResponse, error) {
	resp, err := s.cs.newRequest("listPaloAltoFirewalls", p.toURLValues())
	if err != nil {
		return nil, err
	}

	resp, err = convertFirewallServiceResponse(resp)
	if err != nil {
		return nil, err
	}

	var r ListPaloAltoFirewallsResponse
	if err := json.Unmarshal(resp, &r); err != nil {
		return nil, err
	}

	return &r, nil
}
source: func CompactMinFileSize(fileSize int64) FileStoreOption {
	return func(o *FileStoreOptions) error {
		if fileSize < 0 {
			return fmt.Errorf("compact minimum file size value must be a positive number")
		}
		o.CompactMinFileSize = fileSize
		return nil
	}
}
source: func (mj *mirrorJob) startMirror(ctx context.Context, cancelMirror context.CancelFunc) {
	var totalBytes int64
	var totalObjects int64

	stopParallel := func() {
		close(mj.queueCh)
		mj.parallel.wait()
	}

	URLsCh := prepareMirrorURLs(mj.sourceURL, mj.targetURL, mj.isFake, mj.isOverwrite, mj.isRemove, mj.excludeOptions, mj.encKeyDB)

	for {
		select {
		case sURLs, ok := <-URLsCh:
			if !ok {
				stopParallel()
				return
			}
			if sURLs.Error != nil {
				stopParallel()
				mj.statusCh <- sURLs
				return
			}

			if sURLs.SourceContent != nil {
				if mj.olderThan != "" && isOlder(sURLs.SourceContent.Time, mj.olderThan) {
					continue
				}
				if mj.newerThan != "" && isNewer(sURLs.SourceContent.Time, mj.newerThan) {
					continue
				}
				// copy
				totalBytes += sURLs.SourceContent.Size
			}

			totalObjects++
			mj.TotalBytes = totalBytes
			mj.TotalObjects = totalObjects
			mj.status.SetTotal(totalBytes)

			// Save total count.
			sURLs.TotalCount = mj.TotalObjects
			// Save totalSize.
			sURLs.TotalSize = mj.TotalBytes

			if sURLs.SourceContent != nil {
				mj.queueCh <- func() URLs {
					return mj.doMirror(ctx, cancelMirror, sURLs)
				}
			} else if sURLs.TargetContent != nil && mj.isRemove {
				mj.queueCh <- func() URLs {
					return mj.doRemove(sURLs)
				}
			}
		case <-mj.trapCh:
			stopParallel()
			cancelMirror()
			return
		}
	}
}
source: func (d Document) Has(k string) bool {
	_, ok := d[k]
	return ok
}
source: func (l *JSONLogger) CaptureEnd(output []byte, gasUsed uint64, t time.Duration, err error) error {
	type endLog struct {
		Output  string              `json:"output"`
		GasUsed math.HexOrDecimal64 `json:"gasUsed"`
		Time    time.Duration       `json:"time"`
		Err     string              `json:"error,omitempty"`
	}
	if err != nil {
		return l.encoder.Encode(endLog{common.Bytes2Hex(output), math.HexOrDecimal64(gasUsed), t, err.Error()})
	}
	return l.encoder.Encode(endLog{common.Bytes2Hex(output), math.HexOrDecimal64(gasUsed), t, ""})
}
source: func NewCmdKustomize(streams genericclioptions.IOStreams) *cobra.Command {
	var o kustomizeOptions

	cmd := &cobra.Command{
		Use:     "kustomize <dir>",
		Short:   i18n.T("Build a kustomization target from a directory or a remote url."),
		Long:    kustomizeLong,
		Example: kustomizeExample,

		RunE: func(cmd *cobra.Command, args []string) error {
			err := o.Validate(args)
			if err != nil {
				return err
			}
			return kustomize.RunKustomizeBuild(streams.Out, fs.MakeRealFS(), o.kustomizationDir)
		},
	}

	return cmd
}
source: func GetOrRegisterGauge(name string, r Registry) Gauge {
	if nil == r {
		r = DefaultRegistry
	}
	return r.GetOrRegister(name, NewGauge).(Gauge)
}
source: func (c *Client) SetClient(client *http.Client) {
	c.Lock()
	defer c.Unlock()
	c.httpClient.SetClient(client)
}
source: func (client *SSHClient) SetSSHPrivateKey(s string) {
	client.Creds.mu.Lock()
	client.Creds.SSHPrivateKey = s
	client.Creds.mu.Unlock()
}
source: func (s *grpcAPIService) PresenceStats(ctx context.Context, req *PresenceStatsRequest) (*PresenceStatsResponse, error) {
	return s.api.PresenceStats(ctx, req), nil
}
source: func (c *Client) applyOptions(opts ...ClientOption) error {
	for _, f := range opts {
		if err := f(c); err != nil {
			return err
		}
	}
	return nil
}
source: func sameType(first, second ComponentOrHTML) bool {
	return reflect.TypeOf(first) == reflect.TypeOf(second)
}
source: func _operrno(op string, ret int) error {
	return operrno(op, C.int(ret))
}
source: func (tsv *TabletServer) HeartbeatLag() (time.Duration, error) {
	// If the reader is closed and we are not serving, then the
	// query service is shutdown and this value is not being updated.
	// We return healthy from this as a signal to the healtcheck to attempt
	// to start the query service again. If the query service fails to start
	// with an error, then that error is be reported by the healthcheck.
	if !tsv.hr.IsOpen() && !tsv.IsServing() {
		return 0, nil
	}
	return tsv.hr.GetLatest()
}
source: func (g *GPG) Verify(ctx context.Context, sigf string, in string) error {
	sig, err := ioutil.ReadFile(sigf)
	if err != nil {
		return err
	}
	b, _ := clearsign.Decode(sig)
	infh, err := os.Open(in)
	if err != nil {
		return err
	}
	defer infh.Close()
	_, err = openpgp.CheckDetachedSignature(g.pubring, infh, bytes.NewReader(b.Bytes))
	if err != nil {
		return err
	}
	return nil
}
source: func (dh *Client) BuildDockerfile(dockerfile string, opts *BuildImageOptions) (imageId string, e error) {
	r, e := dh.createDockerfileArchive(dockerfile)
	if e != nil {
		return "", e
	}
	return dh.Build(r, opts)

}
source: func (fbo *folderBranchOps) Shutdown(ctx context.Context) error {
	if fbo.config.CheckStateOnShutdown() {
		lState := makeFBOLockState()

		if fbo.blocks.GetState(lState) == dirtyState {
			fbo.log.CDebugf(ctx, "Skipping state-checking due to dirty state")
		} else if fbo.isUnmerged(lState) {
			fbo.log.CDebugf(ctx, "Skipping state-checking due to being staged")
		} else {
			// Make sure we're up to date first
			if err := fbo.SyncFromServer(ctx,
				fbo.folderBranch, nil); err != nil {
				return err
			}

			// Check the state for consistency before shutting down.
			sc := NewStateChecker(fbo.config)
			if err := sc.CheckMergedState(ctx, fbo.id()); err != nil {
				return err
			}
		}
	}

	if err := fbo.fbm.waitForArchives(ctx); err != nil {
		return err
	}

	close(fbo.shutdownChan)
	fbo.cr.Shutdown()
	fbo.fbm.shutdown()
	fbo.rekeyFSM.Shutdown()
	// Wait for all the goroutines to finish, so that we don't have any races
	// with logging during test reporting.
	fbo.doneWg.Wait()
	return nil
}
source: func (api *API) Watch() (watcher.StringsWatcher, error) {
	var result params.StringsWatchResult
	err := api.caller.FacadeCall("Watch", nil, &result)
	if err != nil {
		return nil, errors.Trace(err)
	}
	if result.Error != nil {
		return nil, errors.Trace(result.Error)
	}
	w := api.newWatcher(api.caller.RawAPICaller(), result)
	return w, nil
} 27%|██▋       | 1354/5000 [00:01<00:03, 925.98it/s]
source: func NewOnionErrorEncrypter(router *Router,
	ephemeralKey *btcec.PublicKey) (*OnionErrorEncrypter, error) {

	sharedSecret, err := router.generateSharedSecret(ephemeralKey)
	if err != nil {
		return nil, err
	}

	return &OnionErrorEncrypter{
		sharedSecret: sharedSecret,
	}, nil
}
source: func ErrPUNotFound(puID string, err error) error {
	return &Error{
		puID:   puID,
		reason: PUNotFound,
		err:    err,
	}
}
source: func (sp *SimpleProof) StringIndented(indent string) string {
	return fmt.Sprintf(`SimpleProof{
%s  Aunts: %X
%s}`,
		indent, sp.Aunts,
		indent)
}
source: func (w *FakeResponseWriter) Write(data []byte) (int, error) {
	return w.buffer.Write(data)
}
source: func (a *Advertisement) unmarshall(b []byte) error {

	// Utility function for creating a list of uuids.
	uuidList := func(u []UUID, d []byte, w int) []UUID {
		for len(d) > 0 {
			u = append(u, UUID{d[:w]})
			d = d[w:]
		}
		return u
	}

	for len(b) > 0 {
		if len(b) < 2 {
			return errors.New("invalid advertise data")
		}
		l, t := b[0], b[1]
		if len(b) < int(1+l) {
			return errors.New("invalid advertise data")
		}
		d := b[2 : 1+l]
		switch t {
		case typeFlags:
			// TODO: should we do anything about the discoverability here?
		case typeSomeUUID16:
			a.Services = uuidList(a.Services, d, 2)
		case typeAllUUID16:
			a.Services = uuidList(a.Services, d, 2)
		case typeSomeUUID32:
			a.Services = uuidList(a.Services, d, 4)
		case typeAllUUID32:
			a.Services = uuidList(a.Services, d, 4)
		case typeSomeUUID128:
			a.Services = uuidList(a.Services, d, 16)
		case typeAllUUID128:
			a.Services = uuidList(a.Services, d, 16)
		case typeShortName:
			a.LocalName = string(d)
		case typeCompleteName:
			a.LocalName = string(d)
		case typeTxPower:
			a.TxPowerLevel = int(d[0])
		case typeServiceSol16:
			a.SolicitedService = uuidList(a.SolicitedService, d, 2)
		case typeServiceSol128:
			a.SolicitedService = uuidList(a.SolicitedService, d, 16)
		case typeServiceSol32:
			a.SolicitedService = uuidList(a.SolicitedService, d, 4)
		case typeManufacturerData:
			a.ManufacturerData = make([]byte, len(d))
			copy(a.ManufacturerData, d)
		// case typeServiceData16,
		// case typeServiceData32,
		// case typeServiceData128:
		default:
			log.Printf("DATA: [ % X ]", d)
		}
		b = b[1+l:]
	}
	return nil
}
source: func ParseTime(header http.Header, key string) time.Time {
	if s := header.Get(key); s != "" {
		for _, layout := range timeLayouts {
			if t, err := time.Parse(layout, s); err == nil {
				return t.UTC()
			}
		}
	}
	return time.Time{}
}
source: func (w *PrefixSuffixSaver) Bytes() []byte {
	if w.suffix == nil {
		return w.prefix
	}
	if w.skipped == 0 {
		return append(w.prefix, w.suffix...)
	}
	var buf bytes.Buffer
	buf.Grow(len(w.prefix) + len(w.suffix) + 50)
	buf.Write(w.prefix)
	buf.WriteString("\n... omitting ")
	buf.WriteString(strconv.FormatInt(w.skipped, 10))
	buf.WriteString(" bytes ...\n")
	buf.Write(w.suffix[w.suffixOff:])
	buf.Write(w.suffix[:w.suffixOff])
	return buf.Bytes()
}
source: func (ec *EpollConsole) signalRead() {
	ec.readc.L.Lock()
	ec.readc.Signal()
	ec.readc.L.Unlock()
}
source: func isHostNetworkContainer(runtime policy.RuntimeReader) bool {

	return runtime.PUType() == common.LinuxProcessPU || (getPausePUID(policyExtensions(runtime)) != "")
}
source: func (r *Renewer) renewAuth() error {
	if !r.secret.Auth.Renewable || r.secret.Auth.ClientToken == "" {
		return ErrRenewerNotRenewable
	}

	priorDuration := time.Duration(r.secret.Auth.LeaseDuration) * time.Second
	r.calculateGrace(priorDuration)

	client, token := r.client, r.secret.Auth.ClientToken

	for {
		// Check if we are stopped.
		select {
		case <-r.stopCh:
			return nil
		default:
		}

		// Renew the auth.
		renewal, err := client.Auth().Token().RenewTokenAsSelf(token, r.increment)
		if err != nil {
			return err
		}

		// Push a message that a renewal took place.
		select {
		case r.renewCh <- &RenewOutput{time.Now().UTC(), renewal}:
		default:
		}

		// Somehow, sometimes, this happens.
		if renewal == nil || renewal.Auth == nil {
			return ErrRenewerNoSecretData
		}

		// Do nothing if we are not renewable
		if !renewal.Auth.Renewable {
			return ErrRenewerNotRenewable
		}

		// Grab the lease duration
		leaseDuration := time.Duration(renewal.Auth.LeaseDuration) * time.Second

		// We keep evaluating a new grace period so long as the lease is
		// extending. Once it stops extending, we've hit the max and need to
		// rely on the grace duration.
		if leaseDuration > priorDuration {
			r.calculateGrace(leaseDuration)
		}
		priorDuration = leaseDuration

		// The sleep duration is set to 2/3 of the current lease duration plus
		// 1/3 of the current grace period, which adds jitter.
		sleepDuration := time.Duration(float64(leaseDuration.Nanoseconds())*2/3 + float64(r.grace.Nanoseconds())/3)

		// If we are within grace, return now; or, if the amount of time we
		// would sleep would land us in the grace period. This helps with short
		// tokens; for example, you don't want a current lease duration of 4
		// seconds, a grace period of 3 seconds, and end up sleeping for more
		// than three of those seconds and having a very small budget of time
		// to renew.
		if leaseDuration <= r.grace || leaseDuration-sleepDuration <= r.grace {
			return nil
		}

		select {
		case <-r.stopCh:
			return nil
		case <-time.After(sleepDuration):
			continue
		}
	}
}
source: func bootstrapSSHOptionsFunc(instanceConfig *instancecfg.InstanceConfig) HostSSHOptionsFunc {
	return func(host string) (*ssh.Options, func(), error) {
		return hostBootstrapSSHOptions(host, instanceConfig)
	}
}
source: func (api *Client) UpdatePhoneNumber(idOrNumber string, data *UpdatePhoneNumberData) error {
	_, _, err := api.makeRequest(http.MethodPost, fmt.Sprintf("%s/%s", api.concatUserPath(phoneNumbersPath), url.QueryEscape(idOrNumber)), nil, data)
	return err
}
source: func serveControllers(servingInfo configv1.HTTPServingInfo, handler http.Handler) error {
	timeout := servingInfo.RequestTimeoutSeconds
	if timeout == -1 {
		timeout = 0
	}

	server := &http.Server{
		Addr:           servingInfo.BindAddress,
		Handler:        handler,
		ReadTimeout:    time.Duration(timeout) * time.Second,
		WriteTimeout:   time.Duration(timeout) * time.Second,
		MaxHeaderBytes: 1 << 20,
	}

	clientCAs, err := getClientCertCAPool(servingInfo)
	if err != nil {
		return err
	}

	go utilwait.Forever(func() {
		klog.Infof("Started health checks at %s", servingInfo.BindAddress)

		extraCerts, err := getNamedCertificateMap(servingInfo.NamedCertificates)
		if err != nil {
			klog.Fatal(err)
		}
		server.TLSConfig = crypto.SecureTLSConfig(&tls.Config{
			// Populate PeerCertificates in requests, but don't reject connections without certificates
			// This allows certificates to be validated by authenticators, while still allowing other auth types
			ClientAuth: tls.RequestClientCert,
			ClientCAs:  clientCAs,
			// Set SNI certificate func
			GetCertificate: cmdutil.GetCertificateFunc(extraCerts),
			MinVersion:     crypto.TLSVersionOrDie(servingInfo.MinTLSVersion),
			CipherSuites:   crypto.CipherSuitesOrDie(servingInfo.CipherSuites),
		})
		klog.Fatal(cmdutil.ListenAndServeTLS(server, servingInfo.BindNetwork, servingInfo.CertFile, servingInfo.KeyFile))
	}, 0)

	return nil
}
source: func (g *GossipSyncer) sendGossipTimestampRange(firstTimestamp time.Time,
	timestampRange uint32) error {

	endTimestamp := firstTimestamp.Add(
		time.Duration(timestampRange) * time.Second,
	)

	log.Infof("GossipSyncer(%x): applying gossipFilter(start=%v, end=%v)",
		g.cfg.peerPub[:], firstTimestamp, endTimestamp)

	localUpdateHorizon := &lnwire.GossipTimestampRange{
		ChainHash:      g.cfg.chainHash,
		FirstTimestamp: uint32(firstTimestamp.Unix()),
		TimestampRange: timestampRange,
	}

	if err := g.cfg.sendToPeer(localUpdateHorizon); err != nil {
		return err
	}

	if firstTimestamp == zeroTimestamp && timestampRange == 0 {
		g.localUpdateHorizon = nil
	} else {
		g.localUpdateHorizon = localUpdateHorizon
	}

	return nil
}
source: func (c *client) getSubsCopy() []*subState {
	subs := make([]*subState, len(c.subs))
	copy(subs, c.subs)
	return subs
}
source: func (c *SCSICmd) MediumError() SCSIResponse {
	return c.CheckCondition(scsi.SenseMediumError, scsi.AscReadError)
}
source: func (s *Layer) SetDefaultRecipes(v *Recipes) *Layer {
	s.DefaultRecipes = v
	return s
}
source: func (vm *VirtualMachine) CreateDiskSpec(ctx context.Context, diskPath string, dsObj *Datastore, volumeOptions *VolumeOptions) (*types.VirtualDisk, types.BaseVirtualDevice, error) {
	var newSCSIController types.BaseVirtualDevice
	vmDevices, err := vm.Device(ctx)
	if err != nil {
		klog.Errorf("Failed to retrieve VM devices. err: %+v", err)
		return nil, nil, err
	}
	// find SCSI controller of particular type from VM devices
	scsiControllersOfRequiredType := getSCSIControllersOfType(vmDevices, volumeOptions.SCSIControllerType)
	scsiController := getAvailableSCSIController(scsiControllersOfRequiredType)
	if scsiController == nil {
		newSCSIController, err = vm.createAndAttachSCSIController(ctx, volumeOptions.SCSIControllerType)
		if err != nil {
			klog.Errorf("Failed to create SCSI controller for VM :%q with err: %+v", vm.InventoryPath, err)
			return nil, nil, err
		}
		// Get VM device list
		vmDevices, err := vm.Device(ctx)
		if err != nil {
			klog.Errorf("Failed to retrieve VM devices. err: %v", err)
			return nil, nil, err
		}
		// verify scsi controller in virtual machine
		scsiControllersOfRequiredType := getSCSIControllersOfType(vmDevices, volumeOptions.SCSIControllerType)
		scsiController = getAvailableSCSIController(scsiControllersOfRequiredType)
		if scsiController == nil {
			klog.Errorf("Cannot find SCSI controller of type: %q in VM", volumeOptions.SCSIControllerType)
			// attempt clean up of scsi controller
			if err := vm.deleteController(ctx, newSCSIController, vmDevices); err != nil {
				return nil, nil, fmt.Errorf("failed to delete SCSI controller after failing to find it on VM: %v", err)
			}
			return nil, nil, fmt.Errorf("Cannot find SCSI controller of type: %q in VM", volumeOptions.SCSIControllerType)
		}
	}
	disk := vmDevices.CreateDisk(scsiController, dsObj.Reference(), diskPath)
	unitNumber, err := getNextUnitNumber(vmDevices, scsiController)
	if err != nil {
		klog.Errorf("Cannot attach disk to VM, unitNumber limit reached - %+v.", err)
		return nil, nil, err
	}
	*disk.UnitNumber = unitNumber
	backing := disk.Backing.(*types.VirtualDiskFlatVer2BackingInfo)
	backing.DiskMode = string(types.VirtualDiskModeIndependent_persistent)

	if volumeOptions.CapacityKB != 0 {
		disk.CapacityInKB = int64(volumeOptions.CapacityKB)
	}
	if volumeOptions.DiskFormat != "" {
		var diskFormat string
		diskFormat = DiskFormatValidType[volumeOptions.DiskFormat]
		switch diskFormat {
		case ThinDiskType:
			backing.ThinProvisioned = types.NewBool(true)
		case EagerZeroedThickDiskType:
			backing.EagerlyScrub = types.NewBool(true)
		default:
			backing.ThinProvisioned = types.NewBool(false)
		}
	}
	return disk, newSCSIController, nil
}
source: func (d *DotGit) NewObjectPack() (*PackWriter, error) {
	d.cleanPackList()
	return newPackWrite(d.fs)
}
source: func (c *Client) GetExpandedFormation(appID, releaseID string) (*ct.ExpandedFormation, error) {
	formation := &ct.ExpandedFormation{}
	return formation, c.Get(fmt.Sprintf("/apps/%s/formations/%s?expand=true", appID, releaseID), formation)
}
source: func (d *dualListener) openAPIPort(topic string, conn apiserver.APIConnection, err error) {
	if err != nil {
		logger.Errorf("programming error: %v", err)
		return
	}
	// We are wanting to make sure that the api-caller has connected before we
	// open the api port. Each api connection is published with the origin tag.
	// Any origin that matches our agent name means that someone has connected
	// to us. We need to also check which agent connected as it is possible that
	// one of the other HA controller could connect before we connect to
	// ourselves.
	if conn.Origin != d.agentName || conn.AgentTag != d.agentName {
		return
	}

	d.unsub()
	if d.delay > 0 {
		d.mu.Lock()
		d.status = "waiting prior to opening agent port"
		d.mu.Unlock()
		logger.Infof("waiting for %s before allowing api connections", d.delay)
		<-d.clock.After(d.delay)
	}

	d.mu.Lock()
	defer d.mu.Unlock()
	// Make sure we haven't been closed already.
	select {
	case <-d.done:
		return
	default:
		// We are all good.
	}

	listenAddr := net.JoinHostPort("", strconv.Itoa(d.apiPort))
	listener, err := net.Listen("tcp", listenAddr)
	if err != nil {
		select {
		case d.errors <- err:
		case <-d.done:
			logger.Errorf("can't open api port: %v, but worker exiting already", err)
		}
		return
	}

	logger.Infof("listening for api connections on %q", listener.Addr())
	d.apiListener = listener
	go d.accept(listener)
	d.status = ""
}
source: func (rs *Ruleset) AddSingular(suffix, replacement string) {
	rs.AddSingularExact(suffix, replacement, false)
}
source: func (s *IPServiceList) FirstPage() (*IPServiceList, error) {
	return s.getPage(s.Meta.FirstPageUri)
}
source: func (ctx *Context) Close() error {
	var empty C.cudnnHandle_t
	if ctx.internal == empty {
		return nil
	}

	if err := result(C.cudnnDestroy(ctx.internal)); err != nil {
		return err
	}
	ctx.internal = empty
	return nil
}
source: func (c *Context) mapSession() {
	if cookie, err := c.req.Cookie(soap.SessionCookieName); err == nil {
		if val, ok := c.svc.sm.sessions[cookie.Value]; ok {
			c.SetSession(val, false)
		}
	}
}
source: func (dswp *desiredStateOfWorldPopulator) getPVSpec(
	name string,
	pvcReadOnly bool,
	expectedClaimUID types.UID) (*volume.Spec, string, error) {
	pv, err := dswp.kubeClient.CoreV1().PersistentVolumes().Get(name, metav1.GetOptions{})
	if err != nil || pv == nil {
		return nil, "", fmt.Errorf(
			"failed to fetch PV %q from API server. err=%v", name, err)
	}

	if pv.Spec.ClaimRef == nil {
		return nil, "", fmt.Errorf(
			"found PV object %q but it has a nil pv.Spec.ClaimRef indicating it is not yet bound to the claim",
			name)
	}

	if pv.Spec.ClaimRef.UID != expectedClaimUID {
		return nil, "", fmt.Errorf(
			"found PV object %q but its pv.Spec.ClaimRef.UID (%q) does not point to claim.UID (%q)",
			name,
			pv.Spec.ClaimRef.UID,
			expectedClaimUID)
	}

	volumeGidValue := getPVVolumeGidAnnotationValue(pv)
	return volume.NewSpecFromPersistentVolume(pv, pvcReadOnly), volumeGidValue, nil
}
source: func (na *cnmNetworkAllocator) IsAllocated(n *api.Network) bool {
	_, ok := na.networks[n.ID]
	return ok
}
source: func (p *ProfilesClient) ListByID(ctx context.Context, userIDs []identity.ID) ([]apitypes.Profile, error) {
	v := &url.Values{}
	for _, id := range userIDs {
		v.Add("id", id.String())
	}

	var results []apitypes.Profile
	err := p.client.RoundTrip(ctx, "GET", "/profiles", v, nil, &results)
	return results, err
}
source: func (s *DefaultStorageFactory) NewConfig(groupResource schema.GroupResource) (*storagebackend.Config, error) {
	chosenStorageResource := s.getStorageGroupResource(groupResource)

	// operate on copy
	storageConfig := s.StorageConfig
	codecConfig := StorageCodecConfig{
		StorageMediaType:  s.DefaultMediaType,
		StorageSerializer: s.DefaultSerializer,
	}

	if override, ok := s.Overrides[getAllResourcesAlias(chosenStorageResource)]; ok {
		override.Apply(&storageConfig, &codecConfig)
	}
	if override, ok := s.Overrides[chosenStorageResource]; ok {
		override.Apply(&storageConfig, &codecConfig)
	}

	var err error
	codecConfig.StorageVersion, err = s.ResourceEncodingConfig.StorageEncodingFor(chosenStorageResource)
	if err != nil {
		return nil, err
	}
	codecConfig.MemoryVersion, err = s.ResourceEncodingConfig.InMemoryEncodingFor(groupResource)
	if err != nil {
		return nil, err
	}
	codecConfig.Config = storageConfig

	storageConfig.Codec, storageConfig.EncodeVersioner, err = s.newStorageCodecFn(codecConfig)
	if err != nil {
		return nil, err
	}
	klog.V(3).Infof("storing %v in %v, reading as %v from %#v", groupResource, codecConfig.StorageVersion, codecConfig.MemoryVersion, codecConfig.Config)

	return &storageConfig, nil
}
source: func (pgb *ChainDB) DisapprovedBlocks() ([]*dbtypes.BlockStatus, error) {
	ctx, cancel := context.WithTimeout(pgb.ctx, pgb.queryTimeout)
	defer cancel()
	disb, err := RetrieveDisapprovedBlocks(ctx, pgb.db)
	return disb, pgb.replaceCancelError(err)
}
source: func (p *PrefixLengthCounter) ToBPFData() (s6, s4 []int) {
	p.RLock()
	defer p.RUnlock()

	return p.v6.ToBPFData(), p.v4.ToBPFData()
}
source: func (a *api) AddPublicEndpointPort(serviceid, endpointName, portAddr string, usetls bool,
	protocol string, isEnabled bool, restart bool) (*servicedefinition.Port, error) {
	client, err := a.connectMaster()
	if err != nil {
		return nil, err
	}

	return client.AddPublicEndpointPort(serviceid, endpointName, portAddr, usetls, protocol, isEnabled, restart)
}
source: func NewID() string {
	b := make([]byte, 8)
	rand.Read(b)
	return fmt.Sprintf("%x", b)
}
source: func (rng *Pcg128x64) Stream(streamH, streamL uint64) {
  // stream must be odd for LCG, so shift left 1 and turn on the 1 bit
  rng.lcg.Stream = Uint128{streamH,streamL}.ShiftLeft(1)
  rng.lcg.Stream.L |= 1
}
source: func (self *OAuth1Mixin) Redirect(w http.ResponseWriter, r *http.Request) {
	if err := self.AuthorizeRedirect(w, r, self.Consumer.AuthorizationURL); err != nil {
		println("Error redirecting to authorization endpoint: " + err.Error())
	}
}
source: func SetupDB(session *gorethink.Session, dbName string, tables []Table) error {
	if err := makeDB(session, dbName); err != nil {
		return fmt.Errorf("unable to create database: %s", err)
	}

	cursor, err := gorethink.DB("rethinkdb").Table("server_config").Count().Run(session)
	if err != nil {
		return fmt.Errorf("unable to query db server config: %s", err)
	}

	var replicaCount uint
	if err := cursor.One(&replicaCount); err != nil {
		return fmt.Errorf("unable to scan db server config count: %s", err)
	}

	for _, table := range tables {
		if err = table.create(session, dbName, replicaCount); err != nil {
			return fmt.Errorf("unable to create table %q: %s", table.Name, err)
		}
	}

	return nil
}
source: func (q *queue) CancelHeaders(request *fetchRequest) {
	q.cancel(request, q.headerTaskQueue, q.headerPendPool)
}
source: func RegisterStatistics(s Statistics) {
	statisticsListLock.Lock()
	statisticsList = append(statisticsList, s)
	statisticsListLock.Unlock()
}
source: func Execute(v string) {
	version = v
	if err := rootCmd.Execute(); err != nil {
		log.Fatal(err)
	}
}
source: func (b *builderBuffer) Grow(n uint) []byte {
	l := uint(len(*b))
	if n > 0 {
		b.growCapacity(n)
		*b = (*b)[:l+n]
	}
	return (*b)[l:]
}
source: func EncodeUint(x uint) string {
	bs := make([]byte, 0, 7)
	for ; x >= 32; x >>= 5 {
		bs = append(bs, byte((x&31)+95))
	}
	bs = append(bs, byte(x+63))
	return string(bs)
}
source: func Apply(db Database, change Change) error {
	db, closer := db.Copy()
	defer closer()

	buildTxn := func(int) ([]txn.Op, error) {
		ops, err := change.Prepare(db)
		if errors.Cause(err) == ErrChangeComplete {
			return nil, jujutxn.ErrNoOperations
		}
		if err != nil {
			return nil, errors.Trace(err)
		}
		return ops, nil
	}

	runner, closer := db.TransactionRunner()
	defer closer()
	if err := runner.Run(buildTxn); err != nil {
		return errors.Trace(err)
	}
	return nil
}
source: func (c *MempoolDataCache) GetFees(N int) (uint32, int, []float64) {
	c.mtx.RLock()
	defer c.mtx.RUnlock()

	numFees := len(c.allFees)

	//var fees []float64
	fees := []float64{} // for consistency
	if N == 0 {
		return c.height, numFees, fees
	}

	if N < 0 || N >= numFees {
		fees = make([]float64, numFees)
		copy(fees, c.allFees)
	} else if N < numFees {
		// fees are in ascending order, take from end of slice
		smallestFeeInd := numFees - N
		fees = make([]float64, N)
		copy(fees, c.allFees[smallestFeeInd:])
	}

	return c.height, numFees, fees
}
source: func (r *Store) Copy(ctx context.Context, from, to string) error {
	return r.move(ctx, from, to, false)
}
source: func runCommand(cmd *cobra.Command, args []string, opts *options.Options) error {
	verflag.PrintAndExitIfRequested()
	utilflag.PrintFlags(cmd.Flags())

	if len(args) != 0 {
		fmt.Fprint(os.Stderr, "arguments are not supported\n")
	}

	if errs := opts.Validate(); len(errs) > 0 {
		fmt.Fprintf(os.Stderr, "%v\n", utilerrors.NewAggregate(errs))
		os.Exit(1)
	}

	if len(opts.WriteConfigTo) > 0 {
		if err := options.WriteConfigFile(opts.WriteConfigTo, &opts.ComponentConfig); err != nil {
			fmt.Fprintf(os.Stderr, "%v\n", err)
			os.Exit(1)
		}
		klog.Infof("Wrote configuration to: %s\n", opts.WriteConfigTo)
	}

	c, err := opts.Config()
	if err != nil {
		fmt.Fprintf(os.Stderr, "%v\n", err)
		os.Exit(1)
	}

	stopCh := make(chan struct{})

	// Get the completed config
	cc := c.Complete()

	// To help debugging, immediately log version
	klog.Infof("Version: %+v", version.Get())

	// Apply algorithms based on feature gates.
	// TODO: make configurable?
	algorithmprovider.ApplyFeatureGates()

	// Configz registration.
	if cz, err := configz.New("componentconfig"); err == nil {
		cz.Set(cc.ComponentConfig)
	} else {
		return fmt.Errorf("unable to register configz: %s", err)
	}

	return Run(cc, stopCh)
}
source: func translateWorkingDir(config *containertypes.Config, platform string) error {
	if config.WorkingDir == "" {
		return nil
	}
	wd := config.WorkingDir
	switch {
	case runtime.GOOS != platform:
		// LCOW. Force Unix semantics
		wd = strings.Replace(wd, string(os.PathSeparator), "/", -1)
		if !path.IsAbs(wd) {
			return fmt.Errorf("the working directory '%s' is invalid, it needs to be an absolute path", config.WorkingDir)
		}
	default:
		wd = filepath.FromSlash(wd) // Ensure in platform semantics
		if !system.IsAbs(wd) {
			return fmt.Errorf("the working directory '%s' is invalid, it needs to be an absolute path", config.WorkingDir)
		}
	}
	config.WorkingDir = wd
	return nil
}
source: func (ctx *context) PostValueBool(name string) (bool, error) {
	v := ctx.PostValue(name)
	if v == "" {
		return false, errUnableToFindPostValue.Format(name)
	}

	return strconv.ParseBool(v)
}
source: func (p *Proxy) checkEndpointList(ctx context.Context, e string) bool {
	if p.endpointBlackList == nil && p.endpointWhiteList == nil {
		return true
	}

	for _, rgx := range p.endpointBlackList {
		if rgx.MatchString(e) {
			return false
		}
	}

	return true
}
source: func NewThrottledeviceOpt(validator ValidatorThrottleFctType) ThrottledeviceOpt {
	values := []*blkiodev.ThrottleDevice{}
	return ThrottledeviceOpt{
		values:    values,
		validator: validator,
	}
}
source: func (m *DbMap) SelectOne(dest interface{}, query string, args ...interface{}) error {
	return hookedget(m, m, dest, query, args...)
}
source: func (s *LoadBalancerService) NewListLoadBalancersParams() *ListLoadBalancersParams {
	p := &ListLoadBalancersParams{}
	p.p = make(map[string]interface{})
	return p
}
source: func (c *CloudPersister) GetBotType(id int64) (*types.BotType, error) {
	ctx := context.Background()
	k := datastore.NewKey(ctx, "BotType", "", id, nil)
	BotType := &types.BotType{}
	if err := c.DatastoreClient().Get(ctx, k, BotType); err != nil {
		return nil, fmt.Errorf("datastoredb: could not get BotType: %v", err)
	}
	BotType.ID = id
	return BotType, nil
}
source: func (f HandlerFunc) HandleMeasures(time time.Time, measures ...Measure) {
	f(time, measures...)
}
source: func (c *FakeOAuthAuthorizeTokens) List(opts v1.ListOptions) (result *oauth.OAuthAuthorizeTokenList, err error) {
	obj, err := c.Fake.
		Invokes(testing.NewRootListAction(oauthauthorizetokensResource, oauthauthorizetokensKind, opts), &oauth.OAuthAuthorizeTokenList{})
	if obj == nil {
		return nil, err
	}

	label, _, _ := testing.ExtractFromListOptions(opts)
	if label == nil {
		label = labels.Everything()
	}
	list := &oauth.OAuthAuthorizeTokenList{ListMeta: obj.(*oauth.OAuthAuthorizeTokenList).ListMeta}
	for _, item := range obj.(*oauth.OAuthAuthorizeTokenList).Items {
		if label.Matches(labels.Set(item.Labels)) {
			list.Items = append(list.Items, item)
		}
	}
	return list, err
}
source: func GetListener(index int) (net.Listener, error) {
	if CountListeners() < (index + 1) {
		return nil, errors.New("einhorn: too few EINHORN_FDs passed")
	}

	name := fmt.Sprintf("EINHORN_FD_%d", index)

	fileno, err := strconv.Atoi(os.Getenv(name))
	if err != nil {
		return nil, err
	}

	listener, err := net.FileListener(os.NewFile(uintptr(fileno), name))
	if err != nil {
		return nil, err
	}

	return listener, nil
}
source: func (h *HTTPBodyMarshaler) Marshal(v interface{}) ([]byte, error) {
	if httpBody, ok := v.(*httpbody.HttpBody); ok {
		return httpBody.Data, nil
	}
	return h.Marshaler.Marshal(v)
}
source: func (s *SortCommand) Run() (*Reply, error) {
	args := packArgs("SORT", s.key)
	if s.by != "" {
		args = append(args, "BY", s.by)
	}
	if s.limit {
		args = append(args, "LIMIT", s.offset, s.count)
	}
	if s.get != nil && len(s.get) > 0 {
		for _, pattern := range s.get {
			args = append(args, "GET", pattern)
		}
	}
	if s.order != "" {
		args = append(args, s.order)
	}
	if s.alpha {
		args = append(args, "ALPHA")
	}
	if s.store != "" {
		args = append(args, "STORE", s.store)
	}
	return s.redis.ExecuteCommand(args...)
}
source: func (d *AuthenticatedGossiper) retransmitStaleChannels() error {
	// Iterate over all of our channels and check if any of them fall
	// within the prune interval or re-broadcast interval.
	type updateTuple struct {
		info *channeldb.ChannelEdgeInfo
		edge *channeldb.ChannelEdgePolicy
	}
	var edgesToUpdate []updateTuple
	err := d.cfg.Router.ForAllOutgoingChannels(func(
		info *channeldb.ChannelEdgeInfo,
		edge *channeldb.ChannelEdgePolicy) error {

		// If there's no auth proof attached to this edge, it means
		// that it is a private channel not meant to be announced to
		// the greater network, so avoid sending channel updates for
		// this channel to not leak its
		// existence.
		if info.AuthProof == nil {
			log.Debugf("Skipping retransmission of channel "+
				"without AuthProof: %v", info.ChannelID)
			return nil
		}

		// If this edge has a ChannelUpdate that was created before the
		// introduction of the MaxHTLC field, then we'll update this
		// edge to propagate this information in the network.
		if !edge.MessageFlags.HasMaxHtlc() {
			edgesToUpdate = append(edgesToUpdate, updateTuple{
				info: info,
				edge: edge,
			})
			return nil
		}

		const broadcastInterval = time.Hour * 24

		timeElapsed := time.Since(edge.LastUpdate)

		// If it's been a full day since we've re-broadcasted the
		// channel, add the channel to the set of edges we need to
		// update.
		if timeElapsed >= broadcastInterval {
			edgesToUpdate = append(edgesToUpdate, updateTuple{
				info: info,
				edge: edge,
			})
		}

		return nil
	})
	if err != nil && err != channeldb.ErrGraphNoEdgesFound {
		return fmt.Errorf("unable to retrieve outgoing channels: %v",
			err)
	}

	var signedUpdates []lnwire.Message
	for _, chanToUpdate := range edgesToUpdate {
		// Re-sign and update the channel on disk and retrieve our
		// ChannelUpdate to broadcast.
		chanAnn, chanUpdate, err := d.updateChannel(
			chanToUpdate.info, chanToUpdate.edge,
		)
		if err != nil {
			return fmt.Errorf("unable to update channel: %v", err)
		}

		// If we have a valid announcement to transmit, then we'll send
		// that along with the update.
		if chanAnn != nil {
			signedUpdates = append(signedUpdates, chanAnn)
		}

		signedUpdates = append(signedUpdates, chanUpdate)
	}

	// If we don't have any channels to re-broadcast, then we'll exit
	// early.
	if len(signedUpdates) == 0 {
		return nil
	}

	log.Infof("Retransmitting %v outgoing channels", len(edgesToUpdate))

	// With all the wire announcements properly crafted, we'll broadcast
	// our known outgoing channels to all our immediate peers.
	if err := d.cfg.Broadcast(nil, signedUpdates...); err != nil {
		return fmt.Errorf("unable to re-broadcast channels: %v", err)
	}

	return nil
}
source: func inSelectInTableIM(p *parser) bool {
	switch p.tok.Type {
	case StartTagToken, EndTagToken:
		switch p.tok.DataAtom {
		case a.Caption, a.Table, a.Tbody, a.Tfoot, a.Thead, a.Tr, a.Td, a.Th:
			if p.tok.Type == StartTagToken || p.elementInScope(tableScope, p.tok.DataAtom) {
				p.parseImpliedToken(EndTagToken, a.Select, a.Select.String())
				return false
			} else {
				// Ignore the token.
				return true
			}
		}
	}
	return inSelectIM(p)
}
source: func (s *TranslateFile) handlePrimaryStoreEvent(ev primaryStoreEvent) error {
	s.mu.Lock()
	defer s.mu.Unlock()

	if ev.id == s.primaryID {
		return nil
	}

	// Stop translate store replication.
	close(s.replicationClosing)
	s.repWG.Wait()

	// Set the primary node for translate store replication.
	s.logger.Debugf("set primary translate store to %s", ev.id)
	s.primaryID = ev.id
	if ev.id == "" {
		s.PrimaryTranslateStore = nil
	} else {
		s.PrimaryTranslateStore = ev.ts
	}

	// Start translate store replication. Stream from primary, if available.
	if s.PrimaryTranslateStore != nil {
		s.replicationClosing = make(chan struct{})
		s.repWG.Add(1)
		go func() { defer s.repWG.Done(); s.monitorReplication() }()
	}

	return nil
}
source: func (w *upgradeSeriesWorker) unpinLeaders() error {
	results, err := w.UnpinMachineApplications()
	if err != nil {
		return errors.Trace(err)
	}

	var lastErr error
	for app, err := range results {
		if err == nil {
			w.logger.Infof("unpinned leader for application %q", app)
			continue
		}
		w.logger.Errorf("failed to unpin leader for application %q: %s", app, err.Error())
		lastErr = err
	}

	if lastErr == nil {
		w.leadersPinned = false
		return nil
	}
	return errors.Trace(lastErr)
}
source: func (md *RootMetadataV3) MakeBareTlfHandle(extra ExtraMetadata) (
	tlf.Handle, error) {
	var writers, readers []keybase1.UserOrTeamID
	if md.TypeForKeying() == tlf.PrivateKeying {
		wkb, rkb, err := md.getTLFKeyBundles(extra)
		if err != nil {
			return tlf.Handle{}, err
		}
		writers = make([]keybase1.UserOrTeamID, 0, len(wkb.Keys))
		readers = make([]keybase1.UserOrTeamID, 0, len(rkb.Keys))
		for w := range wkb.Keys {
			writers = append(writers, w.AsUserOrTeam())
		}
		for r := range rkb.Keys {
			// TODO: Return an error instead if r is
			// PublicUID. Maybe return an error if r is in
			// WKeys also. Or do all this in
			// MakeBareTlfHandle.
			if _, ok := wkb.Keys[r]; !ok &&
				r != keybase1.PublicUID {
				readers = append(readers, r.AsUserOrTeam())
			}
		}
	} else {
		err := md.checkNonPrivateExtra(extra)
		if err != nil {
			return tlf.Handle{}, err
		}

		writers = md.WriterMetadata.Writers
		if md.TypeForKeying() == tlf.PublicKeying {
			readers = []keybase1.UserOrTeamID{keybase1.PublicUID.AsUserOrTeam()}
		}
	}

	return tlf.MakeHandle(
		writers, readers,
		md.WriterMetadata.UnresolvedWriters, md.UnresolvedReaders,
		md.TlfHandleExtensions())
}
source: func (e *PerfEvent) Debug() string {
	return fmt.Sprintf("cpu: %d, Fd: %d, pagesize: %d, npages: %d, lost: %d, unknown: %d, state: %v", e.cpu, e.Fd, e.pagesize, e.npages, e.lost, e.unknown, C.GoBytes(e.state, C.sizeof_struct_read_state))
}
source: func (i *Import) GetFailedStep() string {
	if i == nil || i.FailedStep == nil {
		return ""
	}
	return *i.FailedStep
}
source: func (we *WorkflowExecutor) SaveArtifacts() error {
	if len(we.Template.Outputs.Artifacts) == 0 {
		log.Infof("No output artifacts")
		return nil
	}
	log.Infof("Saving output artifacts")
	mainCtrID, err := we.GetMainContainerID()
	if err != nil {
		return err
	}

	err = os.MkdirAll(tempOutArtDir, os.ModePerm)
	if err != nil {
		return errors.InternalWrapError(err)
	}

	for i, art := range we.Template.Outputs.Artifacts {
		err := we.saveArtifact(mainCtrID, &art)
		if err != nil {
			return err
		}
		we.Template.Outputs.Artifacts[i] = art
	}
	return nil
}
source: func readBuildSecrets(ctx context.Context) (*pb.BuildSecrets, error) {
	swarming := lucictx.GetSwarming(ctx)
	if swarming == nil {
		return nil, nil
	}

	secrets := &pb.BuildSecrets{}
	if err := proto.Unmarshal(swarming.SecretBytes, secrets); err != nil {
		return nil, err
	}
	return secrets, nil
}
source: func midnight(t uint64) (mid uint64) {
	if t > 0 {
		mid = t - t%aDay
	}
	return
}
source: func readRemoteKeyDesc(r io.Reader) (keychain.KeyDescriptor, error) {
	var (
		keyDesc keychain.KeyDescriptor
		pub     [33]byte
	)

	_, err := io.ReadFull(r, pub[:])
	if err != nil {
		return keyDesc, nil
	}

	keyDesc.PubKey, err = btcec.ParsePubKey(pub[:], btcec.S256())
	if err != nil {
		return keyDesc, nil
	}

	keyDesc.PubKey.Curve = nil

	return keyDesc, nil
}
source: func (b ValExprBuilder) NotBetween(from interface{}, to interface{}) BoolExprBuilder {
	return b.makeRangeCond(astNotBetween, from, to)
}
source: func (m *Setpoint8Dof) Decode(buf []byte) {
	data := bytes.NewBuffer(buf)
	binary.Read(data, binary.LittleEndian, &m.VAL1)
	binary.Read(data, binary.LittleEndian, &m.VAL2)
	binary.Read(data, binary.LittleEndian, &m.VAL3)
	binary.Read(data, binary.LittleEndian, &m.VAL4)
	binary.Read(data, binary.LittleEndian, &m.VAL5)
	binary.Read(data, binary.LittleEndian, &m.VAL6)
	binary.Read(data, binary.LittleEndian, &m.VAL7)
	binary.Read(data, binary.LittleEndian, &m.VAL8)
	binary.Read(data, binary.LittleEndian, &m.TARGET_SYSTEM)
}
source: func (r *PURuntime) NSPath() string {
	r.Lock()
	defer r.Unlock()

	return r.nsPath
}
source: func (h *handler) ConvertFieldsUp(ctx ttnlog.Interface, _ *pb_broker.DeduplicatedUplinkMessage, appUp *types.UplinkMessage, dev *device.Device) error {
	// Find Application
	app, err := h.applications.Get(appUp.AppID)
	if err != nil {
		return nil // Do not process if application not found
	}

	var decoder PayloadDecoder
	switch app.PayloadFormat {
	case application.PayloadFormatCustom:
		decoder = &CustomUplinkFunctions{
			Decoder:   app.CustomDecoder,
			Converter: app.CustomConverter,
			Validator: app.CustomValidator,
			Logger:    functions.Ignore,
		}
	case application.PayloadFormatCayenneLPP:
		decoder = &cayennelpp.Decoder{}
	default:
		return nil
	}

	fields, valid, err := decoder.Decode(appUp.PayloadRaw, appUp.FPort)
	if err != nil {
		// Emit the error
		h.qEvent <- &types.DeviceEvent{
			AppID: appUp.AppID,
			DevID: appUp.DevID,
			Event: types.UplinkErrorEvent,
			Data:  types.ErrorEventData{Error: fmt.Sprintf("Unable to decode payload fields: %s", err)},
		}

		// Do not set fields if processing failed, but allow the handler to continue processing
		// without payload formatting
		return nil
	}

	if !valid {
		return errors.NewErrInvalidArgument("Payload", "payload validator function returned false")
	}

	// Check if the functions return valid JSON
	_, err = json.Marshal(fields)
	if err != nil {
		// Emit the error
		h.qEvent <- &types.DeviceEvent{
			AppID: appUp.AppID,
			DevID: appUp.DevID,
			Event: types.UplinkErrorEvent,
			Data:  types.ErrorEventData{Error: fmt.Sprintf("Payload Function output cannot be marshaled to JSON: %s", err.Error())},
		}

		// Do not set fields if processing failed, but allow the handler to continue processing
		// without payload formatting
		return nil
	}

	appUp.PayloadFields = fields
	appUp.Attributes = dev.Attributes

	return nil
}
source: func (a *Autopilot) MinRaftProtocol() (int, error) {
	return minRaftProtocol(a.delegate.Serf().Members(), a.delegate.IsServer)
}
source: func getImageComponents(
	g genericgraph.Graph,
	processedImages map[*imagegraph.ImageNode]*Job,
	image *imagegraph.ImageNode,
) (components ComponentRetentions, blocked bool) {
	components = make(ComponentRetentions)

	for _, node := range g.From(image) {
		kinds := g.EdgeKinds(g.Edge(image, node))
		if len(kinds.Intersection(sets.NewString(
			ReferencedImageLayerEdgeKind,
			ReferencedImageConfigEdgeKind,
			ReferencedImageManifestEdgeKind,
		))) == 0 {
			continue
		}

		imageStrongRefCounter := 0
		imageMarkedForDeletionCounter := 0
		referencingStreams := map[*imagegraph.ImageStreamNode]struct{}{}
		referencingImages := map[*imagegraph.ImageNode]struct{}{}

		comp, ok := node.(*imagegraph.ImageComponentNode)
		if !ok {
			continue
		}

		for _, ref := range g.To(comp) {
			switch t := ref.(type) {
			case (*imagegraph.ImageNode):
				imageStrongRefCounter++
				if _, processed := processedImages[t]; processed {
					imageMarkedForDeletionCounter++
				}
				referencingImages[t] = struct{}{}

			case *imagegraph.ImageStreamNode:
				referencingStreams[t] = struct{}{}

			default:
				continue
			}
		}

		switch {
		// the component is referenced only by the given image -> prunable globally
		case imageStrongRefCounter < 2:
			components.Add(comp, true)
		// the component can be pruned once the other referencing image that is being deleted is finished;
		// don't touch it until then
		case imageStrongRefCounter-imageMarkedForDeletionCounter < 2:
			return nil, true
		// not prunable component
		default:
			components.Add(comp, false)
		}

		if addComponentReferencingStreams(
			g,
			components,
			referencingImages,
			referencingStreams,
			processedImages,
			comp,
		) {
			return nil, true
		}
	}

	return
}
source: func (u *User) GetEmail() string {
	r, ok := u.Get("email")
	if ok {
		return r.(string)
	}

	return ""
}
source: func NewDockerCgroupNetController() Cgroupnetcls {

	controller := &netCls{
		markchan:         make(chan uint64),
		ReleaseAgentPath: "",
		TriremePath:      "",
	}

	return controller
}
source: func Decision(ref func() ast.Ref) func(*Basic) {
	return func(b *Basic) {
		b.decision = ref
	}
}
source: func Convert_v1alpha1_LoadBalancer_To_kops_LoadBalancer(in *LoadBalancer, out *kops.LoadBalancer, s conversion.Scope) error {
	return autoConvert_v1alpha1_LoadBalancer_To_kops_LoadBalancer(in, out, s)
}
source: func scrubValidationError(err error) error {
	if err == nil {
		return nil
	}
	const stopValidateMessage = "if you choose to ignore these errors, turn validation off with --validate=false"

	if strings.Contains(err.Error(), stopValidateMessage) {
		return goerrors.New(strings.Replace(err.Error(), "; "+stopValidateMessage, "", -1))
	}
	return err
}
source: func (opts *TransactionOptions) Destroy() {
	C.rocksdb_transaction_options_destroy(opts.c)
	opts.c = nil
}
source: func (b *Bulk) Run(list *kapi.List, namespace string) []error {
	after := b.After
	if after == nil {
		after = func(*unstructured.Unstructured, error) bool { return false }
	}
	ignoreError := b.IgnoreError
	if ignoreError == nil {
		ignoreError = func(e error) bool { return false }
	}

	errs := []error{}
	for i := range list.Items {
		item := list.Items[i].DeepCopyObject()
		unstructuredObj, ok := item.(*unstructured.Unstructured)
		if !ok {
			var err error
			converter := runtime.ObjectConvertor(b.Scheme)
			groupVersioner := runtime.GroupVersioner(schema.GroupVersions(b.Scheme.PrioritizedVersionsAllGroups()))
			versionedObj, err := converter.ConvertToVersion(item, groupVersioner)
			if err != nil {
				errs = append(errs, err)
				if after(nil, err) {
					break
				}
				continue
			}
			unstructuredObj = &unstructured.Unstructured{}
			unstructuredObj.Object, err = runtime.DefaultUnstructuredConverter.ToUnstructured(versionedObj)
			if err != nil {
				errs = append(errs, err)
				if after(nil, err) {
					break
				}
				continue
			}
		}

		unstructuredObj, err := b.Op(unstructuredObj, namespace)
		if err != nil && b.Retry != nil {
			if unstructuredObj = b.Retry(unstructuredObj, err); unstructuredObj != nil {
				unstructuredObj, err = b.Op(unstructuredObj, namespace)
			}
		}
		if err != nil {
			if !ignoreError(err) {
				errs = append(errs, err)
			}
			if after(unstructuredObj, err) {
				break
			}
			continue
		}
		list.Items[i] = unstructuredObj
		if after(unstructuredObj, nil) {
			break
		}
	}
	return errs
}
source: func (s *Server) getRunningPods(request *restful.Request, response *restful.Response) {
	pods, err := s.host.GetRunningPods()
	if err != nil {
		response.WriteError(http.StatusInternalServerError, err)
		return
	}
	data, err := encodePods(pods)
	if err != nil {
		response.WriteError(http.StatusInternalServerError, err)
		return
	}
	writeJSONResponse(response, data)
}
source: func (a *DictAcceptor) Reset(p int) {
	a.p = p
	a.final = false
	a.offset = 0
	a.valid = true
}
source: func NewReader(r io.Reader) io.ReadCloser {
	fixedHuffmanDecoderInit()

	var f decompressor
	f.r = makeReader(r)
	f.bits = new([maxNumLit + maxNumDist]int)
	f.codebits = new([numCodes]int)
	f.step = (*decompressor).nextBlock
	f.dict.init(maxMatchOffset, nil)
	return &f
}
source: func NewStringSetFromSlice(s []string) StringSet {
	a := NewStringSetWithCapacity(len(s))
	for _, item := range s {
		a.Add(item)
	}
	return a
}
source: func (a *LogOnExceed) Action(t *Tracker) {
	a.mutex.Lock()
	defer a.mutex.Unlock()
	if !a.acted {
		a.acted = true
		logutil.Logger(context.Background()).Warn("memory exceeds quota",
			zap.Error(errMemExceedThreshold.GenWithStackByArgs(t.label, t.BytesConsumed(), t.bytesLimit, t.String())))
	}
}
source: func ReadDiskStats(stats *DiskStats) error {
	// Open the process disk IO counter file
	inf, err := os.Open(fmt.Sprintf("/proc/%d/io", os.Getpid()))
	if err != nil {
		return err
	}
	defer inf.Close()
	in := bufio.NewReader(inf)

	// Iterate over the IO counter, and extract what we need
	for {
		// Read the next line and split to key and value
		line, err := in.ReadString('\n')
		if err != nil {
			if err == io.EOF {
				return nil
			}
			return err
		}
		parts := strings.Split(line, ":")
		if len(parts) != 2 {
			continue
		}
		key := strings.TrimSpace(parts[0])
		value, err := strconv.ParseInt(strings.TrimSpace(parts[1]), 10, 64)
		if err != nil {
			return err
		}

		// Update the counter based on the key
		switch key {
		case "syscr":
			stats.ReadCount = value
		case "syscw":
			stats.WriteCount = value
		case "rchar":
			stats.ReadBytes = value
		case "wchar":
			stats.WriteBytes = value
		}
	}
}
source: func initLookupCell(level, i, j, origOrientation, pos, orientation int) {
	if level == lookupBits {
		ij := (i << lookupBits) + j
		lookupPos[(ij<<2)+origOrientation] = (pos << 2) + orientation
		lookupIJ[(pos<<2)+origOrientation] = (ij << 2) + orientation
		return
	}

	level++
	i <<= 1
	j <<= 1
	pos <<= 2
	r := posToIJ[orientation]
	initLookupCell(level, i+(r[0]>>1), j+(r[0]&1), origOrientation, pos, orientation^posToOrientation[0])
	initLookupCell(level, i+(r[1]>>1), j+(r[1]&1), origOrientation, pos+1, orientation^posToOrientation[1])
	initLookupCell(level, i+(r[2]>>1), j+(r[2]&1), origOrientation, pos+2, orientation^posToOrientation[2])
	initLookupCell(level, i+(r[3]>>1), j+(r[3]&1), origOrientation, pos+3, orientation^posToOrientation[3])
}
source: func (mc *MerkleClient) FetchRootFromServer(m MetaContext, freshness time.Duration) (mr *MerkleRoot, err error) {
	defer m.VTrace(VLog0, "MerkleClient#FetchRootFromServer", func() error { return err })()

	// on startup, many threads might try to mash this call at once (via the Auditor or
	// other pathways). So protect this with a lock.
	mc.freshLock.Lock()
	defer mc.freshLock.Unlock()

	root := mc.LastRoot()
	now := m.G().Clock().Now()
	if root != nil && freshness > 0 && now.Sub(root.fetched) < freshness {
		m.VLogf(VLog0, "freshness=%d, and was current enough, so returning non-nil previously fetched root", freshness)
		return root, nil
	}
	return mc.fetchRootFromServer(m, root)
}
source: func (nap *NapNap) Run(engine *Server) error {
	engine.Handler = nap
	return engine.ListenAndServe()
}
source: func (f *Filter) Set(filter, value string) {
	f.v.Set(filter, value)
}
source: func validateToken(p Provider, access_token string, header http.Header) bool {
	if access_token == "" || p.Data().ValidateURL == nil {
		return false
	}
	endpoint := p.Data().ValidateURL.String()
	if len(header) == 0 {
		params := url.Values{"access_token": {access_token}}
		endpoint = endpoint + "?" + params.Encode()
	}
	resp, err := api.RequestUnparsedResponse(endpoint, header)
	if err != nil {
		log.Printf("GET %s", stripToken(endpoint))
		log.Printf("token validation request failed: %s", err)
		return false
	}

	body, _ := ioutil.ReadAll(resp.Body)
	resp.Body.Close()
	log.Printf("%d GET %s %s", resp.StatusCode, stripToken(endpoint), body)

	if resp.StatusCode == 200 {
		return true
	}
	log.Printf("token validation request failed: status %d - %s", resp.StatusCode, body)
	return false
}
source: func (daemon *Daemon) containerStatPath(container *container.Container, path string) (stat *types.ContainerPathStat, err error) {
	container.Lock()
	defer container.Unlock()

	if err = daemon.Mount(container); err != nil {
		return nil, err
	}
	defer daemon.Unmount(container)

	err = daemon.mountVolumes(container)
	defer container.DetachAndUnmount(daemon.LogVolumeEvent)
	if err != nil {
		return nil, err
	}

	// Normalize path before sending to rootfs
	path = container.BaseFS.FromSlash(path)

	resolvedPath, absPath, err := container.ResolvePath(path)
	if err != nil {
		return nil, err
	}

	return container.StatPath(resolvedPath, absPath)
}
source: func (r *Request) BodyString(body string) *Request {
	r.BodyBuffer = []byte(body)
	return r
}
source: func (c *CloudAPI) GetMachineTag(machineID, tagKey string) (string, error) {
	machine, err := c.GetMachine(machineID)
	if err != nil {
		return "", err
	}

	val, ok := machine.Tags[tagKey]
	if !ok {
		return "", fmt.Errorf(`tag "%s" not found`, tagKey)
	}

	return val, nil
}
source: func getDosVolumeName(path string) (string, error) {

	var VolumeNameBuffer = make([]uint16, syscall.MAX_PATH+1)
	var nVolumeNameSize = uint32(len(VolumeNameBuffer))

	ret, _, err := queryDosDeviceProc.Call(
		uintptr(unsafe.Pointer(syscall.StringToUTF16Ptr(path))),
		uintptr(unsafe.Pointer(&VolumeNameBuffer[0])),
		uintptr(nVolumeNameSize))

	if ret == 0 {
		return "", err
	}

	return syscall.UTF16ToString(VolumeNameBuffer), nil
}
source: func (s *FirewallService) ConfigurePaloAltoFirewall(p *ConfigurePaloAltoFirewallParams) (*PaloAltoFirewallResponse, error) {
	resp, err := s.cs.newRequest("configurePaloAltoFirewall", p.toURLValues())
	if err != nil {
		return nil, err
	}

	var r PaloAltoFirewallResponse
	if err := json.Unmarshal(resp, &r); err != nil {
		return nil, err
	}

	// If we have a async client, we need to wait for the async result
	if s.cs.async {
		b, err := s.cs.GetAsyncJobResult(r.JobID, s.cs.timeout)
		if err != nil {
			if err == AsyncTimeoutErr {
				return &r, err
			}
			return nil, err
		}

		b, err = getRawValue(b)
		if err != nil {
			return nil, err
		}

		b, err = convertFirewallServiceResponse(b)
		if err != nil {
			return nil, err
		}

		if err := json.Unmarshal(b, &r); err != nil {
			return nil, err
		}
	}

	return &r, nil
}
source: func Load(filename string) (*ClosestMatch, error) {
	cm := new(ClosestMatch)

	f, err := os.Open(filename)
	defer f.Close()
	if err != nil {
		return cm, err
	}

	w, err := gzip.NewReader(f)
	if err != nil {
		return cm, err
	}

	err = json.NewDecoder(w).Decode(&cm)
	return cm, err
}
source: func NewConnWithClusterAndUser(clusterName string, userName string) (*Conn, error) {
	c_cluster_name := C.CString(clusterName)
	defer C.free(unsafe.Pointer(c_cluster_name))

	c_name := C.CString(userName)
	defer C.free(unsafe.Pointer(c_name))

	conn := makeConn()
	ret := C.rados_create2(&conn.cluster, c_cluster_name, c_name, 0)
	if ret == 0 {
		return conn, nil
	} else {
		return nil, RadosError(int(ret))
	}
}
source: func (r *Repository) Branch(name string) (*config.Branch, error) {
	cfg, err := r.Storer.Config()
	if err != nil {
		return nil, err
	}

	b, ok := cfg.Branches[name]
	if !ok {
		return nil, ErrBranchNotFound
	}

	return b, nil
}
source: func NewDeliverClientForPeer(channelID string) (*DeliverClient, error) {
	var tlsCertHash []byte
	pc, err := NewPeerClientFromEnv()
	if err != nil {
		return nil, errors.WithMessage(err, "failed to create deliver client")
	}

	d, err := pc.Deliver()
	if err != nil {
		return nil, errors.WithMessage(err, "failed to create deliver client")
	}

	// check for client certificate and create hash if present
	if len(pc.Certificate().Certificate) > 0 {
		tlsCertHash = util.ComputeSHA256(pc.Certificate().Certificate[0])
	}
	ds := &peerDeliverService{d}
	p := &DeliverClient{
		Service:     ds,
		ChannelID:   channelID,
		TLSCertHash: tlsCertHash,
	}
	return p, nil
}
source: func (p *PushNotification) AddLog(log LogPushEntry) {
	if p.log != nil {
		*p.log = append(*p.log, log)
	}
}
source: func order(r rune) int {
	// all the letters sort earlier than all the non-letters
	if unicode.IsLetter(r) {
		return int(r)
	}

	// a tilde sorts before anything
	if r == '~' {
		return -1
	}

	return int(r) + 256
}
source: func openKeychainRef(path string) (C.SecKeychainRef, error) {
	pathName := C.CString(path)
	defer C.free(unsafe.Pointer(pathName))

	var kref C.SecKeychainRef
	if err := checkError(C.SecKeychainOpen(pathName, &kref)); err != nil {
		return 0, err
	}

	return kref, nil
}
source: func ProjectFromContext(ctx context.Context) (string, error) {
	project, ok := ctx.Value(&luciProjectKey).(string)
	if !ok {
		return "", errors.Reason("LUCI project not available in context").Err()
	}
	if project == "" {
		return "", errors.Reason("LUCI project is empty string").Err()
	}
	return project, nil
}
source: func (h *HLLPP) Merge(other *HLLPP) error {
	if h.p != other.p || h.pp != other.pp {
		return errors.New("HLLPPs have different parameters")
	}

	if h.sparse && !other.sparse {
		h.toNormal()
	}

	if other.sparse {
		other.flushTmpSet()
	}

	if h.sparse && other.sparse {
		tmpSet := make([]uint32, other.sparseLength)
		reader := newSparseReader(other.data)
		for index := 0; !reader.Done(); index++ {
			tmpSet[index] = reader.Next()
		}
		h.mergeSparse(tmpSet)
	} else if !h.sparse && !other.sparse {
		for i := uint32(0); i < h.m; i++ {
			rho := getRegister(other.data, other.bitsPerRegister, i)
			h.updateRegisterIfBigger(i, rho)
		}
	} else {
		reader := newSparseReader(other.data)
		for !reader.Done() {
			idx, rho := other.decodeHash(reader.Next(), other.p)
			h.updateRegisterIfBigger(idx, rho)
		}
	}

	return nil
}
source: 29%|██▉       | 1472/5000 [00:01<00:03, 988.68it/s] func NewAdaptor(host string, clientID string) *Adaptor {
	return &Adaptor{
		name:          gobot.DefaultName("MQTT"),
		Host:          host,
		autoReconnect: false,
		cleanSession:  true,
		useSSL:        false,
		clientID:      clientID,
	}
}
source: func (t *TcpListener) Start(acc telegraf.Accumulator) error {
	t.Lock()
	defer t.Unlock()

	log.Println("W! DEPRECATED: the TCP listener plugin has been deprecated " +
		"in favor of the socket_listener plugin " +
		"(https://github.com/influxdata/telegraf/tree/master/plugins/inputs/socket_listener)")

	tags := map[string]string{
		"address": t.ServiceAddress,
	}
	t.MaxConnections = selfstat.Register("tcp_listener", "max_connections", tags)
	t.MaxConnections.Set(int64(t.MaxTCPConnections))
	t.CurrentConnections = selfstat.Register("tcp_listener", "current_connections", tags)
	t.TotalConnections = selfstat.Register("tcp_listener", "total_connections", tags)
	t.PacketsRecv = selfstat.Register("tcp_listener", "packets_received", tags)
	t.BytesRecv = selfstat.Register("tcp_listener", "bytes_received", tags)

	t.acc = acc
	t.in = make(chan []byte, t.AllowedPendingMessages)
	t.done = make(chan struct{})
	t.accept = make(chan bool, t.MaxTCPConnections)
	t.conns = make(map[string]*net.TCPConn)
	for i := 0; i < t.MaxTCPConnections; i++ {
		t.accept <- true
	}

	// Start listener
	var err error
	address, _ := net.ResolveTCPAddr("tcp", t.ServiceAddress)
	t.listener, err = net.ListenTCP("tcp", address)
	if err != nil {
		log.Fatalf("ERROR: ListenUDP - %s", err)
		return err
	}
	log.Println("I! TCP server listening on: ", t.listener.Addr().String())

	t.wg.Add(2)
	go t.tcpListen()
	go t.tcpParser()

	log.Printf("I! Started TCP listener service on %s\n", t.ServiceAddress)
	return nil
}
source: func (t *Template) GetAWSAppStreamUserWithName(name string) (*resources.AWSAppStreamUser, error) {
	if untyped, ok := t.Resources[name]; ok {
		switch resource := untyped.(type) {
		case *resources.AWSAppStreamUser:
			return resource, nil
		}
	}
	return nil, fmt.Errorf("resource %q of type AWSAppStreamUser not found", name)
}
source: func (h Hash) Uint64(key string) (uint64, error) {
	if value, ok := h[key]; ok {
		return value.Uint64()
	}
	return 0, errors.New(ErrInvalidKey, errorMessages, key)
}
source: func VNCSendCommand(vncProxyInfo *sacloud.VNCProxyResponse, command string, option *SendCommandOption) error {
	host := vncProxyInfo.ActualHost()

	fmt.Fprintf(option.ProgressWriter, "Connecting to VM via VNC...\n")
	// Connect to VNC
	nc, err := net.Dial("tcp", fmt.Sprintf("%s:%s", host, vncProxyInfo.Port))
	if err != nil {
		return fmt.Errorf("Error connecting to VNC: %s", err)
	}
	defer nc.Close()

	fmt.Fprintf(option.ProgressWriter, "Handshaking with VNC...\n")
	// Connect to VNC
	auth := []vnc.ClientAuth{&vnc.PasswordAuth{Password: vncProxyInfo.Password}}
	c, err := vnc.Client(nc, &vnc.ClientConfig{Auth: auth, Exclusive: false})
	if err != nil {
		return fmt.Errorf("Error handshaking with VNC: %s", err)
	}
	defer c.Close()

	wrapper := newVNCClientConnWrapper(c, option.Debug, option.ProgressWriter)

	fmt.Fprintf(option.ProgressWriter, "Sending command...\n")
	vncSendString(wrapper, command, option.UseUSKeyboard)
	fmt.Fprintf(option.ProgressWriter, "Done\n")
	return nil
}
source: func (f *Facade) SetHostExpiration(ctx datastore.Context, hostid string, expiration int64) {
	defer ctx.Metrics().Stop(ctx.Metrics().Start("Facade.SetHostExpiration"))
	f.hostRegistry.Set(hostid, expiration)
}
source: func StatBlob(ctx context.Context, bs BlobStatter, br blob.Ref) (blob.SizedRef, error) {
	var ret blob.SizedRef
	err := bs.StatBlobs(ctx, []blob.Ref{br}, func(sb blob.SizedRef) error {
		ret = sb
		return nil
	})
	if err == nil && !ret.Ref.Valid() {
		err = os.ErrNotExist
	}
	return ret, err
}
source: func (p *Paginater) IsLast() bool {
	if p.total == 0 {
		return true
	}
	return p.total > (p.current-1)*p.pagingNum && !p.HasNext()
}
source: func (o *GetJSONWebKeySetParams) WithTimeout(timeout time.Duration) *GetJSONWebKeySetParams {
	o.SetTimeout(timeout)
	return o
}
source: func (c *RegionCache) loadRegion(bo *Backoffer, key []byte, isEndKey bool) (*Region, error) {
	var backoffErr error
	searchPrev := false
	for {
		if backoffErr != nil {
			err := bo.Backoff(BoPDRPC, backoffErr)
			if err != nil {
				return nil, errors.Trace(err)
			}
		}
		var meta *metapb.Region
		var leader *metapb.Peer
		var err error
		if searchPrev {
			meta, leader, err = c.pdClient.GetPrevRegion(bo.ctx, key)
		} else {
			meta, leader, err = c.pdClient.GetRegion(bo.ctx, key)
		}
		if err != nil {
			tikvRegionCacheCounterWithGetRegionError.Inc()
		} else {
			tikvRegionCacheCounterWithGetRegionOK.Inc()
		}
		if err != nil {
			backoffErr = errors.Errorf("loadRegion from PD failed, key: %q, err: %v", key, err)
			continue
		}
		if meta == nil {
			backoffErr = errors.Errorf("region not found for key %q", key)
			continue
		}
		if len(meta.Peers) == 0 {
			return nil, errors.New("receive Region with no peer")
		}
		if isEndKey && !searchPrev && bytes.Compare(meta.StartKey, key) == 0 && len(meta.StartKey) != 0 {
			searchPrev = true
			continue
		}
		region := &Region{
			meta: meta,
			peer: meta.Peers[0],
		}
		if leader != nil {
			region.SwitchPeer(leader.GetStoreId())
		}
		return region, nil
	}
}
source: func NewMux() ServeMux {
	r := httptreemux.New()
	r.EscapeAddedRoutes = true
	return &mux{
		router:  r,
		handles: make(map[string]MuxHandler),
	}
}
source: func (l *ListenerConn) setState(newState int32) bool {
	var expectedState int32

	switch newState {
	case connStateIdle:
		expectedState = connStateExpectReadyForQuery
	case connStateExpectResponse:
		expectedState = connStateIdle
	case connStateExpectReadyForQuery:
		expectedState = connStateExpectResponse
	default:
		panic(fmt.Sprintf("unexpected listenerConnState %d", newState))
	}

	return atomic.CompareAndSwapInt32(&l.connState, expectedState, newState)
}
source: func NewCmdConfigPrint(out io.Writer) *cobra.Command {
	cmd := &cobra.Command{
		Use:   "print",
		Short: "Print configuration",
		Long:  "This command prints configurations for subcommands provided.",
		RunE:  cmdutil.SubCmdRunE("print"),
	}
	cmd.AddCommand(NewCmdConfigPrintInitDefaults(out))
	cmd.AddCommand(NewCmdConfigPrintJoinDefaults(out))
	return cmd
}
source: func (client *Client) Capture(packet *Packet, captureTags map[string]string) (eventID string, ch chan error) {
	ch = make(chan error, 1)

	if client == nil {
		// return a chan that always returns nil when the caller receives from it
		close(ch)
		return
	}

	if client.sampleRate < 1.0 && mrand.Float32() > client.sampleRate {
		return
	}

	if packet == nil {
		close(ch)
		return
	}

	if client.shouldExcludeErr(packet.Message) {
		return
	}

	// Keep track of all running Captures so that we can wait for them all to finish
	// *Must* call client.wg.Done() on any path that indicates that an event was
	// finished being acted upon, whether success or failure
	client.wg.Add(1)

	// Merge capture tags and client tags
	packet.AddTags(captureTags)
	packet.AddTags(client.Tags)

	// Initialize any required packet fields
	client.mu.RLock()
	packet.AddTags(client.context.tags)
	projectID := client.projectID
	release := client.release
	environment := client.environment
	defaultLoggerName := client.defaultLoggerName
	client.mu.RUnlock()

	// set the global logger name on the packet if we must
	if packet.Logger == "" && defaultLoggerName != "" {
		packet.Logger = defaultLoggerName
	}

	err := packet.Init(projectID)
	if err != nil {
		ch <- err
		client.wg.Done()
		return
	}

	if packet.Release == "" {
		packet.Release = release
	}

	if packet.Environment == "" {
		packet.Environment = environment
	}

	outgoingPacket := &outgoingPacket{packet, ch}

	// Lazily start background worker until we
	// do our first write into the queue.
	client.start.Do(func() {
		go client.worker()
	})

	select {
	case client.queue <- outgoingPacket:
	default:
		// Send would block, drop the packet
		if client.DropHandler != nil {
			client.DropHandler(packet)
		}
		ch <- ErrPacketDropped
		client.wg.Done()
	}

	return packet.EventID, ch
}
source: func (actor Actor) RestartApplication(appGUID string) (Warnings, error) {
	_, warnings, err := actor.CloudControllerClient.UpdateApplicationRestart(appGUID)

	return Warnings(warnings), err
}
source: func NewMockDiscoveryService(err error, peers ...fab.Peer) *MockStaticDiscoveryService {
	return &MockStaticDiscoveryService{Error: err, Peers: peers}
}
source: func (m *JobExecutor) WalkDrop(p *plan.Drop) (Task, error) {
	root := m.NewTask(p)
	return root, root.Add(NewDrop(m.Ctx, p))
}
source: func (w LogWriter) Write(bytes []byte) (int, error) {
	if len(bytes) > 0 {
		return fmt.Fprint(Output, Yellow.Regular("["), time.Now().Format("15:04:05"), Yellow.Regular("]"), string(bytes))
	}
	return 0, nil
}
source: func (s *ListJobsInput) SetStatuscode(v string) *ListJobsInput {
	s.Statuscode = &v
	return s
}
source: func Unmarshal(r *request.Request) {
	if r.DataFilled() {
		v := reflect.Indirect(reflect.ValueOf(r.Data))
		unmarshalBody(r, v)
	}
}
source: func (t Term) Downcase(args ...interface{}) Term {
	return constructMethodTerm(t, "Downcase", p.Term_DOWNCASE, args, map[string]interface{}{})
}
source: func (b *ByteBuf) Skip(n int) error {
	if n > b.Readable() {
		return io.ErrShortBuffer
	}

	b.readerIndex += n
	return nil
}
source: func (cacher *txSenderCacher) recover(signer types.Signer, txs []*types.Transaction) {
	// If there's nothing to recover, abort
	if len(txs) == 0 {
		return
	}
	// Ensure we have meaningful task sizes and schedule the recoveries
	tasks := cacher.threads
	if len(txs) < tasks*4 {
		tasks = (len(txs) + 3) / 4
	}
	for i := 0; i < tasks; i++ {
		cacher.tasks <- &txSenderCacherRequest{
			signer: signer,
			txs:    txs[i:],
			inc:    tasks,
		}
	}
}
source: func CachePathObj(cachepath, oname, storeid string) string {
	obase := path.Base(oname)
	opath := path.Dir(oname)
	ext := path.Ext(oname)
	ext2 := fmt.Sprintf("%s.%s%s", ext, storeid, StoreCacheFileExt)
	var obase2 string
	if ext == "" {
		obase2 = obase + ext2
	} else {
		obase2 = strings.Replace(obase, ext, ext2, 1)
	}
	return path.Join(cachepath, opath, obase2)
}
source: func getEmptyFields() map[string]interface{} {
	fields := map[string]interface{}{
		"blocked":  int64(0),
		"zombies":  int64(0),
		"stopped":  int64(0),
		"running":  int64(0),
		"sleeping": int64(0),
		"total":    int64(0),
		"unknown":  int64(0),
	}
	switch runtime.GOOS {
	case "freebsd":
		fields["idle"] = int64(0)
		fields["wait"] = int64(0)
	case "darwin":
		fields["idle"] = int64(0)
	case "openbsd":
		fields["idle"] = int64(0)
	case "linux":
		fields["dead"] = int64(0)
		fields["paging"] = int64(0)
		fields["total_threads"] = int64(0)
		fields["idle"] = int64(0)
	}
	return fields
}
source: func (db *usersDB) Insert(email, fullname string) (schema.User, error) {
	defer db.mutex.Unlock()
	db.mutex.Lock()

	u := schema.User{
		Email:    email,
		Fullname: fullname,
	}
	db.users[email] = u
	return u, nil
}
source: func NewVppClientWithInputQueueSize(shmPrefix string, inputQueueSize uint16) adapter.VppAPI {
	return &vppClient{
		shmPrefix:      shmPrefix,
		inputQueueSize: inputQueueSize,
	}
}
source: func (n *Net) StartProcess() (int, error) {
	listeners, err := n.activeListeners()
	if err != nil {
		return 0, err
	}

	// Extract the fds from the listeners.
	files := make([]*os.File, len(listeners))
	for i, l := range listeners {
		files[i], err = l.(filer).File()
		if err != nil {
			return 0, err
		}
		defer files[i].Close()
	}

	// Use the original binary location. This works with symlinks such that if
	// the file it points to has been changed we will use the updated symlink.
	argv0, err := exec.LookPath(os.Args[0])
	if err != nil {
		return 0, err
	}

	// Pass on the environment and replace the old count key with the new one.
	var env []string
	for _, v := range os.Environ() {
		if !strings.HasPrefix(v, envCountKeyPrefix) {
			env = append(env, v)
		}
	}
	env = append(env, fmt.Sprintf("%s%d", envCountKeyPrefix, len(listeners)))

	allFiles := append([]*os.File{os.Stdin, os.Stdout, os.Stderr}, files...)
	process, err := os.StartProcess(argv0, os.Args, &os.ProcAttr{
		Dir:   originalWD,
		Env:   env,
		Files: allFiles,
	})
	if err != nil {
		return 0, err
	}
	return process.Pid, nil
}
source: func DebugFlush(ctx context.Context, next http.Handler, f Flusher) http.HandlerFunc {
	return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		if r.URL.Path == "/debug/flush" {
			f.Flush(ctx)
			w.Header().Set("Content-Type", "text/html; charset=utf-8")
			w.WriteHeader(http.StatusOK)
			return
		}
		next.ServeHTTP(w, r)
	})
}
source: func checkStatus() error {

	if client := kvstore.Client(); client == nil {
		return fmt.Errorf("kvstore client not configured")
	} else if _, err := client.Status(); err != nil {
		return err
	} else if _, err := k8s.Client().Discovery().ServerVersion(); err != nil {
		return err
	}

	return nil
}
source: func (j *Driver) findHatName(id uint8, hat uint8, list []hat) string {
	for _, lHat := range list {
		if int(id) == lHat.ID && int(hat) == lHat.Hat {
			return lHat.Name
		}
	}
	return ""
}
source: func (is *store) GetLastUpdated(id ID) (time.Time, error) {
	bytes, err := is.fs.GetMetadata(id.Digest(), "lastUpdated")
	if err != nil || len(bytes) == 0 {
		// No lastUpdated time
		return time.Time{}, nil
	}
	return time.Parse(time.RFC3339Nano, string(bytes))
}
source: func doCopy(dst net.Conn, src net.Conn, buf []byte, errCh chan error, stop *uint32) {
	var err error
	defer func() {
		atomic.StoreUint32(stop, 1)
		dst.SetReadDeadline(time.Now().Add(copyTimeout))
		errCh <- err
	}()

	defer func() {
		p := recover()
		if p != nil {
			err = errors.New("Panic while copying: %v", p)
		}
	}()

	for {
		stopping := atomic.LoadUint32(stop) == 1
		if stopping {
			src.SetReadDeadline(time.Now().Add(copyTimeout))
		}
		nr, er := src.Read(buf)
		if nr > 0 {
			nw, ew := dst.Write(buf[0:nr])
			if ew != nil {
				err = ew
				return
			}
			if nw != nr {
				err = io.ErrShortWrite
				return
			}
		}
		if er == io.EOF {
			return
		}
		if er != nil {
			if IsTimeout(er) {
				if stopping {
					return
				}
			} else {
				err = er
				return
			}
		}
	}
}
source: func AllocateSlice(slicePtr interface{}, capacity int) *Allocation {
	slicePtrType := reflect.TypeOf(slicePtr)
	if slicePtrType.Kind() != reflect.Ptr {
		panic("AllocateSlice: slicePtr must be a pointer to a slice")
	}
	sliceType := slicePtrType.Elem()
	if sliceType.Kind() != reflect.Slice {
		panic("AllocateSlice: slicePtr must be a pointer to a slice")
	}

	size := sliceType.Size() * uintptr(capacity)
	alloc := Allocate(size)

	// The slicePtr is actually two words: typeTable, sliceHeaderPtr
	slice := (*reflect.SliceHeader)((*[2]unsafe.Pointer)(unsafe.Pointer(&slicePtr))[1])

	// Set the underlying fields in the slice header.
	slice.Len = 0
	slice.Cap = capacity
	slice.Data = uintptr(alloc.Ptr())

	return alloc
}
source: func (m *testRPC) currentMocks(t *testing.T) *mockedMethods {
	m.lock.Lock()
	defer m.lock.Unlock()

	if t == nil {
		t = m.currentTest
	} else {
		m.currentTest = t
	}

	mocks := m.mocks[t]
	if mocks == nil {
		mocks = &mockedMethods{}
		m.mocks[t] = mocks
	}

	return mocks
}
source: func (s *ObjectLockConfiguration) SetObjectLockEnabled(v string) *ObjectLockConfiguration {
	s.ObjectLockEnabled = &v
	return s
}
source: func (s *store) WatchList(ctx context.Context, key string, resourceVersion string, pred storage.SelectionPredicate) (watch.Interface, error) {
	return s.watch(ctx, key, resourceVersion, pred, true)
}
source: func (t *TokenProvider) GetToken(audience string) (*auth.Token, error) {
	signature, expiry := t.signer.SignWithDuration(audience, 2*time.Hour)
	return auth.NewToken(auth.CBSTokenTypeSAS, signature, expiry), nil
}
source: func applySlice(dst reflect.Value, src reflect.Value) error {
	dst.Set(reflect.MakeSlice(dst.Type(), src.Len(), src.Len()))
	dstElemType := dst.Type().Elem()
	for i := 0; i < src.Len(); i++ {
		v, err := convert(src.Index(i), dstElemType)
		if err != nil {
			return fmt.Errorf("Invalid %dth value: %s", i, err)
		}
		dst.Index(i).Set(v)
	}
	return nil
}
source: func NewMultiResourcePool(
	options Options,
	createPool func(Options) ResourcePool) ResourcePool {

	if createPool == nil {
		createPool = NewSimpleResourcePool
	}

	return &multiResourcePool{
		options:       options,
		createPool:    createPool,
		rwMutex:       sync.RWMutex{},
		isLameDuck:    false,
		locationPools: make(map[string]ResourcePool),
	}
}
source: func (m *Manager) BuildHandlers(rootCtx context.Context, entryPoints []string) map[string]*tcp.Router {
	entryPointsRouters := m.filteredRouters(rootCtx, entryPoints)

	entryPointHandlers := make(map[string]*tcp.Router)
	for _, entryPointName := range entryPoints {
		entryPointName := entryPointName

		routers := entryPointsRouters[entryPointName]

		ctx := log.With(rootCtx, log.Str(log.EntryPointName, entryPointName))

		handler, err := m.buildEntryPointHandler(ctx, routers, m.httpHandlers[entryPointName], m.httpsHandlers[entryPointName])
		if err != nil {
			log.FromContext(ctx).Error(err)
			continue
		}
		entryPointHandlers[entryPointName] = handler
	}
	return entryPointHandlers
}
source: func (veth *VethPair) SetPeerLinkNsToDocker(name string, dockerHost string) error {
	pid, err := DockerPidByName(name, dockerHost)
	if err != nil {
		return fmt.Errorf("Failed to find docker %s :  %s", name, err)
	}

	return netlink.NetworkSetNsPid(veth.peerIfc, pid)
}
source: func (m *model) handleAutoAccepts(deviceCfg config.DeviceConfiguration, folder protocol.Folder) bool {
	if cfg, ok := m.cfg.Folder(folder.ID); !ok {
		defaultPath := m.cfg.Options().DefaultFolderPath
		defaultPathFs := fs.NewFilesystem(fs.FilesystemTypeBasic, defaultPath)
		pathAlternatives := []string{
			sanitizePath(folder.Label),
			sanitizePath(folder.ID),
		}
		for _, path := range pathAlternatives {
			if _, err := defaultPathFs.Lstat(path); !fs.IsNotExist(err) {
				continue
			}

			fcfg := config.NewFolderConfiguration(m.id, folder.ID, folder.Label, fs.FilesystemTypeBasic, filepath.Join(defaultPath, path))
			fcfg.Devices = append(fcfg.Devices, config.FolderDeviceConfiguration{
				DeviceID: deviceCfg.DeviceID,
			})
			// Need to wait for the waiter, as this calls CommitConfiguration,
			// which sets up the folder and as we return from this call,
			// ClusterConfig starts poking at m.folderFiles and other things
			// that might not exist until the config is committed.
			w, _ := m.cfg.SetFolder(fcfg)
			w.Wait()

			l.Infof("Auto-accepted %s folder %s at path %s", deviceCfg.DeviceID, folder.Description(), fcfg.Path)
			return true
		}
		l.Infof("Failed to auto-accept folder %s from %s due to path conflict", folder.Description(), deviceCfg.DeviceID)
		return false
	} else {
		for _, device := range cfg.DeviceIDs() {
			if device == deviceCfg.DeviceID {
				// Already shared nothing todo.
				return false
			}
		}
		cfg.Devices = append(cfg.Devices, config.FolderDeviceConfiguration{
			DeviceID: deviceCfg.DeviceID,
		})
		w, _ := m.cfg.SetFolder(cfg)
		w.Wait()
		l.Infof("Shared %s with %s due to auto-accept", folder.ID, deviceCfg.DeviceID)
		return true
	}
}
source: func (b *Backend) Get(ctx context.Context, key string) (*physical.Entry, error) {
	defer metrics.MeasureSince(metricList, time.Now())

	// Pooling
	b.permitPool.Acquire()
	defer b.permitPool.Release()

	// Read
	row, err := b.client.Single().ReadRow(ctx, b.table, spanner.Key{key}, []string{"Value"})
	if spanner.ErrCode(err) == codes.NotFound {
		return nil, nil
	}
	if err != nil {
		return nil, errwrap.Wrapf(fmt.Sprintf("failed to read value for %q: {{err}}", key), err)
	}

	var value []byte
	if err := row.Column(0, &value); err != nil {
		return nil, errwrap.Wrapf("failed to decode value into bytes: {{err}}", err)
	}

	return &physical.Entry{
		Key:   key,
		Value: value,
	}, nil
}
source: func (o *GetEndpointIDConfigParams) WithHTTPClient(client *http.Client) *GetEndpointIDConfigParams {
	o.SetHTTPClient(client)
	return o
}
source: func (q *PlanQueue) Stats() *QueueStats {
	// Allocate a new stats struct
	stats := new(QueueStats)

	q.l.RLock()
	defer q.l.RUnlock()

	// Copy all the stats
	*stats = *q.stats
	return stats
}
source: func (c MaxReplicationLagModuleConfig) MinDurationBetweenDecreases() time.Duration {
	return time.Duration(c.MinDurationBetweenDecreasesSec) * time.Second
}
source: func (f *RegexFilter) WouldLog(keyvals ...interface{}) bool {
	if f.Disabled() {
		return false
	}
	m := mapFromKeyvals(f.MissingValueKey, keyvals...)
	shouldPass := false
	f.mu.RLock()
	if matches(f.currentFilters, m, f.ErrCallback) {
		shouldPass = true
	}
	f.mu.RUnlock()
	if shouldPass {
		return true
	}
	return false
}
source: func (s *DescribeTransformJobOutput) SetTransformStartTime(v time.Time) *DescribeTransformJobOutput {
	s.TransformStartTime = &v
	return s
}
source: func (m *Manager) Snapshot(path string) error {
	m.lock.Lock()
	defer m.lock.Unlock()
	return m.snapshot(path, false)
}
source: func (b *TimeRangeIterator) readBlock(e *IndexEntry) bool {
	_, b.buf, b.err = b.r.ReadBytes(e, b.buf)
	if b.err != nil {
		return false
	}

	b.err = DecodeTimestampArrayBlock(b.buf, &b.a)
	if b.err != nil {
		return false
	}

	b.stats.ScannedBytes += b.a.Len() * 8 // sizeof Timestamp (int64)
	b.stats.ScannedValues += b.a.Len()
	return true
}
source: func (m *ServeMux) ListenAndServe(addr string) error {
	m.Prepare()

	server := &http.Server{Addr: addr, Handler: m}
	return server.ListenAndServe()
}
source: func (s *TestAuthorizationInput) SetAuthInfos(v []*AuthInfo) *TestAuthorizationInput {
	s.AuthInfos = v
	return s
}
source: func ReadTimetag(data []byte) (Timetag, error) {
	if len(data) < TimetagSize {
		return Timetag(0), errors.New("timetags must be 64-bit")
	}
	zero := []byte{0, 0, 0, 0}
	var (
		L     = append(zero, data[:TimetagSize/2]...)
		R     = append(zero, data[TimetagSize/2:]...)
		secs  uint64
		nsecs uint64
	)
	_ = binary.Read(bytes.NewReader(L), byteOrder, &secs)  // Never fails
	_ = binary.Read(bytes.NewReader(R), byteOrder, &nsecs) // Never fails
	return Timetag((secs << 32) + nsecs), nil
}
source: func (r *reader) ReadRune() (ch rune, size int, err error) {
	ch, _ = r.read()
	if ch == eof {
		err = io.EOF
	}
	return
}
source: func DataFrom(folder keybase1.Folder) Data {
	return Data{
		Name:       folder.Name,
		FolderType: folder.FolderType,
		Private:    folder.Private,
		TeamID:     folder.TeamID,
	}
}
source: func OrderAndCheckPartitions(cell string, srvKeyspace *topodatapb.SrvKeyspace) error {
	// now check them all
	for _, partition := range srvKeyspace.Partitions {
		tabletType := partition.ServedType
		topoproto.ShardReferenceArray(partition.ShardReferences).Sort()

		// check the first Start is MinKey, the last End is MaxKey,
		// and the values in between match: End[i] == Start[i+1]
		first := partition.ShardReferences[0]
		if first.KeyRange != nil && len(first.KeyRange.Start) != 0 {
			return fmt.Errorf("keyspace partition for %v in cell %v does not start with min key", tabletType, cell)
		}
		last := partition.ShardReferences[len(partition.ShardReferences)-1]
		if last.KeyRange != nil && len(last.KeyRange.End) != 0 {
			return fmt.Errorf("keyspace partition for %v in cell %v does not end with max key", tabletType, cell)
		}
		for i := range partition.ShardReferences[0 : len(partition.ShardReferences)-1] {
			currShard := partition.ShardReferences[i]
			nextShard := partition.ShardReferences[i+1]
			currHasKeyRange := currShard.KeyRange != nil
			nextHasKeyRange := nextShard.KeyRange != nil
			if currHasKeyRange != nextHasKeyRange {
				return fmt.Errorf("shards with inconsistent KeyRanges for %v in cell %v. shards: %v, %v", tabletType, cell, currShard, nextShard)
			}
			if !currHasKeyRange {
				// this is the custom sharding case, all KeyRanges must be nil
				continue
			}
			if !bytes.Equal(currShard.KeyRange.End, nextShard.KeyRange.Start) {
				return fmt.Errorf("non-contiguous KeyRange values for %v in cell %v at shard %v to %v: %v != %v", tabletType, cell, i, i+1, hex.EncodeToString(currShard.KeyRange.End), hex.EncodeToString(nextShard.KeyRange.Start))
			}
		}
	}

	return nil
}
source: func defaultClientDockerConfig() credentialprovider.DockerConfig {
	// support the modern config file $HOME/.docker/config.json
	if cfg, err := credentialprovider.ReadDockerConfigJSONFile(defaultPathsForCredentials()); err == nil {
		return cfg
	}
	// support the legacy config file $HOME/.dockercfg
	if cfg, err := credentialprovider.ReadDockercfgFile(defaultPathsForLegacyCredentials()); err == nil {
		return cfg
	}
	return credentialprovider.DockerConfig{}
}
source: func NewErrors() *Errors {
	return &Errors{
		Errors: make(map[string][]string),
		Lock:   new(sync.RWMutex),
	}
}
source: func (b *Bucket) GetRaw(k string) ([]byte, error) {
	d, _, _, err := b.GetsRaw(k)
	return d, err
}
source: func (c *Config) Attrs() map[string]interface{} {
	if c.attrs == nil {
		return nil
	}
	attrs := make(map[string]interface{})
	for k, v := range c.attrs {
		attrs[k] = v
	}
	return attrs
}
source: func NewHandlerWrapper(service micro.Service) server.HandlerWrapper {
	return func(h server.HandlerFunc) server.HandlerFunc {
		return func(ctx context.Context, req server.Request, rsp interface{}) error {
			ctx = micro.NewContext(ctx, service)
			return h(ctx, req, rsp)
		}
	}
}
source: func NewNeutrinoClient(chainParams *chaincfg.Params,
	chainService *neutrino.ChainService) *NeutrinoClient {

	return &NeutrinoClient{
		CS:          chainService,
		chainParams: chainParams,
	}
}
source: func RequestLoggerHandler(c *gin.Context) {
	if c.Request != nil {

		buf, _ := ioutil.ReadAll(c.Request.Body)
		c.Request.Body.Close()

		log.Println("-----------------------------------------------------------------------------------------------------")
		log.Println("REQUEST HEADERS:")
		for k, v := range c.Request.Header {
			log.Printf("\t%s: %s\n", k, v)
		}
		log.Printf("\nREQUEST BODY:\n%s\n", buf)
		log.Println("-----------------------------------------------------------------------------------------------------")

		c.Request.Body = ioutil.NopCloser(bytes.NewReader(buf))
	}
	c.Next()
}
source: func periodic() {
	contents, err := ioutil.ReadFile(procStatFile)
	if err != nil {
		return
	}
	fields := bytes.Fields(contents)

	// PCPU
	pstart := parseInt64(fields[startPos])
	utime := parseInt64(fields[utimePos])
	stime := parseInt64(fields[stimePos])
	total := utime + stime

	var sysinfo syscall.Sysinfo_t
	if err := syscall.Sysinfo(&sysinfo); err != nil {
		return
	}

	seconds := int64(sysinfo.Uptime) - (pstart / ticks)

	// Save off temps
	lt := lastTotal
	ls := lastSeconds

	// Update last sample
	lastTotal = total
	lastSeconds = seconds

	// Adjust to current time window
	total -= lt
	seconds -= ls

	if seconds > 0 {
		atomic.StoreInt64(&ipcpu, (total*1000/ticks)/seconds)
	}

	time.AfterFunc(1*time.Second, periodic)
}
source: func (s *DescribeConfigurationSetInput) SetConfigurationSetAttributeNames(v []*string) *DescribeConfigurationSetInput {
	s.ConfigurationSetAttributeNames = v
	return s
}
source: func getWriterFromUI(ui cli.Ui) io.Writer {
	switch t := ui.(type) {
	case *VaultUI:
		return getWriterFromUI(t.Ui)
	case *cli.BasicUi:
		return t.Writer
	case *cli.ColoredUi:
		return getWriterFromUI(t.Ui)
	case *cli.ConcurrentUi:
		return getWriterFromUI(t.Ui)
	case *cli.MockUi:
		return t.OutputWriter
	default:
		return os.Stdout
	}
}
source: func Convert_v1_ClusterRoleScopeRestriction_To_oauth_ClusterRoleScopeRestriction(in *v1.ClusterRoleScopeRestriction, out *oauth.ClusterRoleScopeRestriction, s conversion.Scope) error {
	return autoConvert_v1_ClusterRoleScopeRestriction_To_oauth_ClusterRoleScopeRestriction(in, out, s)
}
source: func (s Schema) RetrieveColumn(col *Column) *Column {
	index := s.GetColumnIndex(col)
	if index != -1 {
		return s.Columns[index]
	}
	return nil
}
source: func MatchFlags(flags []string, c *imap.SearchCriteria) bool {
	flagsMap := make(map[string]bool)
	for _, f := range flags {
		flagsMap[f] = true
	}

	return matchFlags(flagsMap, c)
}
source: func (h *UserHandler) ListTrackersSelf(ctx context.Context, sessionID int) ([]keybase1.Tracker, error) {
	eng := engine.NewListTrackersSelf()
	return h.listTrackers(ctx, sessionID, eng)
}
source: func NewBundlerFromPEM(caBundlePEM, intBundlePEM []byte, opt ...Option) (*Bundler, error) {
	opts := defaultOptions
	for _, o := range opt {
		o(&opts)
	}

	log.Debug("parsing root certificates from PEM")
	roots, err := helpers.ParseCertificatesPEM(caBundlePEM)
	if err != nil {
		log.Errorf("failed to parse root bundle: %v", err)
		return nil, errors.New(errors.RootError, errors.ParseFailed)
	}

	log.Debug("parse intermediate certificates from PEM")
	intermediates, err := helpers.ParseCertificatesPEM(intBundlePEM)
	if err != nil {
		log.Errorf("failed to parse intermediate bundle: %v", err)
		return nil, errors.New(errors.IntermediatesError, errors.ParseFailed)
	}

	b := &Bundler{
		KnownIssuers:     map[string]bool{},
		IntermediatePool: x509.NewCertPool(),
		opts:             opts,
	}

	log.Debug("building certificate pools")

	// RootPool will be nil if caBundlePEM is nil, also
	// that translates to caBundleFile is "".
	// Systems root store will be used.
	if caBundlePEM != nil {
		b.RootPool = x509.NewCertPool()
	}

	for _, c := range roots {
		b.RootPool.AddCert(c)
		b.KnownIssuers[string(c.Signature)] = true
	}

	for _, c := range intermediates {
		b.IntermediatePool.AddCert(c)
		b.KnownIssuers[string(c.Signature)] = true
	}

	log.Debug("bundler set up")
	return b, nil
}
source: func NewRequestChildNodesArgs(nodeID NodeID) *RequestChildNodesArgs {
	args := new(RequestChildNodesArgs)
	args.NodeID = nodeID
	return args
}
source: func getCompleteMultipartMD5(ctx context.Context, parts []CompletePart) (string, error) {
	var finalMD5Bytes []byte
	for _, part := range parts {
		md5Bytes, err := hex.DecodeString(canonicalizeETag(part.ETag))
		if err != nil {
			logger.LogIf(ctx, err)
			return "", err
		}
		finalMD5Bytes = append(finalMD5Bytes, md5Bytes...)
	}
	s3MD5 := fmt.Sprintf("%s-%d", getMD5Hash(finalMD5Bytes), len(parts))
	return s3MD5, nil
}
source: func Catch(signals []os.Signal, then func()) {
	c := make(chan os.Signal)
	if signals == nil {
		signals = defaultSignals
	}
	signal.Notify(c, signals...)
	<-c
	if then != nil {
		then()
	}
}
source: func AddModule(id string, m ModuleLoader) {
	globalMu.Lock()
	globalModules[id] = m
	globalMu.Unlock()
}
source: func New(r io.Reader) (*WebmKeeper, error) {
	p := webmEdtd.NewParser(r)
	header := bytes.NewBuffer(make([]byte, 0, 4096))
	body := bytes.NewBuffer(make([]byte, 0, 4096))

	for {
		el, err := next(p)
		if err != nil {
			return nil, err
		}

		if el.Name == "Cluster" {
			el.WriteTo(body)
			break
		}
		el.WriteTo(header)
	}

	return &WebmKeeper{
		p:       p,
		header:  header,
		body:    body,
		elemBuf: bytes.NewBuffer(make([]byte, 0, 1024)),
	}, nil
}
source: func (kl *Kubelet) ListenAndServeReadOnly(address net.IP, port uint) {
	server.ListenAndServeKubeletReadOnlyServer(kl, kl.resourceAnalyzer, address, port)
}
source: func (p *MemPostings) Delete(deleted map[uint64]struct{}) {
	var keys, vals []string

	// Collect all keys relevant for deletion once. New keys added afterwards
	// can by definition not be affected by any of the given deletes.
	p.mtx.RLock()
	for n := range p.m {
		keys = append(keys, n)
	}
	p.mtx.RUnlock()

	for _, n := range keys {
		p.mtx.RLock()
		vals = vals[:0]
		for v := range p.m[n] {
			vals = append(vals, v)
		}
		p.mtx.RUnlock()

		// For each posting we first analyse whether the postings list is affected by the deletes.
		// If yes, we actually reallocate a new postings list.
		for _, l := range vals {
			// Only lock for processing one postings list so we don't block reads for too long.
			p.mtx.Lock()

			found := false
			for _, id := range p.m[n][l] {
				if _, ok := deleted[id]; ok {
					found = true
					break
				}
			}
			if !found {
				p.mtx.Unlock()
				continue
			}
			repl := make([]uint64, 0, len(p.m[n][l]))

			for _, id := range p.m[n][l] {
				if _, ok := deleted[id]; !ok {
					repl = append(repl, id)
				}
			}
			if len(repl) > 0 {
				p.m[n][l] = repl
			} else {
				delete(p.m[n], l)
			}
			p.mtx.Unlock()
		}
		p.mtx.Lock()
		if len(p.m[n]) == 0 {
			delete(p.m, n)
		}
		p.mtx.Unlock()
	}
}
source: func (e *Environ) TagInstance(ctx context.ProviderCallContext, id instance.Id, tags map[string]string) error {
	if err := e.nova().SetServerMetadata(string(id), tags); err != nil {
		common.HandleCredentialError(IsAuthorisationFailure, err, ctx)
		return errors.Annotate(err, "setting server metadata")
	}
	return nil
}
source: func (t *ConsoleFormatter) FormatSkip(errin error, skip int) (errtext string, err error) {
	errobj := castErrorObject(nil, skip+1, errin)
	if errobj == nil {
		return "", nil
	}

	buffer := &bytes.Buffer{}

	if t.TimeFormat != "" {
		if _, errio := buffer.WriteString(time.Now().Format(t.TimeFormat)); errio != nil {
			return buffer.String(), errio
		}
	}

	if t.LongFile || t.ShortFile {
		if _, errio := WriteCallInfo(buffer, errobj, t.LongFile, t.Line, t.ReplacePackages); errio != nil {
			return buffer.String(), errio
		}
		if _, errio := buffer.WriteString(" "); errio != nil {
			return buffer.String(), errio
		}
	}

	if t.Seperator == "" {
		if _, errio := buffer.WriteString(getErrorText(errin)); errio != nil {
			return buffer.String(), errio
		}
		return buffer.String(), nil
	}

	firstError := true
	if walkerr := WalkErrors(errobj, func(errloop ErrorObject) (stop bool, walkerr error) {
		if !firstError {
			if _, errio := buffer.WriteString(t.Seperator); errio != nil {
				return true, errio
			}
		}
		firstError = false

		if _, errio := buffer.WriteString(getErrorText(errloop)); errio != nil {
			return true, errio
		}
		return false, nil
	}); walkerr != nil {
		return buffer.String(), walkerr
	}

	return buffer.String(), nil
}
source: func NewBufferedSender(sender Sender, duration time.Duration, number int) Sender {
	if duration == 0 {
		duration = time.Hour * 24
	} else if duration < minBufferLength {
		duration = minBufferLength
	}

	if number == 0 {
		number = 100
	}

	s := &bufferedSender{
		Sender:   sender,
		duration: duration,
		number:   number,
		pipe:     make(chan message.Composer, number),
		signal:   make(chan struct{}),
		errs:     make(chan error),
	}

	go s.backgroundDispatcher()

	return s
}
source: func RawStoreAccess(logger chronograf.Logger, next http.HandlerFunc) http.HandlerFunc {
	return func(w http.ResponseWriter, r *http.Request) {
		ctx := r.Context()
		if isServer := hasServerContext(ctx); isServer {
			next(w, r)
			return
		}

		log := logger.
			WithField("component", "raw_store").
			WithField("remote_addr", r.RemoteAddr).
			WithField("method", r.Method).
			WithField("url", r.URL)

		if isSuperAdmin := hasSuperAdminContext(ctx); isSuperAdmin {
			r = r.WithContext(serverContext(ctx))
		} else {
			log.Error("User making request is not a SuperAdmin")
			Error(w, http.StatusForbidden, "User is not authorized", logger)
			return
		}

		next(w, r)
	}
}
source: func PerformanceSince(what string, t time.Time) {
	PerformanceSinceKey(DefaultKey, what, t)
}
source: func (s *SecureChannelSession) pair(p1 uint8, data []byte) (*responseAPDU, error) {
	return transmit(s.card, &commandAPDU{
		Cla:  claSCWallet,
		Ins:  insPair,
		P1:   p1,
		P2:   0,
		Data: data,
		Le:   0,
	})
}
source: func (c *Context) FlagNames() (names []string) {
	for _, flag := range c.Command.Flags {
		name := strings.Split(flag.GetName(), ",")[0]
		if name == "help" {
			continue
		}
		names = append(names, name)
	}
	return
}
source: func (_class PoolClass) RetrieveWlbRecommendations(sessionID SessionRef) (_retval map[VMRef][]string, _err error) {
	_method := "pool.retrieve_wlb_recommendations"
	_sessionIDArg, _err := convertSessionRefToXen(fmt.Sprintf("%s(%s)", _method, "session_id"), sessionID)
	if _err != nil {
		return
	}
	_result, _err := _class.client.APICall(_method, _sessionIDArg)
	if _err != nil {
		return
	}
	_retval, _err = convertVMRefToStringSetMapToGo(_method + " -> ", _result.Value)
	return
}
source: func NewREST(appsclient appsclient.Interface, kc kubernetes.Interface) *REST {
	return &REST{
		generator: NewRollbackGenerator(),
		dn:        appsclient.AppsV1(),
		rn:        kc.CoreV1(),
	}
}
source: func (s *ServerRPC) PodCreate(ctx context.Context, req *types.PodCreateRequest) (*types.PodCreateResponse, error) {
	p, err := s.daemon.CreatePod(req.PodID, req.PodSpec)
	if err != nil {
		return nil, err
	}

	return &types.PodCreateResponse{
		PodID: p.Id(),
	}, nil
}
source: func (s *State) Deactivate() {
	if s.active < 1 {
		return
	}
	atomic.StoreInt64(&s.active, 0)

	s.do.Lock()
	if s.deactivator != nil {
		s.deactivator()
	}
	s.do.Unlock()
}
source: func (p MongoPlugin) Backup(endpoint plugin.ShieldEndpoint) error {
	mongo, err := mongoConnectionInfo(endpoint)
	if err != nil {
		return err
	}

	cmd := fmt.Sprintf("%s/mongodump %s", mongo.Bin, connectionString(mongo, true))
	plugin.DEBUG("Executing: `%s`", cmd)
	return plugin.Exec(cmd, plugin.STDOUT)
}
source: func (application Application) StagingFailedMessage() string {
	if application.StagingFailedDescription != "" {
		return application.StagingFailedDescription
	}

	return application.StagingFailedReason
}
source: func CreateChaincodeProposalWithTransient(typ common.HeaderType, chainID string, cis *peer.ChaincodeInvocationSpec, creator []byte, transientMap map[string][]byte) (*peer.Proposal, string, error) {
	// generate a random nonce
	nonce, err := crypto.GetRandomNonce()
	if err != nil {
		return nil, "", err
	}

	// compute txid
	txid, err := ComputeTxID(nonce, creator)
	if err != nil {
		return nil, "", err
	}

	return CreateChaincodeProposalWithTxIDNonceAndTransient(txid, typ, chainID, cis, nonce, creator, transientMap)
}
source: func (s *Swarm) ConnsWithGroup(g Group) []*Conn {
	return ConnsWithGroup(g, s.Conns())
}
source: func (l *LiteBackend) Imported(ctx context.Context) (imported bool, err error) {
	err = l.inTransaction(ctx, func(tx *sql.Tx) error {
		q, err := tx.PrepareContext(ctx,
			"SELECT imported from meta LIMIT 1")
		if err != nil {
			return trace.Wrap(err)
		}
		row := q.QueryRowContext(ctx)
		if err := row.Scan(&imported); err != nil {
			if err != sql.ErrNoRows {
				return trace.Wrap(err)
			}
		}
		return nil
	})
	return imported, err
}
source: func NewIntValue(i int) Value {
	value := &Value{}
	value.StoreInt(i)
	return *value
}
source: func cloneBytes(v []byte) []byte {
	var clone = make([]byte, len(v))
	copy(clone, v)
	return clone
}
source: func (mi *mixinInvocation) decsParams() ([]*declaration, map[string]string) {
	md, ok := mi.Context().mixins[mi.name]

	if !ok {
		return nil, nil
	}

	params := make(map[string]string)

	l := len(mi.paramValues)

	for i, name := range md.paramNames {
		if i < l {
			params[name] = mi.paramValues[i]
		}
	}

	return md.decs, params
}
source: func (b *Buckets) setBits(offset, length, bits uint32) {
	byteIndex := offset / 8
	byteOffset := offset % 8
	if byteOffset+length > 8 {
		rem := 8 - byteOffset
		b.setBits(offset, rem, bits)
		b.setBits(offset+rem, length-rem, bits>>rem)
		return
	}
	bitMask := uint32((1 << length) - 1)
	b.data[byteIndex] = byte(uint32(b.data[byteIndex]) & ^(bitMask << byteOffset))
	b.data[byteIndex] = byte(uint32(b.data[byteIndex]) | ((bits & bitMask) << byteOffset))
}
source: func (dt *DirtyTable) DeleteRow(handle int64) {
	delete(dt.addedRows, handle)
	dt.deletedRows[handle] = struct{}{}
}
source: func (t *PlatformsTable) computeChanges(c context.Context, platforms []*config.Platform) {
	cfgs := make(map[string]*Platform, len(platforms))
	for _, cfg := range platforms {
		cfgs[cfg.Name] = &Platform{
			Platform: config.Platform{
				Name:         cfg.Name,
				Description:  cfg.Description,
				Manufacturer: cfg.Manufacturer,
			},
		}
	}

	for _, p := range t.current {
		if cfg, ok := cfgs[p.Name]; ok {
			// Platform found in the config.
			if t.needsUpdate(p, cfg) {
				// Platform doesn't match the config.
				cfg.Id = p.Id
				t.updates = append(t.updates, cfg)
			}
			// Record that the platform config has been seen.
			delete(cfgs, cfg.Name)
		} else {
			// Platform not found in the config.
			t.removals = append(t.removals, p)
		}
	}

	// Platforms remaining in the map are present in the config but not the database.
	// Iterate deterministically over the slice to determine which platforms need to be added.
	for _, cfg := range platforms {
		if p, ok := cfgs[cfg.Name]; ok {
			t.additions = append(t.additions, p)
		}
	}
}
source: func (mat *MatMxN) Add(dst *MatMxN, addend *MatMxN) *MatMxN {
	if mat == nil || addend == nil || mat.m != addend.m || mat.n != addend.n {
		return nil
	}

	dst = dst.Reshape(mat.m, mat.n)

	// No need to care about rows and columns
	// since it's element-wise anyway
	for i, el := range mat.dat {
		dst.dat[i] = el + addend.dat[i]
	}

	return dst
}
source: func (b *Backend) StateMgr(name string) (state.State, error) {
	c, err := b.client(name)
	if err != nil {
		return nil, err
	}

	st := &remote.State{Client: c}

	// Grab the value
	if err := st.RefreshState(); err != nil {
		return nil, err
	}

	// If we have no state, we have to create an empty state
	if v := st.State(); v == nil {

		lockInfo := state.NewLockInfo()
		lockInfo.Operation = "init"
		lockID, err := st.Lock(lockInfo)
		if err != nil {
			return nil, err
		}

		// Local helper function so we can call it multiple places
		unlock := func(baseErr error) error {
			if err := st.Unlock(lockID); err != nil {
				const unlockErrMsg = `%v
				Additionally, unlocking the state file on Google Cloud Storage failed:

				Error message: %q
				Lock ID (gen): %v
				Lock file URL: %v

				You may have to force-unlock this state in order to use it again.
				The GCloud backend acquires a lock during initialization to ensure
				the initial state file is created.`
				return fmt.Errorf(unlockErrMsg, baseErr, err.Error(), lockID, c.lockFileURL())
			}

			return baseErr
		}

		if err := st.WriteState(states.NewState()); err != nil {
			return nil, unlock(err)
		}
		if err := st.PersistState(); err != nil {
			return nil, unlock(err)
		}

		// Unlock, the state should now be initialized
		if err := unlock(nil); err != nil {
			return nil, err
		}

	}

	return st, nil
}
source: func WriteFrame(w io.Writer, frame []byte) (int, error) {
	count, err := writeFrameHeader(w, uint64(len(frame)))
	if err != nil {
		return count, err
	}

	amount, err := w.Write(frame)
	count += amount
	if err != nil {
		return count, err
	}

	return count, nil
}
source: func (e *LogEntry) headerSize() int64 {
	sz := uVarintSize(e.Length) + // total entry length
		1 + // type
		uVarintSize(uint64(len(e.Index))) + len(e.Index) + // Index length and data
		uVarintSize(uint64(len(e.Field))) + len(e.Field) + // Field length and data
		uVarintSize(uint64(len(e.IDs))) // ID/Key pair count
	return int64(sz)
}
source: func (p *Join) less() StringSliceComparator {
	return (&SortKeys{
		Keys:    p.LeftKeys,
		Numeric: p.Numeric,
	}).AsStringSliceComparator()
}
source: func (p *V2) classifyDevice(dev device.GenericDevice) device.GenericDevice {
	common.Log.Debugf("Attempting to determine device type for: %d", dev.ID())
	product, err := dev.GetProduct()
	if err != nil {
		common.Log.Errorf("Error retrieving device hardware product: %v", err)
		return dev
	}

	defer dev.SetProvisional(false)

	if product == nil {
		common.Log.Debugf("Unknown product: %d", dev.ID())
		return dev
	}

	if product.Supports(device.FeatureLight) {
		p.Lock()
		d := dev.(*device.Device)
		d.Lock()
		l := &device.Light{Device: d}
		common.Log.Debugf("Device is a light: %d", l.ID())
		// Replace the known dev with our constructed light
		p.devices[l.ID()] = l
		d.Unlock()
		p.Unlock()
		return l
	}

	common.Log.Debugf("Device is not a light: %d", dev.ID())
	return dev
}
source: func (r ribout) update(p *table.Path) bool {
	key := p.GetNlri().String() // TODO expose (*Path).getPrefix()
	l := r[key]
	if p.IsWithdraw {
		if len(l) == 0 {
			return false
		}
		n := make([]*table.Path, 0, len(l))
		for _, q := range l {
			if p.GetSource() == q.GetSource() {
				continue
			}
			n = append(n, q)
		}
		if len(n) == 0 {
			delete(r, key)
		} else {
			r[key] = n
		}
		return true
	}

	if len(l) == 0 {
		r[key] = []*table.Path{p}
		return true
	}

	doAppend := true
	for idx, q := range l {
		if p.GetSource() == q.GetSource() {
			// if we have sent the same path, don't send it again
			if p.Equal(q) {
				return false
			}
			l[idx] = p
			doAppend = false
		}
	}
	if doAppend {
		r[key] = append(r[key], p)
	}
	return true
}
source: func ToStr(value interface{}, args ...int) (s string) {
	switch v := value.(type) {
	case bool:
		s = strconv.FormatBool(v)
	case float32:
		s = strconv.FormatFloat(float64(v), 'f', argInt(args).Get(0, -1), argInt(args).Get(1, 32))
	case float64:
		s = strconv.FormatFloat(v, 'f', argInt(args).Get(0, -1), argInt(args).Get(1, 64))
	case int:
		s = strconv.FormatInt(int64(v), argInt(args).Get(0, 10))
	case int8:
		s = strconv.FormatInt(int64(v), argInt(args).Get(0, 10))
	case int16:
		s = strconv.FormatInt(int64(v), argInt(args).Get(0, 10))
	case int32:
		s = strconv.FormatInt(int64(v), argInt(args).Get(0, 10))
	case int64:
		s = strconv.FormatInt(v, argInt(args).Get(0, 10))
	case uint:
		s = strconv.FormatUint(uint64(v), argInt(args).Get(0, 10))
	case uint8:
		s = strconv.FormatUint(uint64(v), argInt(args).Get(0, 10))
	case uint16:
		s = strconv.FormatUint(uint64(v), argInt(args).Get(0, 10))
	case uint32:
		s = strconv.FormatUint(uint64(v), argInt(args).Get(0, 10))
	case uint64:
		s = strconv.FormatUint(v, argInt(args).Get(0, 10))
	case string:
		s = v
	case []byte:
		s = string(v)
	default:
		s = fmt.Sprintf("%v", v)
	}
	return s
}
source: func ParseEventScript(v string) []EventScript {
	var filter, script string
	parts := strings.SplitN(v, "=", 2)
	if len(parts) == 1 {
		script = parts[0]
	} else {
		filter = parts[0]
		script = parts[1]
	}

	filters := ParseEventFilter(filter)
	results := make([]EventScript, 0, len(filters))
	for _, filt := range filters {
		result := EventScript{
			EventFilter: filt,
			Script:      script,
		}
		results = append(results, result)
	}
	return results
}
source: func Load(configFile string, logger log.Logger) (*GatewayConfig, error) {
	p, err := loadNoDefault(configFile, logger)
	if err == nil {
		c := pointer.FillDefaultFrom(p, DefaultGatewayConfig()).(*GatewayConfig)
		if err = os.Setenv("gatewayServerName", *c.ServerName); err == nil {
			if c.ClusterName == nil || *c.ClusterName == "" {
				return nil, errors.New("gateway now requires configuring ClusterName at top level of config")
			}
			// fill in environment variable values to override config file
			loadFromEnv(c)
			return c, nil
		}
	}
	return nil, err
}
source: func (s *Condition) SetLt(v int64) *Condition {
	s.Lt = &v
	return s
}
source: func (bs *blobStore) readlink(ctx context.Context, path string) (digest.Digest, error) {
	content, err := bs.driver.GetContent(ctx, path)
	if err != nil {
		return "", err
	}

	linked, err := digest.Parse(string(content))
	if err != nil {
		return "", err
	}

	return linked, nil
}
source: func (fbo *folderBlockOps) getDirtyDirUnrefsLocked(
	lState *kbfssync.LockState, ptr data.BlockPointer) []data.BlockInfo {
	fbo.blockLock.AssertRLocked(lState)
	return fbo.dirtyDirs[ptr]
}
source: func (m *RWMutex) RUnlock() {
	m.mutex.RUnlock()
	if m.log {
		astilog.Debugf("RUnlock executed for %s", m.name)
	}
}
source: func (p *websocketChannel) DataFromSocket(data []byte) (int, error) {
	if !p.read {
		return len(data), nil
	}

	switch p.conn.codec {
	case rawCodec:
		return p.w.Write(data)
	case base64Codec:
		dst := make([]byte, len(data))
		n, err := base64.StdEncoding.Decode(dst, data)
		if err != nil {
			return 0, err
		}
		return p.w.Write(dst[:n])
	}
	return 0, nil
}
source: func populateCheckoutOpts(ptr *C.git_checkout_options, opts *CheckoutOpts) *C.git_checkout_options {
	if opts == nil {
		return nil
	}

	C.git_checkout_init_options(ptr, 1)
	ptr.checkout_strategy = C.uint(opts.Strategy)
	ptr.disable_filters = cbool(opts.DisableFilters)
	ptr.dir_mode = C.uint(opts.DirMode.Perm())
	ptr.file_mode = C.uint(opts.FileMode.Perm())
	ptr.notify_flags = C.uint(opts.NotifyFlags)
	if opts.NotifyCallback != nil || opts.ProgressCallback != nil {
		C._go_git_populate_checkout_cb(ptr)
	}
	payload := pointerHandles.Track(opts)
	if opts.NotifyCallback != nil {
		ptr.notify_payload = payload
	}
	if opts.ProgressCallback != nil {
		ptr.progress_payload = payload
	}
	if opts.TargetDirectory != "" {
		ptr.target_directory = C.CString(opts.TargetDirectory)
	}
	if len(opts.Paths) > 0 {
		ptr.paths.strings = makeCStringsFromStrings(opts.Paths)
		ptr.paths.count = C.size_t(len(opts.Paths))
	}

	if opts.Baseline != nil {
		ptr.baseline = opts.Baseline.cast_ptr
	}

	return ptr
}
source: func GetNode() string {
	var addr []byte
	ifs, _ := net.Interfaces()
	for _, i := range ifs {
		if len(i.HardwareAddr) < 6 {
			continue
		}
		addr = i.HardwareAddr
		break
	}
	if addr == nil {
		addr = make([]byte, 6)
		// Ignore errors.
		_, _ = rand.Read(addr)
	}
	return hex.EncodeToString(addr[:6])
}
source: func (shardSwap *shardSchemaSwap) waitForTabletToBeHealthy(tablet *topodatapb.Tablet) error {
	waitChannel, err := shardSwap.startWaitingOnUnhealthyTablet(tablet)
	if err != nil {
		return err
	}
	if waitChannel != nil {
		select {
		case <-shardSwap.parent.ctx.Done():
			return shardSwap.parent.ctx.Err()
		case <-*waitChannel:
			// Tablet has caught up, we can return successfully.
		}
	}
	return nil
}
source: func (s *RegisterInstanceInput) SetRsaPublicKey(v string) *RegisterInstanceInput {
	s.RsaPublicKey = &v
	return s
}
source: func (cm *ConnManager) Disconnect(id uint64) {
	if atomic.LoadInt32(&cm.stop) != 0 {
		return
	}

	select {
	case cm.requests <- handleDisconnected{id, true}:
	case <-cm.quit:
	}
}
source: func (f *StateFile) Read() (string, string, *Disconnected, error) {
	var st state
	if err := utils.ReadYaml(f.path, &st); err != nil {
		if os.IsNotExist(err) {
			return "", "", nil, nil
		}
		return "", "", nil, errors.Trace(err)
	}

	return st.Code, st.Info, st.Disconnected, nil
}
source: func (r *Robot) AddConnection(c Connection) Connection {
	*r.connections = append(*r.Connections(), c)
	return c
}
source: func (m MiddlewareFunc) HostIsNot(tests ...string) MiddlewareFunc {
	return func(h HandlerFunc) HandlerFunc {
		return func(c *Context) error {
			for _, test := range tests {
				if c.Request().URL().Host != test {
					return m(h)(c)
				}
			}
			return h(c)
		}
	}
} 32%|███▏      | 1583/5000 [00:01<00:04, 734.69it/s]
source: func (o *Compute) SetGPU(v *GPU) *Compute {
	if o.GPU = v; o.GPU == nil {
		o.nullFields = append(o.nullFields, "GPU")
	}
	return o
}
source: func (c *Cmd) CmdStart() error {

	var err error

	// CmdLine check
	if c.CmdLine != "" && c.Cmd == nil {
		parseCmd, err := shellwords.Parse(c.CmdLine)
		if err != nil {
			return err
		}
		c.Cmd = exec.Command(parseCmd[0], parseCmd[1:]...)
	}
	if c.CmdLine == "" {
		c.CmdLine = strings.Join(c.Cmd.Args, " ")
	}

	var stdoutPipe, stderrPipe io.ReadCloser

	if !c.stdoutPipe {
		stdoutPipe, err = c.Cmd.StdoutPipe()
		if err != nil {
			return err
		}
	}
	if !c.stderrPipe {
		stderrPipe, err = c.Cmd.StderrPipe()
		if err != nil {
			return err
		}
	}

	// Start command.
	err = c.Cmd.Start()
	if err != nil {
		c.ExitError = err
		c.GetExitCode()
		return err
	}

	scanWrite := func(c *Cmd, r io.ReadCloser, w io.Writer, enc *encoding.Decoder, print bool) {
		if r == nil {
			return
		}
		c.Wg.Add(1)
		go func() {
			defer c.Wg.Done()
			if enc == nil {
				ScanWrite(bufio.NewScanner(r), w, print)
			} else {
				ScanWrite(bufio.NewScanner(transform.NewReader(r, enc)), w, print)
			}
		}()
	}

	scanWrite(c, stdoutPipe, &c.Stdout, c.StdoutEnc, c.StdoutPrint)
	scanWrite(c, stderrPipe, &c.Stderr, c.StderrEnc, c.StderrPrint)

	return nil
}
source: func (t *TextMatch) GetProperty() string {
	if t == nil || t.Property == nil {
		return ""
	}
	return *t.Property
}
source: func NewListFromFile(path string, options *ParserOption) (*List, error) {
	l := NewList()
	_, err := l.LoadFile(path, options)
	return l, err
}
source: func (in *MiddlewareRef) DeepCopy() *MiddlewareRef {
	if in == nil {
		return nil
	}
	out := new(MiddlewareRef)
	in.DeepCopyInto(out)
	return out
}
source: func (c *Client) transportForConfig(tc *TransportConfig) http.RoundTripper {
	if inGopherJS {
		// Calls to net.Dial* functions - which would happen if the client's transport
		// is not nil - are prohibited with GopherJS. So we force nil here, so that the
		// call to transportForConfig in newClient is of no consequence when on the
		// browser.
		return nil
	}
	if c == nil {
		return nil
	}
	var transport http.RoundTripper
	proxy := http.ProxyFromEnvironment
	if tc != nil && tc.Proxy != nil {
		proxy = tc.Proxy
	}

	if c.useHTTP2(tc) {
		transport = &http2.Transport{
			DialTLS: c.http2DialTLSFunc(),
		}
	} else {
		transport = &http.Transport{
			DialTLS:             c.DialTLSFunc(),
			Dial:                c.DialFunc(),
			Proxy:               proxy,
			MaxIdleConnsPerHost: maxParallelHTTP_h1,
		}
	}
	httpStats := &httputil.StatsTransport{
		Transport: transport,
	}
	if tc != nil {
		httpStats.VerboseLog = tc.Verbose
	}
	transport = httpStats
	if android.IsChild() {
		transport = &android.StatsTransport{transport}
	}
	return transport
}
source: func (lgr *logger) SetLevel(level LogPriority) {
	lgr.mutex.Lock()
	defer lgr.mutex.Unlock()

	lgr.level = level
}
source: func PrependOp(bin *Bin) *Operation {
	return &Operation{opType: _PREPEND, binName: bin.Name, binValue: bin.Value}
}
source: func (shardSwap *shardSchemaSwap) addShardLog(message string) {
	log.Infof("Shard %v: %v", shardSwap.shardName, message)
	shardSwap.shardUILogger.Infof(message)
	shardSwap.shardUINode.Log = shardSwap.shardUILogger.String()
	shardSwap.shardUINode.BroadcastChanges(false /* updateChildren */)
}
source: func (v *Version) PythonBase() string {
	switch {
	case v.IsZero():
		return "python"
	case v.Minor > 0:
		return fmt.Sprintf("python%d.%d", v.Major, v.Minor)
	default:
		return fmt.Sprintf("python%d", v.Major)
	}
}
source: func (s *CertFileUserStore) Delete(key msp.IdentityIdentifier) error {
	return s.store.Delete(storeKeyFromUserIdentifier(key))
}
source: func (s *Statistics) Maximum() float64 {
	s.RLock()
	defer s.RUnlock()
	return s.maximum
}
source: func (e *scriptEntry) ReadFrom(r io.Reader) (n int64, err error) {
	var read int64

	if read, err = binaryRead(r, binary.LittleEndian, &e.scriptHash160); err != nil {
		return n + read, err
	}
	n += read

	read, err = e.script.ReadFrom(r)
	return n + read, err
}
source: func NewFacade(backend Backend, claimer lease.Claimer, auth facade.Authorizer) (*Facade, error) {
	if !auth.AuthController() {
		return nil, common.ErrPerm
	}
	return &Facade{
		auth:            auth,
		modelTag:        backend.ModelTag(),
		controllerTag:   backend.ControllerTag(),
		singularClaimer: claimer,
	}, nil
}
source: func OffsetToCursor(offset int) ConnectionCursor {
	str := fmt.Sprintf("%v%v", PREFIX, offset)
	return ConnectionCursor(base64.StdEncoding.EncodeToString([]byte(str)))
}
source: func (p *BinaryPropagator) Inject(
	sc SpanContext,
	abstractCarrier interface{},
) error {
	carrier, ok := abstractCarrier.(io.Writer)
	if !ok {
		return opentracing.ErrInvalidCarrier
	}

	// Handle the tracer context
	if err := binary.Write(carrier, binary.BigEndian, sc.traceID); err != nil {
		return err
	}
	if err := binary.Write(carrier, binary.BigEndian, sc.spanID); err != nil {
		return err
	}
	if err := binary.Write(carrier, binary.BigEndian, sc.parentID); err != nil {
		return err
	}
	if err := binary.Write(carrier, binary.BigEndian, sc.flags); err != nil {
		return err
	}

	// Handle the baggage items
	if err := binary.Write(carrier, binary.BigEndian, int32(len(sc.baggage))); err != nil {
		return err
	}
	for k, v := range sc.baggage {
		if err := binary.Write(carrier, binary.BigEndian, int32(len(k))); err != nil {
			return err
		}
		io.WriteString(carrier, k)
		if err := binary.Write(carrier, binary.BigEndian, int32(len(v))); err != nil {
			return err
		}
		io.WriteString(carrier, v)
	}

	return nil
}
source: func (f StructField) Get(val interface{}) (err error) {
	b, err := f.db.Get(f.key)
	if err != nil {
		return err
	}
	return rlp.DecodeBytes(b, val)
}
source: func IsRequestEntityTooLargeError(err error) bool {
	if ReasonForError(err) == metav1.StatusReasonRequestEntityTooLarge {
		return true
	}
	switch t := err.(type) {
	case APIStatus:
		return t.Status().Code == http.StatusRequestEntityTooLarge
	}
	return false
}
source: func IsAuthorized(r *http.Request, secret string) (string, bool) {
	raw, er := ioutil.ReadAll(r.Body)
	if er != nil {
		return "", false
	}

	// Since we're reading the request from the network, r.Body will return EOF if any
	// downstream http.Handler attempts to read it. We set it to a new io.ReadCloser
	// that will read from the bytes in memory.
	r.Body = ioutil.NopCloser(bytes.NewReader(raw))

	sig := "sha1=" + Signature(raw, secret)
	return sig, compareStrings(r.Header.Get(HeaderSignature), sig)
}
source: func (mysqld *Mysqld) killConnection(connID int64) error {
	// There's no other interface that both types of connection implement.
	// We only care about one method anyway.
	var killConn interface {
		ExecuteFetch(query string, maxrows int, wantfields bool) (*sqltypes.Result, error)
	}

	// Get another connection with which to kill.
	// Use background context because the caller's context is likely expired,
	// which is the reason we're being asked to kill the connection.
	ctx, cancel := context.WithTimeout(context.Background(), 1*time.Second)
	defer cancel()
	if poolConn, connErr := getPoolReconnect(ctx, mysqld.dbaPool); connErr == nil {
		// We got a pool connection.
		defer poolConn.Recycle()
		killConn = poolConn
	} else {
		// We couldn't get a connection from the pool.
		// It might be because the connection pool is exhausted,
		// because some connections need to be killed!
		// Try to open a new connection without the pool.
		killConn, connErr = mysqld.GetDbaConnection()
		if connErr != nil {
			return connErr
		}
	}

	_, err := killConn.ExecuteFetch(fmt.Sprintf("kill %d", connID), 10000, false)
	return err
}
source: func (g *Cloud) GetDiskByNameUnknownZone(diskName string) (*Disk, error) {
	if utilfeature.DefaultFeatureGate.Enabled(cloudfeatures.GCERegionalPersistentDisk) {
		regionalDisk, err := g.getRegionalDiskByName(diskName)
		if err == nil {
			return regionalDisk, err
		}
	}

	// Note: this is the gotcha right now with GCE PD support:
	// disk names are not unique per-region.
	// (I can create two volumes with name "myvol" in e.g. us-central1-b & us-central1-f)
	// For now, this is simply undefined behaviour.
	//
	// In future, we will have to require users to qualify their disk
	// "us-central1-a/mydisk".  We could do this for them as part of
	// admission control, but that might be a little weird (values changing
	// on create)

	var found *Disk
	for _, zone := range g.managedZones {
		disk, err := g.findDiskByName(diskName, zone)
		if err != nil {
			return nil, err
		}
		// findDiskByName returns (nil,nil) if the disk doesn't exist, so we can't
		// assume that a disk was found unless disk is non-nil.
		if disk == nil {
			continue
		}
		if found != nil {
			switch zoneInfo := disk.ZoneInfo.(type) {
			case multiZone:
				if zoneInfo.replicaZones.Has(zone) {
					klog.Warningf("GCE PD name (%q) was found in multiple zones (%q), but ok because it is a RegionalDisk.",
						diskName, zoneInfo.replicaZones)
					continue
				}
				return nil, fmt.Errorf("GCE PD name was found in multiple zones: %q", diskName)
			default:
				return nil, fmt.Errorf("GCE PD name was found in multiple zones: %q", diskName)
			}
		}
		found = disk
	}
	if found != nil {
		return found, nil
	}
	klog.Warningf("GCE persistent disk %q not found in managed zones (%s)",
		diskName, strings.Join(g.managedZones, ","))

	return nil, cloudprovider.DiskNotFound
}
source: func NewStateCrossControllerAPI(ctx facade.Context) (*CrossControllerAPI, error) {
	st := ctx.State()
	return NewCrossControllerAPI(
		ctx.Resources(),
		func() ([]string, string, error) { return common.StateControllerInfo(st) },
		st.WatchAPIHostPortsForClients,
	)
}
source: func (s *UpdateApnsVoipChannelInput) SetAPNSVoipChannelRequest(v *APNSVoipChannelRequest) *UpdateApnsVoipChannelInput {
	s.APNSVoipChannelRequest = v
	return s
}
source: func (s *Store) idFile(ctx context.Context, name string) string {
	fn := name
	var cnt uint8
	for {
		cnt++
		if cnt > 100 {
			break
		}
		if fn == "" || fn == sep {
			break
		}
		gfn := filepath.Join(fn, s.crypto.IDFile())
		if s.storage.Exists(ctx, gfn) {
			return gfn
		}
		fn = filepath.Dir(fn)
	}
	return s.crypto.IDFile()
}
source: func (m *MetaClient) RemoveRolePerms(ctx context.Context, name string, perms Permissions) error {
	a := &RoleAction{
		Action: "remove-permissions",
		Role: &Role{
			Name:        name,
			Permissions: perms,
		},
	}
	return m.Post(ctx, "/role", a, nil)
}
source: func NewScanStringHandler(s *string) ReplyHandler {
	return func(reply interface{}) error {
		var err error
		(*s), err = redis.String(reply, nil)
		if err != nil {
			return err
		}
		return nil
	}
}
source: func FormatDefinition(definition []string, count int) string {
	var buffer bytes.Buffer

	spacer := strings.Repeat(" ", count)

	for i, d := range definition {
		if i == 0 {
			buffer.WriteString(d)
			buffer.WriteString("\n")
		} else {
			buffer.WriteString(spacer)
			buffer.WriteString(d)
			buffer.WriteString("\n")
		}
	}

	return strings.TrimSuffix(buffer.String(), "\n")
}
source: func getStringResponseWithoutOptions(client *Client, u string) (string, *Response, error) {
	v := new(string)
	resp, err := client.Call("GET", u, nil, v)
	return *v, resp, err
}
source: func NewSsoRemoveLogoutUrlType(Description string) *SsoRemoveLogoutUrlType {
	s := new(SsoRemoveLogoutUrlType)
	s.Description = Description
	return s
}
source: func (p *testSuiteDataParser) ExtractProperties(line string) (map[string]string, bool) {
	// `os::cmd` suites cannot expose properties
	return map[string]string{}, false
}
source: func (k *KBPKIClient) IsTeamReader(
	ctx context.Context, tid keybase1.TeamID, uid keybase1.UID,
	offline keybase1.OfflineAvailability) (bool, error) {
	desiredUser := keybase1.UserVersion{Uid: uid}
	teamInfo, err := k.serviceOwner.KeybaseService().LoadTeamPlusKeys(
		ctx, tid, tlf.Unknown, kbfsmd.UnspecifiedKeyGen, desiredUser,
		kbfscrypto.VerifyingKey{}, keybase1.TeamRole_READER, offline)
	if err != nil {
		return false, err
	}
	return tid.IsPublic() || teamInfo.Writers[uid] || teamInfo.Readers[uid], nil
}
source: func (pb Publish) Logger(l LoggerInterface) *Publish {
	return &Publish{
		WorkerScheduler: pb.WorkerScheduler,
		DB:              pb.DB,
		logger:          l,
		deleteCallback:  pb.deleteCallback,
	}
}
source: func (filebox *Filebox) ServeHTTP(w http.ResponseWriter, req *http.Request) {
	filebox.Download(w, req)
}
source: func WriteError(err error, w http.ResponseWriter) error {
	var status int
	switch grpc.Code(err) {
	case codes.NotFound:
		status = http.StatusNotFound
	case codes.ResourceExhausted:
		// We only expect to hit this if there is a DoS, so we just wait the full TTL.
		// If this is ever hit in steady-state operations, consider increasing the maxInFlight requests,
		// or plumbing through the time to next expiration.
		w.Header().Set("Retry-After", strconv.Itoa(int(cacheTTL.Seconds())))
		status = http.StatusTooManyRequests
	default:
		status = http.StatusInternalServerError
	}
	w.WriteHeader(status)
	_, writeErr := w.Write([]byte(err.Error()))
	return writeErr
}
source: func (m *Manager) Stop() error {
	if !atomic.CompareAndSwapUint32(&m.stopped, 0, 1) {
		return nil
	}

	if err := m.StopAgent(); err != nil {
		log.Errorf("Unable to stop pilot: %v", err)
	}

	close(m.quit)
	m.wg.Wait()

	return nil
}
source: func (p *Peer) AssociateConnection(conn net.Conn) {
	// Already connected?
	if !atomic.CompareAndSwapInt32(&p.connected, 0, 1) {
		return
	}

	p.conn = conn
	p.timeConnected = time.Now()

	if p.inbound {
		p.addr = p.conn.RemoteAddr().String()

		// Set up a NetAddress for the peer to be used with AddrManager.  We
		// only do this inbound because outbound set this up at connection time
		// and no point recomputing.
		na, err := newNetAddress(p.conn.RemoteAddr(), p.services)
		if err != nil {
			log.Errorf("Cannot create remote net address: %v", err)
			p.Disconnect()
			return
		}
		p.na = na
	}

	go func() {
		if err := p.start(); err != nil {
			log.Debugf("Cannot start peer %v: %v", p, err)
			p.Disconnect()
		}
	}()
}
source: func (l *s3EncObjects) GetObject(ctx context.Context, bucket string, key string, startOffset int64, length int64, writer io.Writer, etag string, opts minio.ObjectOptions) error {
	return l.getObject(ctx, bucket, key, startOffset, length, writer, etag, opts)
}
source: func (c *CORSConfig) IsValidOrigin(origin string) bool {
	// If we aren't enabling CORS then all origins are valid
	if !c.IsEnabled() {
		return true
	}

	c.RLock()
	defer c.RUnlock()

	if len(c.AllowedOrigins) == 0 {
		return false
	}

	if len(c.AllowedOrigins) == 1 && (c.AllowedOrigins)[0] == "*" {
		return true
	}

	return strutil.StrListContains(c.AllowedOrigins, origin)
}
source: func (f ES6Formatter) Function(fn Func) string {
	return "import { " + ES6Identifier(fn.Name) + " } from '" + fn.Name + ".js';"
}
source: func (a *API) RemoveFile(ctx context.Context, mhash string, path string, fname string, nameresolver bool) (string, error) {
	apiRmFileCount.Inc(1)

	uri, err := Parse("bzz:/" + mhash)
	if err != nil {
		apiRmFileFail.Inc(1)
		return "", err
	}
	mkey, err := a.ResolveURI(ctx, uri, EmptyCredentials)
	if err != nil {
		apiRmFileFail.Inc(1)
		return "", err
	}

	// trim the root dir we added
	if path[:1] == "/" {
		path = path[1:]
	}

	mw, err := a.NewManifestWriter(ctx, mkey, nil)
	if err != nil {
		apiRmFileFail.Inc(1)
		return "", err
	}

	err = mw.RemoveEntry(filepath.Join(path, fname))
	if err != nil {
		apiRmFileFail.Inc(1)
		return "", err
	}

	newMkey, err := mw.Store()
	if err != nil {
		apiRmFileFail.Inc(1)
		return "", err

	}

	return newMkey.String(), nil
}
source: func (s *translateStore) TranslateRowsToUint64(index, frame string, values []string) ([]uint64, error) {
	return nil, pilosa.ErrNotImplemented
}
source: func (blockID BlockID) Key() string {
	bz, err := cdc.MarshalBinaryBare(blockID.PartsHeader)
	if err != nil {
		panic(err)
	}
	return string(blockID.Hash) + string(bz)
}
source: func PortReasonBitmap(reasons ...ofp.PortReason) (bits uint32) {
	for _, reason := range reasons {
		bits = shl(bits, uint32(reason))
	}

	return
}
source: func (rules *Rules) FindVariable(path string) (*Variable, error) {
	if len(path) <= 1 {
		return nil, ErrorMap[ErrInvalidPath]
	}

	rule, err := rules.FindParentRule(path)
	if err != nil {
		return nil, err
	}

	sep := "/"
	segments := strings.Split(path, sep)
	variableName := strings.ToLower(segments[len(segments)-1])
	for _, variable := range rule.Variables {
		if strings.ToLower(variable.Name) == variableName {
			return variable, nil
		}
	}

	return nil, ErrorMap[ErrVariableNotFound]
}
source: func (cc *clientConn) getSessionVarsWaitTimeout(ctx context.Context) uint64 {
	valStr, exists := cc.ctx.GetSessionVars().GetSystemVar(variable.WaitTimeout)
	if !exists {
		return variable.DefWaitTimeout
	}
	waitTimeout, err := strconv.ParseUint(valStr, 10, 64)
	if err != nil {
		logutil.Logger(ctx).Warn("get sysval wait_timeout error, use default value", zap.Error(err))
		// if get waitTimeout error, use default value
		return variable.DefWaitTimeout
	}
	return waitTimeout
}
source: func NewDriverChecker(ctx Context, drivers map[string]struct{}) *DriverChecker {
	return &DriverChecker{
		ctx:     ctx,
		drivers: drivers,
	}
}
source: func (uf UnitFacade) SetStatus(args params.SetPayloadStatusArgs) (params.PayloadResults, error) {
	var r params.PayloadResults
	for _, arg := range args.Args {
		id, err := api.API2ID(arg.Tag)
		if err != nil {
			return r, errors.Trace(err)
		}

		err = uf.backend.SetStatus(id, arg.Status)
		res := newPayloadResult(id, err)
		r.Results = append(r.Results, res)
	}
	return r, nil
}
source: func (p *ConnPool) Acquire() (*Conn, error) {
	p.cond.L.Lock()
	c, err := p.acquire(nil)
	p.cond.L.Unlock()
	return c, err
}
source: func New(ctx context.Context, sc recipientHashStorer, alias string, u *backend.URL, cfgdir string, agent *client.Client) (*Store, error) {
	out.Debug(ctx, "sub.New - URL: %s", u.String())

	s := &Store{
		alias:  alias,
		url:    u,
		rcs:    noop.New(),
		cfgdir: cfgdir,
		agent:  agent,
		sc:     sc,
	}

	// init store backend
	if backend.HasStorageBackend(ctx) {
		s.url.Storage = backend.GetStorageBackend(ctx)
		out.Debug(ctx, "sub.New - Using storage backend from ctx: %s", backend.StorageBackendName(s.url.Storage))
	}
	if err := s.initStorageBackend(ctx); err != nil {
		return nil, errors.Wrapf(err, "failed to init storage backend: %s", err)
	}

	// init sync backend
	if backend.HasRCSBackend(ctx) {
		s.url.RCS = backend.GetRCSBackend(ctx)
		out.Debug(ctx, "sub.New - Using RCS backend from ctx: %s", backend.RCSBackendName(s.url.RCS))
	}
	if err := s.initRCSBackend(ctx); err != nil {
		return nil, errors.Wrapf(err, "failed to init RCS backend: %s", err)
	}

	// init crypto backend
	if backend.HasCryptoBackend(ctx) {
		s.url.Crypto = backend.GetCryptoBackend(ctx)
		out.Debug(ctx, "sub.New - Using Crypto backend from ctx: %s", backend.CryptoBackendName(s.url.Crypto))
	}
	if err := s.initCryptoBackend(ctx); err != nil {
		return nil, errors.Wrapf(err, "failed to init crypto backend: %s", err)
	}

	out.Debug(ctx, "sub.New - initialized - storage: %s (%p) - rcs: %s (%p) - crypto: %s (%p)", s.storage.Name(), s.storage, s.rcs.Name(), s.rcs, s.crypto.Name(), s.crypto)
	return s, nil
}
source: func WithData(d []byte) source.Option {
	return func(o *source.Options) {
		if o.Context == nil {
			o.Context = context.Background()
		}
		o.Context = context.WithValue(o.Context, changeSetKey{}, &source.ChangeSet{
			Data:   d,
			Format: "json",
		})
	}
}
source: func (s *Server) Alert(msg string) {
	s.logStatus("requesting alert: " + msg)
	for conn := range s.connSet.conns {
		conn.alertChan <- msg
	}
}
source: func (g *UndirectedGraph) RemoveNode(n graph.Node) {
	if _, ok := g.nodes[n.ID()]; !ok {
		return
	}
	delete(g.nodes, n.ID())

	g.edges[n.ID()].Visit(func(neighbor int, edge graph.Edge) {
		g.edges[neighbor] = g.edges[neighbor].Delete(n.ID())
	})
	delete(g.edges, n.ID())

	g.freeIDs.Insert(n.ID())
	g.usedIDs.Remove(n.ID())

}
source: func copyTools(toolsDir, stream string, tools []*coretools.Tools, u ToolsUploader) error {
	for _, tool := range tools {
		logger.Infof("copying %s from %s", tool.Version, tool.URL)
		if err := copyOneToolsPackage(toolsDir, stream, tool, u); err != nil {
			return err
		}
	}
	return nil
}
source: func (m *Metagame) LogRemote(ctx context.Context, arg *protos.Arg) (*protos.Response, error) {
	logger.Log.Infof("argument %+v\n", arg)
	return &protos.Response{Code: 200, Msg: "ok"}, nil
}
source: func WithTags(logger *logging.Logger, tags []common.KVPair) *logging.Logger {
	keyvals := make([]interface{}, len(tags)*2)
	for i, kvp := range tags {
		keyvals[i] = string(kvp.Key)
		keyvals[i+1] = string(kvp.Value)
	}
	return logger.With(keyvals...)
}
source: func (p Page) Summary() (summary string) {
	out, err := sanitize.HTMLAllowing(p.Body, []string{"p"})
	if err != nil {
		log.Println(err)
		return ""
	}
	if strings.Index(out, "\n") > 10 && strings.Index(out, "\n") < 255 {
		return strings.SplitN(out, "\n", 2)[0]
	}
	arr := strings.Split(out, " ")
	if len(arr) < 2 {
		return p.Body
	}
	var cnt = 0
	for i, v := range arr {
		cnt += len(v)
		if cnt > 255 {
			summary = strings.Join(arr[:i-1], " ")
			break
		}
	}
	return
}
source: func (rf Range) OR(f Range) Range {
	return Range(func(v Version) bool {
		return rf(v) || f(v)
	})
}
source: func (_class GPUGroupClass) GetByNameLabel(sessionID SessionRef, label string) (_retval []GPUGroupRef, _err error) {
	_method := "GPU_group.get_by_name_label"
	_sessionIDArg, _err := convertSessionRefToXen(fmt.Sprintf("%s(%s)", _method, "session_id"), sessionID)
	if _err != nil {
		return
	}
	_labelArg, _err := convertStringToXen(fmt.Sprintf("%s(%s)", _method, "label"), label)
	if _err != nil {
		return
	}
	_result, _err := _class.client.APICall(_method, _sessionIDArg, _labelArg)
	if _err != nil {
		return
	}
	_retval, _err = convertGPUGroupRefSetToGo(_method + " -> ", _result.Value)
	return
}
source: func (r *ReferenceConstraint) RefersTo(s string) *ReferenceConstraint {
	r.reference = s
	return r
}
source: func (c *Overlay) HighlightFrameWithParams(v *OverlayHighlightFrameParams) (*gcdmessage.ChromeResponse, error) {
	return gcdmessage.SendDefaultRequest(c.target, c.target.GetSendCh(), &gcdmessage.ParamRequest{Id: c.target.GetId(), Method: "Overlay.highlightFrame", Params: v})
}
source: func NewRemoveXHRBreakpointArgs(url string) *RemoveXHRBreakpointArgs {
	args := new(RemoveXHRBreakpointArgs)
	args.URL = url
	return args
}
source: func ModifierString(mods uint16) string {
	modStrs := make([]string, 0, 3)
	for i, mod := range Modifiers {
		if mod&mods > 0 && len(NiceModifiers[i]) > 0 {
			modStrs = append(modStrs, NiceModifiers[i])
		}
	}
	return strings.Join(modStrs, "-")
}
source: func NewRect(a, b *T) (rect Rect) {
	rect.Min = Min(a, b)
	rect.Max = Max(a, b)
	return rect
}
source: func SetRawTerminalOutput(fd uintptr) (*State, error) {
	state, err := SaveState(fd)
	if err != nil {
		return nil, err
	}

	// Ignore failures, since winterm.DISABLE_NEWLINE_AUTO_RETURN might not be supported on this
	// version of Windows.
	winterm.SetConsoleMode(fd, state.mode|winterm.DISABLE_NEWLINE_AUTO_RETURN)
	return state, err
}
source: func hdrNocache(w http.ResponseWriter) {
	w.Header().Set("Expires", "Fri, 01 Jan 1980 00:00:00 GMT")
	w.Header().Set("Pragma", "no-cache")
	w.Header().Set("Cache-Control", "no-cache, max-age=0, must-revalidate")
}
source: func (h *UserHandler) handleGetUserLog(w http.ResponseWriter, r *http.Request) {
	ctx := r.Context()

	req, err := decodeGetUserLogRequest(ctx, r)
	if err != nil {
		EncodeError(ctx, err, w)
		return
	}

	log, _, err := h.UserOperationLogService.GetUserOperationLog(ctx, req.UserID, req.opts)
	if err != nil {
		EncodeError(ctx, err, w)
		return
	}

	if err := encodeResponse(ctx, w, http.StatusOK, newUserLogResponse(req.UserID, log)); err != nil {
		EncodeError(ctx, err, w)
		return
	}
}
source: func (c *Client) NewRequest(method, urlPath string, body interface{}) (*http.Request, error) {
	// Append out OXR App ID to URL, :-(
	urlPath = fmt.Sprintf("%s&app_id=%s", urlPath, c.AppID)

	// Parse our URL.
	rel, err := url.Parse(urlPath)
	if err != nil {
		return nil, err
	}

	// Resolve to absolute URI.
	u := c.BackendURL.ResolveReference(rel)

	buf := new(bytes.Buffer)
	if body != nil {
		err = json.NewEncoder(buf).Encode(body)
		if err != nil {
			return nil, err
		}
	}

	// Create the request.
	req, err := http.NewRequest(method, u.String(), buf)
	if err != nil {
		return nil, err
	}

	// Add our libraries UA.
	req.Header.Add("User-Agent", c.UserAgent)

	return req, nil
}
source: func hasValue(field reflect.Value) bool {
	switch field.Kind() {
	case reflect.Slice, reflect.Map, reflect.Ptr, reflect.Interface, reflect.Chan, reflect.Func:
		return !field.IsNil()
	default:
		return field.IsValid() && field.Interface() != reflect.Zero(field.Type()).Interface()
	}
}
source: func IsEmptyDir(root string) (bool, error) {
	if _, err := os.Stat(root); err != nil && os.IsNotExist(err) {
		return true, nil
	}

	fs, os, err := dirFiles(root)
	if err != nil {
		return false, err
	}

	return len(fs) == 0 && len(os) == 0, nil
}
source: func (p *printer) writeWhitespace(n int) {
	// write entries
	var data [1]byte
	for i := 0; i < n; i++ {
		switch ch := p.wsbuf[i]; ch {
		case ignore:
			// ignore!
		case indent:
			p.indent++
		case unindent:
			p.indent--
			if p.indent < 0 {
				p.internalError("negative indentation:", p.indent)
				p.indent = 0
			}
		case newline, formfeed:
			// A line break immediately followed by a "correcting"
			// unindent is swapped with the unindent - this permits
			// proper label positioning. If a comment is between
			// the line break and the label, the unindent is not
			// part of the comment whitespace prefix and the comment
			// will be positioned correctly indented.
			if i+1 < n && p.wsbuf[i+1] == unindent {
				// Use a formfeed to terminate the current section.
				// Otherwise, a long label name on the next line leading
				// to a wide column may increase the indentation column
				// of lines before the label; effectively leading to wrong
				// indentation.
				p.wsbuf[i], p.wsbuf[i+1] = unindent, formfeed
				i-- // do it again
				continue
			}
			fallthrough
		default:
			data[0] = byte(ch)
			p.write(data[0:])
		}
	}

	// shift remaining entries down
	i := 0
	for ; n < len(p.wsbuf); n++ {
		p.wsbuf[i] = p.wsbuf[n]
		i++
	}
	p.wsbuf = p.wsbuf[0:i]
}
source: func BuildOnewayYARPCProcedures(server OnewayYARPCServer) []transport.Procedure {
	handler := &_OnewayYARPCHandler{server}
	return protobuf.BuildProcedures(
		protobuf.BuildProceduresParams{
			ServiceName:        "uber.yarpc.internal.crossdock.Oneway",
			UnaryHandlerParams: []protobuf.BuildProceduresUnaryHandlerParams{},
			OnewayHandlerParams: []protobuf.BuildProceduresOnewayHandlerParams{
				{
					MethodName: "Echo",
					Handler: protobuf.NewOnewayHandler(
						protobuf.OnewayHandlerParams{
							Handle:     handler.Echo,
							NewRequest: newOnewayServiceEchoYARPCRequest,
						},
					),
				},
			},
			StreamHandlerParams: []protobuf.BuildProceduresStreamHandlerParams{},
		},
	)
}
source: func (ns *Namespace) Title(s interface{}) (string, error) {
	ss, err := cast.ToStringE(s)
	if err != nil {
		return "", err
	}

	return ns.titleFunc(ss), nil
}
source: func (r *Timing) Add(duration time.Duration) {
	b := r.getCurrentBucket()

	r.Mutex.Lock()
	defer r.Mutex.Unlock()

	b.Durations = append(b.Durations, duration)
	r.removeOldBuckets()
}
source: func (kubemarkController *KubemarkController) SetNodeGroupSize(nodeGroup string, size int) error {
	currSize, err := kubemarkController.GetNodeGroupTargetSize(nodeGroup)
	if err != nil {
		return err
	}
	switch delta := size - currSize; {
	case delta < 0:
		absDelta := -delta
		nodes, err := kubemarkController.GetNodeNamesForNodeGroup(nodeGroup)
		if err != nil {
			return err
		}
		if len(nodes) < absDelta {
			return fmt.Errorf("can't remove %d nodes from %s nodegroup, not enough nodes: %d", absDelta, nodeGroup, len(nodes))
		}
		for i, node := range nodes {
			if i == absDelta {
				return nil
			}
			if err := kubemarkController.RemoveNodeFromNodeGroup(nodeGroup, node); err != nil {
				return err
			}
		}
	case delta > 0:
		kubemarkController.nodeGroupQueueSizeLock.Lock()
		for i := 0; i < delta; i++ {
			kubemarkController.nodeGroupQueueSize[nodeGroup]++
			kubemarkController.createNodeQueue <- nodeGroup
		}
		kubemarkController.nodeGroupQueueSizeLock.Unlock()
	}

	return nil
}
source: func Tiocmbic(fd uintptr, status *int) error {
	return ioctl(fd, syscall.TIOCMBIC, uintptr(unsafe.Pointer(status)))
}
source: func (org *User) IsOrgMember(uid int64) bool {
	return org.IsOrganization() && IsOrganizationMember(org.ID, uid)
}
source: func Reset(c *gc.C) {
	logger.Infof("reset model")
	dummy.mu.Lock()
	dummy.ops = discardOperations
	oldState := dummy.state
	dummy.controllerState = nil
	dummy.state = make(map[string]*environState)
	dummy.newStatePolicy = stateenvirons.GetNewPolicyFunc()
	dummy.supportsSpaces = true
	dummy.supportsSpaceDiscovery = false
	dummy.mu.Unlock()

	// NOTE(axw) we must destroy the old states without holding
	// the provider lock, or we risk deadlocking. Destroying
	// state involves closing the embedded API server, which
	// may require waiting on RPC calls that interact with the
	// EnvironProvider (e.g. EnvironProvider.Open).
	for _, s := range oldState {
		if s.httpServer != nil {
			logger.Debugf("closing httpServer")
			s.httpServer.Close()
		}
		s.destroy()
	}
	if mongoAlive() {
		err := retry.Call(retry.CallArgs{
			Func: gitjujutesting.MgoServer.Reset,
			// Only interested in retrying the intermittent
			// 'unexpected message'.
			IsFatalError: func(err error) bool {
				return !strings.HasSuffix(err.Error(), "unexpected message")
			},
			Delay:    time.Millisecond,
			Clock:    clock.WallClock,
			Attempts: 5,
		})
		c.Assert(err, jc.ErrorIsNil)
	}
}
source: func (h *Headers) HasCorsHeadersDefined() bool {
	return h != nil && (h.AccessControlAllowCredentials ||
		len(h.AccessControlAllowHeaders) != 0 ||
		len(h.AccessControlAllowMethods) != 0 ||
		h.AccessControlAllowOrigin != "" ||
		len(h.AccessControlExposeHeaders) != 0 ||
		h.AccessControlMaxAge != 0 ||
		h.AddVaryHeader)
}
source: func deleteDeviceService(ds models.DeviceService, w http.ResponseWriter, ctx context.Context) error {
	// Delete the associated devices
	devices, err := dbClient.GetDevicesByServiceId(ds.Id)
	if err != nil {
		http.Error(w, err.Error(), http.StatusServiceUnavailable)
		return err
	}
	for _, device := range devices {
		if err = deleteDevice(device, w, ctx); err != nil {
			return err
		}
	}

	// Delete the associated provision watchers
	watchers, err := dbClient.GetProvisionWatchersByServiceId(ds.Id)
	if err != nil {
		http.Error(w, err.Error(), http.StatusServiceUnavailable)
		return err
	}
	for _, watcher := range watchers {
		if err = deleteProvisionWatcher(watcher, w); err != nil {
			return err
		}
	}

	// Delete the device service
	if err = dbClient.DeleteDeviceServiceById(ds.Id); err != nil {
		http.Error(w, err.Error(), http.StatusServiceUnavailable)
		return err
	}

	return nil
}
source: func (s *Server) Get(ctx context.Context, q *ClusterQuery) (*appv1.Cluster, error) {
	if err := s.enf.EnforceErr(ctx.Value("claims"), rbacpolicy.ResourceClusters, rbacpolicy.ActionGet, q.Server); err != nil {
		return nil, err
	}
	clust, err := s.db.GetCluster(ctx, q.Server)
	return redact(clust), err
}
source: func (r *DNSResolver) resolveOnceAsync(ctx context.Context, name string, options opts.ResolveOpts) <-chan onceResult {
	var fqdn string
	out := make(chan onceResult, 1)
	segments := strings.SplitN(name, "/", 2)
	domain := segments[0]

	if !isd.IsDomain(domain) {
		out <- onceResult{err: errors.New("not a valid domain name")}
		close(out)
		return out
	}
	log.Debugf("DNSResolver resolving %s", domain)

	if strings.HasSuffix(domain, ".") {
		fqdn = domain
	} else {
		fqdn = domain + "."
	}

	rootChan := make(chan lookupRes, 1)
	go workDomain(r, fqdn, rootChan)

	subChan := make(chan lookupRes, 1)
	go workDomain(r, "_dnslink."+fqdn, subChan)

	appendPath := func(p path.Path) (path.Path, error) {
		if len(segments) > 1 {
			return path.FromSegments("", strings.TrimRight(p.String(), "/"), segments[1])
		}
		return p, nil
	}

	go func() {
		defer close(out)
		for {
			select {
			case subRes, ok := <-subChan:
				if !ok {
					subChan = nil
					break
				}
				if subRes.error == nil {
					p, err := appendPath(subRes.path)
					emitOnceResult(ctx, out, onceResult{value: p, err: err})
					return
				}
			case rootRes, ok := <-rootChan:
				if !ok {
					rootChan = nil
					break
				}
				if rootRes.error == nil {
					p, err := appendPath(rootRes.path)
					emitOnceResult(ctx, out, onceResult{value: p, err: err})
				}
			case <-ctx.Done():
				return
			}
			if subChan == nil && rootChan == nil {
				return
			}
		}
	}()

	return out
}
source: func (b *BlockGen) OffsetTime(seconds int64) {
	b.header.Time += uint64(seconds)
	if b.header.Time <= b.parent.Header().Time {
		panic("block time out of range")
	}
	chainreader := &fakeChainReader{config: b.config}
	b.header.Difficulty = b.engine.CalcDifficulty(chainreader, b.header.Time, b.parent.Header())
}
source: func (m *mruNonceMap) Exists(nonce uint64) bool {
	m.mtx.Lock()
	_, exists := m.nonceMap[nonce]
	m.mtx.Unlock()

	return exists
}
source: func (re *Regexp) FindRunesMatchStartingAt(r []rune, startAt int) (*Match, error) {
	return re.run(false, startAt, r)
}
source: func NewMockService(ctrl *gomock.Controller) *MockService {
	mock := &MockService{ctrl: ctrl}
	mock.recorder = &MockServiceMockRecorder{mock}
	return mock
}
source: func (m *Meta) loadConfig(rootDir string) (*configs.Config, tfdiags.Diagnostics) {
	var diags tfdiags.Diagnostics
	rootDir = m.normalizePath(rootDir)

	loader, err := m.initConfigLoader()
	if err != nil {
		diags = diags.Append(err)
		return nil, diags
	}

	config, hclDiags := loader.LoadConfig(rootDir)
	diags = diags.Append(hclDiags)
	return config, diags
}
source: func (e *Endpoint) ConntrackName() string {
	if e.ConntrackLocalLocked() {
		return fmt.Sprintf("%05d", int(e.ID))
	}
	return "global"
}
source: func NewTempFileSink() (Sink, error) {
	tempFile, err := ioutil.TempFile("/tmp", "grpcgo_binarylog_*.txt")
	if err != nil {
		return nil, fmt.Errorf("failed to create temp file: %v", err)
	}
	return newBufWriteCloserSink(tempFile), nil
}
source: func (s *ShutdownEventConfiguration) SetExecutionTimeout(v int64) *ShutdownEventConfiguration {
	s.ExecutionTimeout = &v
	return s
}
source: func (user *User) OauthRedirectURL() string {
	providerID := user.ctx.OAuthProvider().internalID()
	if providerID == user.ctx.ServiceName {
		return fmt.Sprintf("%s/auth/%s", Config.BaseURL, user.ctx.ServiceName)
	}

	return fmt.Sprintf("%s/auth/%s/%s", Config.BaseURL, user.ctx.ServiceName, providerID)
}
source: func (nu *Numbered) unregister(id int64, reason string) bool {
	nu.mu.Lock()
	defer nu.mu.Unlock()

	_, ok := nu.resources[id]
	delete(nu.resources, id)
	if len(nu.resources) == 0 {
		nu.empty.Broadcast()
	}
	return ok
}
source: func (s *PipelineActivity) SetAddAttributes(v *AddAttributesActivity) *PipelineActivity {
	s.AddAttributes = v
	return s
}
source: func WriteJSON(data interface{}) ([]byte, error) {
	if d, ok := data.(ejMarshaler); ok {
		jw := new(jwriter.Writer)
		d.MarshalEasyJSON(jw)
		return jw.BuildBytes()
	}
	if d, ok := data.(json.Marshaler); ok {
		return d.MarshalJSON()
	}
	return json.Marshal(data)
}
source: func NewSuggesterCategoryIndex(name string, values ...string) *SuggesterCategoryIndex {
	q := &SuggesterCategoryIndex{
		name:   name,
		values: values,
	}
	return q
}
source: func (c *Client) CollaboratorList(appIdentity string, lr *ListRange) ([]Collaborator, error) {
	req, err := c.NewRequest("GET", "/apps/"+appIdentity+"/collaborators", nil, nil)
	if err != nil {
		return nil, err
	}

	if lr != nil {
		lr.SetHeader(req)
	}

	var collaboratorsRes []Collaborator
	return collaboratorsRes, c.DoReq(req, &collaboratorsRes)
}
source: func Init(params map[string]string) (volume.VolumeDriver, error) {
	nbdInit()

	inst := &driver{
		IODriver: volume.IONotSupported,
		StoreEnumerator: common.NewDefaultStoreEnumerator(Name,
			kvdb.Instance()),
		StatsDriver:        volume.StatsNotSupported,
		QuiesceDriver:      volume.QuiesceNotSupported,
		CredsDriver:        volume.CredsNotSupported,
		CloudBackupDriver:  volume.CloudBackupNotSupported,
		CloudMigrateDriver: volume.CloudMigrateNotSupported,
	}
	inst.buseDevices = make(map[string]*buseDev)
	if err := os.MkdirAll(BuseMountPath, 0744); err != nil {
		return nil, err
	}
	volumeInfo, err := inst.StoreEnumerator.Enumerate(
		&api.VolumeLocator{},
		nil,
	)
	if err == nil {
		for _, info := range volumeInfo {
			if info.Status == api.VolumeStatus_VOLUME_STATUS_NONE {
				info.Status = api.VolumeStatus_VOLUME_STATUS_UP
				inst.UpdateVol(info)
			}
		}
	} else {
		logrus.Println("Could not enumerate Volumes, ", err)
	}

	inst.cl = &clusterListener{}
	c, err := clustermanager.Inst()
	if err != nil {
		logrus.Println("BUSE initializing in single node mode")
	} else {
		logrus.Println("BUSE initializing in clustered mode")
		c.AddEventListener(inst.cl)
	}

	logrus.Println("BUSE initialized and driver mounted at: ", BuseMountPath)
	return inst, nil
}
source: func (arn Arn) String() string {
	return "arn:" + arn.Partition + ":" + arn.Service + ":" + arn.Region + ":" + arn.AccountID + ":" + arn.Resource
}
source: func GetSummary(c ConfusionMatrix) string {
	var buffer bytes.Buffer
	w := new(tabwriter.Writer)
	w.Init(&buffer, 0, 8, 0, '\t', 0)

	fmt.Fprintln(w, "Reference Class\tTrue Positives\tFalse Positives\tTrue Negatives\tPrecision\tRecall\tF1 Score")
	fmt.Fprintln(w, "---------------\t--------------\t---------------\t--------------\t---------\t------\t--------")
	for k := range c {
		tp := GetTruePositives(k, c)
		fp := GetFalsePositives(k, c)
		tn := GetTrueNegatives(k, c)
		prec := GetPrecision(k, c)
		rec := GetRecall(k, c)
		f1 := GetF1Score(k, c)

		fmt.Fprintf(w, "%s\t%.0f\t%.0f\t%.0f\t%.4f\t%.4f\t%.4f\n", k, tp, fp, tn, prec, rec, f1)
	}
	w.Flush()
	buffer.WriteString(fmt.Sprintf("Overall accuracy: %.4f\n", GetAccuracy(c)))

	return buffer.String()
}
source: func getPanicLogger() *zap.Logger {
	panicLoggerOnce.Do(func() {
		panicLogger = influxlogger.New(os.Stderr)
		panicLogger = panicLogger.With(zap.String("handler", "panic"))
	})

	return panicLogger
}
source: func InitDB(path string) error {
	db, err := sql.Open("sqlite3", path)
	if err != nil {
		return err
	}
	defer db.Close()
	for _, tableSQL := range SQLCreateTables() {
		if _, err := db.Exec(tableSQL); err != nil {
			return err
		}
	}

	// Use Write Ahead Logging which improves SQLite concurrency.
	// Requires SQLite >= 3.7.0
	if _, err := db.Exec("PRAGMA journal_mode = WAL"); err != nil {
		return err
	}

	// Check if the WAL mode was set correctly
	var journalMode string
	if err = db.QueryRow("PRAGMA journal_mode").Scan(&journalMode); err != nil {
		log.Fatalf("Unable to determine sqlite3 journal_mode: %v", err)
	}
	if journalMode != "wal" {
		log.Fatal("SQLite Write Ahead Logging (introducted in v3.7.0) is required. See http://perkeep.org/issue/114")
	}

	_, err = db.Exec(fmt.Sprintf(`REPLACE INTO meta VALUES ('version', '%d')`, SchemaVersion()))
	return err
}
source: func CreateFrame(x, y, w, h int, fg, bg termbox.Attribute) *Frame {
	c := Frame{x: x, y: y, width: w, height: h,
		fg: fg, bg: bg, activeFg: fg, activeBg: bg,
		bordered: true,
	}
	return &c
}
source: func (s *Server) UpdateConfiguration(_ context.Context, request *throttlerdatapb.UpdateConfigurationRequest) (_ *throttlerdatapb.UpdateConfigurationResponse, err error) {
	defer servenv.HandlePanic("throttler", &err)

	names, err := s.manager.UpdateConfiguration(request.ThrottlerName, request.Configuration, request.CopyZeroValues)
	if err != nil {
		return nil, err
	}
	return &throttlerdatapb.UpdateConfigurationResponse{
		Names: names,
	}, nil
}
source: func (ya *YubiAuth) UseHttps(useHttps bool) {
	// Lock
	ya.use.Lock()
	defer ya.use.Unlock()

	// change setting
	if useHttps {
		ya.protocol = "https://"
	} else {
		ya.protocol = "http://"
	}

	// no need to rebuild workers, they re-read ya.protocol on each request.
}
source: func SamplePercentile(values int64Slice, p float64) float64 {
	return SamplePercentiles(values, []float64{p})[0]
}
source: func (i *Datetime) Reduce(input chan *Entry, output chan *Entry) {
	for entry := range input {
		if valid := i.Filter(entry); valid != nil {
			output <- valid
		}
	}
	close(output)
}
source: func (api *Client) InviteGuestContext(ctx context.Context, teamName, channel, firstName, lastName, emailAddress string) error {
	values := url.Values{
		"email":            {emailAddress},
		"channels":         {channel},
		"first_name":       {firstName},
		"last_name":        {lastName},
		"ultra_restricted": {"1"},
		"token":            {api.token},
		"resend":           {"true"},
		"set_active":       {"true"},
		"_attempts":        {"1"},
	}

	err := api.adminRequest(ctx, "invite", teamName, values)
	if err != nil {
		return fmt.Errorf("Failed to invite single-channel guest: %s", err)
	}

	return nil
}
source: func (u *ID) Addr() (updateAddr storage.Address) {
	serializedData := make([]byte, idLength)
	var cursor int
	u.Feed.binaryPut(serializedData[cursor : cursor+feedLength])
	cursor += feedLength

	eid := u.Epoch.ID()
	copy(serializedData[cursor:cursor+lookup.EpochLength], eid[:])

	hasher := hashPool.Get().(hash.Hash)
	defer hashPool.Put(hasher)
	hasher.Reset()
	hasher.Write(serializedData)
	return hasher.Sum(nil)
}
source: func (c *Client) TorrentGetAll() (torrents []*Torrent, err error) {
	// Send already validated fields to the low level fx
	return c.torrentGet(validTorrentFields, nil)
}
source: func NewGLogWriterV(level int) io.Writer {
	return &gLogWriter{
		level: klog.Level(level),
	}
}
source: func (store *EvidenceStore) MarkEvidenceAsCommitted(evidence types.Evidence) {
	// if its committed, its been broadcast
	store.MarkEvidenceAsBroadcasted(evidence)

	pendingKey := keyPending(evidence)
	store.db.Delete(pendingKey)

	// committed EvidenceInfo doens't need priority
	ei := EvidenceInfo{
		Committed: true,
		Evidence:  evidence,
		Priority:  0,
	}

	lookupKey := keyLookup(evidence)
	store.db.SetSync(lookupKey, cdc.MustMarshalBinaryBare(ei))
}
source: func (c *Client) GetIDNameMap(id string) (map[string]string, error) {
	uri := fmt.Sprintf("%s/code-lists/%s/codes", c.url, id)
	resp, err := c.cli.Get(context.Background(), uri)
	if err != nil {
		return nil, err
	}

	if resp.StatusCode != http.StatusOK {
		err = &ErrInvalidCodelistAPIResponse{http.StatusOK, resp.StatusCode, uri}
		return nil, err
	}

	b, err := ioutil.ReadAll(resp.Body)
	if err != nil {
		return nil, err
	}
	defer resp.Body.Close()

	var vals DimensionValues
	if err = json.Unmarshal(b, &vals); err != nil {
		return nil, err
	}

	idNames := make(map[string]string)
	for _, val := range vals.Items {
		idNames[val.ID] = val.Label
	}

	return idNames, nil
}
source: func (f *LogFile) TagValueSeriesIDSet(name, key, value []byte) (*tsdb.SeriesIDSet, error) {
	f.mu.RLock()
	defer f.mu.RUnlock()

	mm, ok := f.mms[string(name)]
	if !ok {
		return nil, nil
	}

	tk, ok := mm.tagSet[string(key)]
	if !ok {
		return nil, nil
	}

	tv, ok := tk.tagValues[string(value)]
	if !ok {
		return nil, nil
	} else if tv.cardinality() == 0 {
		return nil, nil
	}

	return tv.seriesIDSet(), nil
}
source: func newNode(id, network, address string) (*node, error) {
	if len(id) != 20 {
		return nil, errors.New("node id should be a 20-length string")
	}

	addr, err := net.ResolveUDPAddr(network, address)
	if err != nil {
		return nil, err
	}

	return &node{newBitmapFromString(id), addr, time.Now()}, nil
}
source: func (c *Carbon) NextWeekendDay() *Carbon {
	c = c.AddDay()
	for !c.IsWeekend() {
		c = c.AddDay()
	}

	return c
}
source: func (l *proxyProtocolListener) Accept() (net.Conn, error) {
	ce := <-l.acceptQueue
	if opErr, ok := ce.err.(*net.OpError); ok {
		if opErr.Err.Error() == "use of closed network connection" {
			close(l.acceptQueue)
		}
	}
	return ce.conn, ce.err
}
source: func (b *Bucket) Delete(key []byte) error {
	err := b.bucket.Delete(key)
	if err == bolt.ErrTxNotWritable {
		return kv.ErrTxNotWritable
	}
	return err
}
source: func (s *AdminCreateUserConfigType) SetUnusedAccountValidityDays(v int64) *AdminCreateUserConfigType {
	s.UnusedAccountValidityDays = &v
	return s
}
source: func Convert_route_RouteList_To_v1_RouteList(in *route.RouteList, out *v1.RouteList, s conversion.Scope) error {
	return autoConvert_route_RouteList_To_v1_RouteList(in, out, s)
}
source: func (t Term) Timezone(args ...interface{}) Term {
	return constructMethodTerm(t, "Timezone", p.Term_TIMEZONE, args, map[string]interface{}{})
}
source: func (c *Callbacks) OnCMsgSource1LegacyListenEvents(fn func(*dota.CMsgSource1LegacyListenEvents) error) {
	c.onCMsgSource1LegacyListenEvents = append(c.onCMsgSource1LegacyListenEvents, fn)
}
source: func Check(err error, checker func(error) bool) bool {
	if annotated, ok := err.(*annotatedError); ok {
		return checker(annotated.LastError())
	}
	return checker(err)
}
source: func (_class PVSProxyClass) GetStatus(sessionID SessionRef, self PVSProxyRef) (_retval PvsProxyStatus, _err error) {
	_method := "PVS_proxy.get_status"
	_sessionIDArg, _err := convertSessionRefToXen(fmt.Sprintf("%s(%s)", _method, "session_id"), sessionID)
	if _err != nil {
		return
	}
	_selfArg, _err := convertPVSProxyRefToXen(fmt.Sprintf("%s(%s)", _method, "self"), self)
	if _err != nil {
		return
	}
	_result, _err := _class.client.APICall(_method, _sessionIDArg, _selfArg)
	if _err != nil {
		return
	}
	_retval, _err = convertEnumPvsProxyStatusToGo(_method + " -> ", _result.Value)
	return
}
source: func (cache *RelationCache) Settings(unitName string) (params.Settings, error) {
	settings, isMember := cache.members[unitName]
	if settings == nil {
		if !isMember {
			settings = cache.others[unitName]
		}
		if settings == nil {
			var err error
			settings, err = cache.readSettings(unitName)
			if err != nil {
				return nil, err
			}
		}
	}
	if isMember {
		cache.members[unitName] = settings
	} else {
		cache.others[unitName] = settings
	}
	return settings, nil
}
source: func (dec *Decoder) Array(v UnmarshalerJSONArray) error {
	newCursor, err := dec.decodeArray(v)
	if err != nil {
		return err
	}
	dec.cursor = newCursor
	dec.called |= 1
	return nil
}
source: func (c *CipherSeed) decode(r io.Reader) error {
	err := binary.Read(r, binary.BigEndian, &c.InternalVersion)
	if err != nil {
		return err
	}

	if err := binary.Read(r, binary.BigEndian, &c.Birthday); err != nil {
		return err
	}

	if _, err := io.ReadFull(r, c.Entropy[:]); err != nil {
		return err
	}

	return nil
}
source: func (h *ScriptEventHandler) UpdateScripts(scripts []EventScript) {
	h.scriptLock.Lock()
	defer h.scriptLock.Unlock()
	h.newScripts = scripts
}
source: func (s *Store) ChangePassphrase(new []byte) error {
	s.mtx.Lock()
	defer s.mtx.Unlock()

	if s.flags.watchingOnly {
		return ErrWatchingOnly
	}

	if s.isLocked() {
		return ErrLocked
	}

	oldkey := s.secret
	newkey := kdf(new, &s.kdfParams)

	for _, wa := range s.addrMap {
		// Only btcAddresses curently have private keys.
		a, ok := wa.(*btcAddress)
		if !ok {
			continue
		}

		if err := a.changeEncryptionKey(oldkey, newkey); err != nil {
			return err
		}
	}

	// zero old secrets.
	zero(s.passphrase)
	zero(s.secret)

	// Save new secrets.
	s.passphrase = new
	s.secret = newkey

	return nil
}
source: func (s *FirewallService) NewDeleteFirewallRuleParams(id string) *DeleteFirewallRuleParams {
	p := &DeleteFirewallRuleParams{}
	p.p = make(map[string]interface{})
	p.p["id"] = id
	return p
}
source: func clamp(x int64) uint64 {
	if x < 0 {
		return 0
	}
	if x > math.MaxInt64 {
		return math.MaxUint64
	}
	return uint64(x)
}
source: func commitID() string {
	// git log --format="%h" -n1
	var (
		commit []byte
		e      error
	)
	cmdName := "git"
	cmdArgs := []string{"log", "--format=%H", "-n1"}
	if commit, e = exec.Command(cmdName, cmdArgs...).Output(); e != nil {
		fmt.Fprintln(os.Stderr, "Error generating git commit-id: ", e)
		os.Exit(1)
	}

	return strings.TrimSpace(string(commit))
}
source: func (p *htlcPacket) inKey() CircuitKey {
	return CircuitKey{
		ChanID: p.incomingChanID,
		HtlcID: p.incomingHTLCID,
	}
}
source: func (cniApp *cniAppInfo) init() {
	cniApp.serverURL = "http://localhost"

	trans := &http.Transport{Dial: func(network, addr string) (net.Conn,
		error) {
		return net.Dial("unix", cniapi.ContivMesosSocket)
	}}
	cniApp.httpClient = &http.Client{Transport: trans}
}
source: func NewCertCreator() *CertCreator {
	return &CertCreator{
		Serial:    1,
		NotBefore: time.Now(),
		NotAfter:  time.Date(2049, 12, 31, 23, 59, 59, 0, time.UTC), // end of ASN.1 time
		KeySize:   4096,
	}
}
source: func Create(y int, mon time.Month, d, h, m, s, ns int, location string) (*Carbon, error) {
	l, err := time.LoadLocation(location)
	if err != nil {
		return nil, err
	}
	return create(y, mon, d, h, m, s, ns, l), nil
}
source: func (uf UnitFacade) Track(args params.TrackPayloadArgs) (params.PayloadResults, error) {
	logger.Debugf("tracking %d payloads from API", len(args.Payloads))

	var r params.PayloadResults
	for _, apiPayload := range args.Payloads {
		pl, err := api.API2Payload(apiPayload)
		if err != nil {
			return r, errors.Trace(err)
		}
		logger.Debugf("tracking payload from API: %#v", pl)

		id, err := uf.track(pl.Payload)
		res := newPayloadResult(id, err)
		r.Results = append(r.Results, res)
	}
	return r, nil
}
source: func serializeKeysetBundle(o *kops.Keyset) ([]byte, error) {
	var objectData bytes.Buffer
	codecs := kopscodecs.Codecs
	yaml, ok := runtime.SerializerInfoForMediaType(codecs.SupportedMediaTypes(), "application/yaml")
	if !ok {
		glog.Fatalf("no YAML serializer registered")
	}
	encoder := codecs.EncoderForVersion(yaml.Serializer, v1alpha2.SchemeGroupVersion)

	if err := encoder.Encode(o, &objectData); err != nil {
		return nil, fmt.Errorf("error serializing keyset: %v", err)
	}
	return objectData.Bytes(), nil
}
source: func (d *Data) UnmarshalBinary(p []byte) error {
	b := buffer.New(p)
	return d.Unmarshal(b)
}
source: func (c *Client) DeleteReverseTunnel(domainName string) error {
	// this is to avoid confusing error in case if domain empty for example
	// HTTP route will fail producing generic not found error
	// instead we catch the error here
	if strings.TrimSpace(domainName) == "" {
		return trace.BadParameter("empty domain name")
	}
	_, err := c.Delete(c.Endpoint("reversetunnels", domainName))
	return trace.Wrap(err)
}
source: func (s *lockBasedTxSimulator) SetStateMetadata(namespace, key string, metadata map[string][]byte) error {
	if err := s.checkWritePrecondition(key, nil); err != nil {
		return err
	}
	s.rwsetBuilder.AddToMetadataWriteSet(namespace, key, metadata)
	return nil
}
source: func (db *nodeDB) findFails(id NodeID) int {
	return int(db.fetchInt64(makeKey(id, nodeDBDiscoverFindFails)))
}
source: func (g *Cloud) DeleteNetworkEndpointGroup(name string, zone string) error {
	ctx, cancel := cloud.ContextWithCallTimeout()
	defer cancel()

	mc := newNetworkEndpointGroupMetricContext("delete", zone)
	return mc.Observe(g.c.BetaNetworkEndpointGroups().Delete(ctx, meta.ZonalKey(name, zone)))
} 35%|███▍      | 1730/5000 [00:02<00:03, 889.16it/s]
source: func Copypath(dst string, src string, tests, all bool) error {
	err := filepath.Walk(src, func(path string, info os.FileInfo, err error) error {
		if err != nil {
			return err
		}

		skip := ShouldSkip(path, info, tests, all)

		if skip {
			if info.IsDir() {
				return filepath.SkipDir
			}
			return nil
		}

		if info.IsDir() {
			return nil
		}

		dst := filepath.Join(dst, path[len(src):])

		if info.Mode()&os.ModeSymlink != 0 {
			return Copylink(dst, path)
		}

		return Copyfile(dst, path)
	})
	if err != nil {
		// if there was an error during copying, remove the partial copy.
		RemoveAll(dst)
	}
	return err
}
source: func (m *Multiplexer) RPCObserver() rpc.Observer {
	rpcObservers := make([]rpc.Observer, len(m.observers))
	for i, o := range m.observers {
		rpcObservers[i] = o.RPCObserver()
	}
	return rpc.NewObserverMultiplexer(rpcObservers...)
}
source: func (c *Client) SetModelConstraints(args params.SetConstraints) error {
	if err := c.checkCanWrite(); err != nil {
		return err
	}

	if err := c.check.ChangeAllowed(); err != nil {
		return errors.Trace(err)
	}
	return c.api.stateAccessor.SetModelConstraints(args.Constraints)
}
source: func (s *VideoPreprocessor) SetColorCorrector(v *ColorCorrector) *VideoPreprocessor {
	s.ColorCorrector = v
	return s
}
source: func (service *BaseService) Unicast(
	topic string, id string, result interface{}, callback func(bool)) {
	service.unicast(service.getTopic(topic), topic, id, result, callback)
}
source: func setTagsDynamoDb(conn *dynamodb.DynamoDB, d *schema.ResourceData) error {
	arn := d.Get("arn").(string)
	oraw, nraw := d.GetChange("tags")
	o := oraw.(map[string]interface{})
	n := nraw.(map[string]interface{})
	create, remove := diffTagsDynamoDb(tagsFromMapDynamoDb(o), tagsFromMapDynamoDb(n))

	// Set tags
	if len(remove) > 0 {
		err := resource.Retry(2*time.Minute, func() *resource.RetryError {
			log.Printf("[DEBUG] Removing tags: %#v from %s", remove, d.Id())
			_, err := conn.UntagResource(&dynamodb.UntagResourceInput{
				ResourceArn: aws.String(arn),
				TagKeys:     remove,
			})
			if err != nil {
				if isAWSErr(err, dynamodb.ErrCodeResourceNotFoundException, "") {
					return resource.RetryableError(err)
				}
				return resource.NonRetryableError(err)
			}
			return nil
		})
		if err != nil {
			return err
		}
	}
	if len(create) > 0 {
		err := resource.Retry(2*time.Minute, func() *resource.RetryError {
			log.Printf("[DEBUG] Creating tags: %s for %s", create, d.Id())
			_, err := conn.TagResource(&dynamodb.TagResourceInput{
				ResourceArn: aws.String(arn),
				Tags:        create,
			})
			if err != nil {
				if isAWSErr(err, dynamodb.ErrCodeResourceNotFoundException, "") {
					return resource.RetryableError(err)
				}
				return resource.NonRetryableError(err)
			}
			return nil
		})
		if err != nil {
			return err
		}
	}

	return nil
}
source: func LinkSubscribe(ch chan<- LinkUpdate, done <-chan struct{}) error {
	return linkSubscribeAt(netns.None(), netns.None(), ch, done, nil, false)
}
source: func (s *Service) OrganizationMemberAppList(ctx context.Context, organizationIdentity string, organizationMemberIdentity string, lr *ListRange) (OrganizationMemberAppListResult, error) {
	var organizationMember OrganizationMemberAppListResult
	return organizationMember, s.Get(ctx, &organizationMember, fmt.Sprintf("/organizations/%v/members/%v/apps", organizationIdentity, organizationMemberIdentity), nil, lr)
}
source: func (u *Unit) ApplicationName() string {
	application, err := names.UnitApplication(u.Name())
	if err != nil {
		panic(err)
	}
	return application
}
source: func (l *dependencyListCmd) printRequirements(reqs *chartutil.Requirements, out io.Writer) {
	table := uitable.New()
	table.MaxColWidth = 80
	table.AddRow("NAME", "VERSION", "REPOSITORY", "STATUS")
	for _, row := range reqs.Dependencies {
		table.AddRow(row.Name, row.Version, row.Repository, l.dependencyStatus(row))
	}
	fmt.Fprintln(out, table)
}
source: func (c *Callbacks) OnCUserMessageSendAudio(fn func(*dota.CUserMessageSendAudio) error) {
	c.onCUserMessageSendAudio = append(c.onCUserMessageSendAudio, fn)
}
source: func (w *filePoller) sendErr(e error, chClose <-chan struct{}) error {
	select {
	case w.errors <- e:
	case <-chClose:
		return fmt.Errorf("closed")
	}
	return nil
}
source: func SaveRole(directory, filename, section string, roleUUID string) error {
	kfile := directory + filename

	config, err := ini.Load(kfile)

	if err != nil {
		os.Mkdir(directory, 0755)
		config = ini.Empty()
		config.NewSection(section)
	}

	config.Section(section).NewKey("role_uuid", roleUUID)
	return config.SaveTo(kfile)
}
source: func (s *Scheme) ObjectVersionAndKind(obj Object) (version, kind string, err error) {
	return s.raw.ObjectVersionAndKind(obj)
}
source: func ExtractInsidePolygon(opts ...interface{}) *opt.InsidePolygonOption {
	for _, o := range opts {
		if v, ok := o.(*opt.InsidePolygonOption); ok {
			return v
		}
	}
	return nil
}
source: func (b *AESGCMBarrier) persistKeyring(ctx context.Context, keyring *Keyring) error {
	// Create the keyring entry
	keyringBuf, err := keyring.Serialize()
	defer memzero(keyringBuf)
	if err != nil {
		return errwrap.Wrapf("failed to serialize keyring: {{err}}", err)
	}

	// Create the AES-GCM
	gcm, err := b.aeadFromKey(keyring.MasterKey())
	if err != nil {
		return err
	}

	// Encrypt the barrier init value
	value, err := b.encrypt(keyringPath, initialKeyTerm, gcm, keyringBuf)
	if err != nil {
		return err
	}

	// Create the keyring physical entry
	pe := &physical.Entry{
		Key:   keyringPath,
		Value: value,
	}
	if err := b.backend.Put(ctx, pe); err != nil {
		return errwrap.Wrapf("failed to persist keyring: {{err}}", err)
	}

	// Serialize the master key value
	key := &Key{
		Term:    1,
		Version: 1,
		Value:   keyring.MasterKey(),
	}
	keyBuf, err := key.Serialize()
	defer memzero(keyBuf)
	if err != nil {
		return errwrap.Wrapf("failed to serialize master key: {{err}}", err)
	}

	// Encrypt the master key
	activeKey := keyring.ActiveKey()
	aead, err := b.aeadFromKey(activeKey.Value)
	if err != nil {
		return err
	}
	value, err = b.encrypt(masterKeyPath, activeKey.Term, aead, keyBuf)
	if err != nil {
		return err
	}

	// Update the masterKeyPath for standby instances
	pe = &physical.Entry{
		Key:   masterKeyPath,
		Value: value,
	}
	if err := b.backend.Put(ctx, pe); err != nil {
		return errwrap.Wrapf("failed to persist master key: {{err}}", err)
	}
	return nil
}
source: func (c *config) initialize(prefixFlag string) {
	// Local container map to query by expanded name
	containerMap := make(map[string]*container)
	for rawName, container := range c.RawContainers {
		container.RawName = rawName
		containerMap[container.Name()] = container
	}
	// Local hooks map to query by expanded name
	hooksMap := make(map[string]hooks)
	for hooksRawName, hooks := range c.RawHooks {
		hooksMap[expandEnv(hooksRawName)] = hooks
	}
	// Groups
	c.groups = make(map[string][]string)
	for groupRawName, rawNames := range c.RawGroups {
		groupName := expandEnv(groupRawName)
		for _, rawName := range rawNames {
			c.groups[groupName] = append(c.groups[groupName], expandEnv(rawName))
		}
		if hooks, ok := hooksMap[groupName]; ok {
			// attach group-defined hooks to the group containers
			for _, name := range c.groups[groupName] {
				if overriden := containerMap[name].hooks.CopyFrom(hooks); overriden {
					panic(StatusError{fmt.Errorf("Multiple conflicting hooks inherited from groups for container `%s`", name), 64})
				}
			}
		}
	}
	// Cmds
	c.cmds = make(map[string][]string)
	for cmdRawName, rawCmd := range c.RawCmds {
		cmdName := expandEnv(cmdRawName)
		c.cmds[cmdName] = stringSlice(rawCmd)
	}
	// Container map
	c.containerMap = make(map[string]Container)
	for name, container := range containerMap {
		if hooks, ok := hooksMap[name]; ok {
			// attach container-defined hooks, overriding potential group-inherited hooks
			container.hooks.CopyFrom(hooks)
		}
		c.containerMap[name] = container
	}

	c.determinePrefix(prefixFlag)
	c.setNetworkMap()
	c.setVolumeMap()
	c.setAcceleratedMountMap()
}
source: func listPipelineGroupsAction(client *gocd.Client, c *cli.Context) (r interface{}, resp *gocd.APIResponse, err error) {
	return client.PipelineGroups.List(context.Background(), c.String("group-name"))
}
source: func (s *NielsenConfiguration) SetDistributorId(v string) *NielsenConfiguration {
	s.DistributorId = &v
	return s
}
source: func MinTLS(connectionType string) uint16 {
	configInfo, ok := configMap[connectionType]
	if !ok {
		glog.Fatalf("connectionType %s is undefined", connectionType)
	}
	return configInfo.minTLSVersion
}
source: func (s *PublicTransactionPoolAPI) SendRawTransaction(ctx context.Context, encodedTx hexutil.Bytes) (common.Hash, error) {
	tx := new(types.Transaction)
	if err := rlp.DecodeBytes(encodedTx, tx); err != nil {
		return common.Hash{}, err
	}
	return SubmitTransaction(ctx, s.b, tx)
}
source: func (r *Response) StatusCode() int {
	if r.statusCode <= 0 {
		r.statusCode = 200
	}
	return r.statusCode
}
source: func (c *Overlay) SetShowScrollBottleneckRectsWithParams(v *OverlaySetShowScrollBottleneckRectsParams) (*gcdmessage.ChromeResponse, error) {
	return gcdmessage.SendDefaultRequest(c.target, c.target.GetSendCh(), &gcdmessage.ParamRequest{Id: c.target.GetId(), Method: "Overlay.setShowScrollBottleneckRects", Params: v})
}
source: func (r *Router) PutFunc(pattern string, fn http.HandlerFunc) Route {
	return r.Put(pattern, http.HandlerFunc(fn))
}
source: func (c *Client) Update(object Object) (updateTime time.Time, err error) {
	className, err := objectTypeName(object)
	if err != nil {
		return updateTime, err
	}
	payload, err := json.Marshal(object)
	uri := fmt.Sprintf("/1/classes/%s/%s", className, object.ObjectID())
	resp, err := c.doWithBody("PUT", uri, bytes.NewReader(payload))
	if err != nil {
		return updateTime, err
	}
	defer resp.Body.Close()
	body, err := ioutil.ReadAll(resp.Body)
	if err != nil {
		return updateTime, err
	}
	c.trace("Update", uri, string(body))
	updatedAt := &struct {
		Time time.Time `json:"updatedAt"`
	}{}
	err = json.Unmarshal(body, updatedAt)
	return updatedAt.Time, err
}
source: func (c *cluster) ShardNodes(index string, shard uint64) []*Node {
	c.mu.RLock()
	defer c.mu.RUnlock()
	return c.shardNodes(index, shard)
}
source: func (l *HandlerList) SwapNamed(n NamedHandler) (swapped bool) {
	for i := 0; i < len(l.list); i++ {
		if l.list[i].Name == n.Name {
			l.list[i].Fn = n.Fn
			swapped = true
		}
	}

	return swapped
}
source: func (ctx *context) URLParamInt32Default(name string, def int32) int32 {
	if v := ctx.URLParam(name); v != "" {
		n, err := strconv.ParseInt(v, 10, 32)
		if err != nil {
			return def
		}

		return int32(n)
	}

	return def
}
source: func (rb *Bitmap) GetCardinality() uint64 {
	size := uint64(0)
	for _, c := range rb.highlowcontainer.containers {
		size += uint64(c.getCardinality())
	}
	return size
}
source: func IndexOfImageSignatureByName(signatures []ImageSignature, name string) int {
	for i := range signatures {
		if signatures[i].Name == name {
			return i
		}
	}
	return -1
}
source: func (m *MockSDListener) AddServer(arg0 *cluster.Server) {
	m.ctrl.Call(m, "AddServer", arg0)
}
source: func Tags(tags map[string]string) TracerOption {
	return func(o *tracerOptions) {
		for k, v := range tags {
			o.tags[k] = v
		}
	}
}
source: func (j *Job) Refresh() error {
	t := newTransaction()
	t.scanJobById(j.id, j)
	if err := t.exec(); err != nil {
		return err
	}
	return nil
}
source: func (n *Narcissus) NewPasswdUser(user string) (p *PasswdUser, err error) {
	p = &PasswdUser{
		augeasPath: "/files/etc/passwd/" + user,
	}
	err = n.Parse(p)
	return
}
source: func (l *Logger) Info(msg string, v ...interface{}) {
	l.Log("INFO", msg, v)
}
source: func (md *RootMetadataV3) SetLastModifyingWriter(user keybase1.UID) {
	md.WriterMetadata.LastModifyingWriter = user
}
source: func (e *etc) Write(target io.Writer, prettyPrint bool) error {
	// Build the nodes tree.
	builder := sml.NewNodeBuilder()
	depth := 0
	err := e.values.DoAllDeep(func(ks []string, v string) error {
		doDepth := len(ks)
		tag := ks[doDepth-1]
		for i := depth; i > doDepth; i-- {
			builder.EndTagNode()
		}
		switch {
		case doDepth > depth:
			builder.BeginTagNode(tag)
			builder.TextNode(v)
			depth = doDepth
		case doDepth == depth:
			builder.EndTagNode()
			builder.BeginTagNode(tag)
			builder.TextNode(v)
		case doDepth < depth:
			builder.EndTagNode()
			builder.BeginTagNode(tag)
			builder.TextNode(v)
			depth = doDepth
		}
		return nil
	})
	if err != nil {
		return err
	}
	for i := depth; i > 0; i-- {
		builder.EndTagNode()
	}
	root, err := builder.Root()
	if err != nil {
		return err
	}
	// Now write the node structure.
	wp := sml.NewStandardSMLWriter()
	wctx := sml.NewWriterContext(wp, target, prettyPrint, "   ")
	return sml.WriteSML(root, wctx)
}
source: func (c *Client) Enqueue(arg params.Actions) (params.ActionResults, error) {
	results := params.ActionResults{}
	err := c.facade.FacadeCall("Enqueue", arg, &results)
	return results, err
}
source: func (p *PushEvent) GetDistinctSize() int {
	if p == nil || p.DistinctSize == nil {
		return 0
	}
	return *p.DistinctSize
}
source: func (w *CeleryWorker) GetTask(name string) interface{} {
	w.taskLock.RLock()
	task, ok := w.registeredTasks[name]
	if !ok {
		w.taskLock.RUnlock()
		return nil
	}
	w.taskLock.RUnlock()
	return task
}
source: func TCPConnectionExpirationNotifier(c cache.DataStore, id interface{}, item interface{}) {

	if conn, ok := item.(*TCPConnection); ok {
		conn.Cleanup(true)
	}
}
source: func NewImportPrivKeyCmd(privKey string, label *string, rescan *bool) *ImportPrivKeyCmd {
	return &ImportPrivKeyCmd{
		PrivKey: privKey,
		Label:   label,
		Rescan:  rescan,
	}
}
source: func Convert_v1beta1_ClusterRoleBindingList_To_rbac_ClusterRoleBindingList(in *v1beta1.ClusterRoleBindingList, out *rbac.ClusterRoleBindingList, s conversion.Scope) error {
	return autoConvert_v1beta1_ClusterRoleBindingList_To_rbac_ClusterRoleBindingList(in, out, s)
}
source: func (s *Service) TeamInvitationRevoke(ctx context.Context, teamIdentity string, teamInvitationIdentity string) (*TeamInvitation, error) {
	var teamInvitation TeamInvitation
	return &teamInvitation, s.Delete(ctx, &teamInvitation, fmt.Sprintf("/teams/%v/invitations/%v", teamIdentity, teamInvitationIdentity))
}
source: func (c *Ctx) SetTicketStore(store *TicketStore) {
	c.ticket_store = store

	if store == nil {
		C.X_SSL_CTX_set_tlsext_ticket_key_cb(c.ctx, nil)
	} else {
		C.X_SSL_CTX_set_tlsext_ticket_key_cb(c.ctx,
			(*[0]byte)(C.X_SSL_CTX_ticket_key_cb))
	}
}
source: func ReadFile(fn string) (string, error) {
	fil, err := os.Open(fn)
	if err != nil {
		return "", errors.New(fmt.Sprintf("fileio.go: web.ReadFile: cannot read file <%v>", fn))
	}
	defer fil.Close()
	var l string
	r := bufio.NewReader(fil)
	for {
		lin, prefix, errl := r.ReadLine()
		if prefix {
			return "", errors.New(fmt.Sprintf("fileio.go: web.ReadFile: cannot read long lines yet. file = <%v>", fn))
		}
		if errl == io.EOF {
			break
		}
		if errl != nil {
			return "", errors.New(fmt.Sprintf("fileio.go: web.ReadFile: cannot read line for some reason. file = <%v>", fn))
		}
		l += string(lin)
	}
	return l, nil
}
source: func (s *BackendImplementation) Call(method, path, key string, params ParamsContainer, v interface{}) error {
	var body *form.Values
	var commonParams *Params

	if params != nil {
		// This is a little unfortunate, but Go makes it impossible to compare
		// an interface value to nil without the use of the reflect package and
		// its true disciples insist that this is a feature and not a bug.
		//
		// Here we do invoke reflect because (1) we have to reflect anyway to
		// use encode with the form package, and (2) the corresponding removal
		// of boilerplate that this enables makes the small performance penalty
		// worth it.
		reflectValue := reflect.ValueOf(params)

		if reflectValue.Kind() == reflect.Ptr && !reflectValue.IsNil() {
			commonParams = params.GetParams()
			body = &form.Values{}
			form.AppendTo(body, params)
		}
	}

	return s.CallRaw(method, path, key, body, commonParams, v)
}
source: func (t ValueType) Zero() interface{} {
	switch t {
	case TypeInvalid:
		return nil
	case TypeBool:
		return false
	case TypeInt:
		return 0
	case TypeFloat:
		return 0.0
	case TypeString:
		return ""
	case TypeList:
		return []interface{}{}
	case TypeMap:
		return map[string]interface{}{}
	case TypeSet:
		return new(Set)
	case typeObject:
		return map[string]interface{}{}
	default:
		panic(fmt.Sprintf("unknown type %s", t))
	}
}
source: func getDeviceResourcesForNode(deviceGroupStats []*api.DeviceGroupStats, node *api.Node) []string {
	statsSummaryMap := buildDeviceStatsSummaryMap(deviceGroupStats)

	devices := []string{}
	for _, dg := range node.NodeResources.Devices {
		for _, inst := range dg.Instances {
			id := deviceQualifiedID(dg.Vendor, dg.Type, dg.Name, inst.ID)
			statStr := ""
			if stats, ok := statsSummaryMap[id]; ok && stats != nil {
				statStr = stats.String()
			}

			devices = append(devices, fmt.Sprintf("%v|%v", id, statStr))
		}
	}

	sort.Strings(devices)

	return devices
}
source: func (r FutureDecodeScriptResult) Receive() (*btcjson.DecodeScriptResult, error) {
	res, err := receiveFuture(r)
	if err != nil {
		return nil, err
	}

	// Unmarshal result as a decodescript result object.
	var decodeScriptResult btcjson.DecodeScriptResult
	err = json.Unmarshal(res, &decodeScriptResult)
	if err != nil {
		return nil, err
	}

	return &decodeScriptResult, nil
}
source: func (sb *storageBackend) RemoveStorageAttachment(storage names.StorageTag, unit names.UnitTag, force bool) (err error) {
	defer errors.DeferredAnnotatef(&err, "cannot remove storage attachment %s:%s", storage.Id(), unit.Id())
	buildTxn := func(attempt int) ([]txn.Op, error) {
		s, err := sb.storageAttachment(storage, unit)
		if errors.IsNotFound(err) && attempt > 0 {
			// On the first attempt, we expect it to exist.
			return nil, jujutxn.ErrNoOperations
		} else if err != nil {
			return nil, errors.Trace(err)
		}
		if s.doc.Life != Dying {
			// TODO (anastasiamac 2019-04-05) We might want to ignore this when forcing...
			return nil, errors.New("storage attachment is not dying")
		}
		inst, err := sb.storageInstance(storage)
		if errors.IsNotFound(err) {
			// This implies that the attachment was removed
			// after the call to st.storageAttachment.
			return nil, jujutxn.ErrNoOperations
		} else if err != nil {
			return nil, errors.Trace(err)
		}
		ops, err := removeStorageAttachmentOps(sb, s, inst, force, bson.D{{"life", Dying}})
		if err != nil {
			return nil, errors.Trace(err)
		}
		return ops, nil
	}
	return sb.mb.db().Run(buildTxn)
}
source: func Parse(in io.Reader) (config Config, err error) {
	dec := yaml.NewDecoder(in)
	dec.SetStrict(true)
	if err = dec.Decode(&config); err != nil {
		return
	}

	config.Info.Version = os.ExpandEnv(config.Info.Version)
	err = config.Validate()
	return
}
source: func (d rackspaceNetworkingDecorator) DecorateNetworking(n openstack.Networking) (openstack.Networking, error) {
	return rackspaceNetworking{n}, nil
}
source: func (s *DescribeAlgorithmOutput) SetAlgorithmStatusDetails(v *AlgorithmStatusDetails) *DescribeAlgorithmOutput {
	s.AlgorithmStatusDetails = v
	return s
}
source: func NewCmdPortForward(fullName string, f kcmdutil.Factory, streams genericclioptions.IOStreams) *cobra.Command {
	cmd := portforward.NewCmdPortForward(f, streams)
	cmd.Long = portForwardLong
	cmd.Example = fmt.Sprintf(portForwardExample, fullName)
	return cmd
}
source: func (args Args) Clone() (newArgs Args) {
	newArgs.fields = make(map[string]map[string]bool, len(args.fields))
	for k, m := range args.fields {
		var mm map[string]bool
		if m != nil {
			mm = make(map[string]bool, len(m))
			for kk, v := range m {
				mm[kk] = v
			}
		}
		newArgs.fields[k] = mm
	}
	return newArgs
}
source: func (c *VaultClient) VReadKey(path, key string) (string, int64, error) {
	data, ver, err := c.VRead(path)
	if err != nil {
		return "", -1, err
	}
	val, ok := data[key]
	if !ok {
		return "", -1, ErrKeyNotFound
	}
	return val.(string), ver, nil
}
source: func (a *api) GetHostPublicKey(id string) ([]byte, error) {
	client, err := a.connectMaster()
	if err != nil {
		return nil, err
	}
	return client.GetHostPublicKey(id)
}
source: func (gc *gossipChannel) EligibleForChannel(member discovery.NetworkMember) bool {
	peerIdentity := gc.GetIdentityByPKIID(member.PKIid)
	if len(peerIdentity) == 0 {
		gc.logger.Warning("Identity for peer", member.PKIid, "doesn't exist")
		return false
	}
	msg := gc.stateInfoMsgStore.MsgByID(member.PKIid)
	if msg == nil {
		return false
	}
	return true
}
source: func (u *User) GetAvatarByLabel(label string) (avatar Avatar, err error) {
	for _, avatar = range u.Avatars {
		if avatar.Label == label {
			return
		}
	}
	err = errors.New("Could not find Avatar with Label " + label)
	return
}
source: func (i *ASCIIArt) SetHeight(h int) {
	if len(i.contents) > h {
		i.contents = i.contents[:h]
	} else {
		for j := len(i.contents); j < h; j++ {
			i.contents = append(i.contents, "")
		}
	}
}
source: func QueryChannels(reqCtx reqContext.Context, peer fab.ProposalProcessor, opts ...Opt) (*pb.ChannelQueryResponse, error) {

	if peer == nil {
		return nil, errors.New("peer required")
	}

	optionsValue := getOpts(opts...)

	cir := createChannelsInvokeRequest()
	payload, err := queryChaincodeWithTarget(reqCtx, cir, peer, optionsValue)
	if err != nil {
		return nil, errors.WithMessage(err, "cscc.GetChannels failed")
	}

	response := new(pb.ChannelQueryResponse)
	err = proto.Unmarshal(payload, response)
	if err != nil {
		return nil, errors.Wrap(err, "unmarshal ChannelQueryResponse failed")
	}
	return response, nil
}
source: func (c MultiCollector) Close() error {
	return c.aggregateErrors(func(coll Collector) error { return coll.Close() })
}
source: func (bot *BotAPI) UploadFile(endpoint string, params map[string]string, fieldname string, file interface{}) (APIResponse, error) {
	ms := multipartstreamer.New()

	switch f := file.(type) {
	case string:
		ms.WriteFields(params)

		fileHandle, err := os.Open(f)
		if err != nil {
			return APIResponse{}, err
		}
		defer fileHandle.Close()

		fi, err := os.Stat(f)
		if err != nil {
			return APIResponse{}, err
		}

		ms.WriteReader(fieldname, fileHandle.Name(), fi.Size(), fileHandle)
	case FileBytes:
		ms.WriteFields(params)

		buf := bytes.NewBuffer(f.Bytes)
		ms.WriteReader(fieldname, f.Name, int64(len(f.Bytes)), buf)
	case FileReader:
		ms.WriteFields(params)

		if f.Size != -1 {
			ms.WriteReader(fieldname, f.Name, f.Size, f.Reader)

			break
		}

		data, err := ioutil.ReadAll(f.Reader)
		if err != nil {
			return APIResponse{}, err
		}

		buf := bytes.NewBuffer(data)

		ms.WriteReader(fieldname, f.Name, int64(len(data)), buf)
	case url.URL:
		params[fieldname] = f.String()

		ms.WriteFields(params)
	default:
		return APIResponse{}, errors.New(ErrBadFileType)
	}

	method := fmt.Sprintf(APIEndpoint, bot.Token, endpoint)

	req, err := http.NewRequest("POST", method, nil)
	if err != nil {
		return APIResponse{}, err
	}

	ms.SetupRequest(req)

	res, err := bot.Client.Do(req)
	if err != nil {
		return APIResponse{}, err
	}
	defer res.Body.Close()

	bytes, err := ioutil.ReadAll(res.Body)
	if err != nil {
		return APIResponse{}, err
	}

	if bot.Debug {
		log.Println(string(bytes))
	}

	var apiResp APIResponse

	err = json.Unmarshal(bytes, &apiResp)
	if err != nil {
		return APIResponse{}, err
	}

	if !apiResp.Ok {
		return APIResponse{}, errors.New(apiResp.Description)
	}

	return apiResp, nil
}
source: func (s *UsageService) NewListTrafficTypesParams(physicalnetworkid string) *ListTrafficTypesParams {
	p := &ListTrafficTypesParams{}
	p.p = make(map[string]interface{})
	p.p["physicalnetworkid"] = physicalnetworkid
	return p
}
source: func WriteXML(suites []*Suite, out io.Writer, xmlTemplate string, testTime time.Time) {
	testsResult := TestResults{
		Suites:   suites,
		Assembly: suites[len(suites)-1].Name,
		RunDate:  testTime.Format("2006-01-02"),
		RunTime:  testTime.Format("15:04:05"),
		Skipped:  Skipped,
		Passed:   Passed,
		Failed:   Failed,
	}
	testsResult.calcTotals()
	t := template.New("test template").Funcs(template.FuncMap{
		"escape": escapeForXML,
	})

	t, err := t.Parse(xml.Header + xmlTemplate)
	if err != nil {
		fmt.Printf("Error in parse %v\n", err)
		return
	}
	err = t.Execute(out, testsResult)
	if err != nil {
		fmt.Printf("Error in execute %v\n", err)
		return
	}
}
source: func (r *Response) PageSlice() []Page {
	pl := []Page{}
	for _, page := range r.Query.Pages {
		pl = append(pl, page)
	}
	return pl
}
source: func (m *MockRbacV1Interface) RoleBindings(arg0 string) v11.RoleBindingInterface {
	ret := m.ctrl.Call(m, "RoleBindings", arg0)
	ret0, _ := ret[0].(v11.RoleBindingInterface)
	return ret0
}
source: func (d *ResourceDiff) diffChange(key string) (interface{}, interface{}, bool, bool, bool) {
	old, new, customized := d.getChange(key)

	if !old.Exists {
		old.Value = nil
	}
	if !new.Exists || d.removed(key) {
		new.Value = nil
	}

	return old.Value, new.Value, !reflect.DeepEqual(old.Value, new.Value), new.Computed, customized
}
source: func (c CloudstackClient) CreateTags(options *CreateTags) (CreateTagsResponse, error) {
	var resp CreateTagsResponse
	params := url.Values{}

	params.Set("resourceids", strings.Join(options.Resourceids, ","))
	params.Set("resourcetype", options.Resourcetype)
	for j, tag := range options.Tags {
		params.Set("tags["+strconv.Itoa(j+1)+"].key", tag.Key)
		params.Set("tags["+strconv.Itoa(j+1)+"].value", tag.Value)
	}

	if options.Customer != "" {
		params.Set("customer", options.Customer)
	}

	response, err := NewRequest(c, "createTags", params)
	if err != nil {
		return resp, err
	}

	resp = response.(CreateTagsResponse)
	return resp, err
}
source: func getFirstChildEl(n *html.Node) *html.Node {
	c := n.FirstChild
	for c != nil && c.Type != html.ElementNode {
		c = c.NextSibling
	}
	return c
}
source: func (c *ConfigLocal) SetKeyServer(k libkey.KeyServer) {
	c.lock.Lock()
	defer c.lock.Unlock()
	c.keyserv = k
}
source: func (c *Config) Set(ctx context.Context) context.Context {
	return SetLevel(ctx, c.Level)
}
source: func (k *Apk) MainActivity() (activity string, err error) {
	for _, act := range k.manifest.App.Activities {
		for _, intent := range act.IntentFilters {
			if isMainIntentFilter(intent) {
				return act.Name, nil
			}
		}
	}
	for _, act := range k.manifest.App.ActivityAliases {
		for _, intent := range act.IntentFilters {
			if isMainIntentFilter(intent) {
				return act.TargetActivity, nil
			}
		}
	}

	return "", errors.New("No main activity found")
}
source: func IsSimpleTuple(node Expr) bool {
	switch vals := node.(type) {
	case ValTuple:
		for _, n := range vals {
			if !IsValue(n) {
				return false
			}
		}
		return true
	case ListArg:
		return true
	}
	// It's a subquery
	return false
}
source: func (cm *CIDRMap) checkPrefixlen(key *cidrKey, operation string) error {
	if cm.Prefixlen != 0 &&
		((cm.PrefixIsDynamic && cm.Prefixlen < key.Prefixlen) ||
			(!cm.PrefixIsDynamic && cm.Prefixlen != key.Prefixlen)) {
		return fmt.Errorf("Unable to %s element with dynamic prefix length cm.Prefixlen=%d key.Prefixlen=%d",
			operation, cm.Prefixlen, key.Prefixlen)
	}
	return nil
}
source: func MarkControlPlane(client clientset.Interface, controlPlaneName string, taints []v1.Taint) error {

	fmt.Printf("[mark-control-plane] Marking the node %s as control-plane by adding the label \"%s=''\"\n", controlPlaneName, constants.LabelNodeRoleMaster)

	if len(taints) > 0 {
		taintStrs := []string{}
		for _, taint := range taints {
			taintStrs = append(taintStrs, taint.ToString())
		}
		fmt.Printf("[mark-control-plane] Marking the node %s as control-plane by adding the taints %v\n", controlPlaneName, taintStrs)
	}

	return apiclient.PatchNode(client, controlPlaneName, func(n *v1.Node) {
		markControlPlaneNode(n, taints)
	})
}
source: func (c *Clientset) Image() imageinternalversion.ImageInterface {
	return &fakeimageinternalversion.FakeImage{Fake: &c.Fake}
}
source: func (s *CopyBackupToRegionOutput) SetDestinationBackup(v *DestinationBackup) *CopyBackupToRegionOutput {
	s.DestinationBackup = v
	return s
}
source: func (r *distributionRouter) initRoutes() {
	r.routes = []router.Route{
		// GET
		router.NewGetRoute("/distribution/{name:.*}/json", r.getDistributionInfo),
	}
}
source: func (d *DiscussionComment) GetDiscussionURL() string {
	if d == nil || d.DiscussionURL == nil {
		return ""
	}
	return *d.DiscussionURL
}
source: func (c *Connection) Scroll(scrollId string, timeout string) (*Response, error) {
	v := url.Values{}
	v.Add("scroll", timeout)

	r := Request{
		Conn:      c,
		method:    "POST",
		api:       "_search/scroll",
		ExtraArgs: v,
		Body:      []byte(scrollId),
	}

	return r.Run()
}
source: func (c *Client) SetRetryCount(count int) *Client {
	c.RetryCount = count
	return c
}
source: func RegexpToQuery(r *syntax.Regexp, minTextSize int) Q {
	q := regexpToQueryRecursive(r, minTextSize)
	q = Simplify(q)
	return q
}
source: func (f *FileRotator) createOrResetBuffer() {
	f.bufLock.Lock()
	defer f.bufLock.Unlock()
	if f.bufw == nil {
		f.bufw = bufio.NewWriterSize(f.currentFile, logBufferSize)
	} else {
		f.bufw.Reset(f.currentFile)
	}
}
source: func (l *txList) Add(tx *types.Transaction, priceBump uint64) (bool, *types.Transaction) {
	// If there's an older better transaction, abort
	old := l.txs.Get(tx.Nonce())
	if old != nil {
		threshold := new(big.Int).Div(new(big.Int).Mul(old.GasPrice(), big.NewInt(100+int64(priceBump))), big.NewInt(100))
		// Have to ensure that the new gas price is higher than the old gas
		// price as well as checking the percentage threshold to ensure that
		// this is accurate for low (Wei-level) gas price replacements
		if old.GasPrice().Cmp(tx.GasPrice()) >= 0 || threshold.Cmp(tx.GasPrice()) > 0 {
			return false, nil
		}
	}
	// Otherwise overwrite the old transaction with the current one
	l.txs.Put(tx)
	if cost := tx.Cost(); l.costcap.Cmp(cost) < 0 {
		l.costcap = cost
	}
	if gas := tx.Gas(); l.gascap < gas {
		l.gascap = gas
	}
	return true, old
}
source: func NewOutboundCall(options ...CallOption) *OutboundCall {
	var call OutboundCall
	for _, opt := range options {
		opt.apply(&call)
	}
	return &call
}
source: func (s *ServerLaunchConfiguration) SetSubnet(v string) *ServerLaunchConfiguration {
	s.Subnet = &v
	return s
}
source: func (list *ReviewBlockerList) AddReviewBlocker(
	fixed bool,
	commentURL string,
	commitSHA string,
	blockerSummary string,
) bool {

	for _, item := range list.items {
		if item.CommentURL == commentURL {
			return false
		}
	}

	list.items = append(list.items, &ReviewBlockerItem{
		Fixed:          fixed,
		CommentURL:     commentURL,
		CommitSHA:      commitSHA,
		BlockerNumber:  len(list.items) + 1,
		BlockerSummary: blockerSummary,
	})
	return true
}
source: func (p Path) ChildPath(name string, ptr BlockPointer) Path {
	child := Path{
		FolderBranch: p.FolderBranch,
		Path:         make([]PathNode, len(p.Path), len(p.Path)+1),
	}
	copy(child.Path, p.Path)
	child.Path = append(child.Path, PathNode{Name: name, BlockPointer: ptr})
	return child
}
source: func (m *TokenManager) ForeverToken(user User) (token Token) {
	token.UserID = user.ID
	token.manager = m

	// Generate a new token
	for {
		token.Key = m.keyFunc()

		// No duplicates - generate a new key if this key already exists
		stmt := sol.Select(
			Tokens.C("key"),
		).Where(Tokens.C("key").Equals(token.Key)).Limit(1)
		var duplicate string
		m.conn.Query(stmt, &duplicate)
		if duplicate == "" {
			break
		}
	}

	// Insert the token into the database
	m.conn.Query(postgres.Insert(Tokens).Values(token).Returning(), &token)
	return
}
source: func (t *Template) GetAllAWSCloud9EnvironmentEC2Resources() map[string]*resources.AWSCloud9EnvironmentEC2 {
	results := map[string]*resources.AWSCloud9EnvironmentEC2{}
	for name, untyped := range t.Resources {
		switch resource := untyped.(type) {
		case *resources.AWSCloud9EnvironmentEC2:
			results[name] = resource
		}
	}
	return results
}
source: func (d *DeviceMapperDriver) deviceSize(deviceHash string) (uint64, error) {
	return getDeviceSize(d.devicePath(deviceHash))
}
source: func (e *Enforcer) IsFiltered() bool {
	filteredAdapter, ok := e.adapter.(persist.FilteredAdapter)
	if !ok {
		return false
	}
	return filteredAdapter.IsFiltered()
}
source: func (ec *EthereumClient) GetTransactionByHash(ctx *Context, hash *Hash) (tx *Transaction, _ error) {
	// TODO(karalabe): handle isPending
	rawTx, _, err := ec.client.TransactionByHash(ctx.context, hash.hash)
	return &Transaction{rawTx}, err
}
source: func NewKinesisReactor(reactor KinesisReactor,
	kinesisStream gocf.Stringable,
	startingPosition string,
	batchSize int64,
	additionalLambdaPermissions []sparta.IAMRolePrivilege) (*sparta.LambdaAWSInfo, error) {

	reactorLambda := func(ctx context.Context, kinesisEvent awsLambdaEvents.KinesisEvent) (interface{}, error) {
		return reactor.OnKinesisMessage(ctx, kinesisEvent)
	}

	lambdaFn, lambdaFnErr := sparta.NewAWSLambda(reactorName(reactor),
		reactorLambda,
		sparta.IAMRoleDefinition{})
	if lambdaFnErr != nil {
		return nil, errors.Wrapf(lambdaFnErr, "attempting to create reactor")
	}

	lambdaFn.EventSourceMappings = append(lambdaFn.EventSourceMappings,
		&sparta.EventSourceMapping{
			EventSourceArn:   kinesisStream,
			StartingPosition: startingPosition,
			BatchSize:        batchSize,
		})
	if len(additionalLambdaPermissions) != 0 {
		lambdaFn.RoleDefinition.Privileges = additionalLambdaPermissions
	}
	return lambdaFn, nil
}
source: func (c *Client) GetRuleVCL(i *GetRuleInput) (*RuleVCL, error) {
	if i.RuleID == "" {
		return nil, ErrMissingRuleID
	}

	path := fmt.Sprintf("/wafs/rules/%s/vcl", i.RuleID)
	resp, err := c.Get(path, nil)
	if err != nil {
		return nil, err
	}

	var vcl RuleVCL
	if err := jsonapi.UnmarshalPayload(resp.Body, &vcl); err != nil {
		return nil, err
	}
	return &vcl, nil
}
source: func NewPromScope(registerer prometheus.Registerer, scopes ...string) Scope {
	return &promScope{
		prefix:         scopes,
		autoRegisterer: newAutoRegisterer(registerer),
		registerer:     registerer,
	}
}
source: func NewMigrationBox(box packd.Walkable, c *Connection) (MigrationBox, error) {
	fm := MigrationBox{
		Migrator: NewMigrator(c),
		Box:      box,
	}

	err := fm.findMigrations()
	if err != nil {
		return fm, errors.WithStack(err)
	}

	return fm, nil
}
source: func (c *client) MaxRates(ctx context.Context) (map[string]int64, error) {
	response, err := c.gRPCClient.MaxRates(ctx, &throttlerdatapb.MaxRatesRequest{})
	if err != nil {
		return nil, vterrors.FromGRPC(err)
	}
	return response.Rates, nil
}
source: func (p *Postgres) CleanExpiredRows(expire time.Duration) (int64, error) {
	// See: http://stackoverflow.com/questions/14465727/how-to-insert-things-like-now-interval-2-minutes-into-php-pdo-query
	// basically by passing an integer to INTERVAL is not possible, we need to
	// cast it. However there is a more simpler way, we can multiply INTERVAL
	// with an integer so we just declare a one second INTERVAL and multiply it
	// with the amount we want.
	cleanOldRows := `DELETE FROM kite.kite WHERE updated_at < (now() at time zone 'utc') - ((INTERVAL '1 second') * $1)`

	rows, err := p.DB.Exec(cleanOldRows, int64(expire/time.Second))
	if err != nil {
		return 0, err
	}

	return rows.RowsAffected()
}
source: func (client *Client) UpdateApplicationRestart(appGUID string) (Application, Warnings, error) {
	request, err := client.newHTTPRequest(requestOptions{
		RequestName: internal.PostApplicationActionRestartRequest,
		URIParams:   map[string]string{"app_guid": appGUID},
	})
	if err != nil {
		return Application{}, nil, err
	}

	var responseApp Application
	response := cloudcontroller.Response{
		DecodeJSONResponseInto: &responseApp,
	}
	err = client.connection.Make(request, &response)

	return responseApp, response.Warnings, err
}
source: func newRedirect(_ context.Context, next http.Handler, regex string, replacement string, permanent bool, name string) (http.Handler, error) {
	re, err := regexp.Compile(regex)
	if err != nil {
		return nil, err
	}

	return &redirect{
		regex:       re,
		replacement: replacement,
		permanent:   permanent,
		errHandler:  utils.DefaultHandler,
		next:        next,
		name:        name,
	}, nil
}
source: func Cached(d string) {
	if r, ok := relationalModelDefinition(false); ok {
		r.Cached = true
		dur, err := strconv.Atoi(d)
		if err != nil {
			dslengine.ReportError("Duration %s couldn't be parsed as integer", d)
		}
		r.CacheDuration = dur
	}
}
source: func NewValueI8(v int8) Value {
	return Value{
		typ:     TI8,
		tnumber: uint64(v),
	}
}
source: func (l *logger) close() {
	if !l.disablePooling {
		l.level = 0
		l.output = nil
		l.fields = nil
		loggerPool.Put(l)
	}
}
source: func (c *Controller) Subscribe(name string, pubkey *ecdsa.PublicKey, address pss.PssAddress, handler func(string, []byte) error) error {
	c.mu.Lock()
	defer c.mu.Unlock()
	msg := NewMsg(MsgCodeStart, name, c.pss.BaseAddr())
	c.pss.SetPeerPublicKey(pubkey, controlTopic, address)
	pubkeyId := hexutil.Encode(crypto.FromECDSAPub(pubkey))
	smsg, err := rlp.EncodeToBytes(msg)
	if err != nil {
		return err
	}
	err = c.pss.SendAsym(pubkeyId, controlTopic, smsg)
	if err != nil {
		return err
	}
	c.subscriptions[name] = &subscription{
		pubkeyId: pubkeyId,
		address:  address,
		handler:  handler,
	}
	return nil
}
source: func (term *Terminal) Password(prefix string) (string, error) {
	var err error
	var input string

	for input == "" {
		input, err = term.GetPassword(prefix)
		if err != nil && err != io.EOF {
			return "", err
		}
	}

	return input, nil
}
source: func New(operationsPerSecond float64) ratecontroller.Controller {
	return &fixedRateController{opsPerSecond: operationsPerSecond, replayStartTime: time.Now()}
}
source: func (ident Identifier) Sanitize() string {
	parts := make([]string, len(ident))
	for i := range ident {
		parts[i] = `"` + strings.Replace(ident[i], `"`, `""`, -1) + `"`
	}
	return strings.Join(parts, ".")
}
source: func (c Client) SetBucketPolicy(bucketName, policy string) error {
	// Input validation.
	if err := s3utils.CheckValidBucketName(bucketName); err != nil {
		return err
	}

	// If policy is empty then delete the bucket policy.
	if policy == "" {
		return c.removeBucketPolicy(bucketName)
	}

	// Save the updated policies.
	return c.putBucketPolicy(bucketName, policy)
}
source: func (s *CertFileUserStore) Store(user *msp.UserData) error {
	key := storeKeyFromUserIdentifier(msp.IdentityIdentifier{MSPID: user.MSPID, ID: user.ID})
	return s.store.Store(key, user.EnrollmentCertificate)
}
source: func parentKey(parent, child uint64) []byte {
	b := make([]byte, binary.Size([]uint64{parent, child})+1)
	i := binary.PutUvarint(b, parent)
	j := binary.PutUvarint(b[i+1:], child)
	return b[0 : i+j+1]
}
source: func (m *MockImplementor) ACLProvider() aclprovider.IptablesProvider {
	ret := m.ctrl.Call(m, "ACLProvider")
	ret0, _ := ret[0].(aclprovider.IptablesProvider)
	return ret0
}
source: func (s *GetAccountAuthorizationDetailsOutput) SetRoleDetailList(v []*RoleDetail) *GetAccountAuthorizationDetailsOutput {
	s.RoleDetailList = v
	return s
}
source: func (c DeviceClient) CheckDeviceNameForUser(ctx context.Context, __arg CheckDeviceNameForUserArg) (err error) {
	err = c.Cli.Call(ctx, "keybase.1.device.checkDeviceNameForUser", []interface{}{__arg}, nil)
	return
}
source: func NewUpgraderFacade(st *state.State, resources facade.Resources, auth facade.Authorizer) (Upgrader, error) {
	// The type of upgrader we return depends on who is asking.
	// Machines get an UpgraderAPI, units get a UnitUpgraderAPI.
	// This is tested in the api/upgrader package since there
	// are currently no direct srvRoot tests.
	// TODO(dfc) this is redundant
	tag, err := names.ParseTag(auth.GetAuthTag().String())
	if err != nil {
		return nil, common.ErrPerm
	}
	switch tag.(type) {
	case names.MachineTag, names.ApplicationTag:
		return NewUpgraderAPI(st, resources, auth)
	case names.UnitTag:
		return NewUnitUpgraderAPI(st, resources, auth)
	}
	// Not a machine or unit.
	return nil, common.ErrPerm
}
source: func (ar *allocRunner) persistDeploymentStatus(ds *structs.AllocDeploymentStatus) {
	if err := ar.stateDB.PutDeploymentStatus(ar.id, ds); err != nil {
		// While any persistence errors are very bad, the worst case
		// scenario for failing to persist deployment status is that if
		// the agent is restarted it will monitor the deployment status
		// again. This could cause a deployment's status to change when
		// that shouldn't happen. However, allowing that seems better
		// than failing the entire allocation.
		ar.logger.Error("error storing deployment status", "error", err)
	}
}
source: func (s *DeleteService) Parent(parent string) *DeleteService {
	s.parent = parent
	return s
}
source: func (conn *FakeVTGateConn) Commit(ctx context.Context, session *vtgatepb.Session, twopc bool) error {
	if session == nil {
		return errors.New("commit: not in transaction")
	}
	return nil
}
source: func (jm *JobController) addPod(obj interface{}) {
	pod := obj.(*v1.Pod)
	if pod.DeletionTimestamp != nil {
		// on a restart of the controller controller, it's possible a new pod shows up in a state that
		// is already pending deletion. Prevent the pod from being a creation observation.
		jm.deletePod(pod)
		return
	}

	// If it has a ControllerRef, that's all that matters.
	if controllerRef := metav1.GetControllerOf(pod); controllerRef != nil {
		job := jm.resolveControllerRef(pod.Namespace, controllerRef)
		if job == nil {
			return
		}
		jobKey, err := controller.KeyFunc(job)
		if err != nil {
			return
		}
		jm.expectations.CreationObserved(jobKey)
		jm.enqueueController(job, true)
		return
	}

	// Otherwise, it's an orphan. Get a list of all matching controllers and sync
	// them to see if anyone wants to adopt it.
	// DO NOT observe creation because no controller should be waiting for an
	// orphan.
	for _, job := range jm.getPodJobs(pod) {
		jm.enqueueController(job, true)
	}
}
source: func validateKeyArgs(keyName string, targetDir string) error {
	if !validKeyName(keyName) {
		return fmt.Errorf("key name \"%s\" must start with lowercase alphanumeric characters and can include \"-\" or \"_\" after the first character", keyName)
	}

	pubKeyFileName := keyName + ".pub"
	if _, err := os.Stat(targetDir); err != nil {
		return fmt.Errorf("public key path does not exist: \"%s\"", targetDir)
	}
	targetPath := filepath.Join(targetDir, pubKeyFileName)
	if _, err := os.Stat(targetPath); err == nil {
		return fmt.Errorf("public key file already exists: \"%s\"", targetPath)
	}
	return nil
}
source: func Output(environment, name string) (string, error) {
	cmd := exec.Command("sh", "-c", fmt.Sprintf("terraform output %s", name))
	cmd.Dir = filepath.Join(Dir, environment)

	out, err := cmd.CombinedOutput()
	if err != nil {
		return "", err
	}

	return strings.Trim(string(out), "\n"), nil
}
source: func (m *Machine) supportsContainerType(ctype instance.ContainerType) bool {
	supportedContainers, ok := m.SupportedContainers()
	if !ok {
		// We don't know yet, so we report that we support the container.
		return true
	}
	for _, ct := range supportedContainers {
		if ct == ctype {
			return true
		}
	}
	return false
}
source: func (s *GrantAccessOutput) SetTemporaryCredential(v *TemporaryCredential) *GrantAccessOutput {
	s.TemporaryCredential = v
	return s
}
source: func (c environConfig) validate() error {
	// All fields must be populated, even with just the default.
	for _, field := range configRequiredFields {
		if c.attrs[field].(string) == "" {
			return errors.Errorf("%s: must not be empty", field)
		}
	}
	return nil
}
source: func couldHaveUnknownBlockPlaceholder(v cty.Value, blockS *configschema.NestedBlock, nested bool) bool {
	switch blockS.Nesting {
	case configschema.NestingSingle, configschema.NestingGroup:
		if nested && v.IsNull() {
			return true // for nested blocks, a single block being unset doesn't disqualify from being an unknown block placeholder
		}
		return couldBeUnknownBlockPlaceholderElement(v, &blockS.Block)
	default:
		// These situations should be impossible for correct providers, but
		// we permit the legacy SDK to produce some incorrect outcomes
		// for compatibility with its existing logic, and so we must be
		// tolerant here.
		if !v.IsKnown() {
			return true
		}
		if v.IsNull() {
			return false // treated as if the list were empty, so we would see zero iterations below
		}

		// For all other nesting modes, our value should be something iterable.
		for it := v.ElementIterator(); it.Next(); {
			_, ev := it.Element()
			if couldBeUnknownBlockPlaceholderElement(ev, &blockS.Block) {
				return true
			}
		}

		// Our default changes depending on whether we're testing the candidate
		// block itself or something nested inside of it: zero blocks of a type
		// can never contain a dynamic block placeholder, but a dynamic block
		// placeholder might contain zero blocks of one of its own nested block
		// types, if none were set in the config at all.
		return nested
	}
}
source: func SystemdVersion(systemdBinaryPath string) (int, error) {
	versionBytes, err := exec.Command(systemdBinaryPath, "--version").CombinedOutput()
	if err != nil {
		return -1, errwrap.Wrap(fmt.Errorf("unable to probe %s version", systemdBinaryPath), err)
	}
	versionStr := strings.SplitN(string(versionBytes), "\n", 2)[0]
	var version int
	n, err := fmt.Sscanf(versionStr, "systemd %d", &version)
	if err != nil || n != 1 {
		return -1, fmt.Errorf("cannot parse version: %q", versionStr)
	}

	return version, nil
}
source: func (s *CodeSigning) SetAwsSignerJobId(v string) *CodeSigning {
	s.AwsSignerJobId = &v
	return s
}
source: func (c *EC2Metadata) IAMInfo() (EC2IAMInfo, error) {
	resp, err := c.GetMetadata("iam/info")
	if err != nil {
		return EC2IAMInfo{},
			awserr.New("EC2MetadataRequestError",
				"failed to get EC2 IAM info", err)
	}

	info := EC2IAMInfo{}
	if err := json.NewDecoder(strings.NewReader(resp)).Decode(&info); err != nil {
		return EC2IAMInfo{},
			awserr.New("SerializationError",
				"failed to decode EC2 IAM info", err)
	}

	if info.Code != "Success" {
		errMsg := fmt.Sprintf("failed to get EC2 IAM Info (%s)", info.Code)
		return EC2IAMInfo{},
			awserr.New("EC2MetadataError", errMsg, nil)
	}

	return info, nil
}
source: func (s *SigningConfigurationOverrides) SetEncryptionAlgorithm(v string) *SigningConfigurationOverrides {
	s.EncryptionAlgorithm = &v
	return s
}
source: func (tx *Transaction) EndTransaction() error {
	err := tx.err
	tx.err = nil
	return err
}
source: func funcTypeWrap(t funcType, fn interface{}) func(context.Context) error {
	switch f := fn.(type) {
	case func():
		return func(context.Context) error {
			f()
			return nil
		}
	case func() error:
		return func(context.Context) error {
			return f()
		}
	case func(context.Context):
		return func(ctx context.Context) error {
			f(ctx)
			return nil
		}
	case func(context.Context) error:
		return f
	}
	args := []reflect.Value{reflect.ValueOf(struct{}{})}
	switch t {
	case namespaceVoidType:
		return func(context.Context) error {
			v := reflect.ValueOf(fn)
			v.Call(args)
			return nil
		}
	case namespaceErrorType:
		return func(context.Context) error {
			v := reflect.ValueOf(fn)
			ret := v.Call(args)
			val := ret[0].Interface()
			if val == nil {
				return nil
			}
			return val.(error)
		}
	case namespaceContextVoidType:
		return func(ctx context.Context) error {
			v := reflect.ValueOf(fn)
			v.Call(append(args, reflect.ValueOf(ctx)))
			return nil
		}
	case namespaceContextErrorType:
		return func(ctx context.Context) error {
			v := reflect.ValueOf(fn)
			ret := v.Call(append(args, reflect.ValueOf(ctx)))
			val := ret[0].Interface()
			if val == nil {
				return nil
			}
			return val.(error)
		}
	default:
		panic(fmt.Errorf("Don't know how to deal with dep of type %T", fn))
	}
}
source: func NewListMemberDevicesArg(TeamMemberId string) *ListMemberDevicesArg {
	s := new(ListMemberDevicesArg)
	s.TeamMemberId = TeamMemberId
	s.IncludeWebSessions = true
	s.IncludeDesktopClients = true
	s.IncludeMobileClients = true
	return s
}
source: func refreshVolumeBlockDevices(ctx *context, volumeTags []names.VolumeTag) error {
	machineTag, ok := ctx.config.Scope.(names.MachineTag)
	if !ok {
		// This function should only be called by machine-scoped
		// storage provisioners.
		logger.Warningf("refresh block devices, expected machine tag, got %v", ctx.config.Scope)
		return nil
	}
	ids := make([]params.MachineStorageId, len(volumeTags))
	for i, volumeTag := range volumeTags {
		ids[i] = params.MachineStorageId{
			MachineTag:    machineTag.String(),
			AttachmentTag: volumeTag.String(),
		}
	}
	results, err := ctx.config.Volumes.VolumeBlockDevices(ids)
	if err != nil {
		return errors.Annotate(err, "refreshing volume block devices")
	}
	for i, result := range results {
		if result.Error == nil {
			ctx.volumeBlockDevices[volumeTags[i]] = result.Result
			for _, params := range ctx.incompleteFilesystemParams {
				if params.Volume == volumeTags[i] {
					updatePendingFilesystem(ctx, params)
				}
			}
			for id, params := range ctx.incompleteFilesystemAttachmentParams {
				filesystem, ok := ctx.filesystems[params.Filesystem]
				if !ok {
					continue
				}
				if filesystem.Volume == volumeTags[i] {
					updatePendingFilesystemAttachment(ctx, id, params)
				}
			}
		} else if params.IsCodeNotProvisioned(result.Error) || params.IsCodeNotFound(result.Error) {
			// Either the volume (attachment) isn't provisioned,
			// or the corresponding block device is not yet known.
			//
			// Neither of these errors is fatal; we just wait for
			// the block device watcher to notify us again.
		} else {
			return errors.Annotatef(
				err, "getting block device info for volume attachment %v",
				ids[i],
			)
		}
	}
	return nil
}
source: func Forbidden(ctx context.Context, attributes authorizer.Attributes, w http.ResponseWriter, req *http.Request, reason string, s runtime.NegotiatedSerializer) {
	msg := sanitizer.Replace(forbiddenMessage(attributes))
	w.Header().Set("X-Content-Type-Options", "nosniff")

	var errMsg string
	if len(reason) == 0 {
		errMsg = fmt.Sprintf("%s", msg)
	} else {
		errMsg = fmt.Sprintf("%s: %s", msg, reason)
	}
	gv := schema.GroupVersion{Group: attributes.GetAPIGroup(), Version: attributes.GetAPIVersion()}
	gr := schema.GroupResource{Group: attributes.GetAPIGroup(), Resource: attributes.GetResource()}
	ErrorNegotiated(apierrors.NewForbidden(gr, attributes.GetName(), fmt.Errorf(errMsg)), s, gv, w, req)
}
source: func (c *VFSClientset) InstanceGroupsFor(cluster *kops.Cluster) kopsinternalversion.InstanceGroupInterface {
	return newInstanceGroupVFS(c, cluster)
}
source: func (o *Option) ShortNames() []string {
	var short []string
	for _, n := range o.Names {
		if len([]rune(n)) == 1 {
			short = append(short, n)
		}
	}
	return short
}
source: func (k *KeyValueYARPCServer) SetValue(ctx context.Context, request *examplepb.SetValueRequest) (*examplepb.SetValueResponse, error) {
	if request == nil {
		return nil, errRequestNil
	}
	if request.Key == "" {
		return nil, errRequestKeyNil
	}
	k.Lock()
	if request.Value == "" {
		delete(k.items, request.Key)
	} else {
		k.items[request.Key] = request.Value
	}
	var nextError error
	if k.nextError != nil {
		nextError = k.nextError
		k.nextError = nil
	}
	k.Unlock()
	return nil, nextError
}
source: func trimAroundNewlines(v []byte) string {
	var b strings.Builder
	for {
		i := bytes.IndexByte(v, '\n')
		if i < 0 {
			writeContinued(&b, v)
			break
		}
		writeContinued(&b, v[:i])
		v = v[i+1:]
	}

	return b.String()
}
source: func displayProcessTree() {
	ps := goprocess.FindAll()
	pstree = make(map[int][]goprocess.P)
	for _, p := range ps {
		pstree[p.PPID] = append(pstree[p.PPID], p)
	}
	tree := treeprint.New()
	tree.SetValue("...")
	seen := map[int]bool{}
	for _, p := range ps {
		constructProcessTree(p.PPID, p, seen, tree)
	}
	fmt.Println(tree.String())
}
source: func (service *BaseHTTPService) RemoveAccessControlAllowOrigin(origins ...string) {
	for _, origin := range origins {
		delete(service.AccessControlAllowOrigins, origin)
	}
}
source: func ValidateNamespaceName(name string, prefix bool) (bool, string) {
	return NameIsDNSLabel(name, prefix)
}
source: func Magefiles(magePath, goos, goarch, goCmd string, stderr io.Writer, isDebug bool) ([]string, error) {
	start := time.Now()
	defer func() {
		debug.Println("time to scan for Magefiles:", time.Since(start))
	}()
	fail := func(err error) ([]string, error) {
		return nil, err
	}

	env, err := internal.EnvWithGOOS(goos, goarch)
	if err != nil {
		return nil, err
	}

	debug.Println("getting all non-mage files in", magePath)
	// // first, grab all the files with no build tags specified.. this is actually
	// // our exclude list of things without the mage build tag.
	cmd := exec.Command(goCmd, "list", "-e", "-f", `{{join .GoFiles "||"}}`)
	cmd.Env = env
	if isDebug {
		cmd.Stderr = stderr
	}
	cmd.Dir = magePath
	b, err := cmd.Output()
	if err != nil {
		return fail(fmt.Errorf("failed to list non-mage gofiles: %v", err))
	}
	list := strings.TrimSpace(string(b))
	debug.Println("found non-mage files", list)
	exclude := map[string]bool{}
	for _, f := range strings.Split(list, "||") {
		if f != "" {
			debug.Printf("marked file as non-mage: %q", f)
			exclude[f] = true
		}
	}
	debug.Println("getting all files plus mage files")
	cmd = exec.Command(goCmd, "list", "-tags=mage", "-e", "-f", `{{join .GoFiles "||"}}`)
	cmd.Env = env

	if isDebug {
		cmd.Stderr = stderr
	}
	cmd.Dir = magePath
	b, err = cmd.Output()
	if err != nil {
		return fail(fmt.Errorf("failed to list mage gofiles: %v", err))
	}

	list = strings.TrimSpace(string(b))
	files := []string{}
	for _, f := range strings.Split(list, "||") {
		if f != "" && !exclude[f] {
			files = append(files, f)
		}
	}
	for i := range files {
		files[i] = filepath.Join(magePath, files[i])
	}
	return files, nil
}
source: func WithContext(b BackOff, ctx context.Context) BackOffContext {
	if ctx == nil {
		panic("nil context")
	}

	if b, ok := b.(*backOffContext); ok {
		return &backOffContext{
			BackOff: b.BackOff,
			ctx:     ctx,
		}
	}

	return &backOffContext{
		BackOff: b,
		ctx:     ctx,
	}
}
source: func NewTeamProfileChangeLogoType(Description string) *TeamProfileChangeLogoType {
	s := new(TeamProfileChangeLogoType)
	s.Description = Description
	return s
}
source: func (db *DB) DeleteLinkNode(identity *btcec.PublicKey) error {
	return db.Update(func(tx *bbolt.Tx) error {
		return db.deleteLinkNode(tx, identity)
	})
}
source: func (w *Wallet) SignTxWithPassphrase(account accounts.Account, passphrase string, tx *types.Transaction, chainID *big.Int) (*types.Transaction, error) {
	if !w.session.verified {
		if err := w.Open(passphrase); err != nil {
			return nil, err
		}
	}
	return w.SignTx(account, tx, chainID)
}
source: func (c *Commit) File(path string) (*File, error) {
	tree, err := c.Tree()
	if err != nil {
		return nil, err
	}

	return tree.File(path)
}
source: func (sg *sessionPool) put(ctx sessionctx.Context) {
	if sg.resPool == nil {
		return
	}

	// no need to protect sg.resPool, even the sg.resPool is closed, the ctx still need to
	// put into resPool, because when resPool is closing, it will wait all the ctx returns, then resPool finish closing.
	sg.resPool.Put(ctx.(pools.Resource))
}
source: func values(m map[string]peer.Identifier) []peer.Identifier {
	vs := make([]peer.Identifier, 0, len(m))
	for _, v := range m {
		vs = append(vs, v)
	}
	return vs
}
source: func FetchCommonDeps() {
	// github.com/golang/go
	d, _ := gosrc.ResolveImportPath(http.DefaultClient, "time")
	u, _ := url.Parse(d.CloneURL)
	_, _ = NewDepRepoVFS(context.Background(), u, d.Rev, nil)
}
source: func Convert_kops_AuthenticationSpec_To_v1alpha2_AuthenticationSpec(in *kops.AuthenticationSpec, out *AuthenticationSpec, s conversion.Scope) error {
	return autoConvert_kops_AuthenticationSpec_To_v1alpha2_AuthenticationSpec(in, out, s)
}
source: func newCmdUpdateCheckInUse(cl *libcmdline.CommandLine, g *libkb.GlobalContext) cli.Command {
	return cli.Command{
		Name:         "check-in-use",
		ArgumentHelp: "",
		Usage:        "Check if we are in use (safe for restart)",
		Action: func(c *cli.Context) {
			cl.SetLogForward(libcmdline.LogForwardNone)
			cl.SetForkCmd(libcmdline.NoFork)
			cl.ChooseCommand(newCmdUpdateCheckInUseRunner(g), "check-in-use", c)
		},
	}
}
source: func (m *Miniredis) CommandCount() int {
	m.Lock()
	defer m.Unlock()
	return int(m.srv.TotalCommands())
}
source: func transmit(card *pcsc.Card, command *commandAPDU) (*responseAPDU, error) {
	data, err := command.serialize()
	if err != nil {
		return nil, err
	}

	responseData, _, err := card.Transmit(data)
	if err != nil {
		return nil, err
	}

	response := new(responseAPDU)
	if err = response.deserialize(responseData); err != nil {
		return nil, err
	}

	// Are we being asked to fetch the response separately?
	if response.Sw1 == sw1GetResponse && (command.Cla != claISO7816 || command.Ins != insGetResponse) {
		return transmit(card, &commandAPDU{
			Cla:  claISO7816,
			Ins:  insGetResponse,
			P1:   0,
			P2:   0,
			Data: nil,
			Le:   response.Sw2,
		})
	}

	if response.Sw1 != sw1Ok {
		return nil, fmt.Errorf("Unexpected insecure response status Cla=0x%x, Ins=0x%x, Sw=0x%x%x", command.Cla, command.Ins, response.Sw1, response.Sw2)
	}

	return response, nil
}
source: func checkUpdates(ctx *cli.Context) error {
	cfg, err := config.LoadConfig()
	if err != nil {
		return err
	}

	client := api.NewClient(cfg)
	c := context.Background()

	updateInfo, err := client.Updates.Check(c)
	if err != nil {
		return err
	}

	if updateInfo.NeedsUpdate {
		ui.Info("A new version of Torus is available (%s)! You can download it from %s.", updateInfo.Version, downloadURL)
	}

	return nil
}
source: func (c *IPMessageList) LastPage() (*IPMessageList, error) {
	return c.getPage(c.Meta.LastPageUri)
}
source: func (c *SES) WaitUntilIdentityExists(input *GetIdentityVerificationAttributesInput) error {
	return c.WaitUntilIdentityExistsWithContext(aws.BackgroundContext(), input)
}
source: func SplitWithNewlines(data []byte, atEOF bool) (advance int, token []byte, err error) {
	return split(true, data, atEOF)
}
source: func (us UsersService) Create(username, email, token string) (User, error) {
	resp, err := newNetworkClient(us.config).MakeRequest(network.Request{
		Method:        "POST",
		Path:          "/Users",
		Authorization: network.NewTokenAuthorization(token),
		Body: network.NewJSONRequestBody(documents.CreateUserRequest{
			UserName: username,
			Emails: []documents.Email{
				{Value: email},
			},
		}),
		AcceptableStatusCodes: []int{http.StatusCreated},
	})
	if err != nil {
		return User{}, translateError(err)
	}

	var response documents.UserResponse
	err = json.Unmarshal(resp.Body, &response)
	if err != nil {
		return User{}, MalformedResponseError{err}
	}

	return newUserFromResponse(us.config, response), nil
} 38%|███▊      | 1885/5000 [00:02<00:02, 1041.69it/s]
source: func rotateRemoteKey(role data.RoleName, remote store.RemoteStore) (data.PublicKey, error) {
	rawPubKey, err := remote.RotateKey(role)
	if err != nil {
		return nil, err
	}

	pubKey, err := data.UnmarshalPublicKey(rawPubKey)
	if err != nil {
		return nil, err
	}

	return pubKey, nil
}
source: func (c *testCluster) RandomManager() *testNode {
	var managers []*testNode
	for _, n := range c.nodes {
		if n.IsManager() {
			managers = append(managers, n)
		}
	}
	idx := rand.Intn(len(managers))
	return managers[idx]
}
source: func (client *Client) GetApplicationTasks(appGUID string, query ...Query) ([]Task, Warnings, error) {
	request, err := client.newHTTPRequest(requestOptions{
		RequestName: internal.GetApplicationTasksRequest,
		URIParams: internal.Params{
			"app_guid": appGUID,
		},
		Query: query,
	})
	if err != nil {
		return nil, nil, err
	}

	var fullTasksList []Task
	warnings, err := client.paginate(request, Task{}, func(item interface{}) error {
		if task, ok := item.(Task); ok {
			fullTasksList = append(fullTasksList, task)
		} else {
			return ccerror.UnknownObjectInListError{
				Expected:   Task{},
				Unexpected: item,
			}
		}
		return nil
	})

	return fullTasksList, warnings, err
}
source: func (c *T) UpsertServer(beSrv backend.Srv) {
	c.mu.Lock()
	defer c.mu.Unlock()

	c.beSrvRTMs[beSrv.URLKey()] = BeSrvEntry{beSrv.Cfg(), NewRTMetrics()}
}
source: func (in *DeploymentConfigStatus) DeepCopy() *DeploymentConfigStatus {
	if in == nil {
		return nil
	}
	out := new(DeploymentConfigStatus)
	in.DeepCopyInto(out)
	return out
}
source: func (s *ReplicationTask) SetReplicationTaskCreationDate(v time.Time) *ReplicationTask {
	s.ReplicationTaskCreationDate = &v
	return s
}
source: func (mc *MerkleClient) readSkipSequenceFromAPIRes(m MetaContext, res *APIRes, thisRoot *MerkleRoot, lastRoot *MerkleRoot) (ret SkipSequence, err error) {
	defer m.VTrace(VLog1, "MerkleClient#readSkipSequenceFromAPIRes", func() error { return err })()
	if lastRoot == nil {
		m.VLogf(VLog0, "| lastRoot==nil")
		return nil, nil
	}
	if !thisRoot.HasSkips() {
		m.VLogf(VLog0, "| thisRoot has no skips")
		return nil, nil
	}
	skips := res.Body.AtKey("skips")

	if skips.IsNil() {
		m.VLogf(VLog1, "| skip list from API server is nil")
		return nil, nil
	}

	var v []string
	if err = skips.UnmarshalAgain(&v); err != nil {
		m.VLogf(VLog0, "| failed to unmarshal skip list as a list of strings")
		return nil, err
	}

	ret, err = readSkipSequenceFromStringList(v)
	if err != nil {
		return nil, err
	}

	// Create the skip sequence by bookending the list the server replies with
	// with: (1) the most recent root, sent back in this reply; and (2) our last
	// root, which we read out of cache (in memory or on disk). HOWEVER, in the
	// case of lookup up historical roots, the ordering might be reversed.  So
	// we swap in that case.

	left, right := thisRoot.payload, lastRoot.payload
	if left.seqno() < right.seqno() {
		left, right = right, left
	}

	ret = append(SkipSequence{left}, ret...)
	ret = append(ret, right)

	return ret, nil
}
source: func (c *certificateCache) set(addr string, certificate ssh.Signer, ttl time.Duration) error {
	c.mu.Lock()
	defer c.mu.Unlock()

	err := c.cache.Set(addr, certificate, ttl)
	if err != nil {
		return trace.Wrap(err)
	}

	return nil
}
source: func (s *Server) GetCluster(ctx context.Context, request *api.GetClusterRequest) (*api.GetClusterResponse, error) {
	if request.ClusterID == "" {
		return nil, status.Errorf(codes.InvalidArgument, errInvalidArgument.Error())
	}

	var cluster *api.Cluster
	s.store.View(func(tx store.ReadTx) {
		cluster = store.GetCluster(tx, request.ClusterID)
	})
	if cluster == nil {
		return nil, status.Errorf(codes.NotFound, "cluster %s not found", request.ClusterID)
	}

	redactedClusters := redactClusters([]*api.Cluster{cluster})

	// WARN: we should never return cluster here. We need to redact the private fields first.
	return &api.GetClusterResponse{
		Cluster: redactedClusters[0],
	}, nil
}
source: func newSampleController(context *opkit.Context, sampleClientset sampleclient.MyprojectV1alpha1Interface) *SampleController {
	return &SampleController{
		context:         context,
		sampleClientset: sampleClientset,
	}
}
source: func (pg *GoEvtxMap) GetUint(path *GoEvtxPath) (uint64, error) {
	s, err := pg.GetString(path)
	if err != nil {
		return 0, &ErrEvtxEltNotFound{*path}
	}
	u, err := strconv.ParseUint(s, 10, 64)
	if err != nil {
		return 0, err
	}
	return u, nil
}
source: func (c *Config) allowFQDN(fqdn string) bool {
	fqdn = strings.ToLower(fqdn)
	if len(c.Outgoing.AllowSites) > 0 {
		for _, match := range c.Outgoing.AllowSites {
			if siteMatch(fqdn, match) {
				goto CHECK_DENY
			}
		}
		return false
	}

CHECK_DENY:
	for _, match := range c.Outgoing.DenySites {
		if siteMatch(fqdn, match) {
			return false
		}
	}
	return true
}
source: func (a VarRefs) Strings() []string {
	s := make([]string, len(a))
	for i, ref := range a {
		s[i] = ref.Val
	}
	return s
}
source: func (ipc *IPCache) LookupByPrefix(IP string) (Identity, bool) {
	ipc.mutex.RLock()
	defer ipc.mutex.RUnlock()
	return ipc.LookupByPrefixRLocked(IP)
}
source: func (e *Engine) SetTimeManager(manager TimeManager) func(*Engine) {
	return func(engine *Engine) {
		engine.timeManager = manager
	}
}
source: func kvImageInfo(v []byte) (ii camtypes.ImageInfo, ok bool) {
	pipei := bytes.IndexByte(v, '|')
	if pipei < 0 {
		return
	}
	w, err := strutil.ParseUintBytes(v[:pipei], 10, 16)
	if err != nil {
		return
	}
	h, err := strutil.ParseUintBytes(v[pipei+1:], 10, 16)
	if err != nil {
		return
	}
	ii.Width = uint16(w)
	ii.Height = uint16(h)
	return ii, true
}
source: func appsDestroy(db *gorm.DB, app *App) error {
	now := timex.Now()
	app.DeletedAt = &now
	return appsUpdate(db, app)
}
source: func ToScss(r io.Reader, w io.Writer) error {
	bs, _ := ioutil.ReadAll(r)
	in := C.CString(string(bs))
	defer C.free(unsafe.Pointer(in))

	chars := C.sass2scss(
		// FIXME: readers would be much more efficient
		in,
		// SASS2SCSS_PRETTIFY_1 Egyptian brackets
		C.int(1),
	)
	_, err := io.WriteString(w, C.GoString(chars))
	return err
}
source: func (s *VMGroupService) DeleteInstanceGroup(p *DeleteInstanceGroupParams) (*DeleteInstanceGroupResponse, error) {
	resp, err := s.cs.newRequest("deleteInstanceGroup", p.toURLValues())
	if err != nil {
		return nil, err
	}

	var r DeleteInstanceGroupResponse
	if err := json.Unmarshal(resp, &r); err != nil {
		return nil, err
	}

	return &r, nil
}
source: func copyBuffer(f syncer, dst io.Writer, src io.Reader, buf []byte) (written int64, err error) {
	if buf == nil {
		buf = make([]byte, 32*1024)
	}
	var lastSync int64
	for {
		nr, er := src.Read(buf)
		if nr > 0 {
			nw, ew := dst.Write(buf[0:nr])
			if nw > 0 {
				written += int64(nw)
			}

			if f != nil && written-lastSync > fsyncEvery {
				if err := f.Sync(); err != nil {
					return 0, err
				}
				lastSync = written
			}
			if ew != nil {
				err = ew
				break
			}
			if nr != nw {
				err = io.ErrShortWrite
				break
			}
		}
		if er != nil {
			if er != io.EOF {
				err = er
			}
			break
		}
	}
	return written, err
}
source: func Convert_v1_ServiceReference_To_apiregistration_ServiceReference(in *ServiceReference, out *apiregistration.ServiceReference, s conversion.Scope) error {
	return autoConvert_v1_ServiceReference_To_apiregistration_ServiceReference(in, out, s)
}
source: func (c *Client) doHTTPRequest(req *http.Request) (*http.Response, error) {
	if c.UserAgent != "" && req.Header.Get("User-Agent") == "" {
		req.Header.Set("User-Agent", c.UserAgent)
	}
	return c.HTTPClient.Do(req)
}
source: func (m *MutexKV) Lock(key string) {
	log.Printf("[DEBUG] Locking %q", key)
	m.get(key).Lock()
	log.Printf("[DEBUG] Locked %q", key)
}
source: func (p *policyChecker) CheckPolicyNoChannel(policyName string, signedProp *pb.SignedProposal) error {
	if policyName == "" {
		return errors.New("Invalid policy name during channelless check policy. Name must be different from nil.")
	}

	if signedProp == nil {
		return fmt.Errorf("Invalid signed proposal during channelless check policy with policy [%s]", policyName)
	}

	proposal, err := utils.GetProposal(signedProp.ProposalBytes)
	if err != nil {
		return fmt.Errorf("Failing extracting proposal during channelless check policy with policy [%s]: [%s]", policyName, err)
	}

	header, err := utils.GetHeader(proposal.Header)
	if err != nil {
		return fmt.Errorf("Failing extracting header during channelless check policy with policy [%s]: [%s]", policyName, err)
	}

	shdr, err := utils.GetSignatureHeader(header.SignatureHeader)
	if err != nil {
		return fmt.Errorf("Invalid Proposal's SignatureHeader during channelless check policy with policy [%s]: [%s]", policyName, err)
	}

	// Deserialize proposal's creator with the local MSP
	id, err := p.localMSP.DeserializeIdentity(shdr.Creator)
	if err != nil {
		return fmt.Errorf("Failed deserializing proposal creator during channelless check policy with policy [%s]: [%s]", policyName, err)
	}

	// Load MSPPrincipal for policy
	principal, err := p.principalGetter.Get(policyName)
	if err != nil {
		return fmt.Errorf("Failed getting local MSP principal during channelless check policy with policy [%s]: [%s]", policyName, err)
	}

	// Verify that proposal's creator satisfies the principal
	err = id.SatisfiesPrincipal(principal)
	if err != nil {
		return fmt.Errorf("Failed verifying that proposal's creator satisfies local MSP principal during channelless check policy with policy [%s]: [%s]", policyName, err)
	}

	// Verify the signature
	return id.Verify(signedProp.ProposalBytes, signedProp.Signature)
}
source: func (s *Store) GetCollection(name string) *Collection {
	if s.collLock != nil {
		s.collLock.RLock()
		defer s.collLock.RUnlock()
	}
	return s.colls[name]
}
source: func (a *Agent) keyringProcess(args *structs.KeyringRequest) (*structs.KeyringResponses, error) {
	var reply structs.KeyringResponses

	if _, ok := a.delegate.(*consul.Server); !ok {
		return nil, fmt.Errorf("keyring operations must run against a server node")
	}
	if err := a.RPC("Internal.KeyringOperation", args, &reply); err != nil {
		return &reply, err
	}

	return &reply, nil
}
source: func (in *VolumeSnapshotCondition) DeepCopy() *VolumeSnapshotCondition {
	if in == nil {
		return nil
	}
	out := new(VolumeSnapshotCondition)
	in.DeepCopyInto(out)
	return out
}
source: func SnakeString(s string) string {
	data := make([]byte, 0, len(s)*2)
	j := false
	num := len(s)
	for i := 0; i < num; i++ {
		d := s[i]
		if i > 0 && d >= 'A' && d <= 'Z' && j {
			data = append(data, '_')
		}
		if d != '_' {
			j = true
		}
		data = append(data, d)
	}
	return strings.ToLower(string(data[:]))
}
source: func (w *window) Reset() {
	w.bucketLock.Lock()

	w.buckets.Do(func(x interface{}) {
		x.(*bucket).Reset()
	})
	w.bucketLock.Unlock()
}
source: func (a *managedAddress) PrivKey() (*btcec.PrivateKey, error) {
	// No private keys are available for a watching-only address manager.
	if a.manager.rootManager.WatchOnly() {
		return nil, managerError(ErrWatchingOnly, errWatchingOnly, nil)
	}

	a.manager.mtx.Lock()
	defer a.manager.mtx.Unlock()

	// Account manager must be unlocked to decrypt the private key.
	if a.manager.rootManager.IsLocked() {
		return nil, managerError(ErrLocked, errLocked, nil)
	}

	// Decrypt the key as needed.  Also, make sure it's a copy since the
	// private key stored in memory can be cleared at any time.  Otherwise
	// the returned private key could be invalidated from under the caller.
	privKeyCopy, err := a.unlock(a.manager.rootManager.cryptoKeyPriv)
	if err != nil {
		return nil, err
	}

	privKey, _ := btcec.PrivKeyFromBytes(btcec.S256(), privKeyCopy)
	zero.Bytes(privKeyCopy)
	return privKey, nil
}
source: func (env *maasEnviron) newCloudinitConfig(hostname, forSeries string) (cloudinit.CloudConfig, error) {
	cloudcfg, err := cloudinit.New(forSeries)
	if err != nil {
		return nil, err
	}

	info := machineInfo{hostname}
	runCmd, err := info.cloudinitRunCmd(cloudcfg)
	if err != nil {
		return nil, errors.Trace(err)
	}

	operatingSystem, err := series.GetOSFromSeries(forSeries)
	if err != nil {
		return nil, errors.Trace(err)
	}
	switch operatingSystem {
	case os.Windows:
		cloudcfg.AddScripts(runCmd)
	case os.Ubuntu:
		cloudcfg.SetSystemUpdate(true)
		cloudcfg.AddScripts("set -xe", runCmd)
		// DisableNetworkManagement can still disable the bridge(s) creation.
		if on, set := env.Config().DisableNetworkManagement(); on && set {
			logger.Infof(
				"network management disabled - not using %q bridge for containers",
				instancecfg.DefaultBridgeName,
			)
			break
		}
		cloudcfg.AddPackage("bridge-utils")
	}
	return cloudcfg, nil
}
source: func objectMetaFieldsSet(objectMeta metav1.Object, namespaceScoped bool) fields.Set {
	if namespaceScoped {
		return fields.Set{
			"metadata.name":      objectMeta.GetName(),
			"metadata.namespace": objectMeta.GetNamespace(),
		}
	}
	return fields.Set{
		"metadata.name": objectMeta.GetName(),
	}
}
source: func (a *btcAddress) changeEncryptionKey(oldkey, newkey []byte) error {
	// Address must have a private key and be encrypted to continue.
	if !a.flags.hasPrivKey {
		return errors.New("no private key")
	}
	if !a.flags.encrypted {
		return errors.New("address is not encrypted")
	}

	privKeyCT, err := a.unlock(oldkey)
	if err != nil {
		return err
	}

	aesBlockEncrypter, err := aes.NewCipher(newkey)
	if err != nil {
		return err
	}
	newIV := make([]byte, len(a.initVector))
	if _, err := rand.Read(newIV); err != nil {
		return err
	}
	copy(a.initVector[:], newIV)
	aesEncrypter := cipher.NewCFBEncrypter(aesBlockEncrypter, a.initVector[:])
	aesEncrypter.XORKeyStream(a.privKey[:], privKeyCT)

	return nil
}
source: func (e *EnumSpec) LookupItem(name string) (*EnumItem, bool) {
	for _, item := range e.Items {
		if item.Name == name {
			return &item, true
		}
	}
	return nil, false
}
source: func StreamServerInterceptor(opts ...Option) grpc.StreamServerInterceptor {
	o := evaluateOptions(opts)
	return func(srv interface{}, stream grpc.ServerStream, info *grpc.StreamServerInfo, handler grpc.StreamHandler) error {
		newCtx := newTagsForCtx(stream.Context())
		if o.requestFieldsFunc == nil {
			// Short-circuit, don't do the expensive bit of allocating a wrappedStream.
			wrappedStream := grpc_middleware.WrapServerStream(stream)
			wrappedStream.WrappedContext = newCtx
			return handler(srv, wrappedStream)
		}
		wrapped := &wrappedStream{stream, info, o, newCtx, true}
		err := handler(srv, wrapped)
		return err
	}
}
source: func (cli *Client) Events(ctx context.Context, options types.EventsOptions) (io.ReadCloser, error) {
	query := url.Values{}
	ref := time.Now()

	if options.Since != "" {
		ts, err := timetypes.GetTimestamp(options.Since, ref)
		if err != nil {
			return nil, err
		}
		query.Set("since", ts)
	}
	if options.Until != "" {
		ts, err := timetypes.GetTimestamp(options.Until, ref)
		if err != nil {
			return nil, err
		}
		query.Set("until", ts)
	}
	if options.Filters.Len() > 0 {
		filterJSON, err := filters.ToParamWithVersion(cli.version, options.Filters)
		if err != nil {
			return nil, err
		}
		query.Set("filters", filterJSON)
	}

	serverResponse, err := cli.get(ctx, "/events", query, nil)
	if err != nil {
		return nil, err
	}
	return serverResponse.body, nil
}
source: func EncodeTLSToObject(t *tls.ConnectionState) interface{} {
	version := lookup(tlsVersions, t.Version)
	cipher := lookup(cipherSuites, t.CipherSuite)
	return &TLSDescription{
		version.Slug,
		cipher.Slug,
	}
}
source: func Auto() *printer.Logger {
	initRuntimeVerbose()
	_, file, _, _ := runtime.Caller(1)
	name := runtimeV.DeterminePackage(file)
	return From(name)
}
source: func NewFileRequestDetails(AssetIndex uint64) *FileRequestDetails {
	s := new(FileRequestDetails)
	s.AssetIndex = AssetIndex
	return s
}
source: func (vm VirtualMachine) NicByNetworkID(networkID UUID) *Nic {
	for _, nic := range vm.Nic {
		if nic.NetworkID.Equal(networkID) {
			n := nic
			n.VirtualMachineID = vm.ID
			return &n
		}
	}
	return nil
}
source: func (c *MemcacheClient) SetKey(k cache.Keyer, refreshDeadline time.Time, v []byte) error {
	expiry := refreshDeadline.Sub(time.Now()) * 2
	if expiry < MinExpiry {
		expiry = MinExpiry
	}

	deadlineBytes := make([]byte, 4, 4)
	binary.BigEndian.PutUint32(deadlineBytes, uint32(refreshDeadline.Unix()))
	if err := c.client.Set(&memcache.Item{
		Key:        k.Key(),
		Value:      append(deadlineBytes, v...),
		Expiration: int32(expiry.Seconds()),
	}); err != nil {
		c.logger.Log("err", errors.Wrap(err, "storing in memcache"))
		return err
	}
	return nil
}
source: func AddLogStreamPathFilter(q *ds.Query, path string) (*ds.Query, error) {
	prefix, name := types.StreamPath(path).Split()

	err := error(nil)
	q, err = addComponentFilter(q, "Prefix", "_C", "P", prefix)
	if err != nil {
		return nil, err
	}
	q, err = addComponentFilter(q, "Name", "_C", "N", name)
	if err != nil {
		return nil, err
	}
	return q, nil
}
source: func NewStringTypeDef(init ...*StringTypeDef) *StringTypeDef {
	var o *StringTypeDef
	if len(init) == 1 {
		o = init[0]
	} else {
		o = new(StringTypeDef)
	}
	return o
}
source: func newConn(c net.Conn) *conn {
	br := bufio.NewReader(c)
	bw := bufio.NewWriter(c)

	brw := bufio.NewReadWriter(br, bw)
	return &conn{rwc: c, buf: brw}
}
source: func validateSplitQueryParameters(
	target *querypb.Target,
	query *querypb.BoundQuery,
	splitCount int64,
	numRowsPerQueryPart int64,
	algorithm querypb.SplitQueryRequest_Algorithm,
) error {
	// Check that the caller requested a RDONLY tablet.
	// Since we're called by VTGate this should not normally be violated.
	if target.TabletType != topodatapb.TabletType_RDONLY {
		return vterrors.Errorf(
			vtrpcpb.Code_INVALID_ARGUMENT,
			"SplitQuery must be called with a RDONLY tablet. TableType passed is: %v",
			target.TabletType)
	}
	if numRowsPerQueryPart < 0 {
		return vterrors.Errorf(
			vtrpcpb.Code_INVALID_ARGUMENT,
			"splitQuery: numRowsPerQueryPart must be non-negative. Got: %v. SQL: %v",
			numRowsPerQueryPart,
			queryAsString(query.Sql, query.BindVariables))
	}
	if splitCount < 0 {
		return vterrors.Errorf(
			vtrpcpb.Code_INVALID_ARGUMENT,
			"splitQuery: splitCount must be non-negative. Got: %v. SQL: %v",
			splitCount,
			queryAsString(query.Sql, query.BindVariables))
	}
	if (splitCount == 0 && numRowsPerQueryPart == 0) ||
		(splitCount != 0 && numRowsPerQueryPart != 0) {
		return vterrors.Errorf(
			vtrpcpb.Code_INVALID_ARGUMENT,
			"splitQuery: exactly one of {numRowsPerQueryPart, splitCount} must be"+
				" non zero. Got: numRowsPerQueryPart=%v, splitCount=%v. SQL: %v",
			numRowsPerQueryPart,
			splitCount,
			queryAsString(query.Sql, query.BindVariables))
	}
	if algorithm != querypb.SplitQueryRequest_EQUAL_SPLITS &&
		algorithm != querypb.SplitQueryRequest_FULL_SCAN {
		return vterrors.Errorf(
			vtrpcpb.Code_INVALID_ARGUMENT,
			"splitquery: unsupported algorithm: %v. SQL: %v",
			algorithm,
			queryAsString(query.Sql, query.BindVariables))
	}
	return nil
}
source: func New(app string, opts ...Option) (*Ringpop, error) {
	var err error

	ringpop := &Ringpop{
		config: &configuration{
			App:           app,
			InitialLabels: make(swim.LabelMap),
		},
		logger: logging.Logger("ringpop"),
	}

	err = applyOptions(ringpop, defaultOptions)
	if err != nil {
		panic(fmt.Errorf("Error applying default Ringpop options: %v", err))
	}

	err = applyOptions(ringpop, opts)
	if err != nil {
		return nil, err
	}

	errs := checkOptions(ringpop)
	if len(errs) != 0 {
		return nil, fmt.Errorf("%v", errs)
	}

	ringpop.setState(created)

	return ringpop, nil
}
source: func getFieldNames(instance interface{}) []string {
	var (
		fields []string
		v      = reflect.Indirect(reflect.ValueOf(instance))
		t      = v.Type()
	)

	if t.Kind() != reflect.Struct {
		return nil
	}

	for i := 0; i < v.NumField(); i++ {
		var (
			vField = v.Field(i)
			tField = v.Type().Field(i)
		)

		// Is exportable?
		if tField.PkgPath != "" {
			continue
		}

		if tField.Type.Kind() == reflect.Struct && tField.Anonymous {
			fields = append(fields, getFieldNames(vField.Interface())...)
			continue
		}

		fields = append(fields, tField.Name)
	}

	return fields
}
source: func (fs *KBFSOpsStandard) Write(
	ctx context.Context, file Node, data []byte, off int64) error {
	timeTrackerDone := fs.longOperationDebugDumper.Begin(ctx)
	defer timeTrackerDone()

	ops := fs.getOpsByNode(ctx, file)
	return ops.Write(ctx, file, data, off)
}
source: func (r *DB) Select(dest interface{}, query string, args ...interface{}) error {
	var err error
	exec := func() error {
		if r.Tx != nil {
			return r.Tx.SelectContext(r.ctx, dest, query, args...)
		}
		return r.DB.SelectContext(r.ctx, dest, query, args...)
	}

	r.Log(func() {
		err = exec()
	}, query, args...)

	// clear no rows returned error
	if err == sql.ErrNoRows {
		return nil
	}

	return errors.Wrap(err, "select query failed")
}
source: func (b *BaseBuilder) quoteColumns(cols []string) string {
	s := ""
	for i, col := range cols {
		if i == 0 {
			s = b.db.QuoteColumnName(col)
		} else {
			s += ", " + b.db.QuoteColumnName(col)
		}
	}
	return s
}
source: func (self *Commands) IsString(value interface{}) error {
	if typeutil.IsKindOfString(value) {
		return nil
	} else {
		return fmt.Errorf("Expected string value")
	}
}
source: func (s *ScheduledImageStreamController) enqueueImageStream(stream *imagev1.ImageStream) {
	if !s.enabled {
		return
	}
	if needsScheduling(stream) {
		key, err := cache.DeletionHandlingMetaNamespaceKeyFunc(stream)
		if err != nil {
			klog.V(2).Infof("unable to get namespace key function for stream %s/%s: %v", stream.Namespace, stream.Name, err)
			return
		}
		s.scheduler.Add(key, uniqueItem{uid: string(stream.UID), resourceVersion: stream.ResourceVersion})
	}
}
source: func OSVersion() (semver.Version, error) {
	out, err := exec.Command("sw_vers", "-productVersion").Output()
	if err != nil {
		return semver.Version{}, err
	}
	swver := strings.TrimSpace(string(out))
	// The version might not be semver compliant for beta macOS (e.g. "10.12")
	if strings.Count(swver, ".") == 1 {
		swver = swver + ".0"
	}
	return semver.Make(swver)
}
source: func (oa *orderedAggregate) Wireup(bldr builder, jt *jointab) error {
	for i, colnum := range oa.eaggr.Keys {
		if sqltypes.IsText(oa.resultColumns[colnum].column.typ) {
			// len(oa.resultColumns) does not change. No harm using the value multiple times.
			oa.eaggr.TruncateColumnCount = len(oa.resultColumns)
			oa.eaggr.Keys[i] = oa.input.SupplyWeightString(colnum)
		}
	}
	return oa.input.Wireup(bldr, jt)
}
source: func ParseListing(raw json.RawMessage) (
	[]*Link,
	[]*Comment,
	[]*Message,
	error,
) {
	thing, err := handleThing(raw)
	if err != nil {
		return nil, nil, nil, err
	}

	buffer, ok := thing.(*listingBuffer)
	if !ok {
		return nil, nil, nil, fmt.Errorf("JSON message was nonlisting")
	}

	return buffer.links, buffer.comments, buffer.messages, nil
}
source: func defaultHTTPClient() (*http.Client, error) {
	urand, err := earlyrand.UrandomReader()
	if err != nil {
		return nil, err
	}

	tlsConfig := tls.Config{
		Rand: urand,
	}
	transport := http.Transport{
		ResponseHeaderTimeout: time.Duration(defaultHttpResponseHeaderTimeout) * time.Second,
		Dial: (&net.Dialer{
			Timeout:   30 * time.Second,
			KeepAlive: 30 * time.Second,
			Resolver: &net.Resolver{
				PreferGo: true,
			},
		}).Dial,
		TLSClientConfig:     &tlsConfig,
		TLSHandshakeTimeout: 10 * time.Second,
	}
	client := http.Client{
		Transport: &transport,
	}
	return &client, nil
}
source: func (h *NumericHistogram) Mean() float64 {
	if h.total == 0 {
		return 0
	}

	sum := 0.0

	for i := range h.bins {
		sum += h.bins[i].value * h.bins[i].count
	}

	return sum / float64(h.total)
}
source: func (r *RemoteProofLinks) Insert(link RemoteProofChainLink, err ProofError) {
	key := link.TableKey()
	if len(key) == 0 {
		return
	}
	r.links[key] = append(r.links[key], ProofLinkWithState{link: link, state: ProofErrorToState(err)})
}
source: func NewTCPListener(ln net.Listener, secretConnKey ed25519.PrivKeyEd25519) *tcpListener {
	return &tcpListener{
		TCPListener:      ln.(*net.TCPListener),
		secretConnKey:    secretConnKey,
		timeoutAccept:    time.Second * defaultTimeoutAcceptSeconds,
		timeoutReadWrite: time.Second * defaultTimeoutReadWriteSeconds,
	}
}
source: func (evpool *EvidencePool) MarkEvidenceAsCommitted(height int64, evidence []types.Evidence) {
	// make a map of committed evidence to remove from the clist
	blockEvidenceMap := make(map[string]struct{})
	for _, ev := range evidence {
		evpool.evidenceStore.MarkEvidenceAsCommitted(ev)
		blockEvidenceMap[evMapKey(ev)] = struct{}{}
	}

	// remove committed evidence from the clist
	maxAge := evpool.State().ConsensusParams.Evidence.MaxAge
	evpool.removeEvidence(height, maxAge, blockEvidenceMap)

}
source: func initialize() {
	if lowPort+maxBlocks*blockSize > 65535 {
		panic("freeport: block size too big or too many blocks requested")
	}

	rand.Seed(time.Now().UnixNano())
	firstPort, lockLn = alloc()
}
source: func (o *UpdateJSONWebKeyParams) WithKid(kid string) *UpdateJSONWebKeyParams {
	o.SetKid(kid)
	return o
}
source: func InitConsumer(topic string) chan []byte {
	consumer, err := bus.StartConsumer(topic)
	if err != nil {
		fmt.Println(err)
	}
	return consumer
}
source: func (s *QueryService) Query(ctx context.Context, req *query.Request) (flux.ResultIterator, error) {
	u, err := newURL(s.Addr, queryPath)
	if err != nil {
		return nil, err
	}
	var body bytes.Buffer
	if err := json.NewEncoder(&body).Encode(req); err != nil {
		return nil, err
	}

	hreq, err := http.NewRequest("POST", u.String(), &body)
	if err != nil {
		return nil, err
	}
	SetToken(s.Token, hreq)
	hreq = hreq.WithContext(ctx)

	hc := newClient(u.Scheme, s.InsecureSkipVerify)
	resp, err := hc.Do(hreq)
	if err != nil {
		return nil, err
	}
	if err := CheckError(resp, true); err != nil {
		return nil, err
	}

	var decoder flux.MultiResultDecoder
	switch resp.Header.Get("Content-Type") {
	case "text/csv":
		fallthrough
	default:
		decoder = csv.NewMultiResultDecoder(csv.ResultDecoderConfig{})
	}
	results, err := decoder.Decode(resp.Body)
	if err != nil {
		return nil, err
	}

	statResults := &statsResultIterator{
		results: results,
		resp:    resp,
	}
	return statResults, nil
}
source: func (d *Daemon) getExecConfig(name string) (*exec.Config, error) {
	ec := d.execCommands.Get(name)
	if ec == nil {
		return nil, errExecNotFound(name)
	}

	// If the exec is found but its container is not in the daemon's list of
	// containers then it must have been deleted, in which case instead of
	// saying the container isn't running, we should return a 404 so that
	// the user sees the same error now that they will after the
	// 5 minute clean-up loop is run which erases old/dead execs.
	container := d.containers.Get(ec.ContainerID)
	if container == nil {
		return nil, containerNotFound(name)
	}
	if !container.IsRunning() {
		return nil, fmt.Errorf("Container %s is not running: %s", container.ID, container.State.String())
	}
	if container.IsPaused() {
		return nil, errExecPaused(container.ID)
	}
	if container.IsRestarting() {
		return nil, errContainerIsRestarting(container.ID)
	}
	return ec, nil
}
source: func (f *Flash) Add(key string, value interface{}) {
	if !f.changed {
		f.changed = true
	}
	if f.v == nil {
		f.v = make(data)
	}
	f.v[key] = append(f.v[key], value)
}
source: func (tsv *TabletServer) VStream(ctx context.Context, target *querypb.Target, startPos string, filter *binlogdatapb.Filter, send func([]*binlogdatapb.VEvent) error) error {
	if err := tsv.verifyTarget(ctx, target); err != nil {
		return err
	}
	return tsv.vstreamer.Stream(ctx, startPos, filter, send)
}
source: func ReadInt(r io.Reader) (int, error) {
	data, err := ReadN(r, 4)

	if err != nil {
		return 0, err
	}

	return Byte2Int(data), nil
}
source: func (b *builtinTidbParseTsoSig) evalTime(row chunk.Row) (types.Time, bool, error) {
	arg, isNull, err := b.args[0].EvalInt(b.ctx, row)
	if isNull || err != nil || arg <= 0 {
		return types.Time{}, true, handleInvalidTimeError(b.ctx, err)
	}

	t := oracle.GetTimeFromTS(uint64(arg))
	result := types.Time{
		Time: types.FromGoTime(t),
		Type: mysql.TypeDatetime,
		Fsp:  types.MaxFsp,
	}
	err = result.ConvertTimeZone(time.Local, b.ctx.GetSessionVars().Location())
	if err != nil {
		return types.Time{}, true, err
	}
	return result, false, nil
}
source: func (a keystonePasswordAuthenticator) AuthenticatePassword(ctx context.Context, username, password string) (*authenticator.Response, bool, error) {
	defer func() {
		if e := recover(); e != nil {
			utilruntime.HandleError(fmt.Errorf("Recovered panic: %v, %s", e, debug.Stack()))
		}
	}()

	// if password is missing, fail authentication immediately
	if len(password) == 0 {
		return nil, false, nil
	}

	opts := gophercloud.AuthOptions{
		IdentityEndpoint: a.url,
		Username:         username,
		Password:         password,
		DomainName:       a.domainName,
	}

	// Calling NewClient/Authenticate manually rather than simply calling AuthenticatedClient
	// in order to pass in a transport object that supports SSL
	client, err := openstack.NewClient(opts.IdentityEndpoint)
	if err != nil {
		klog.Warningf("Failed: Initializing openstack authentication client: %v", err)
		return nil, false, err
	}

	client.HTTPClient = *a.client
	userid, err := getUserIDv3(client, &opts, gophercloud.EndpointOpts{})

	if err != nil {
		if _, ok := err.(gophercloud.ErrDefault401); ok {
			return nil, false, nil
		}
		klog.Warningf("Failed: Calling openstack AuthenticateV3: %v", err)
		return nil, false, err
	}

	providerUserID := username
	if a.useKeystoneIdentity {
		providerUserID = userid
	}

	identity := authapi.NewDefaultUserIdentityInfo(a.providerName, providerUserID)
	identity.Extra[authapi.IdentityPreferredUsernameKey] = username

	return identitymapper.ResponseFor(a.identityMapper, identity)
}
source: func (forwarder *BufferedForwarder) AddEvents(ctx context.Context, events []*event.Event) error {
	if forwarder.checker.CtxFlagCheck.HasFlag(ctx) {
		forwarder.cdim.With(ctx, forwarder.logger).Log("Events call received in buffered forwarder")
	}
	atomic.AddInt64(&forwarder.stats.totalEventsBuffered, int64(len(events)))
	if *forwarder.config.MaxTotalEvents <= atomic.LoadInt64(&forwarder.stats.totalEventsBuffered) {
		atomic.AddInt64(&forwarder.stats.totalEventsBuffered, int64(-len(events)))
		return errEBufferFull(forwarder.identifier)
	}
	select {
	case forwarder.eChan <- events:
		return nil
	case <-forwarder.stopContext.Done():
		return forwarder.stopContext.Err()
	case <-ctx.Done():
		return ctx.Err()
	}
}
source: func ParseAcceptHeader(accept string) (AcceptHeader, error) {
	ranges := make(AcceptHeader, 0)
	p := httpParser{r: []rune(accept)}
	p.space()
	for !p.eof() {
		if len(ranges) > 0 {
			if !p.consume(",") {
				return ranges, &parseError{Expected: "','", Found: p.peek(), EOF: p.eof()}
			}
			p.space()
		}

		r, err := parseMediaRange(&p)
		if err != nil {
			if r != "" {
				ranges = append(ranges, MediaRange{Range: r, Quality: 1.0})
			}
			return ranges, err
		}
		quality, params, err := parseAcceptParams(&p)
		ranges = append(ranges, MediaRange{Range: r, Quality: quality, Params: params})
		if err != nil {
			return ranges, err
		}

	}
	return ranges, nil
}
source: func (c *Clientset) Apiextensions() apiextensionsinternalversion.ApiextensionsInterface {
	return &fakeapiextensionsinternalversion.FakeApiextensions{Fake: &c.Fake}
}
source: func (prefs Preferences) CountFields(fieldName string) int {
	value, err := reflections.GetField(prefs, fieldName)
	count := 0
	if err != nil {
		return count
	}
	items, _ := reflections.Items(value)
	for i := range items {
		value, _ := reflections.GetField(value, i)
		if value != nil && value != "" {
			count++
		}
	}
	return count
}
source: func (builder *MetricBuilder) Metric(metric Metric) *MetricMetricBuilder {
	newMetric := MetricMetricBuilder{
		Metric{
			ID:          metric.ID,
			Name:        metric.Name,
			Description: metric.Description,
			Counter:     metric.Counter,
			CounterMax:  metric.CounterMax,
			ResetValue:  metric.ResetValue,
			Unit:        metric.Unit,
		},
		make(map[string][]string),
	}
	builder.metrics = append(builder.metrics, newMetric)
	return &builder.metrics[len(builder.metrics)-1]
}
source: func (s *StatsInfo) Scale(factor float64) *StatsInfo {
	profile := &StatsInfo{
		RowCount:     s.RowCount * factor,
		Cardinality:  make([]float64, len(s.Cardinality)),
		HistColl:     s.HistColl,
		StatsVersion: s.StatsVersion,
	}
	for i := range profile.Cardinality {
		profile.Cardinality[i] = s.Cardinality[i] * factor
	}
	return profile
}
source: func (p *Number) Validate() error {
	if p.Int8 != nil {
		p.Variant = NumberVariantInt8
	} else if p.Int16 != nil {
		p.Variant = NumberVariantInt16
	} else if p.Int32 != nil {
		p.Variant = NumberVariantInt32
	} else if p.Int64 != nil {
		p.Variant = NumberVariantInt64
	} else if p.Float32 != nil {
		p.Variant = NumberVariantFloat32
	} else if p.Float64 != nil {
		p.Variant = NumberVariantFloat64
	} else {
		return fmt.Errorf("Number: Missing required variant")
	}
	return nil
}
source: func (s *ListCodeRepositoriesOutput) SetCodeRepositorySummaryList(v []*CodeRepositorySummary) *ListCodeRepositoriesOutput {
	s.CodeRepositorySummaryList = v
	return s
}
source: func (r *realisClient) GetPendingReason(query *aurora.TaskQuery) ([]*aurora.PendingReason, error) {

	r.logger.DebugPrintf("GetPendingReason Thrift Payload: %+v\n", query)

	resp, retryErr := r.thriftCallWithRetries(func() (*aurora.Response, error) {
		return r.client.GetPendingReason(nil, query)
	})

	if retryErr != nil {
		return nil, errors.Wrap(retryErr, "Error querying Aurora Scheduler for pending Reasons")
	}

	var pendingReasons []*aurora.PendingReason

	if resp.GetResult_() != nil {
		pendingReasons = resp.GetResult_().GetGetPendingReasonResult_().GetReasons()
	}

	return pendingReasons, nil
}
source: func (f *BasicFilesystem) Hide(name string) error {
	_, err := f.rooted(name)
	return err
}
source: func (p pointer) getPointer() pointer {
	return pointer{p: *(*unsafe.Pointer)(p.p)}
}
source: func (s policyRules) JSON() string {
	policyJSONBytes, e := json.MarshalIndent(s, "", " ")
	fatalIf(probe.NewError(e), "Unable to marshal into JSON.")
	return string(policyJSONBytes)
}
source: func (m *DefaultScriptSourceManager) Add(s ScriptHandler) {
	if len(m.sources) == 0 {
		m.sources = []ScriptHandler{}
	}
	m.sources = append(m.sources, s)
}
source: func (r *Release) Delete(name string) error {
	ok, err := r.canDelete(name)
	if !ok {
		if err != nil {
			return err
		}
		return nil
	}

	_, err = r.HelmClient.DeleteRelease(name, k8shelm.DeletePurge(true))
	if err != nil {
		r.logger.Log("error", fmt.Sprintf("Release deletion error: %#v", err))
		return err
	}
	r.logger.Log("info", fmt.Sprintf("Release deleted: [%s]", name))
	return nil
}
source: func Default(devMode ...bool) *Logger {
	if len(devMode) > 0 && devMode[0] {
		std.SetLogConsume(developmentConsume)
	}
	return std
}
source: func NewUI(config Config) (*UI, error) {
	translateFunc, err := GetTranslationFunc(config)
	if err != nil {
		return nil, err
	}

	location := time.Now().Location()

	return &UI{
		In:               os.Stdin,
		Out:              color.Output,
		OutForInteration: os.Stdout,
		Err:              os.Stderr,
		colorEnabled:     config.ColorEnabled(),
		translate:        translateFunc,
		terminalLock:     &sync.Mutex{},
		Exiter:           realExiter,
		fileLock:         &sync.Mutex{},
		Interactor:       realInteract,
		IsTTY:            config.IsTTY(),
		TerminalWidth:    config.TerminalWidth(),
		TimezoneLocation: location,
	}, nil
}
source: func NewUDPTransport(hostPort string, maxPacketSize int) (Transport, error) {
	if len(hostPort) == 0 {
		hostPort = fmt.Sprintf("%s:%d", DefaultUDPSpanServerHost, DefaultUDPSpanServerPort)
	}
	if maxPacketSize == 0 {
		maxPacketSize = utils.UDPPacketMaxLength
	}

	protocolFactory := thrift.NewTCompactProtocolFactory()

	// Each span is first written to thriftBuffer to determine its size in bytes.
	thriftBuffer := thrift.NewTMemoryBufferLen(maxPacketSize)
	thriftProtocol := protocolFactory.GetProtocol(thriftBuffer)

	client, err := utils.NewAgentClientUDP(hostPort, maxPacketSize)
	if err != nil {
		return nil, err
	}

	sender := &udpSender{
		client:         client,
		maxSpanBytes:   maxPacketSize - emitBatchOverhead,
		thriftBuffer:   thriftBuffer,
		thriftProtocol: thriftProtocol}
	return sender, nil
}
source: func (m *RemoteReleaseModule) Update(current, target *release.Release, req *services.UpdateReleaseRequest, env *environment.Environment) error {
	upgrade := &rudderAPI.UpgradeReleaseRequest{
		Current:  current,
		Target:   target,
		Recreate: req.Recreate,
		Timeout:  req.Timeout,
		Wait:     req.Wait,
		Force:    req.Force,
	}
	_, err := rudder.UpgradeRelease(upgrade)
	return err
}
source: func (l *Logger) Fatal(format string, v ...interface{}) {
	l.output(LFatal, format, v...)
}
source: func (d *DefaultMetricCollector) Reset() {
	d.mutex.Lock()
	defer d.mutex.Unlock()

	d.numRequests = rolling.NewNumber()
	d.errors = rolling.NewNumber()
	d.successes = rolling.NewNumber()
	d.rejects = rolling.NewNumber()
	d.shortCircuits = rolling.NewNumber()
	d.failures = rolling.NewNumber()
	d.timeouts = rolling.NewNumber()
	d.fallbackSuccesses = rolling.NewNumber()
	d.fallbackFailures = rolling.NewNumber()
	d.contextCanceled = rolling.NewNumber()
	d.contextDeadlineExceeded = rolling.NewNumber()
	d.totalDuration = rolling.NewTiming()
	d.runDuration = rolling.NewTiming()
}
source: func (ref Ref) Append(term *Term) Ref {
	n := len(ref)
	dst := make(Ref, n+1)
	copy(dst, ref)
	dst[n] = term
	return dst
}
source: func (v *InstancesView) RemoveClassAttribute(a Attribute) error {
	v.classAttrs[a] = false
	return nil
}
source: func (g *Graph) TopologicalSort() []Node {
	if g.Kind == Undirected {
		return nil
	}
	// init states
	for i := range g.nodes {
		g.nodes[i].state = unseen
	}
	sorted := make([]Node, 0, len(g.nodes))
	// sort preorder (first jacket, then shirt)
	for _, node := range g.nodes {
		if node.state == unseen {
			g.dfs(node, &sorted)
		}
	}
	// now make post order for correct sort (jacket follows shirt). O(V)
	length := len(sorted)
	for i := 0; i < length/2; i++ {
		sorted[i], sorted[length-i-1] = sorted[length-i-1], sorted[i]
	}
	return sorted
}
source: func (ig *InstanceIdGetter) InstanceId(args params.Entities) (params.StringResults, error) {
	result := params.StringResults{
		Results: make([]params.StringResult, len(args.Entities)),
	}
	canRead, err := ig.getCanRead()
	if err != nil {
		return result, err
	}
	for i, entity := range args.Entities {
		tag, err := names.ParseTag(entity.Tag)
		if err != nil {
			result.Results[i].Error = ServerError(ErrPerm)
			continue
		}
		err = ErrPerm
		if canRead(tag) {
			var instanceId instance.Id
			instanceId, err = ig.getInstanceId(tag)
			if err == nil {
				result.Results[i].Result = string(instanceId)
			}
		}
		result.Results[i].Error = ServerError(err)
	}
	return result, nil
}
source: func ReadHtmOrFail(fn string) (t *template.Template) {
	var err error
	t, err = ReadHtm(fn)
	if err != nil {
		log.Printf("ERROR: %v\n", err.Error())
		log.Fatalf("ERROR: %v\n", err.Error())
	}
	return
}
source: func (e *AutoscalingGroup) CheckChanges(a, ex, changes *AutoscalingGroup) error {
	if a != nil {
		if ex.Name == nil {
			return fi.RequiredField("Name")
		}
	}

	return nil
}
source: func (n *drainingNode) DeadlineTime() (bool, time.Time) {
	n.l.RLock()
	defer n.l.RUnlock()

	// Should never happen
	if n.node == nil || n.node.DrainStrategy == nil {
		return false, time.Time{}
	}

	return n.node.DrainStrategy.DeadlineTime()
}
source: func (k *Key) String() string {
	s := string(k.Format) + " " + base64.StdEncoding.EncodeToString(k.Blob)

	if k.Comment != "" {
		s += " " + k.Comment
	}

	return s
}
source: func (pb *ProgressBar) Write(p []byte) (n int, err error) {
	n = len(p)
	pb.Add(n)
	return
}
source: func (f *File) SetSheetName(oldName, newName string) {
	oldName = trimSheetName(oldName)
	newName = trimSheetName(newName)
	content := f.workbookReader()
	for k, v := range content.Sheets.Sheet {
		if v.Name == oldName {
			content.Sheets.Sheet[k].Name = newName
			f.sheetMap[newName] = f.sheetMap[oldName]
			delete(f.sheetMap, oldName)
		}
	}
}
source: func Uninstall(targets []string, b backend.Backend) error {
	if len(targets) == 1 {
		switch targets[0] {
		case PlatformCommand:
			return UninstallPlatform(b, false)
		case StatelessPlatformCommand:
			return UninstallPlatform(b, true)
		}
	}

	var wg sync.WaitGroup

	// uninstall the specific target
	b.Destroy(targets, &wg, Stdout, Stderr)
	wg.Wait()

	return nil
}
source: func (t *Template) Delims(left, right string) *Template {
	return t.replaceTmpl(t.tmpl.Delims(left, right))
}
source: func (t *Template) GetAllAWSDAXSubnetGroupResources() map[string]*resources.AWSDAXSubnetGroup {
	results := map[string]*resources.AWSDAXSubnetGroup{}
	for name, untyped := range t.Resources {
		switch resource := untyped.(type) {
		case *resources.AWSDAXSubnetGroup:
			results[name] = resource
		}
	}
	return results
}
source: func (rtr *Router) Use(f func(http.ResponseWriter, *http.Request, http.HandlerFunc)) {
	srv := rtr.serveHandler
	rtr.serveHandler = func(rw http.ResponseWriter, req *http.Request) {
		f(rw, req, srv)
	}
}
source: func Marshal(pb Message) ([]byte, error) {
	if m, ok := pb.(newMarshaler); ok {
		siz := m.XXX_Size()
		b := make([]byte, 0, siz)
		return m.XXX_Marshal(b, false)
	}
	if m, ok := pb.(Marshaler); ok {
		// If the message can marshal itself, let it do it, for compatibility.
		// NOTE: This is not efficient.
		return m.Marshal()
	}
	// in case somehow we didn't generate the wrapper
	if pb == nil {
		return nil, ErrNil
	}
	var info InternalMessageInfo
	siz := info.Size(pb)
	b := make([]byte, 0, siz)
	return info.Marshal(b, pb, false)
}
source: func (o *IntOptions) set(name string, value OptionSetting) {
	o.enable(name)
	o.Opts[name] = value
}
source: func (s *DBInstance) SetDbInstancePort(v int64) *DBInstance {
	s.DbInstancePort = &v
	return s
}
source: func (v Value) GoString() string {
	var values []string
	if v.Arch != nil {
		values = append(values, fmt.Sprintf("Arch: %q", *v.Arch))
	}
	if v.CpuCores != nil {
		values = append(values, fmt.Sprintf("Cores: %v", *v.CpuCores))
	}
	if v.CpuPower != nil {
		values = append(values, fmt.Sprintf("CpuPower: %v", *v.CpuPower))
	}
	if v.Mem != nil {
		values = append(values, fmt.Sprintf("Mem: %v", *v.Mem))
	}
	if v.RootDisk != nil {
		values = append(values, fmt.Sprintf("RootDisk: %v", *v.RootDisk))
	}
	if v.InstanceType != nil {
		values = append(values, fmt.Sprintf("InstanceType: %q", *v.InstanceType))
	}
	if v.Container != nil {
		values = append(values, fmt.Sprintf("Container: %q", *v.Container))
	}
	if v.Tags != nil && *v.Tags != nil {
		values = append(values, fmt.Sprintf("Tags: %q", *v.Tags))
	} else if v.Tags != nil {
		values = append(values, "Tags: (*[]string)(nil)")
	}
	if v.Spaces != nil && *v.Spaces != nil {
		values = append(values, fmt.Sprintf("Spaces: %q", *v.Spaces))
	} else if v.Spaces != nil {
		values = append(values, "Spaces: (*[]string)(nil)")
	}
	if v.VirtType != nil {
		values = append(values, fmt.Sprintf("VirtType: %q", *v.VirtType))
	}
	if v.Zones != nil && *v.Zones != nil {
		values = append(values, fmt.Sprintf("Zones: %q", *v.Zones))
	} else if v.Zones != nil {
		values = append(values, "Zones: (*[]string)(nil)")
	}
	return fmt.Sprintf("{%s}", strings.Join(values, ", "))
}
source: func (s *jobLister) Jobs(namespace string) JobNamespaceLister {
	return jobNamespaceLister{indexer: s.indexer, namespace: namespace}
}
source: func (c *Context) Stream(step func(w io.Writer) bool) bool {
	w := c.Writer
	clientGone := w.CloseNotify()
	for {
		select {
		case <-clientGone:
			return true
		default:
			keepOpen := step(w)
			w.Flush()
			if !keepOpen {
				return false
			}
		}
	}
}
source: func (u *Ugen) Expon(val Input) Input {
	return binOpExpon(u.Rate, u, val, u.NumOutputs)
}
source: func NewResponse(query, host string) *Response {
	return &Response{
		Query:     query,
		Host:      host,
		FetchedAt: time.Now().UTC(),
		MediaType: "text/plain",
		Charset:   "utf-8",
	}
}
source: func (Attr *FloatAttribute) Equals(other Attribute) bool {
	// Check whether this FloatAttribute is equal to another
	_, ok := other.(*FloatAttribute)
	if !ok {
		// Not the same type, so can't be equal
		return false
	}
	if Attr.GetName() != other.GetName() {
		return false
	}
	return true
}
source: func Wrap(err error, message ...string) Error {
	var ctx context
	return ctx.Wrap(err, message...)
}
source: func NewBox(pos vect.Vect, w, h vect.Float) *Shape {
	shape := newShape()

	box := &BoxShape{
		Polygon:  &PolygonShape{Shape: shape},
		Width:    w,
		Height:   h,
		Position: pos,
		Shape:    shape,
	}

	hw := w / 2.0
	hh := h / 2.0

	if hw < 0 {
		hw = -hw
	}
	if hh < 0 {
		hh = -hh
	}

	box.verts = [4]vect.Vect{
		{-hw, -hh},
		{-hw, hh},
		{hw, hh},
		{hw, -hh},
	}

	poly := box.Polygon
	poly.SetVerts(box.verts[:], box.Position)

	shape.ShapeClass = box
	return shape
}
source: func ValidateCustomResourceDefinitionNames(names *apiextensions.CustomResourceDefinitionNames, fldPath *field.Path) field.ErrorList {
	allErrs := field.ErrorList{}
	if errs := validationutil.IsDNS1035Label(names.Plural); len(names.Plural) > 0 && len(errs) > 0 {
		allErrs = append(allErrs, field.Invalid(fldPath.Child("plural"), names.Plural, strings.Join(errs, ",")))
	}
	if errs := validationutil.IsDNS1035Label(names.Singular); len(names.Singular) > 0 && len(errs) > 0 {
		allErrs = append(allErrs, field.Invalid(fldPath.Child("singular"), names.Singular, strings.Join(errs, ",")))
	}
	if errs := validationutil.IsDNS1035Label(strings.ToLower(names.Kind)); len(names.Kind) > 0 && len(errs) > 0 {
		allErrs = append(allErrs, field.Invalid(fldPath.Child("kind"), names.Kind, "may have mixed case, but should otherwise match: "+strings.Join(errs, ",")))
	}
	if errs := validationutil.IsDNS1035Label(strings.ToLower(names.ListKind)); len(names.ListKind) > 0 && len(errs) > 0 {
		allErrs = append(allErrs, field.Invalid(fldPath.Child("listKind"), names.ListKind, "may have mixed case, but should otherwise match: "+strings.Join(errs, ",")))
	}

	for i, shortName := range names.ShortNames {
		if errs := validationutil.IsDNS1035Label(shortName); len(errs) > 0 {
			allErrs = append(allErrs, field.Invalid(fldPath.Child("shortNames").Index(i), shortName, strings.Join(errs, ",")))
		}
	}

	// kind and listKind may not be the same or parsing become ambiguous
	if len(names.Kind) > 0 && names.Kind == names.ListKind {
		allErrs = append(allErrs, field.Invalid(fldPath.Child("listKind"), names.ListKind, "kind and listKind may not be the same"))
	}

	for i, category := range names.Categories {
		if errs := validationutil.IsDNS1035Label(category); len(errs) > 0 {
			allErrs = append(allErrs, field.Invalid(fldPath.Child("categories").Index(i), category, strings.Join(errs, ",")))
		}
	}

	return allErrs
}
source: func (c *Container) optimize() {
	if c.n == 0 {
		statsHit("optimize/empty")
		return
	}
	runs := c.countRuns()

	var newType byte
	if runs <= runMaxSize && runs <= c.n/2 {
		newType = containerRun
	} else if c.n < ArrayMaxSize {
		newType = containerArray
	} else {
		newType = containerBitmap
	}

	// Then convert accordingly.
	if c.isArray() {
		if newType == containerBitmap {
			statsHit("optimize/arrayToBitmap")
			c.arrayToBitmap()
		} else if newType == containerRun {
			statsHit("optimize/arrayToRun")
			c.arrayToRun(runs)
		} else {
			statsHit("optimize/arrayUnchanged")
		}
	} else if c.isBitmap() {
		if newType == containerArray {
			statsHit("optimize/bitmapToArray")
			c.bitmapToArray()
		} else if newType == containerRun {
			statsHit("optimize/bitmapToRun")
			c.bitmapToRun(runs)
		} else {
			statsHit("optimize/bitmapUnchanged")
		}
	} else if c.isRun() {
		if newType == containerBitmap {
			statsHit("optimize/runToBitmap")
			c.runToBitmap()
		} else if newType == containerArray {
			statsHit("optimize/runToArray")
			c.runToArray()
		} else {
			statsHit("optimize/runUnchanged")
		}
	}
}
source: func HgetString(key string, field int) string {
	c, err := redis.Dial("tcp", GetRedisServer())
	if err != nil {
		panic(err)
	}
	defer c.Close()

	value, err := redis.String(c.Do("HGET", key, field))
	if err != nil {
		fmt.Println("key not found")
	}

	return value
}
source: func (o *ListSubjectConsentSessionsParams) WithContext(ctx context.Context) *ListSubjectConsentSessionsParams {
	o.SetContext(ctx)
	return o
}
source: func Context(ctx context.Context) Option {
	return func(o *Options) {
		o.Context = ctx
	}
}
source: func GetStackOrchestrator(flagValue, contextValue, globalDefault string, stderr io.Writer) (Orchestrator, error) {
	// Check flag
	if o, err := normalize(flagValue); o != orchestratorUnset {
		return o, err
	}
	// Check environment variable
	env := os.Getenv(envVarDockerStackOrchestrator)
	if env == "" && os.Getenv(envVarDockerOrchestrator) != "" {
		fmt.Fprintf(stderr, "WARNING: experimental environment variable %s is set. Please use %s instead\n", envVarDockerOrchestrator, envVarDockerStackOrchestrator)
	}
	if o, err := normalize(env); o != orchestratorUnset {
		return o, err
	}
	if o, err := normalize(contextValue); o != orchestratorUnset {
		return o, err
	}
	if o, err := normalize(globalDefault); o != orchestratorUnset {
		return o, err
	}
	// Nothing set, use default orchestrator
	return defaultOrchestrator, nil
}
source: func Del(id string, params *stripe.CustomerParams) (*stripe.Customer, error) {
	return getC().Del(id, params)
}
source: func (ocfr *OCFReader) SkipThisBlockAndReset() {
	// ??? is it an error to call method unless the reader has had an error
	ocfr.remainingBlockItems = 0
	ocfr.block = ocfr.block[:0]
	ocfr.rerr = nil
}
source: func (w *Watcher) Alive(key string) (bool, error) {
	result := make(chan bool, 1)
	w.sendReq(reqAlive{key, result})
	var alive bool
	select {
	case alive = <-result:
	case <-w.tomb.Dying():
		return false, errors.Errorf("cannot check liveness: watcher is dying")
	}
	logger.Tracef("[%s] Alive(%q) -> %v", w.modelUUID[:6], key, alive)
	return alive, nil
}
source: func loadPrefDefaults(ctx *cli.Context) error {
	p, err := prefs.NewPreferences()
	if err != nil {
		return err
	}

	return reflectArgs(ctx, p, p.Defaults, "ini")
}
source: func (os *OpenStack) FindSnapshot(tags map[string]string) ([]string, []string, error) {
	var snapshotIDs, statuses []string
	ss, err := os.snapshotService()
	if err != nil || ss == nil {
		glog.Errorf("Unable to initialize cinder client for region: %s", os.region)
		return snapshotIDs, statuses, fmt.Errorf("Failed to find snapshot by tags %v: %v", tags, err)
	}

	opts := SnapshotListOpts{}
	snapshots, err := ss.listSnapshots(opts)

	if err != nil {
		glog.Errorf("Failed to list snapshots. Error: %v", err)
		return snapshotIDs, statuses, err
	}
	glog.Infof("Listed [%v] snapshots.", len(snapshots))

	glog.Infof("Looking for matching tags [%#v] in snapshots.", tags)
	// Loop around to find the snapshot with the matching input metadata
	// NOTE(xyang): Metadata based filtering for snapshots is supported by Cinder volume API
	// microversion 3.21 and above. Currently the OpenStack Cloud Provider only supports V2.0.
	// Revisit this later when V3.0 is supported.
	for _, snapshot := range snapshots {
		glog.Infof("Looking for matching tags in snapshot [%#v].", snapshot)
		namespaceVal, ok := snapshot.Metadata[ctrlsnap.CloudSnapshotCreatedForVolumeSnapshotNamespaceTag]
		if ok {
			if tags[ctrlsnap.CloudSnapshotCreatedForVolumeSnapshotNamespaceTag] == namespaceVal {
				nameVal, ok := snapshot.Metadata[ctrlsnap.CloudSnapshotCreatedForVolumeSnapshotNameTag]
				if ok {
					if tags[ctrlsnap.CloudSnapshotCreatedForVolumeSnapshotNameTag] == nameVal {
						uidVal, ok := snapshot.Metadata[ctrlsnap.CloudSnapshotCreatedForVolumeSnapshotUIDTag]
						if ok {
							if tags[ctrlsnap.CloudSnapshotCreatedForVolumeSnapshotUIDTag] == uidVal {
								timeVal, ok := snapshot.Metadata[ctrlsnap.CloudSnapshotCreatedForVolumeSnapshotTimestampTag]
								if ok {
									if tags[ctrlsnap.CloudSnapshotCreatedForVolumeSnapshotTimestampTag] == timeVal {
										snapshotIDs = append(snapshotIDs, snapshot.ID)
										statuses = append(statuses, snapshot.Status)
										glog.Infof("Add snapshot [%#v].", snapshot)
									}
								}
							}
						}

					}
				}
			}
		}
	}

	return snapshotIDs, statuses, nil
} 40%|████      | 2014/5000 [00:02<00:02, 1098.52it/s]
source: func (in *ImagePolicyConfig) DeepCopy() *ImagePolicyConfig {
	if in == nil {
		return nil
	}
	out := new(ImagePolicyConfig)
	in.DeepCopyInto(out)
	return out
}
source: func runForAllModelStates(pool *StatePool, runner func(st *State) error) error {
	st := pool.SystemState()
	models, closer := st.db().GetCollection(modelsC)
	defer closer()

	var modelDocs []bson.M
	err := models.Find(nil).Select(bson.M{"_id": 1}).All(&modelDocs)
	if err != nil {
		return errors.Annotate(err, "failed to read models")
	}

	for _, modelDoc := range modelDocs {
		modelUUID := modelDoc["_id"].(string)
		model, err := pool.Get(modelUUID)
		if err != nil {
			return errors.Annotatef(err, "failed to open model %q", modelUUID)
		}
		defer func() {
			model.Release()
		}()
		if err := runner(model.State); err != nil {
			return errors.Annotatef(err, "model UUID %q", modelUUID)
		}
	}
	return nil
}
source: func Subtract(left interface{}, right interface{}) interface{} {
	var rleft, rright int64
	var fleft, fright float64
	var isInt bool = true
	switch left.(type) {
	case int:
		rleft = int64(left.(int))
	case int8:
		rleft = int64(left.(int8))
	case int16:
		rleft = int64(left.(int16))
	case int32:
		rleft = int64(left.(int32))
	case int64:
		rleft = left.(int64)
	case float32:
		fleft = float64(left.(float32))
		isInt = false
	case float64:
		fleft = left.(float64)
		isInt = false
	}

	switch right.(type) {
	case int:
		rright = int64(right.(int))
	case int8:
		rright = int64(right.(int8))
	case int16:
		rright = int64(right.(int16))
	case int32:
		rright = int64(right.(int32))
	case int64:
		rright = right.(int64)
	case float32:
		fright = float64(left.(float32))
		isInt = false
	case float64:
		fleft = left.(float64)
		isInt = false
	}

	if isInt {
		return rleft - rright
	} else {
		return fleft + float64(rleft) - (fright + float64(rright))
	}
}
source: func (co *Context) SpatialTfSamplerBackward(stDesc *SpatialTransformer, alpha float64, xDesc *TensorDescriptor, x Memory, beta float64, dxDesc *TensorDescriptor, dx Memory, alphaDgrid Memory, dyDesc *TensorDescriptor, dy Memory, grid Memory, betaDgrid Memory, dgrid Memory) error {
	// DOUBLECHECK: "cudnnSpatialTfSamplerBackward" returns Memory type in Parameter 13
	var alphaC, betaC unsafe.Pointer
	switch xDesc.dataType {
	case Float, Half:
		var alphaF, betaF C.float
		alphaF = C.float(float32(alpha))
		betaF = C.float(float32(beta))
		alphaC = unsafe.Pointer(&alphaF)
		betaC = unsafe.Pointer(&betaF)
	case Double:
		var alphaF, betaF C.double
		alphaF = C.double(alpha)
		betaF = C.double(beta)
		alphaC = unsafe.Pointer(&alphaF)
		betaC = unsafe.Pointer(&betaF)
	default:
		return errors.Errorf("Unsupported data type: %v", xDesc.dataType)
	}
	// call cudnnSpatialTfSamplerBackward
	return result(C.cudnnSpatialTfSamplerBackward(co.internal, stDesc.internal, alphaC, xDesc.internal, x.Pointer(), betaC, dxDesc.internal, dx.Pointer(), alphaDgrid.Pointer(), dyDesc.internal, dy.Pointer(), grid.Pointer(), betaDgrid.Pointer(), dgrid.Pointer()))
}
source: func (h *SessionHandle) GetAllBindRecord() (bindRecords []*BindMeta) {
	for _, bindRecord := range h.ch {
		bindRecords = append(bindRecords, bindRecord...)
	}
	return bindRecords
}
source: func (s *PortSpec) IsIncluded(port int) bool {
	p := uint16(port)
	if s.Min <= p && p <= s.Max {
		return true
	}
	return false
}
source: func (s *State) Resource(addr addrs.AbsResource) *Resource {
	ms := s.Module(addr.Module)
	if ms == nil {
		return nil
	}
	return ms.Resource(addr.Resource)
}
source: func (s *Latency) SetP85(v float64) *Latency {
	s.P85 = &v
	return s
}
source: func toSchemaHref(api *design.APIDefinition, r *design.RouteDefinition) string {
	params := r.Params()
	args := make([]interface{}, len(params))
	for i, p := range params {
		args[i] = fmt.Sprintf("/{%s}", p)
	}
	tmpl := design.WildcardRegex.ReplaceAllLiteralString(r.FullPath(), "%s")
	return fmt.Sprintf(tmpl, args...)
}
source: func (fbo *folderBlockOps) GetDirtyDirBlockRefs(
	lState *kbfssync.LockState) []data.BlockRef {
	fbo.blockLock.RLock(lState)
	defer fbo.blockLock.RUnlock(lState)
	var dirtyRefs []data.BlockRef
	for ptr := range fbo.dirtyDirs {
		dirtyRefs = append(dirtyRefs, ptr.Ref())
	}
	return dirtyRefs
}
source: func (s *AuthServer) initializeTOTP(accountName string) (key string, qr []byte, err error) {
	// create totp key
	otpKey, err := totp.Generate(totp.GenerateOpts{
		Issuer:      "Teleport",
		AccountName: accountName,
	})
	if err != nil {
		return "", nil, trace.Wrap(err)
	}

	// create QR code
	var otpQRBuf bytes.Buffer
	otpImage, err := otpKey.Image(456, 456)
	if err != nil {
		return "", nil, trace.Wrap(err)
	}
	png.Encode(&otpQRBuf, otpImage)

	return otpKey.Secret(), otpQRBuf.Bytes(), nil
}
source: func (s *Semaphore) Release() {
	s.rMutex.Lock()
	defer s.rMutex.Unlock()

	s.channel <- struct{}{}

	s.pMutex.Lock()
	s.avail++
	s.pMutex.Unlock()
}
source: func (s *Section) Keys() []string {
	keys := make([]string, len(s.keys))
	for i, k := range s.keys {
		keys[i] = s.file.KeyManipFunc(k)
	}

	return keys
}
source: func GodoClientToken(ctxt context.Context, token string) Option {
	return func(c *Client) error {
		return GodoClient(godo.NewClient(oauth2.NewClient(
			ctxt,
			oauth2.StaticTokenSource(
				&oauth2.Token{
					AccessToken: token,
				},
			),
		)))(c)
	}
}
source: func (cache *Cache) SetInt(key int64, value []byte, expireSeconds int) (err error) {
	var bKey [8]byte
	binary.LittleEndian.PutUint64(bKey[:], uint64(key))
	return cache.Set(bKey[:], value, expireSeconds)
}
source: func Convert_kops_OpenstackRouter_To_v1alpha1_OpenstackRouter(in *kops.OpenstackRouter, out *OpenstackRouter, s conversion.Scope) error {
	return autoConvert_kops_OpenstackRouter_To_v1alpha1_OpenstackRouter(in, out, s)
}
source: func (m *PerformanceQueryImpl) Open() error {
	if m.query != 0 {
		err := m.Close()
		if err != nil {
			return err
		}
	}
	var handle PDH_HQUERY

	if ret := PdhOpenQuery(0, 0, &handle); ret != ERROR_SUCCESS {
		return NewPdhError(ret)
	}
	m.query = handle
	return nil
}
source: func (m *Graphobject) Validate(formats strfmt.Registry) error {
	var res []error

	if err := m.validateNode(formats); err != nil {
		// prop
		res = append(res, err)
	}

	if len(res) > 0 {
		return errors.CompositeValidationError(res...)
	}
	return nil
}
source: func newISO88591CharsetReader(reader io.Reader) *iso88591CharsetReader {
	buffer := bytes.NewBuffer(make([]byte, 0, utf8.UTFMax))
	return &iso88591CharsetReader{reader.(io.ByteReader), buffer}
}
source: func (v *version) ClusterRoles() ClusterRoleInformer {
	return &clusterRoleInformer{factory: v.factory, tweakListOptions: v.tweakListOptions}
}
source: func (a *netAPI) HashLookup(ctx context.Context, req *pb.FindFullHashesRequest) (*pb.FindFullHashesResponse, error) {
	resp := new(pb.FindFullHashesResponse)
	return resp, a.doRequest(ctx, findHashPath, req, resp)
}
source: func (s *ContainerSettings) SetF4vSettings(v *F4vSettings) *ContainerSettings {
	s.F4vSettings = v
	return s
}
source: func New() *Validate {

	tc := new(tagCache)
	tc.m.Store(make(map[string]*cTag))

	sc := new(structCache)
	sc.m.Store(make(map[reflect.Type]*cStruct))

	v := &Validate{
		tagName:     defaultTagName,
		aliases:     make(map[string]string, len(bakedInAliases)),
		validations: make(map[string]FuncCtx, len(bakedInValidators)),
		tagCache:    tc,
		structCache: sc,
	}

	// must copy alias validators for separate validations to be used in each validator instance
	for k, val := range bakedInAliases {
		v.RegisterAlias(k, val)
	}

	// must copy validators for separate validations to be used in each instance
	for k, val := range bakedInValidators {

		// no need to error check here, baked in will always be valid
		_ = v.registerValidation(k, wrapFunc(val), true)
	}

	v.pool = &sync.Pool{
		New: func() interface{} {
			return &validate{
				v:        v,
				ns:       make([]byte, 0, 64),
				actualNs: make([]byte, 0, 64),
				misc:     make([]byte, 32),
			}
		},
	}

	return v
}
source: func (s *IdentityService) GetSignupToken(token string) (*services.SignupToken, error) {
	if token == "" {
		return nil, trace.BadParameter("missing token")
	}
	item, err := s.Get(context.TODO(), backend.Key(userTokensPrefix, token))
	if err != nil {
		return nil, trace.Wrap(err)
	}
	var signupToken services.SignupToken
	err = json.Unmarshal(item.Value, &signupToken)
	if err != nil {
		return nil, trace.Wrap(err)
	}
	return &signupToken, nil
}
source: func (r *realisClient) RestartJob(key *aurora.JobKey) (*aurora.Response, error) {

	instanceIds, err1 := r.GetInstanceIds(key, aurora.ACTIVE_STATES)
	if err1 != nil {
		return nil, errors.Wrap(err1, "Could not retrieve relevant task instance IDs")
	}

	r.logger.DebugPrintf("RestartShards Thrift Payload: %+v %v\n", key, instanceIds)

	if len(instanceIds) > 0 {
		resp, retryErr := r.thriftCallWithRetries(func() (*aurora.Response, error) {
			return r.client.RestartShards(nil, key, instanceIds)
		})

		if retryErr != nil {
			return nil, errors.Wrap(retryErr, "Error sending Restart command to Aurora Scheduler")
		}

		return resp, nil
	} else {
		return nil, errors.New("No tasks in the Active state")
	}
}
source: func (pp *TxPreparedPool) Forget(dtid string) {
	pp.mu.Lock()
	defer pp.mu.Unlock()
	delete(pp.reserved, dtid)
}
source: func stripUserPrefix(s []string) []string {
	for i, a := range s {
		if strings.HasPrefix(a, userPrefix) {
			s[i] = a[5:]
		}
	}
	return s
}
source: func (in *JoinConfiguration) DeepCopy() *JoinConfiguration {
	if in == nil {
		return nil
	}
	out := new(JoinConfiguration)
	in.DeepCopyInto(out)
	return out
}
source: func (s *DbSession) Collection(d Document) *mgo.Collection {
	return s.Session.DB(s.db.Config.DBName).C(d.CollectionName())
}
source: func MaxResponseBodyBytes(m int64) optSetter {
	return func(b *Buffer) error {
		if m < 0 {
			return fmt.Errorf("max bytes should be >= 0 got %d", m)
		}
		b.maxResponseBodyBytes = m
		return nil
	}
}
source: func (p *BlockPrefetchClient) storeNext(msgBlock *wire.MsgBlock, headerResult *dcrjson.GetBlockHeaderVerboseResult) {
	p.current = p.next
	p.next = &blockData{
		height:       msgBlock.Header.Height,
		hash:         msgBlock.BlockHash(),
		msgBlock:     msgBlock,
		headerResult: headerResult,
	}
}
source: func NewTemplate() *Template {
	return &Template{
		Conditions: make(map[string]interface{}),
		Outputs:    make(map[string]Output),
		Parameters: make(map[string]Parameter),
		Resources:  make(map[string]Resource),
	}
}
source: func (c Context) MACAddr(key string, ha net.HardwareAddr) Context {
	c.l.context = enc.AppendMACAddr(enc.AppendKey(c.l.context, key), ha)
	return c
}
source: func NewDriver(url string) (Driver, error) {

	if url == "" {
		url = client.DefaultSockPath()
	}

	scopedLog := log.WithField("url", url)
	c, err := client.NewClient(url)
	if err != nil {
		scopedLog.WithError(err).Fatal("Error while starting cilium-client")
	}

	d := &driver{client: c}

	for tries := 0; tries < 24; tries++ {
		if res, err := c.ConfigGet(); err != nil {
			if tries == 23 {
				scopedLog.WithError(err).Fatal("Unable to connect to cilium daemon")
			} else {
				scopedLog.Info("Waiting for cilium daemon to start up...")
			}
			time.Sleep(time.Duration(tries) * time.Second)
		} else {
			if res.Status.Addressing == nil || (res.Status.Addressing.IPV4 == nil && res.Status.Addressing.IPV6 == nil) {
				scopedLog.Fatal("Invalid addressing information from daemon")
			}

			d.conf = *res.Status
			break
		}
	}

	if err := connector.SufficientAddressing(d.conf.Addressing); err != nil {
		scopedLog.WithError(err).Fatal("Insufficient addressing")
	}

	d.updateRoutes(nil)

	log.Infof("Cilium Docker plugin ready")

	return d, nil
}
source: func (i *InvoiceRegistry) dispatchToSingleClients(event *invoiceEvent) {
	// Dispatch to single invoice subscribers.
	for _, client := range i.singleNotificationClients {
		if client.hash != event.hash {
			continue
		}

		select {
		case client.ntfnQueue.ChanIn() <- &invoiceEvent{
			state:   event.state,
			invoice: event.invoice,
		}:
		case <-i.quit:
			return
		}
	}
}
source: func (t *Template) GetAWSDocDBDBClusterParameterGroupWithName(name string) (*resources.AWSDocDBDBClusterParameterGroup, error) {
	if untyped, ok := t.Resources[name]; ok {
		switch resource := untyped.(type) {
		case *resources.AWSDocDBDBClusterParameterGroup:
			return resource, nil
		}
	}
	return nil, fmt.Errorf("resource %q of type AWSDocDBDBClusterParameterGroup not found", name)
}
source: func Md5(data []byte) string {
	md5 := md5.New()
	md5.Write(data)
	return hex.EncodeToString(md5.Sum(nil))
}
source: func (m ComponentMatches) Inexact() ComponentMatches {
	inexact := ComponentMatches{}
	for _, match := range m {
		if !match.Exact() {
			inexact = append(inexact, match)
		}
	}
	return inexact
}
source: func Run(t crossdock.T) {
	fatals := crossdock.Fatals(t)

	server := t.Param(params.Server)
	fatals.NotEmpty(server, "server is required")

	dispatcher := yarpc.NewDispatcher(yarpc.Config{
		Name: "client",
		Outbounds: yarpc.Outbounds{
			"yarpc-test": {
				Unary: grpc.NewTransport().NewSingleOutbound(fmt.Sprintf("%s:8090", server)),
			},
		},
	})
	fatals.NoError(dispatcher.Start(), "could not start Dispatcher")
	defer dispatcher.Stop()

	client := crossdockpb.NewEchoYARPCClient(dispatcher.ClientConfig("yarpc-test"))

	ctx, cancel := context.WithTimeout(context.Background(), time.Second)
	defer cancel()

	token := random.String(5)

	pong, err := client.Echo(ctx, &crossdockpb.Ping{Beep: token})

	crossdock.Fatals(t).NoError(err, "call to Echo::echo failed: %v", err)
	crossdock.Assert(t).Equal(token, pong.Boop, "server said: %v", pong.Boop)
}
source: func (s *ProxyQueryService) Query(ctx context.Context, w io.Writer, req *query.ProxyRequest) (int64, error) {
	if req != nil {
		s.Logger.Info("query", zap.Any("request", req))
	}
	n, err := w.Write([]byte{})
	return int64(n), err
}
source: func (s *IspPlacement) SetPlacementStatistics(v *PlacementStatistics) *IspPlacement {
	s.PlacementStatistics = v
	return s
}
source: func (b *Bucket) GetAndLock(key string, lockTime uint32, valuePtr interface{}) (Cas, error) {
	return b.getAndLock(key, lockTime, valuePtr)
}
source: func mutateTimersList(blob *[]byte, cb func(*[]*internal.Timer)) error {
	list, err := unmarshalTimersList(*blob)
	if err != nil {
		return err
	}
	cb(&list)
	*blob = marshalTimersList(list)
	return nil
}
source: func NewLoopDeviceManager() LoopDeviceManager {
	run := func(cmd string, args ...string) (string, error) {
		out, err := exec.Command(cmd, args...).CombinedOutput()
		out = bytes.TrimSpace(out)
		if err != nil {
			if len(out) > 0 {
				err = errors.Annotatef(err, "failed with %q", out)
			}
			return "", err
		}
		return string(out), nil
	}
	return &loopDeviceManager{run, os.Stat, fileInode}
}
source: func (a *Application) FatalUsage(format string, args ...interface{}) {
	a.Errorf(format, args...)
	// Force usage to go to error output.
	a.usageWriter = a.errorWriter
	a.Usage([]string{})
	a.terminate(1)
}
source: func printDecoderPass(p *Prog, pc int, printing bool, ops map[string]bool) int {
	// Record PC on first pass.
	if p.PC == 0 {
		p.PC = pc
	}

	// If PC doesn't match, we've already printed this code
	// because it was reached some other way. Jump to that copy.
	if p.PC != pc {
		if printing {
			fmt.Printf("/*%d*/\tuint16(xJump), %d,\n", pc, p.PC)
		}
		return pc + 2
	}

	// Otherwise, emit the code for the given action.

	// At the bottom, if next is non-nil, emit code for next.
	// Then emit the code for the children named by the keys.
	keys := p.keys()
	var next *Prog

	switch p.Action {
	default:
		log.Printf("printDecoderPass: unknown action %q: %s", p.Action, p.Path)

	case "decode":
		// Decode hex bytes or /n modrm op checks.
		// Hex bytes take priority, so do them first.
		// Hex bytes of the form "40+" indicate an
		// 8 entry-wide swath of codes: 40, 41, ..., 47.
		hex := 0
		slash := 0
		for _, key := range keys {
			if isHex(key) {
				if strings.Contains(key, "+") {
					hex += 8
				} else {
					hex++
				}
			}
			if isSlashNum(key) {
				slash++
			}
		}
		if hex > 0 {
			// TODO(rsc): Introduce an xCondByte256 that has 256 child entries
			// and no explicit keys. That will cut the size in half for large
			// tables.
			if printing {
				fmt.Printf("/*%d*/\tuint16(xCondByte), %d,\n", pc, hex)
				for _, key := range keys {
					if !isHex(key) {
						continue
					}
					if i := strings.Index(key, "+"); i >= 0 {
						nextPC := p.Child[key].PC
						n, _ := strconv.ParseUint(key[:i], 16, 0)
						for j := 0; j < 8; j++ {
							fmt.Printf("\t%#02x, %d,\n", int(n)+j, nextPC)
						}
						continue
					}
					fmt.Printf("\t0x%s, %d,\n", key, p.Child[key].PC)
				}
			}
			pc += 2 + 2*hex

			// All other condition checks fail the decoding if nothing is found,
			// but this one falls through so that we can then do /n checks.
			// If there are no upcoming /n checks, insert an explicit failure.
			if slash == 0 {
				if printing {
					fmt.Printf("\tuint16(xFail),\n")
				}
				pc++
			}
		}
		if slash > 0 {
			if printing {
				fmt.Printf("/*%d*/\tuint16(xCondSlashR),\n", pc)
				for i := 0; i < 8; i++ {
					fmt.Printf("\t%d, // %d\n", p.childPC(fmt.Sprintf("/%d", i)), i)
				}
			}
			pc += 1 + 8
		}

	case "is64":
		// Decode based on processor mode: 64-bit or not.
		if len(keys) == 1 && keys[0] == "any" {
			next = p.Child["any"]
			break
		}
		if p.Child["any"] != nil {
			log.Printf("%s: mixed is64 keys: %v", p.Path, keys)
		}

		if printing {
			fmt.Printf("/*%d*/\tuint16(xCondIs64), %d, %d,\n", pc, p.childPC("0"), p.childPC("1"))
		}
		pc += 3

	case "prefix":
		// Decode based on presence of prefix.
		// The "0" prefix means "none of the above", so if there's
		// nothing else, it's the same as "any".
		if len(keys) == 1 && (keys[0] == "any" || keys[0] == "0") {
			next = p.Child["any"]
			break
		}
		if p.Child["any"] != nil {
			log.Printf("%s: mixed prefix keys: %v", p.Path, keys)
		}

		// Emit the prefixes in reverse sorted order, so that F3 and F2 are
		// considered before 66, and the fallback 0 is considered last.
		if printing {
			fmt.Printf("/*%d*/\tuint16(xCondPrefix), %d,\n", pc, len(keys))
			for i := len(keys) - 1; i >= 0; i-- {
				key := keys[i]
				nextPC := p.Child[key].PC
				fmt.Printf("\t0x%s, %d,\n", key, nextPC)
			}
		}
		pc += 2 + 2*len(keys)

	case "addrsize":
		// Decode based on address size attribute.
		if len(keys) == 1 && keys[0] == "any" {
			next = p.Child["any"]
			break
		}
		if p.Child["any"] != nil {
			log.Printf("%s: mixed addrsize keys: %v", p.Path, keys)
		}

		if printing {
			fmt.Printf("/*%d*/\tuint16(xCondAddrSize), %d, %d, %d,\n", pc, p.childPC("16"), p.childPC("32"), p.childPC("64"))
		}
		pc += 4

	case "datasize":
		// Decode based on operand size attribute.
		if len(keys) == 1 && keys[0] == "any" {
			next = p.Child["any"]
			break
		}
		if p.Child["any"] != nil {
			log.Printf("%s: mixed datasize keys: %v", p.Path, keys)
		}

		if printing {
			fmt.Printf("/*%d*/\tuint16(xCondDataSize), %d, %d, %d,\n", pc, p.childPC("16"), p.childPC("32"), p.childPC("64"))
		}
		pc += 4

	case "ismem":
		// Decode based on modrm form: memory or register reference.
		if len(keys) == 1 && keys[0] == "any" {
			next = p.Child["any"]
			break
		}
		if p.Child["any"] != nil {
			log.Printf("%s: mixed ismem keys: %v", p.Path, keys)
		}

		if printing {
			fmt.Printf("/*%d*/\tuint16(xCondIsMem), %d, %d,\n", pc, p.childPC("0"), p.childPC("1"))
		}
		pc += 3

	case "op":
		// Set opcode.
		ops[keys[0]] = true
		if printing {
			fmt.Printf("/*%d*/\tuint16(xSetOp), uint16(%s),\n", pc, keys[0])
		}
		next = p.Child[keys[0]]
		pc += 2

	case "read":
		// Read argument bytes.
		if printing {
			fmt.Printf("/*%d*/\tuint16(xRead%s),\n", pc, xOp(keys[0]))
		}
		next = p.Child[keys[0]]
		pc++

	case "arg":
		// Record instruction argument (interpret bytes loaded with read).
		if printing {
			fmt.Printf("/*%d*/\tuint16(xArg%s),\n", pc, xOp(keys[0]))
		}
		next = p.Child[keys[0]]
		pc++

	case "match":
		// Finish match.
		if printing {
			fmt.Printf("/*%d*/\tuint16(xMatch),\n", pc)
		}
		pc++
		return pc
	}

	if next != nil {
		pc = printDecoderPass(next, pc, printing, ops)
	}

	for _, key := range keys {
		q := p.Child[key]
		if q.PC == 0 || q.PC == pc {
			pc = printDecoderPass(q, pc, printing, ops)
		}
	}

	return pc
}
source: func (h *Heap) ListKeys() []string {
	h.lock.RLock()
	defer h.lock.RUnlock()
	list := make([]string, 0, len(h.data.items))
	for key := range h.data.items {
		list = append(list, key)
	}
	return list
}
source: func (l *LogFS) Create(ctx context.Context, path string) (io.WriteCloser, error) {
	l.logger.Printf("%v: create: %v", l.name, path)
	wc, err := l.fs.Create(ctx, path)
	if err != nil {
		l.logger.Printf("%v: create error: %v: %v", l.name, path, err)
	}
	return wc, err
}
source: func (c *Fetch) FailRequestWithParams(v *FetchFailRequestParams) (*gcdmessage.ChromeResponse, error) {
	return gcdmessage.SendDefaultRequest(c.target, c.target.GetSendCh(), &gcdmessage.ParamRequest{Id: c.target.GetId(), Method: "Fetch.failRequest", Params: v})
}
source: func PermissionDenied(w http.ResponseWriter, req *http.Request) {
	http.Error(w, "Permission denied.", http.StatusForbidden)
}
source: func newHealFormatSets(refFormat *formatXLV3, setCount, disksPerSet int, formats []*formatXLV3, errs []error) [][]*formatXLV3 {
	newFormats := make([][]*formatXLV3, setCount)
	for i := range refFormat.XL.Sets {
		newFormats[i] = make([]*formatXLV3, disksPerSet)
	}
	for i := range refFormat.XL.Sets {
		for j := range refFormat.XL.Sets[i] {
			if errs[i*disksPerSet+j] == errUnformattedDisk || errs[i*disksPerSet+j] == nil {
				newFormats[i][j] = &formatXLV3{}
				newFormats[i][j].Version = refFormat.Version
				newFormats[i][j].ID = refFormat.ID
				newFormats[i][j].Format = refFormat.Format
				newFormats[i][j].XL.Version = refFormat.XL.Version
				newFormats[i][j].XL.DistributionAlgo = refFormat.XL.DistributionAlgo
			}
			if errs[i*disksPerSet+j] == errUnformattedDisk {
				newFormats[i][j].XL.This = ""
				newFormats[i][j].XL.Sets = nil
				continue
			}
			if errs[i*disksPerSet+j] == nil {
				newFormats[i][j].XL.This = formats[i*disksPerSet+j].XL.This
				newFormats[i][j].XL.Sets = nil
			}
		}
	}
	return newFormats
}
source: func (tc *TransactionContext) Cleanup() {
	//tc.InfoSchema = nil; we cannot do it now, because some operation like handleFieldList depend on this.
	tc.DirtyDB = nil
	tc.Binlog = nil
	tc.History = nil
	tc.TableDeltaMap = nil
}
source: func RecognizedUnitType(name string) bool {
	types := []string{"service", "socket", "timer", "path", "device", "mount", "automount"}
	for _, t := range types {
		suffix := fmt.Sprintf(".%s", t)
		if strings.HasSuffix(name, suffix) {
			return true
		}
	}
	return false
}
source: func (priorityClassStrategy) PrepareForCreate(ctx context.Context, obj runtime.Object) {
	pc := obj.(*scheduling.PriorityClass)
	pc.Generation = 1
}
source: func (s *roleManagementServiceImpl) ListByResource(ctx context.Context, currentIdentity uuid.UUID, resourceID string) ([]rolerepo.IdentityRole, error) {
	err := s.requireViewRolesScope(ctx, currentIdentity, resourceID)
	if err != nil {
		return nil, err
	}

	return s.Repositories().IdentityRoleRepository().FindIdentityRolesByResource(ctx, resourceID, false)
}
source: func WithSchema1Conversion(client *Client, c *RemoteContext) error {
	c.ConvertSchema1 = true
	return nil
}
source: func uint32FromNetwork(u uint32) uint32 {
	b := *(*[4]byte)(unsafe.Pointer(&u))
	return binary.BigEndian.Uint32(b[:])
}
source: func (p *PriorityQueue) SchedulingCycle() int64 {
	p.lock.RLock()
	defer p.lock.RUnlock()
	return p.schedulingCycle
}
source: func (d date) TimeUTC(hour, min, sec, nsec int) time.Time {
	return time.Date(0, 0, 0, hour, min, sec, nsec, time.UTC)
}
source: func PerformStaticPodUpgrade(client clientset.Interface, waiter apiclient.Waiter, internalcfg *kubeadmapi.InitConfiguration, etcdUpgrade, renewCerts bool) error {
	pathManager, err := GetPathManagerForUpgrade(internalcfg, etcdUpgrade)
	if err != nil {
		return err
	}

	// The arguments oldEtcdClient and newEtdClient, are uninitialized because passing in the clients allow for mocking the client during testing
	return upgrade.StaticPodControlPlane(client, waiter, pathManager, internalcfg, etcdUpgrade, renewCerts, nil, nil)
}
source: func (p *fileParser) parsePackage(path string) error {
	var pkgs map[string]*ast.Package
	if imp, err := build.Import(path, p.srcDir, build.FindOnly); err != nil {
		return err
	} else if pkgs, err = parser.ParseDir(p.fileSet, imp.Dir, nil, 0); err != nil {
		return err
	}
	for _, pkg := range pkgs {
		file := ast.MergePackageFiles(pkg, ast.FilterFuncDuplicates|ast.FilterUnassociatedComments|ast.FilterImportDuplicates)
		if _, ok := p.importedInterfaces[path]; !ok {
			p.importedInterfaces[path] = make(map[string]*ast.InterfaceType)
		}
		for ni := range iterInterfaces(file) {
			p.importedInterfaces[path][ni.name.Name] = ni.it
		}
		imports, _ := importsOfFile(file)
		for pkgName, pkgPath := range imports {
			if _, ok := p.imports[pkgName]; !ok {
				p.imports[pkgName] = pkgPath
			}
		}
	}
	return nil
}
source: func (rb *RangeBuilder) Span(bp, ep uint64) *RangeBuilder {
	rb.Ranges = append(rb.Ranges, mesos.Value_Range{Begin: bp, End: ep})
	return rb
}
source: func (h *health) overloaded() {
	timeout := time.Duration(5 * time.Second)
	client := http.Client{
		Timeout: timeout,
	}
	url := "http://" + h.Addr
	tick := time.NewTicker(1 * time.Second)

	for {
		select {
		case <-tick.C:
			start := time.Now()
			resp, err := client.Get(url)
			if err != nil {
				HealthDuration.Observe(timeout.Seconds())
				continue
			}
			resp.Body.Close()
			HealthDuration.Observe(time.Since(start).Seconds())

		case <-h.stop:
			tick.Stop()
			return
		}
	}
}
source: func fetchBuilds(c context.Context, client *bbv1.Service, bid BuilderID,
	status string, limit int, cursor string) ([]*bbv1.ApiCommonBuildMessage, string, error) {

	c, _ = context.WithTimeout(c, bbRPCTimeout)
	search := client.Search()
	search.Context(c)
	search.Bucket(bid.V1Bucket())
	search.Status(status)
	search.Tag(strpair.Format(bbv1.TagBuilder, bid.Builder))
	search.IncludeExperimental(true)
	search.StartCursor(cursor)

	if limit < 0 {
		limit = 100
	}

	start := clock.Now(c)
	msgs, cursor, err := search.Fetch(limit, nil)
	if err != nil {
		return nil, "", err
	}
	logging.Infof(c, "Fetched %d %s builds in %s", len(msgs), status, clock.Since(c, start))
	return msgs, cursor, nil
}
source: func (p *TCompactProtocol) WriteStructEnd() error {
	p.lastFieldId = p.lastField[len(p.lastField)-1]
	p.lastField = p.lastField[:len(p.lastField)-1]
	return nil
}
source: func (blog Blog) JSONAPILinks() *jsonapi.Links {
	return &jsonapi.Links{
		"self": fmt.Sprintf("https://example.com/blogs/%d", blog.ID),
	}
}
source: func (s *EmbeddedSourceSettings) SetScte20Detection(v string) *EmbeddedSourceSettings {
	s.Scte20Detection = &v
	return s
}
source: func (l FrontendList) LooseMatch(frontend loadbalancer.L3n4Addr) (exists bool) {
	switch frontend.Protocol {
	case loadbalancer.NONE:
		for _, protocol := range loadbalancer.AllProtocols {
			frontend.Protocol = protocol
			_, exists = l[frontend.StringWithProtocol()]
			if exists {
				return
			}
		}

	// If the protocol is set, perform an exact match
	default:
		_, exists = l[frontend.StringWithProtocol()]
	}
	return
}
source: func (e ServerError) Error() string {
	if e.Err != nil {
		return e.Err.Error()
	}
	return "ServerError"
}
source: func NewHTMLElementFromSelectionNode(resp *Response, s *goquery.Selection, n *html.Node, idx int) *HTMLElement {
	return &HTMLElement{
		Name:       n.Data,
		Request:    resp.Request,
		Response:   resp,
		Text:       goquery.NewDocumentFromNode(n).Text(),
		DOM:        s,
		Index:      idx,
		attributes: n.Attr,
	}
}
source: func (o *DisconnectUserParams) WithContext(ctx context.Context) *DisconnectUserParams {
	o.SetContext(ctx)
	return o
}
source: func NewHandlerFunc(allow, deny func(http.ResponseWriter, *http.Request), acl ACL) (*HandlerFunc, error) {
	if allow == nil {
		return nil, errors.New("whitelist: allow cannot be nil")
	}

	if acl == nil {
		return nil, errors.New("whitelist: ACL cannot be nil")
	}

	return &HandlerFunc{
		allow:     allow,
		deny:      deny,
		whitelist: acl,
	}, nil
}
source: func filterChains(chains map[utiliptables.Chain]string, filterChains []utiliptables.Chain) {
	for _, chain := range filterChains {
		if _, ok := chains[chain]; ok {
			delete(chains, chain)
		}
	}
}
source: func IsTypeVarchar(tp byte) bool {
	return tp == mysql.TypeVarString || tp == mysql.TypeVarchar
}
source: func CheckCompatible(s1 FixedDataGrid, s2 FixedDataGrid) []Attribute {
	s1Attrs := s1.AllAttributes()
	s2Attrs := s2.AllAttributes()
	interAttrs := AttributeIntersect(s1Attrs, s2Attrs)
	if len(interAttrs) != len(s1Attrs) {
		return nil
	} else if len(interAttrs) != len(s2Attrs) {
		return nil
	}
	return interAttrs
}
source: func (dv *DynamicVerifier) updateToHeight(h int64) (FullCommit, error) {

	// Fetch latest full commit from source.
	sourceFC, err := dv.source.LatestFullCommit(dv.chainID, h, h)
	if err != nil {
		return FullCommit{}, err
	}

	// If sourceFC.Height() != h, we can't do it.
	if sourceFC.Height() != h {
		return FullCommit{}, lerr.ErrCommitNotFound()
	}

	// Validate the full commit.  This checks the cryptographic
	// signatures of Commit against Validators.
	if err := sourceFC.ValidateFull(dv.chainID); err != nil {
		return FullCommit{}, err
	}

	// Verify latest FullCommit against trusted FullCommits
FOR_LOOP:
	for {
		// Fetch latest full commit from trusted.
		trustedFC, err := dv.trusted.LatestFullCommit(dv.chainID, 1, h)
		if err != nil {
			return FullCommit{}, err
		}
		// We have nothing to do.
		if trustedFC.Height() == h {
			return trustedFC, nil
		}

		// Try to update to full commit with checks.
		err = dv.verifyAndSave(trustedFC, sourceFC)
		if err == nil {
			// All good!
			return sourceFC, nil
		}

		// Handle special case when err is ErrTooMuchChange.
		if types.IsErrTooMuchChange(err) {
			// Divide and conquer.
			start, end := trustedFC.Height(), sourceFC.Height()
			if !(start < end) {
				panic("should not happen")
			}
			mid := (start + end) / 2
			_, err = dv.updateToHeight(mid)
			if err != nil {
				return FullCommit{}, err
			}
			// If we made it to mid, we retry.
			continue FOR_LOOP
		}
		return FullCommit{}, err
	}
}
source: func GetHostPartIP(ip net.IP, mask net.IPMask) (net.IP, error) {
	// Find the effective starting of address and mask
	is, ms, err := compareIPMask(ip, mask)
	if err != nil {
		return nil, fmt.Errorf("cannot compute host portion ip address because %s", err)
	}

	// Compute host portion
	out := GetIPCopy(ip)
	for i := 0; i < len(mask[ms:]); i++ {
		out[is+i] &= ^mask[ms+i]
	}

	return out, nil
}
source: func Cancel(username string, password string, yes bool) error {
	c, err := client.New()

	if err != nil {
		return err
	}

	if username == "" || password != "" {
		fmt.Println("Please log in again in order to cancel this account")

		if err = Login(c.ControllerURL.String(), username, password, c.SSLVerify); err != nil {
			return err
		}
	}

	if yes == false {
		confirm := ""

		c, err = client.New()

		if err != nil {
			return err
		}

		deletedUser := username

		if deletedUser == "" {
			deletedUser = c.Username
		}

		fmt.Printf("cancel account %s at %s? (y/N): ", deletedUser, c.ControllerURL.String())
		fmt.Scanln(&confirm)

		if strings.ToLower(confirm) == "y" {
			yes = true
		}
	}

	if yes == false {
		fmt.Fprintln(os.Stderr, "Account not changed")
		return nil
	}

	err = auth.Delete(c, username)

	cleanup := fmt.Errorf("\n%s %s\n\n", "409", "Conflict")
	if reflect.DeepEqual(err, cleanup) {
		fmt.Printf("%s still has application associated with it. Transfer ownership or delete them first\n", username)
		return nil
	} else if err != nil {
		return err
	}

	// If user targets themselves, logout.
	if username == "" || c.Username == username {
		if err := client.Delete(); err != nil {
			return err
		}
	}

	fmt.Println("Account cancelled")
	return nil
}
source: func (db *DynamoDB) GetByID(id string) (u *models.User, ok bool) {
	res, err := db.DB.GetItem(&dynamodb.GetItemInput{
		ConsistentRead: aws.Bool(true),
		TableName:      aws.String("users"),
		Key: map[string]*dynamodb.AttributeValue{
			"ID": {
				S: aws.String(id),
			},
		},
	})
	if err != nil {
		log.Printf("dynamodb: error: %v", err)
		return nil, false
	}
	if len(res.Item) == 0 {
		return nil, false
	}

	var user models.User
	if err := dynamodbattribute.UnmarshalMap(res.Item, &user); err != nil {
		log.Printf("dynamodb: getbyid error: %v", err)
		return nil, false
	}

	return &user, true
}
source: func (d *DNSProvider) CleanUp(domainName, token, keyAuth string) error {
	fqdn, _ := dns01.GetRecord(domainName, keyAuth)

	authZone, err := dns01.FindZoneByFqdn(fqdn)
	if err != nil {
		return fmt.Errorf("dnsmadeeasy: unable to find zone for %s: %v", fqdn, err)
	}

	// fetch the domain details
	domain, err := d.client.GetDomain(authZone)
	if err != nil {
		return fmt.Errorf("dnsmadeeasy: unable to get domain for zone %s: %v", authZone, err)
	}

	// find matching records
	name := strings.Replace(fqdn, "."+authZone, "", 1)
	records, err := d.client.GetRecords(domain, name, "TXT")
	if err != nil {
		return fmt.Errorf("dnsmadeeasy: unable to get records for domain %s: %v", domain.Name, err)
	}

	// delete records
	var lastError error
	for _, record := range *records {
		err = d.client.DeleteRecord(record)
		if err != nil {
			lastError = fmt.Errorf("dnsmadeeasy: unable to delete record [id=%d, name=%s]: %v", record.ID, record.Name, err)
		}
	}

	return lastError
}
source: func setFlenDecimal4Int(retTp, a, b *types.FieldType) {
	retTp.Decimal = 0
	retTp.Flen = mysql.MaxIntWidth
}
source: func GetBoolErr(key string, args ...interface{}) (bool, error) {
	return std.GetBoolErr(key, args...)
}
source: func (c *PreparedQuery) Get(queryID string, q *QueryOptions) ([]*PreparedQueryDefinition, *QueryMeta, error) {
	var out []*PreparedQueryDefinition
	qm, err := c.c.query("/v1/query/"+queryID, &out, q)
	if err != nil {
		return nil, nil, err
	}
	return out, qm, nil
}
source: func (a *Adaptor) Connect() (err error) {
	a.client, err = a.connect()
	return
}
source: func (s *Store) Open(ctx context.Context, key string, fetcher Fetcher) (file *File, err error) {
	span, ctx := opentracing.StartSpanFromContext(ctx, "Cached Fetch")
	if s.Component != "" {
		ext.Component.Set(span, s.Component)
	}
	defer func() {
		if err != nil {
			ext.Error.Set(span, true)
			span.SetTag("err", err.Error())
		}
		if file != nil {
			// Update modified time. Modified time is used to decide which
			// files to evict from the cache.
			touch(file.Path)
		}
		span.Finish()
	}()

	if s.Dir == "" {
		return nil, errors.New("diskcache.Store.Dir must be set")
	}

	// path uses a sha256 hash of the key since we want to use it for the
	// disk name.
	h := sha256.Sum256([]byte(key))
	path := filepath.Join(s.Dir, hex.EncodeToString(h[:])) + ".zip"
	span.LogKV("key", key, "path", path)

	// First do a fast-path, assume already on disk
	f, err := os.Open(path)
	if err == nil {
		span.SetTag("source", "fast")
		return &File{File: f, Path: path}, nil
	}

	// We (probably) have to fetch
	span.SetTag("source", "fetch")

	// Do the fetch in another goroutine so we can respect ctx cancellation.
	type result struct {
		f   *File
		err error
	}
	ch := make(chan result, 1)
	go func(ctx context.Context) {
		if s.BackgroundTimeout != 0 {
			var cancel context.CancelFunc
			ctx, cancel = context.WithTimeout(context.Background(), s.BackgroundTimeout)
			defer cancel()
		}
		f, err := doFetch(ctx, path, fetcher)
		ch <- result{f, err}
	}(ctx)

	select {
	case <-ctx.Done():
		// *os.File sets a finalizer to close the file when no longer used, so
		// we don't need to worry about closing the file in the case of context
		// cancellation.
		return nil, ctx.Err()
	case r := <-ch:
		return r.f, r.err
	}
}
source: func (s *SecureChannelSession) Open() error {
	if s.iv != nil {
		return fmt.Errorf("Session already opened")
	}

	response, err := s.open()
	if err != nil {
		return err
	}

	// Generate the encryption/mac key by hashing our shared secret,
	// pairing key, and the first bytes returned from the Open APDU.
	md := sha512.New()
	md.Write(s.secret)
	md.Write(s.PairingKey)
	md.Write(response.Data[:scSecretLength])
	keyData := md.Sum(nil)
	s.sessionEncKey = keyData[:scSecretLength]
	s.sessionMacKey = keyData[scSecretLength : scSecretLength*2]

	// The IV is the last bytes returned from the Open APDU.
	s.iv = response.Data[scSecretLength:]

	return s.mutuallyAuthenticate()
}
source: func loadArguments(path string, line int) (string, bool) {
	f, err := os.Open(path)
	if err != nil {
		return "", false
	}
	defer f.Close()
	s := bufio.NewScanner(f)
	i := 1
	for s.Scan() {
		if i == line {
			text := s.Text()
			braceI := strings.Index(text, "(")
			if braceI == -1 {
				return "", false
			}
			text = text[braceI+1:]
			cs := bufio.NewScanner(strings.NewReader(text))
			cs.Split(bufio.ScanBytes)
			j := 0
			c := 1
			for cs.Scan() {
				switch cs.Text() {
				case ")":
					c--
				case "(":
					c++
				}
				if c == 0 {
					break
				}
				j++
			}
			text = text[:j]
			return text, true
		}
		i++
	}
	return "", false
}
source: func merge(appliabels ...[]appliable) []appliable {
	all := []appliable{}

	for _, appl := range appliabels {
		all = append(all, appl...)
	}

	return all
}
source: func (d *clusterDiscoveryGCE) findGCEDisks() ([]*compute.Disk, error) {
	c := d.gceCloud

	clusterTag := gce.SafeClusterName(d.clusterName)

	var matches []*compute.Disk

	ctx := context.Background()

	// TODO: Push down tag filter?

	err := c.Compute().Disks.AggregatedList(c.Project()).Pages(ctx, func(page *compute.DiskAggregatedList) error {
		for _, list := range page.Items {
			for _, d := range list.Disks {
				match := false
				for k, v := range d.Labels {
					if k == gce.GceLabelNameKubernetesCluster {
						if v == clusterTag {
							match = true
						} else {
							match = false
							break
						}
					}
				}

				if !match {
					continue
				}

				matches = append(matches, d)
			}
		}

		return nil
	})
	if err != nil {
		return nil, fmt.Errorf("error listing disks: %v", err)
	}

	return matches, nil
}
source: func (ac *APIController) PolicyCreate(policy *contivModel.Policy) error {
	log.Infof("Received PolicyCreate: %+v", policy)

	// Make sure tenant exists
	if policy.TenantName == "" {
		return core.Errorf("Invalid tenant name")
	}

	tenant := contivModel.FindTenant(policy.TenantName)
	if tenant == nil {
		return core.Errorf("Tenant not found")
	}

	// Setup links
	modeldb.AddLink(&policy.Links.Tenant, tenant)
	modeldb.AddLinkSet(&tenant.LinkSets.Policies, policy)

	// Save the tenant too since we added the links
	err := tenant.Write()
	if err != nil {
		log.Errorf("Error updating tenant state(%+v). Err: %v", tenant, err)
		return err
	}

	return nil
}
source: func (w *windowsConfigure) ConfigureJuju() error {
	if err := w.icfg.VerifyConfig(); err != nil {
		return errors.Trace(err)
	}
	if w.icfg.Controller != nil {
		return errors.Errorf("controllers not supported on windows")
	}

	tools := w.icfg.ToolsList()[0]
	toolsJson, err := json.Marshal(tools)
	if err != nil {
		return errors.Annotate(err, "while serializing the agent binaries")
	}

	renderer := w.conf.ShellRenderer()
	w.conf.AddScripts(
		fmt.Sprintf(`$binDir="%s"`, renderer.FromSlash(w.icfg.JujuTools())),
		fmt.Sprintf(`mkdir '%s'`, renderer.FromSlash(w.icfg.LogDir)),
		`mkdir $binDir`,
	)

	toolsDownloadCmds, err := addDownloadToolsCmds(
		w.icfg.Series, w.icfg.APIInfo.CACert, w.icfg.ToolsList(),
	)
	if err != nil {
		return errors.Trace(err)
	}
	w.conf.AddScripts(toolsDownloadCmds...)

	w.conf.AddScripts(
		`$dToolsHash = Get-FileSHA256 -FilePath "$binDir\tools.tar.gz"`,
		fmt.Sprintf(`$dToolsHash > "$binDir\juju%s.sha256"`, tools.Version),
		fmt.Sprintf(`if ($dToolsHash.ToLower() -ne "%s"){ Throw "Tools checksum mismatch"}`,
			tools.SHA256),
		fmt.Sprintf(`GUnZip-File -infile $binDir\tools.tar.gz -outdir $binDir`),
		`rm "$binDir\tools.tar*"`,
		fmt.Sprintf(`Set-Content $binDir\downloaded-tools.txt '%s'`, string(toolsJson)),
	)

	for _, cmd := range createJujuRegistryKeyCmds(w.icfg.Series) {
		w.conf.AddRunCmd(cmd)
	}

	machineTag := names.NewMachineTag(w.icfg.MachineId)
	_, err = w.addAgentInfo(machineTag)
	if err != nil {
		return errors.Trace(err)
	}
	return w.addMachineAgentToBoot()
}
source: func (c *OperatorMigrateCommand) migrateAll(ctx context.Context, from physical.Backend, to physical.Backend) error {
	return dfsScan(ctx, from, func(ctx context.Context, path string) error {
		if path < c.flagStart || path == storageMigrationLock || path == vault.CoreLockPath {
			return nil
		}

		entry, err := from.Get(ctx, path)

		if err != nil {
			return errwrap.Wrapf("error reading entry: {{err}}", err)
		}

		if entry == nil {
			return nil
		}

		if err := to.Put(ctx, entry); err != nil {
			return errwrap.Wrapf("error writing entry: {{err}}", err)
		}
		c.logger.Info("copied key", "path", path)
		return nil
	})
}
source: func (dl *DaemonLocal) CreateTeamTLF(
	ctx context.Context, teamID keybase1.TeamID, tlfID tlf.ID) (err error) {
	if err := checkContext(ctx); err != nil {
		return err
	}

	// TODO: add check to make sure the private/public suffix of the
	// team ID matches that of the tlf ID.
	dl.lock.Lock()
	defer dl.lock.Unlock()
	iteamInfo, isImplicit := dl.localImplicitTeams[teamID]
	if isImplicit {
		iteamInfo.TlfID = tlfID
		dl.localImplicitTeams[teamID] = iteamInfo
	}
	_, isRegularTeam := dl.localTeams[teamID]
	if !isImplicit && !isRegularTeam {
		return NoSuchTeamError{teamID.String()}
	}
	dl.localTeamSettings[teamID] = keybase1.KBFSTeamSettings{
		TlfID: keybase1.TLFID(tlfID.String())}
	return nil
}
source: func (ctx *Context) PushGlobalStruct(name string, s interface{}) (int, error) {
	ctx.PushGlobalObject()
	obj, err := ctx.PushStruct(s)
	if err != nil {
		return -1, err
	}

	ctx.PutPropString(-2, name)
	ctx.Pop()

	return obj, nil
}
source: func (_class VMMetricsClass) GetAllRecords(sessionID SessionRef) (_retval map[VMMetricsRef]VMMetricsRecord, _err error) {
	_method := "VM_metrics.get_all_records"
	_sessionIDArg, _err := convertSessionRefToXen(fmt.Sprintf("%s(%s)", _method, "session_id"), sessionID)
	if _err != nil {
		return
	}
	_result, _err := _class.client.APICall(_method, _sessionIDArg)
	if _err != nil {
		return
	}
	_retval, _err = convertVMMetricsRefToVMMetricsRecordMapToGo(_method + " -> ", _result.Value)
	return
}
source: func Proto3ToResult(qr *querypb.QueryResult) *Result {
	if qr == nil {
		return nil
	}
	return &Result{
		Fields:       qr.Fields,
		RowsAffected: qr.RowsAffected,
		InsertID:     qr.InsertId,
		Rows:         proto3ToRows(qr.Fields, qr.Rows),
		Extras:       qr.Extras,
	}
}
source: func (s *GetAppsOutput) SetApplicationsResponse(v *ApplicationsResponse) *GetAppsOutput {
	s.ApplicationsResponse = v
	return s
}
source: func DecodeInt64(t Trits) (value int64, size uint64, err error) {
	numTrits := uint64(len(t))

	equal, err := TritsEqual(t[0:4], encodedZero)
	if err != nil {
		return 0, 0, err
	}

	if equal {
		return 0, EncodedLength(0), nil
	}

	value = 0
	var encodingStart uint64 = 0

	for (encodingStart < numTrits) && (TritsToInt(t[encodingStart:encodingStart+TrinaryRadix]) <= 0) {
		encodingStart += TrinaryRadix
	}

	if encodingStart >= numTrits {
		return 0, 0, errors.New("encodingStart > numTrits")
	}

	encodingStart += TrinaryRadix
	encodingLength := MinTrits((1 << (encodingStart / TrinaryRadix)) - 1)
	encoding := TritsToInt(t[encodingStart : encodingStart+encodingLength])

	// Bound checking for the lookup table
	if encodingStart/TrinaryRadix > 13 {
		return 0, 0, errors.New("encodingStart/TrinaryRadix > 13")
	}

	for i := 0; i < int(encodingStart/TrinaryRadix); i++ {
		tryteValue := TritsToInt(t[i*TrinaryRadix : (i*TrinaryRadix)+TrinaryRadix])

		if ((encoding >> uint(i)) & 1) == 1 {
			tryteValue = -tryteValue
		}
		value += Pow27LUT[i] * tryteValue
	}

	return value, encodingStart + encodingLength, nil
}
source: func (p *Project) Log(ctx context.Context, follow bool, services ...string) error {
	return p.forEach(services, wrapperAction(func(wrapper *serviceWrapper, wrappers map[string]*serviceWrapper) {
		wrapper.Do(nil, events.NoEvent, events.NoEvent, func(service Service) error {
			return service.Log(ctx, follow)
		})
	}), nil)
}
source: func (am *AutogitManager) GetBrowserForRepo(
	ctx context.Context, gitFS *libfs.FS, repoName string,
	branch plumbing.ReferenceName, subdir string) (*libfs.FS, *Browser, error) {
	am.browserLock.Lock()
	defer am.browserLock.Unlock()
	return am.getBrowserForRepoLocked(ctx, gitFS, repoName, branch, subdir)
}
source: func (h *Client) ProductIndex(productIndex string) *Client {
	h.productIndex = productIndex
	h.productIndexSet = true
	return h
}
source: func NewMockApiextensionsV1beta1Interface(ctrl *gomock.Controller) *MockApiextensionsV1beta1Interface {
	mock := &MockApiextensionsV1beta1Interface{ctrl: ctrl}
	mock.recorder = &MockApiextensionsV1beta1InterfaceMockRecorder{mock}
	return mock
}
source: func newMeResponse(usr *chronograf.User, org string) meResponse {
	base := "/chronograf/v1"
	name := "me"
	if usr != nil {
		base = fmt.Sprintf("/chronograf/v1/organizations/%s/users", org)
		name = PathEscape(fmt.Sprintf("%d", usr.ID))
	}

	return meResponse{
		User: usr,
		Links: meLinks{
			Self: fmt.Sprintf("%s/%s", base, name),
		},
	}
}
source: func NewBlockHeaderStore(filePath string, db walletdb.DB,
	netParams *chaincfg.Params) (BlockHeaderStore, error) {

	hStore, err := newHeaderStore(db, filePath, Block)
	if err != nil {
		return nil, err
	}

	// With the header store created, we'll fetch the file size to see if
	// we need to initialize it with the first header or not.
	fileInfo, err := hStore.file.Stat()
	if err != nil {
		return nil, err
	}

	bhs := &blockHeaderStore{
		headerStore: hStore,
	}

	// If the size of the file is zero, then this means that we haven't yet
	// written the initial genesis header to disk, so we'll do so now.
	if fileInfo.Size() == 0 {
		genesisHeader := BlockHeader{
			BlockHeader: &netParams.GenesisBlock.Header,
			Height:      0,
		}
		if err := bhs.WriteHeaders(genesisHeader); err != nil {
			return nil, err
		}

		return bhs, nil
	}

	// As a final initialization step (if this isn't the first time), we'll
	// ensure that the header tip within the flat files, is in sync with
	// out database index.
	tipHash, tipHeight, err := bhs.chainTip()
	if err != nil {
		return nil, err
	}

	// First, we'll compute the size of the current file so we can
	// calculate the latest header written to disk.
	fileHeight := uint32(fileInfo.Size()/80) - 1

	// Using the file's current height, fetch the latest on-disk header.
	latestFileHeader, err := bhs.readHeader(fileHeight)
	if err != nil {
		return nil, err
	}

	// If the index's tip hash, and the file on-disk match, then we're
	// done here.
	latestBlockHash := latestFileHeader.BlockHash()
	if tipHash.IsEqual(&latestBlockHash) {
		return bhs, nil
	}

	// TODO(roasbeef): below assumes index can never get ahead?
	//  * we always update files _then_ indexes
	//  * need to dual pointer walk back for max safety

	// Otherwise, we'll need to truncate the file until it matches the
	// current index tip.
	for fileHeight > tipHeight {
		if err := bhs.singleTruncate(); err != nil {
			return nil, err
		}

		fileHeight--
	}

	return bhs, nil
}
source: func IsDeviceNode(path string) bool {
	d, err := os.Lstat(path)
	if err == nil {
		m := d.Mode()
		return m&os.ModeDevice == os.ModeDevice
	}
	return false
}
source: func (g *Geometry) Covers(other *Geometry) (bool, error) {
	return g.binaryPred("Covers", cGEOSCovers, other)
}
source: func (builder *StoreValueCommandBuilder) WithIfNoneMatch(ifNoneMatch bool) *StoreValueCommandBuilder {
	builder.protobuf.IfNoneMatch = &ifNoneMatch
	return builder
}
source: func (self *Domain) Info(name string) (*DomainInfo, error) {
	var res map[string]interface{}
	params := []interface{}{self.Key, name}
	if err := self.Call("domain.info", params, &res); err != nil {
		return nil, err
	}
	return ToDomainInfo(res), nil
}
source: func (g *Driver) AnalogRead(pin string) (value int, err error) {
	var (
		grovePin, grovePort Grove
		analogCmd           byte
	)
	grovePin, grovePort, analogCmd, _, err = getGroveAddresses(pin)
	if err != nil {
		return value, err
	}
	err = g.SetGroveType(grovePort, CUSTOM)
	if err != nil {
		return value, err
	}
	time.Sleep(10 * time.Millisecond)
	err = g.SetGroveMode(grovePin, GROVE_INPUT_ANALOG)
	if err != nil {
		return value, err
	}
	time.Sleep(10 * time.Millisecond)
	response, err := g.readBytes(goPiGo3Address, analogCmd, 7)
	if err != nil {
		return value, err
	}
	if err := g.responseValid(response); err != nil {
		return value, err
	}
	if err := g.valueValid(response); err != nil {
		return value, err
	}
	highBytes := uint16(response[5])
	lowBytes := uint16(response[6])
	return int((highBytes<<8)&0xFF00) | int(lowBytes&0xFF), nil
}
source: func loadGroup(path string) error {
	_, hexid := filepath.Split(path)
	b, err := ioutil.ReadFile(path)
	if err != nil {
		return err
	}

	group := &Group{}
	err = yaml.Unmarshal(b, group)
	if err != nil {
		return err
	}
	groups[hexid] = group
	return nil
}
source: func (p *page) hexdump(n int) {
	buf := (*[maxAllocSize]byte)(unsafe.Pointer(p))[:n]
	fmt.Fprintf(os.Stderr, "%x\n", buf)
}
source: func RegisterFormatFactory(kind string, fn CreateFormatterFunc) {
	if kind == "" {
		panic("kind is empty string")
	}
	if fn == nil {
		panic("creator is nil")
	}
	formatterCreators[kind] = fn
}
source: func (c *client) updateSmap(sub *subscription, delta int32) {
	key := keyFromSub(sub)

	c.mu.Lock()
	n := c.leaf.smap[key]
	// We will update if its a queue, if count is zero (or negative), or we were 0 and are N > 0.
	update := sub.queue != nil || n == 0 || n+delta <= 0
	n += delta
	if n > 0 {
		c.leaf.smap[key] = n
	} else {
		delete(c.leaf.smap, key)
	}
	if update {
		c.sendLeafNodeSubUpdate(key, n)
	}
	c.mu.Unlock()
}
source: func (t *Topic) generatePartitionAssignments(brokers []int32, partitionCount int, replicationFactor int) (PartitionList, error) {
	if partitionCount <= 0 {
		return nil, ErrInvalidPartitionCount
	}
	if replicationFactor <= 0 || len(brokers) < replicationFactor {
		return nil, ErrInvalidReplicationFactor
	}

	result := make(PartitionList, partitionCount)

	brokerCount := len(brokers)
	brokerIdx := rand.Intn(brokerCount)

	for p := 0; p < partitionCount; p++ {
		partition := &Partition{topic: t, ID: int32(p), Replicas: make([]int32, replicationFactor)}

		brokerIndices := rand.Perm(len(brokers))[0:replicationFactor]

		for r := 0; r < replicationFactor; r++ {
			partition.Replicas[r] = brokers[brokerIndices[r]]
		}

		result[p] = partition
		brokerIdx = (brokerIdx + 1) % brokerCount
	}

	return result, nil
}
source: func (pw *Writer) TryWriteBits(v, nb uint) bool {
	if 64-pw.numBits < nb {
		return false
	}
	pw.bufBits |= uint64(v) << pw.numBits
	pw.numBits += nb
	return true
}
source: func PseudoHeaderChecksum(protocol tcpip.TransportProtocolNumber, srcAddr tcpip.Address, dstAddr tcpip.Address, totalLen uint16) uint16 {
	xsum := Checksum([]byte(srcAddr), 0)
	xsum = Checksum([]byte(dstAddr), xsum)

	// Add the length portion of the checksum to the pseudo-checksum.
	tmp := make([]byte, 2)
	binary.BigEndian.PutUint16(tmp, totalLen)
	xsum = Checksum(tmp, xsum)

	return Checksum([]byte{0, uint8(protocol)}, xsum)
}
source: func selectNodesForPreemption(pod *v1.Pod,
	nodeNameToInfo map[string]*schedulernodeinfo.NodeInfo,
	potentialNodes []*v1.Node,
	fitPredicates map[string]predicates.FitPredicate,
	metadataProducer predicates.PredicateMetadataProducer,
	queue internalqueue.SchedulingQueue,
	pdbs []*policy.PodDisruptionBudget,
) (map[*v1.Node]*schedulerapi.Victims, error) {
	nodeToVictims := map[*v1.Node]*schedulerapi.Victims{}
	var resultLock sync.Mutex

	// We can use the same metadata producer for all nodes.
	meta := metadataProducer(pod, nodeNameToInfo)
	checkNode := func(i int) {
		nodeName := potentialNodes[i].Name
		var metaCopy predicates.PredicateMetadata
		if meta != nil {
			metaCopy = meta.ShallowCopy()
		}
		pods, numPDBViolations, fits := selectVictimsOnNode(pod, metaCopy, nodeNameToInfo[nodeName], fitPredicates, queue, pdbs)
		if fits {
			resultLock.Lock()
			victims := schedulerapi.Victims{
				Pods:             pods,
				NumPDBViolations: numPDBViolations,
			}
			nodeToVictims[potentialNodes[i]] = &victims
			resultLock.Unlock()
		}
	}
	workqueue.ParallelizeUntil(context.TODO(), 16, len(potentialNodes), checkNode)
	return nodeToVictims, nil
}
source: func (m *ChannelMap) Equal(other *ChannelMap) bool {
	cmap1 := m.toC()
	cmap2 := other.toC()
	return C.pa_channel_map_equal(cmap1, cmap2) == 1
}
source: func (s *PutParameterInput) SetOverwrite(v bool) *PutParameterInput {
	s.Overwrite = &v
	return s
}
source: func (sw *StackEventWatcher) Watch() error {
	if sw.seenEvents == nil {
		sw.seenEvents = map[string]struct{}{}
	}
	lastStackStatus := ""
	for {
		// print the events for the stack
		sw.Service.DescribeStackEventsPages(&cloudformation.DescribeStackEventsInput{
			StackName: aws.String(sw.StackName),
		}, func(p *cloudformation.DescribeStackEventsOutput, _ bool) bool {
			for _, stackEvent := range p.StackEvents {
				if _, ok := sw.seenEvents[*stackEvent.EventId]; ok {
					continue
				}
				wrapStrPtr := func(s *string) string {
					if s == nil {
						return ""
					}
					return *s
				}

				l := log.WithField("Status", *stackEvent.ResourceStatus)
				if stackEvent.ResourceType != nil {
					l = l.WithField("Type", *stackEvent.ResourceType)
				}
				if stackEvent.ResourceType != nil {
					l = l.WithField("Type", *stackEvent.ResourceType)
				}
				if stackEvent.PhysicalResourceId != nil {
					l = l.WithField("PhysicalID", *stackEvent.PhysicalResourceId)
				}
				if stackEvent.LogicalResourceId != nil {
					l = l.WithField("LogicalID", *stackEvent.LogicalResourceId)
				}
				if strings.Contains(*stackEvent.ResourceStatus, "FAIL") {
					l.Error(wrapStrPtr(stackEvent.ResourceStatusReason))
				} else {
					l.Info(wrapStrPtr(stackEvent.ResourceStatusReason))
				}

				sw.seenEvents[*stackEvent.EventId] = struct{}{}
			}
			return true
		})

		// monitor the status of the stack
		describeStacksResponse, err := sw.Service.DescribeStacks(&cloudformation.DescribeStacksInput{
			StackName: aws.String(sw.StackName),
		})
		if err != nil {
			// the stack might not exist yet
			log.Errorf("DescribeStacks: %s", err)
			time.Sleep(time.Second)
			continue
		}

		stackStatus := *describeStacksResponse.Stacks[0].StackStatus
		if stackStatus != lastStackStatus {
			log.Infof("Stack: %s\n", stackStatus)
			lastStackStatus = stackStatus
		}
		switch stackStatus {
		case cloudformation.StackStatusCreateComplete:
			return nil
		case cloudformation.StackStatusCreateFailed:
			return fmt.Errorf("%s", stackStatus)
		case cloudformation.StackStatusRollbackComplete:
			return fmt.Errorf("%s", stackStatus)
		case cloudformation.StackStatusUpdateRollbackComplete:
			return fmt.Errorf("%s", stackStatus)
		case cloudformation.StackStatusRollbackFailed:
			return fmt.Errorf("%s", stackStatus)
		case cloudformation.StackStatusUpdateComplete:
			return nil
		case cloudformation.StackStatusUpdateRollbackFailed:
			return fmt.Errorf("%s", stackStatus)
		default:
			time.Sleep(time.Second * 5)
			continue
		}
	}
} 43%|████▎     | 2137/5000 [00:02<00:02, 1124.57it/s]
source: func TunnelAuthDialer(proxyAddr string, sshConfig *ssh.ClientConfig) auth.DialContext {
	return func(ctx context.Context, network string, addr string) (net.Conn, error) {
		// Connect to the reverse tunnel server.
		dialer := proxy.DialerFromEnvironment(proxyAddr)
		sconn, err := dialer.Dial("tcp", proxyAddr, sshConfig)
		if err != nil {
			return nil, trace.Wrap(err)
		}

		conn, err := connectProxyTransport(sconn.Conn, RemoteAuthServer)
		if err != nil {
			return nil, trace.Wrap(err)
		}
		return conn, nil
	}
}
source: func New(dsn string, options ...Option) (*Rabbus, error) {
	r := &Rabbus{
		emit:       make(chan Message),
		emitErr:    make(chan error),
		emitOk:     make(chan struct{}),
		reconn:     make(chan struct{}),
		exDeclared: make(map[string]struct{}),
	}

	for _, o := range options {
		if err := o(r); err != nil {
			return nil, err
		}
	}

	if r.Amqp == nil {
		amqpWrapper, err := amqpWrap.New(dsn, r.config.isExchangePassive)
		if err != nil {
			return nil, err
		}
		r.Amqp = amqpWrapper
	}

	if err := r.WithQos(
		r.config.qos.prefetchCount,
		r.config.qos.prefetchSize,
		r.config.qos.global,
	); err != nil {
		return nil, err
	}

	r.config.dsn = dsn
	r.breaker = gobreaker.NewCircuitBreaker(newBreakerSettings(r.config))

	return r, nil
}
source: func (h *UserHandler) Setup(r *powermux.Route) {

	// using path parameters
	// these functions don't know or care what the route is above them
	r.Route("/:id").GetFunc(h.Get)

	// use the root of this section of the route tree
	r.PostFunc(h.CreateUser)
}
source: func (d *Duration) UnmarshalText(text []byte) error {
	return d.Set(string(text))
}
source: func makeBigDataBaseName(key string) string {
	reader := strings.NewReader(key)
	for reader.Len() > 0 {
		ch, size, err := reader.ReadRune()
		if err != nil || size != 1 {
			break
		}
		if ch != '.' && !(ch >= '0' && ch <= '9') && !(ch >= 'a' && ch <= 'z') {
			break
		}
	}
	if reader.Len() > 0 {
		return "=" + base64.StdEncoding.EncodeToString([]byte(key))
	}
	return key
}
source: func (client *Client) StartAssemblyReplay(ctx context.Context, assembly AssemblyReplay) (*AssemblyInfo, error) {
	options := map[string]interface{}{
		"steps": assembly.steps,
	}

	if assembly.ReparseTemplate {
		options["reparse_template"] = 1
	}

	if assembly.NotifyURL != "" {
		options["notify_url"] = assembly.NotifyURL
	}

	var info AssemblyInfo
	err := client.request(ctx, "POST", assembly.assemblyURL+"/replay", options, &info)
	if err != nil {
		return nil, err
	}

	if info.Error != "" {
		return &info, fmt.Errorf("failed to start assembly replay: %s", info.Error)
	}

	return &info, nil
}
source: func (p *partition) entry(key []byte) *entry {
	p.mu.RLock()
	e := p.store[string(key)]
	p.mu.RUnlock()
	return e
}
source: func updateIPAddressDocOp(existingDoc, newDoc *ipAddressDoc) (txn.Op, bool) {
	changes := make(bson.M)
	deletes := make(bson.M)
	if existingDoc.ProviderID == "" && newDoc.ProviderID != "" {
		// Only allow changing the ProviderID if it was empty.
		changes["providerid"] = newDoc.ProviderID
	}
	if existingDoc.ConfigMethod != newDoc.ConfigMethod {
		changes["config-method"] = newDoc.ConfigMethod
	}

	if existingDoc.SubnetCIDR != newDoc.SubnetCIDR {
		changes["subnet-cidr"] = newDoc.SubnetCIDR
	}

	if strsDiffer(newDoc.DNSServers, existingDoc.DNSServers) {
		if len(newDoc.DNSServers) == 0 {
			deletes["dns-servers"] = 1
		} else {
			changes["dns-servers"] = newDoc.DNSServers
		}
	}
	if strsDiffer(newDoc.DNSSearchDomains, existingDoc.DNSSearchDomains) {
		if len(newDoc.DNSSearchDomains) == 0 {
			deletes["dns-search-domains"] = 1
		} else {
			changes["dns-search-domains"] = newDoc.DNSSearchDomains
		}
	}

	if existingDoc.GatewayAddress != newDoc.GatewayAddress {
		changes["gateway-address"] = newDoc.GatewayAddress
	}

	var updates bson.D
	if len(changes) > 0 {
		updates = append(updates, bson.DocElem{Name: "$set", Value: changes})
	}
	if len(deletes) > 0 {
		updates = append(updates, bson.DocElem{Name: "$unset", Value: deletes})
	}

	return txn.Op{
		C:      ipAddressesC,
		Id:     existingDoc.DocID,
		Assert: txn.DocExists,
		Update: updates,
	}, len(updates) > 0
}
source: func (bot TgBot) GetUserProfilePhotosQuery(quer GetUserProfilePhotosQuery) ResultWithUserProfilePhotos {
	url := bot.buildPath("getUserProfilePhotos")
	body, error := postPetition(url, quer, nil)

	if error != nil {
		errc := 500
		err := "Some error happened while sending the message"
		return ResultWithUserProfilePhotos{ResultBase{false, &errc, &err}, nil}
	}
	var result ResultWithUserProfilePhotos
	json.Unmarshal([]byte(body), &result)
	return result
}
source: func (o *orderedMap) Insert(key string, value interface{}) {
	if o.backingMap == nil {
		o.backingMap = map[string]interface{}{}
	}
	if o.orderedKeys == nil {
		o.orderedKeys = list.New()
	}

	if _, exists := o.backingMap[key]; !exists {
		o.orderedKeys.PushBack(key)
	}
	o.backingMap[key] = value
}
source: func (m *MockCluster) AddEventListener(arg0 cluster.ClusterListener) error {
	ret := m.ctrl.Call(m, "AddEventListener", arg0)
	ret0, _ := ret[0].(error)
	return ret0
}
source: func (r Network_Component) GetInterface() (resp datatypes.Network_Bandwidth_Version1_Interface, err error) {
	err = r.Session.DoRequest("SoftLayer_Network_Component", "getInterface", nil, &r.Options, &resp)
	return
}
source: func (m *Manager) SaveMember(organization *Organization, username string) error {
	return m.collection.Update(
		bson.M{"globalid": organization.Globalid},
		bson.M{"$addToSet": bson.M{"members": username}})
}
source: func NewTimer(sec time.Duration, worker *worker.Worker) (*Timer, error) {
	return &Timer{
		ticker: time.NewTicker(sec * time.Second),
		worker: worker,
	}, nil
}
source: func GetGzipOption(defaultValue bool, options map[string]interface{}) bool {
	gzipOpt := options["gzip"] // we only need that, so don't create new map to keep the options.
	if b, isBool := gzipOpt.(bool); isBool {
		return b
	}
	return defaultValue
}
source: func (s *systemInfo) CPUModel() string {
	err := s.collectPlatformInfo()
	if err != nil {
		return "unknown"
	}
	return s.cpuModel
}
source: func (s *SecuritySchemeDefinition) Finalize() {
	tu, _ := url.Parse(s.TokenURL)         // validated in Validate
	au, _ := url.Parse(s.AuthorizationURL) // validated in Validate
	tokenOK := s.TokenURL == "" || tu.IsAbs()
	authOK := s.AuthorizationURL == "" || au.IsAbs()
	if tokenOK && authOK {
		return
	}
	var scheme string
	if len(Design.Schemes) > 0 {
		scheme = Design.Schemes[0]
	}
	if !tokenOK {
		tu.Scheme = scheme
		tu.Host = Design.Host
		s.TokenURL = tu.String()
	}
	if !authOK {
		au.Scheme = scheme
		au.Host = Design.Host
		s.AuthorizationURL = au.String()
	}
}
source: func writeServiceFile(g *generateInfo) error {
	return writeGoFile(filepath.Join(g.PackageDir, "service.go"),
		codeLayout,
		"",
		g.API.PackageName(),
		g.API.ServiceGoCode(),
	)
}
source: func (user *User) AddChatToHook(chatID int64) error {
	data, _ := user.getData()
	token := user.ServiceHookToken()

	for i, hook := range data.Hooks {
		if hook.Token == token {
			for _, service := range hook.Services {
				if service == user.ctx.ServiceName {
					for _, existingChatID := range hook.Chats {
						if existingChatID == chatID {
							return nil
						}
					}
					data.Hooks[i].Chats = append(data.Hooks[i].Chats, chatID)
					err := user.ctx.db.C("users").Update(bson.M{"_id": user.ID, "hooks.services": service}, bson.M{"$addToSet": bson.M{"hooks.$.chats": chatID}})

					return err
				}
			}
		}
	}
	err := errors.New("Can't add chat to serviceHook. Can't find a hook.")
	user.ctx.Log().Error(err)
	return err
}
source: func (m *Message) closeResponseChan() {
	if atomic.CompareAndSwapInt32(&m.responseChanClosed, 0, 1) {
		if ch := m.responseChan; ch != nil {
			m.responseChan = nil
			close(ch)
		}
	}
}
source: func (s *storage) SupportedArchitectures(criteria MetadataFilter) ([]string, error) {
	coll, closer := s.store.GetCollection(s.collection)
	defer closer()

	var arches []string
	if err := coll.Find(buildSearchClauses(criteria)).Distinct("arch", &arches); err != nil {
		return nil, errors.Trace(err)
	}
	return arches, nil
}
source: func ParseL4Proto(proto string) (L4Proto, error) {
	if proto == "" {
		return ProtoAny, nil
	}

	p := L4Proto(strings.ToUpper(proto))
	return p, p.Validate()
}
source: func (r Network_LBaaS_LoadBalancer) GetL7Pools() (resp []datatypes.Network_LBaaS_L7Pool, err error) {
	err = r.Session.DoRequest("SoftLayer_Network_LBaaS_LoadBalancer", "getL7Pools", nil, &r.Options, &resp)
	return
}
source: func (u UUID) MarshalJSON() ([]byte, error) {
	var uuidSlice []string
	err := u.validateUUID()
	if err == nil {
		uuidSlice = []string{"uuid", u.GoUUID}
	} else {
		uuidSlice = []string{"named-uuid", u.GoUUID}
	}

	return json.Marshal(uuidSlice)
}
source: func (f *FIFO) addIfNotPresent(id string, obj interface{}) {
	f.populated = true
	if _, exists := f.items[id]; exists {
		return
	}

	f.queue = append(f.queue, id)
	f.items[id] = obj
	f.cond.Broadcast()
}
source: func (d *DockerHelper) DoInspectContainerBenchmark(interval, testPeriod time.Duration, containerIDs []string) []int {
	startTime := time.Now()
	latencies := []int{}
	rand.Seed(time.Now().Unix())
	for {
		containerID := containerIDs[rand.Int()%len(containerIDs)]
		start := time.Now()
		_, err := d.client.ContainerInspect(getContext(), containerID)
		d.errStats.add("inspect container", err)
		latencies = append(latencies, int(time.Since(start).Nanoseconds()))
		if time.Now().Sub(startTime) >= testPeriod {
			break
		}
		if interval != 0 {
			time.Sleep(interval)
		}
	}
	return latencies
}
source: func BoundSerializedSizeInBytes(cardinality uint64, universeSize uint64) uint64 {
	contnbr := (universeSize + uint64(65535)) / uint64(65536)
	if contnbr > cardinality {
		contnbr = cardinality
		// we can't have more containers than we have values
	}
	headermax := 8*contnbr + 4
	if 4 > (contnbr+7)/8 {
		headermax += 4
	} else {
		headermax += (contnbr + 7) / 8
	}
	valsarray := uint64(arrayContainerSizeInBytes(int(cardinality)))
	valsbitmap := contnbr * uint64(bitmapContainerSizeInBytes())
	valsbest := valsarray
	if valsbest > valsbitmap {
		valsbest = valsbitmap
	}
	return valsbest + headermax
}
source: func (in *ImageImportSpec) DeepCopy() *ImageImportSpec {
	if in == nil {
		return nil
	}
	out := new(ImageImportSpec)
	in.DeepCopyInto(out)
	return out
}
source: func passDynamicOptions() {
	myApp := newApp(options.Options{"MaxRequests": 17, "DevMode": true})

	fmt.Printf("passDynamicOptions: %#v\n", myApp.options)
}
source: func Convert_config_SchedulerPolicySource_To_v1alpha1_SchedulerPolicySource(in *config.SchedulerPolicySource, out *v1alpha1.SchedulerPolicySource, s conversion.Scope) error {
	return autoConvert_config_SchedulerPolicySource_To_v1alpha1_SchedulerPolicySource(in, out, s)
}
source: func (agent *ActionAgent) InitSlave(ctx context.Context, parent *topodatapb.TabletAlias, position string, timeCreatedNS int64) error {
	if err := agent.lock(ctx); err != nil {
		return err
	}
	defer agent.unlock()

	pos, err := mysql.DecodePosition(position)
	if err != nil {
		return err
	}
	ti, err := agent.TopoServer.GetTablet(ctx, parent)
	if err != nil {
		return err
	}

	agent.setSlaveStopped(false)

	// If using semi-sync, we need to enable it before connecting to master.
	// If we were a master type, we need to switch back to replica settings.
	// Otherwise we won't be able to commit anything.
	tt := agent.Tablet().Type
	if tt == topodatapb.TabletType_MASTER {
		tt = topodatapb.TabletType_REPLICA
	}
	if err := agent.fixSemiSync(tt); err != nil {
		return err
	}

	if err := agent.MysqlDaemon.SetSlavePosition(ctx, pos); err != nil {
		return err
	}
	if err := agent.MysqlDaemon.SetMaster(ctx, topoproto.MysqlHostname(ti.Tablet), int(topoproto.MysqlPort(ti.Tablet)), false /* slaveStopBefore */, true /* slaveStartAfter */); err != nil {
		return err
	}
	agent.initReplication = true

	// If we were a master type, switch our type to replica.  This
	// is used on the old master when using InitShardMaster with
	// -force, and the new master is different from the old master.
	if agent.Tablet().Type == topodatapb.TabletType_MASTER {
		if _, err := topotools.ChangeType(ctx, agent.TopoServer, agent.TabletAlias, topodatapb.TabletType_REPLICA); err != nil {
			return err
		}

		if err := agent.refreshTablet(ctx, "InitSlave"); err != nil {
			return err
		}
	}

	// wait until we get the replicated row, or our context times out
	return agent.MysqlDaemon.WaitForReparentJournal(ctx, timeCreatedNS)
}
source: func NewCipherReader(r io.Reader, mask [4]byte) *CipherReader {
	return &CipherReader{r, mask, 0}
}
source: func New(req *http.Request, retry time.Duration) *EventSource {
	req.Header.Set("Accept", "text/event-stream")
	req.Header.Set("Cache-Control", "no-cache")

	return &EventSource{
		retry:   retry,
		request: req,
	}
}
source: func (gr *guiRouter) ensureFiles(req *http.Request) (rootDir string, hash string, err error) {
	// Retrieve the Juju GUI info from the GUI storage.
	st := gr.ctxt.srv.shared.statePool.SystemState()
	storage, err := st.GUIStorage()
	if err != nil {
		return "", "", errors.Annotate(err, "cannot open GUI storage")
	}
	defer storage.Close()
	vers, hash, err := guiVersionAndHash(st, storage)
	if err != nil {
		return "", "", errors.Trace(err)
	}
	logger.Debugf("serving Juju GUI version %s", vers)

	// Check if the current Juju GUI archive has been already expanded on disk.
	baseDir := agenttools.SharedGUIDir(gr.dataDir)
	// Note that we include the hash in the root directory so that when the GUI
	// archive changes we can be sure that clients will not use files from
	// mixed versions.
	rootDir = filepath.Join(baseDir, hash)
	info, err := os.Stat(rootDir)
	if err == nil {
		if info.IsDir() {
			return rootDir, hash, nil
		}
		return "", "", errors.Errorf("cannot use Juju GUI root directory %q: not a directory", rootDir)
	}
	if !os.IsNotExist(err) {
		return "", "", errors.Annotate(err, "cannot stat Juju GUI root directory")
	}

	// Fetch the Juju GUI archive from the GUI storage and expand it.
	_, r, err := storage.Open(vers)
	if err != nil {
		return "", "", errors.Annotatef(err, "cannot find GUI archive version %q", vers)
	}
	defer r.Close()
	if err := os.MkdirAll(baseDir, 0755); err != nil {
		return "", "", errors.Annotate(err, "cannot create Juju GUI base directory")
	}
	guiDir := "jujugui-" + vers + "/jujugui"
	if err := uncompressGUI(r, guiDir, rootDir); err != nil {
		return "", "", errors.Annotate(err, "cannot uncompress Juju GUI archive")
	}
	return rootDir, hash, nil
}
source: func FormatStatusResponseBrief(w io.Writer, sr *models.StatusResponse) {
	msg := ""

	switch {
	case statusUnhealthy(sr.Kvstore):
		msg = fmt.Sprintf("kvstore: %s", sr.Kvstore.Msg)
	case statusUnhealthy(sr.ContainerRuntime):
		msg = fmt.Sprintf("container runtime: %s", sr.ContainerRuntime.Msg)
	case sr.Kubernetes != nil && stateUnhealthy(sr.Kubernetes.State):
		msg = fmt.Sprintf("kubernetes: %s", sr.Kubernetes.Msg)
	case statusUnhealthy(sr.Cilium):
		msg = fmt.Sprintf("cilium: %s", sr.Cilium.Msg)
	case sr.Cluster != nil && statusUnhealthy(sr.Cluster.CiliumHealth):
		msg = fmt.Sprintf("cilium-health: %s", sr.Cluster.CiliumHealth.Msg)
	}

	// Only bother looking at controller failures if everything else is ok
	if msg == "" {
		for _, ctrl := range sr.Controllers {
			if ctrl.Status == nil {
				continue
			}
			if ctrl.Status.LastFailureMsg != "" {
				msg = fmt.Sprintf("controller %s: %s",
					ctrl.Name, ctrl.Status.LastFailureMsg)
				break
			}
		}
	}

	if msg == "" {
		fmt.Fprintf(w, "OK\n")
	} else {
		fmt.Fprintf(w, "error in %s\n", msg)
	}
}
source: func (m *Matrix) L() *Matrix {
	rows, cols := m.Size()
	m2 := New(rows, cols)
	for row := 0; row < rows; row++ {
		for col := row; col < cols; col++ {
			m2.Set(row, col, m.Get(row, col))
		}
	}
	return m2
}
source: func checkProofOfWork(header wire.BlockHeader, p *chaincfg.Params) bool {
	target := blockchain.CompactToBig(header.Bits)

	// The target must more than 0.  Why can you even encode negative...
	if target.Sign() <= 0 {
		log.Debugf("Block target %064x is neagtive(??)\n", target.Bytes())
		return false
	}
	// The target must be less than the maximum allowed (difficulty 1)
	if target.Cmp(p.PowLimit) > 0 {
		log.Debugf("Block target %064x is "+
			"higher than max of %064x", target, p.PowLimit.Bytes())
		return false
	}
	// The header hash must be less than the claimed target in the header.
	blockHash := header.BlockHash()
	hashNum := blockchain.HashToBig(&blockHash)
	if hashNum.Cmp(target) > 0 {
		log.Debugf("Block hash %064x is higher than "+
			"required target of %064x", hashNum, target)
		return false
	}
	return true
}
source: func validateChallengeParameters(challengeParams map[string]string) error {
	var errString string

	realm, exists := challengeParams["realm"]
	if !exists || len(realm) == 0 {
		errString += "missing or invalid realm. "
	}

	nonce, exists := challengeParams["nonce"]
	if !exists || len(nonce) == 0 {
		errString += "missing or invalid nonce. "
	}

	qop, exists := challengeParams["qop"]
	if !exists || qop != "auth" {
		errString += "missing, invalid or unsupported qop. "
	}

	charset, exists := challengeParams["charset"]
	if !exists || charset != "utf-8" {
		errString += "missing, invalid or unsupported charset. "
	}

	algorithm, exists := challengeParams["algorithm"]
	if !exists || algorithm != "md5-sess" {
		errString += "missing, invalid or unsupported algorithm. "
	}

	if len(errString) > 0 {
		return errors.New(errString)
	}

	return nil
}
source: func (o *PutServiceIDParams) WithID(id int64) *PutServiceIDParams {
	o.SetID(id)
	return o
}
source: func (s *Service) UpdateSource(w http.ResponseWriter, r *http.Request) {
	id, err := paramID("id", r)
	if err != nil {
		Error(w, http.StatusUnprocessableEntity, err.Error(), s.Logger)
		return
	}

	ctx := r.Context()
	src, err := s.Store.Sources(ctx).Get(ctx, id)
	if err != nil {
		notFound(w, id, s.Logger)
		return
	}

	var req chronograf.Source
	if err := json.NewDecoder(r.Body).Decode(&req); err != nil {
		invalidJSON(w, s.Logger)
		return
	}

	src.Default = req.Default
	src.InsecureSkipVerify = req.InsecureSkipVerify
	if req.Name != "" {
		src.Name = req.Name
	}
	if req.Password != "" {
		src.Password = req.Password
	}
	if req.Username != "" {
		src.Username = req.Username
	}
	if req.URL != "" {
		src.URL = req.URL
	}
	// If the supplied MetaURL is different from the
	// one supplied on the request, update the value
	if req.MetaURL != src.MetaURL {
		src.MetaURL = req.MetaURL
	}
	if req.Type != "" {
		src.Type = req.Type
	}
	if req.Telegraf != "" {
		src.Telegraf = req.Telegraf
	}
	src.DefaultRP = req.DefaultRP

	defaultOrg, err := s.Store.Organizations(ctx).DefaultOrganization(ctx)
	if err != nil {
		unknownErrorWithMessage(w, err, s.Logger)
		return
	}

	if err := ValidSourceRequest(&src, defaultOrg.ID); err != nil {
		invalidData(w, err, s.Logger)
		return
	}

	dbType, err := s.tsdbType(ctx, &src)
	if err != nil {
		Error(w, http.StatusBadRequest, "Error contacting source", s.Logger)
		return
	}
	src.Type = dbType

	if err := s.Store.Sources(ctx).Update(ctx, src); err != nil {
		msg := fmt.Sprintf("Error updating source ID %d", id)
		Error(w, http.StatusInternalServerError, msg, s.Logger)
		return
	}
	encodeJSON(w, http.StatusOK, newSourceResponse(context.Background(), src), s.Logger)
}
source: func (widgetSetting *QorWidgetSetting) GetSerializableArgumentKind() string {
	if widgetSetting.WidgetType != "" {
		return widgetSetting.WidgetType
	}
	return widgetSetting.Kind
}
source: func SaveDownlinkFrames(p *redis.Pool, devEUI lorawan.EUI64, frames []gw.DownlinkFrame) error {
	if len(frames) == 0 {
		return nil
	}

	var token uint32
	var frameBytes [][]byte
	for _, frame := range frames {
		token = frame.Token
		b, err := proto.Marshal(&frame)
		if err != nil {
			return errors.Wrap(err, "marshal proto error")
		}
		frameBytes = append(frameBytes, b)
	}

	c := p.Get()
	defer c.Close()

	exp := int64(downlinkFramesTTL) / int64(time.Millisecond)
	c.Send("MULTI")

	// store frames
	key := fmt.Sprintf(downlinkFramesKeyTempl, token)
	for i := range frameBytes {
		c.Send("RPUSH", key, frameBytes[i])
	}
	c.Send("PEXPIRE", key, exp)

	// store pointer to deveui
	key = fmt.Sprintf(downlinkFramesDevEUIKeyTempl, token)
	c.Send("PSETEX", key, exp, devEUI[:])

	// execute
	if _, err := c.Do("EXEC"); err != nil {
		return errors.Wrap(err, "exec error")
	}

	log.WithFields(log.Fields{
		"token":   token,
		"dev_eui": devEUI,
	}).Info("downlink-frames saved")

	return nil
}
source: func (m UsersAPIAuthMethod) LogoutURL(c context.Context, dest string) (string, error) {
	return user.LogoutURL(c, dest)
}
source: func (s *ConfigurationRecorder) SetRecordingGroup(v *RecordingGroup) *ConfigurationRecorder {
	s.RecordingGroup = v
	return s
}
source: func (c *testCluster) AddNode(n *testNode) error {
	c.counter++
	if err := c.runNode(n, c.counter); err != nil {
		c.counter--
		return err
	}
	c.nodes[n.node.NodeID()] = n
	c.nodesOrder[n.node.NodeID()] = c.counter
	return nil
}
source: func (a Args) Copy() Args {
	cpy := Args{}
	for _, t := range a {
		cpy = append(cpy, t.Copy())
	}
	return cpy
}
source: func NewExternalCATLSConfig(certs []tls.Certificate, rootPool *x509.CertPool) *tls.Config {
	return &tls.Config{
		Certificates: certs,
		RootCAs:      rootPool,
		MinVersion:   tls.VersionTLS12,
	}
}
source: func (c *ServerConn) NoOp() error {
	_, _, err := c.cmd(StatusCommandOK, "NOOP")
	return err
}
source: func (d *partialArray) set(key string, val *lazyNode) error {
	idx, err := strconv.Atoi(key)
	if err != nil {
		return err
	}
	(*d)[idx] = val
	return nil
}
source: func globalLogTags(args *pb.RunnerArgs) map[string]string {
	ret := make(map[string]string, 4)
	ret[logDogViewerURLTag] = fmt.Sprintf("https://%s/build/%d", args.BuildbucketHost, args.Build.Id)

	// SWARMING_SERVER is the full URL: https://example.com
	// We want just the hostname.
	env := environ.System()
	if v, ok := env.Get("SWARMING_SERVER"); ok {
		if u, err := url.Parse(v); err == nil && u.Host != "" {
			ret["swarming.host"] = u.Host
		}
	}
	if v, ok := env.Get("SWARMING_TASK_ID"); ok {
		ret["swarming.run_id"] = v
	}
	if v, ok := env.Get("SWARMING_BOT_ID"); ok {
		ret["swarming.bot_id"] = v
	}
	return ret
}
source: func (g *Gomo) Initialize(onStart func(glc *GLContext), onStop func(), updateCallback func()) {
	simlog.FuncIn()
	g.onStart = onStart
	g.onStop = onStop
	g.updateCallback = updateCallback
	g.screensize = screensize
	simlog.FuncOut()
}
source: func (n *NodeInfo) FilterOutPods(pods []*v1.Pod) []*v1.Pod {
	node := n.Node()
	if node == nil {
		return pods
	}
	filtered := make([]*v1.Pod, 0, len(pods))
	for _, p := range pods {
		if p.Spec.NodeName != node.Name {
			filtered = append(filtered, p)
			continue
		}
		// If pod is on the given node, add it to 'filtered' only if it is present in nodeInfo.
		podKey, _ := GetPodKey(p)
		for _, np := range n.Pods() {
			npodkey, _ := GetPodKey(np)
			if npodkey == podKey {
				filtered = append(filtered, p)
				break
			}
		}
	}
	return filtered
}
source: func NewAudit(info AppInfo, logger Logger, next http.Handler) *Audit {
	basePath := info.BasePath
	if basePath == "" {
		basePath = "/"
	}
	return &Audit{
		Logger:   logger,
		basePath: basePath,
		next:     next,
		info:     info,
	}
}
source: func expandConfig(c context.Context, payload proto.Message) error {
	task, ok := payload.(*tasks.ExpandConfig)
	switch {
	case !ok:
		return errors.Reason("unexpected payload type %T", payload).Err()
	case task.GetId() == "":
		return errors.Reason("ID is required").Err()
	}
	cfg, err := getConfig(c).Get(c, &config.GetRequest{Id: task.Id})
	if err != nil {
		return errors.Annotate(err, "failed to fetch config").Err()
	}
	now := clock.Now(c)
	amt, err := cfg.Amount.GetAmount(now)
	if err != nil {
		return errors.Annotate(err, "failed to parse amount").Err()
	}
	t := make([]*tq.Task, amt)
	for i := int32(0); i < amt; i++ {
		t[i] = &tq.Task{
			Payload: &tasks.CreateVM{
				Id:         fmt.Sprintf("%s-%d", cfg.Prefix, i),
				Attributes: cfg.Attributes,
				Config:     task.Id,
				Created: &timestamp.Timestamp{
					Seconds: now.Unix(),
				},
				Index:    i,
				Lifetime: cfg.Lifetime.GetSeconds(),
				Prefix:   cfg.Prefix,
				Revision: cfg.Revision,
				Swarming: cfg.Swarming,
				Timeout:  cfg.Timeout.GetSeconds(),
			},
		}
	}
	logging.Debugf(c, "creating %d VMs", len(t))
	if err := getDispatcher(c).AddTask(c, t...); err != nil {
		return errors.Annotate(err, "failed to schedule tasks").Err()
	}
	return nil
}
source: func (conn *gdbConn) getLoadedDynamicLibraries() ([]imageDescription, error) {
	cmd := []byte("$jGetLoadedDynamicLibrariesInfos:{\"fetch_all_solibs\":true}")
	if err := conn.send(cmd); err != nil {
		return nil, err
	}
	resp, err := conn.recv(cmd, "get dynamic libraries", true)
	if err != nil {
		return nil, err
	}
	var images imageList
	err = json.Unmarshal(resp, &images)
	return images.Images, err
}
source: func (p *gateway) setupEtcdServer(ctx context.Context, etcdCfg *embetcd.Config) (err error) {
	// if the cluster op is invalid short circuit and return
	if !(etcdCfg.ClusterState == embed.ClusterStateFlagExisting || etcdCfg.ClusterState == embed.ClusterStateFlagNew || etcdCfg.ClusterState == "") {
		return fmt.Errorf("unsupported cluster-op specified \"%s\"", etcdCfg.ClusterState)
	}

	// instantiate the etcdServer
	if etcdCfg.ClusterState != "" {
		p.etcdServer = embetcd.New()

		// set up the etcd server
		timeout, cancel := context.WithTimeout(ctx, time.Second*120)
		defer cancel()
		err = p.etcdServer.Start(timeout, etcdCfg)
	}

	return err
}
source: func (g *Container) ArrayElementP(index int, path string) (*Container, error) {
	return g.ArrayElement(index, strings.Split(path, ".")...)
}
source: func (config resolutionConfig) Covers(gr metav1.GroupResource) bool {
	for _, rule := range config.config.ResolutionRules {
		if resolutionRuleCoversResource(rule.TargetResource, gr) {
			return true
		}
	}
	return false
}
source: func initStorageDisks(endpoints EndpointList) ([]StorageAPI, error) {
	// Bootstrap disks.
	storageDisks := make([]StorageAPI, len(endpoints))
	for index, endpoint := range endpoints {
		storage, err := newStorageAPI(endpoint)
		if err != nil && err != errDiskNotFound {
			return nil, err
		}
		storageDisks[index] = storage
	}
	return storageDisks, nil
}
source: func NewWorker(config Config) (worker.Worker, error) {
	if err := config.Validate(); err != nil {
		return nil, errors.Trace(err)
	}
	w := &forwarder{
		config: config,
	}
	unsubscribe, err := w.config.Hub.Subscribe(w.config.Topic, w.handleRequest)
	if err != nil {
		return nil, errors.Annotatef(err, "subscribing to %q", w.config.Topic)
	}
	w.unsubscribe = unsubscribe
	if err := catacomb.Invoke(catacomb.Plan{
		Site: &w.catacomb,
		Work: w.loop,
	}); err != nil {
		unsubscribe()
		return nil, errors.Trace(err)
	}
	return w, nil
}
source: func NewShowcaseFileAddedDetails(EventUuid string) *ShowcaseFileAddedDetails {
	s := new(ShowcaseFileAddedDetails)
	s.EventUuid = EventUuid
	return s
}
source: func (s *TerminateProvisionedProductInput) SetTerminateToken(v string) *TerminateProvisionedProductInput {
	s.TerminateToken = &v
	return s
}
source: func (b *BufferedLogger) Flush() error {
	b.mu.Lock()
	b.mu.Unlock()
	return b.flush()
}
source: func snmpTranslate(oid string) (mibName string, oidNum string, oidText string, conversion string, err error) {
	snmpTranslateCachesLock.Lock()
	if snmpTranslateCaches == nil {
		snmpTranslateCaches = map[string]snmpTranslateCache{}
	}

	var stc snmpTranslateCache
	var ok bool
	if stc, ok = snmpTranslateCaches[oid]; !ok {
		// This will result in only one call to snmptranslate running at a time.
		// We could speed it up by putting a lock in snmpTranslateCache and then
		// returning it immediately, and multiple callers would then release the
		// snmpTranslateCachesLock and instead wait on the individual
		// snmpTranlsation.Lock to release. But I don't know that the extra complexity
		// is worth it. Especially when it would slam the system pretty hard if lots
		// of lookups are being perfomed.

		stc.mibName, stc.oidNum, stc.oidText, stc.conversion, stc.err = snmpTranslateCall(oid)
		snmpTranslateCaches[oid] = stc
	}

	snmpTranslateCachesLock.Unlock()

	return stc.mibName, stc.oidNum, stc.oidText, stc.conversion, stc.err
}
source: func (wg *WaitGroup) Wait() error {
	wg.counterLocker.Lock()
	defer wg.counterLocker.Unlock()

	var err error
Loop:
	for i, comp := range wg.pendingCompletions {
		select {
		case <-comp.Completed():
			err = updateError(err, comp.Err()) // Keep the most severe error value we encounter
			continue Loop
		case <-wg.ctx.Done():
			// Complete the remaining completions (if any) to make sure their completed
			// channels are closed.
			for _, comp := range wg.pendingCompletions[i:] {
				// 'comp' may have already completed on a different error
				compErr := comp.Complete(wg.ctx.Err())
				err = updateError(err, compErr) // Keep the most severe error value we encounter
			}
			break Loop
		}
	}
	wg.pendingCompletions = nil
	return err
}
source: func (v *view) deleteFragment(shard uint64) error {
	fragment := v.Fragment(shard)
	if fragment == nil {
		return ErrFragmentNotFound
	}

	v.logger.Printf("delete fragment: (%s/%s/%s) %d", v.index, v.field, v.name, shard)

	// Close data files before deletion.
	if err := fragment.Close(); err != nil {
		return errors.Wrap(err, "closing fragment")
	}

	// Delete fragment file.
	if err := os.Remove(fragment.path); err != nil {
		return errors.Wrap(err, "deleting fragment file")
	}

	// Delete fragment cache file.
	if err := os.Remove(fragment.cachePath()); err != nil {
		v.logger.Printf("no cache file to delete for shard %d", shard)
	}

	delete(v.fragments, shard)

	return nil
}
source: func DigestAuthParams(authorization string) map[string]string {
	s := strings.SplitN(authorization, " ", 2)
	if len(s) != 2 || s[0] != "Digest" {
		return nil
	}

	return ParsePairs(s[1])
}
source: func Convert_v1_OAuthRedirectReference_To_oauth_OAuthRedirectReference(in *v1.OAuthRedirectReference, out *oauth.OAuthRedirectReference, s conversion.Scope) error {
	return autoConvert_v1_OAuthRedirectReference_To_oauth_OAuthRedirectReference(in, out, s)
}
source: func (c *Config) LoadToDepth(ctx context.Context, qs graph.QuadStore, dst interface{}, depth int, ids ...quad.Value) error {
	if dst == nil {
		return fmt.Errorf("nil destination object")
	}
	var it graph.Iterator
	if len(ids) != 0 {
		fixed := iterator.NewFixed()
		for _, id := range ids {
			fixed.Add(qs.ValueOf(id))
		}
		it = fixed
	}
	var rv reflect.Value
	if v, ok := dst.(reflect.Value); ok {
		rv = v
	} else {
		rv = reflect.ValueOf(dst)
	}
	return c.LoadIteratorToDepth(ctx, qs, rv, depth, it)
}
source: func uint64FromKeyspaceID(keyspaceID []byte) uint64 {
	// Copy into 8 bytes because keyspaceID could be shorter.
	bits := make([]byte, 8)
	copy(bits, keyspaceID)
	return binary.BigEndian.Uint64(bits)
}
source: func (s *PresetWatermark) SetVerticalOffset(v string) *PresetWatermark {
	s.VerticalOffset = &v
	return s
}
source: func (cd service) Read(uuid string, transId string) (interface{}, bool, error) {
	var results []struct {
		content
	}

	query := &neoism.CypherQuery{
		Statement: `MATCH (n:Content {uuid:{uuid}})
			OPTIONAL MATCH (sp:Thing)-[rel1:IS_CURATED_FOR]->(n)
			OPTIONAL MATCH (n)-[rel2:CONTAINS]->(cp:Thing)
			WITH n,sp,cp
			return  n.uuid as uuid,
				n.title as title,
				n.publishedDate as publishedDate,
				sp.uuid as storyPackage,
				cp.uuid as contentPackage`,
		Parameters: map[string]interface{}{
			"uuid": uuid,
		},
		Result: &results,
	}

	err := cd.conn.CypherBatch([]*neoism.CypherQuery{query})

	if err != nil {
		return content{}, false, err
	}

	if len(results) == 0 {
		return content{}, false, nil
	}

	result := results[0]

	contentItem := content{
		UUID:           result.UUID,
		Title:          result.Title,
		PublishedDate:  result.PublishedDate,
		StoryPackage:   result.StoryPackage,
		ContentPackage: result.ContentPackage,
	}
	return contentItem, true, nil
}
source: func Concat(bss ...[]byte) []byte {
	offset := 0
	for _, bs := range bss {
		offset += len(bs)
	}
	bytes := make([]byte, offset)
	offset = 0
	for _, bs := range bss {
		for i, b := range bs {
			bytes[offset+i] = b
		}
		offset += len(bs)
	}
	return bytes
}
source: func NewChainIndexer(chainDb ethdb.Database, indexDb ethdb.Database, backend ChainIndexerBackend, section, confirm uint64, throttling time.Duration, kind string) *ChainIndexer {
	c := &ChainIndexer{
		chainDb:     chainDb,
		indexDb:     indexDb,
		backend:     backend,
		update:      make(chan struct{}, 1),
		quit:        make(chan chan error),
		sectionSize: section,
		confirmsReq: confirm,
		throttling:  throttling,
		log:         log.New("type", kind),
	}
	// Initialize database dependent fields and start the updater
	c.loadValidSections()
	c.ctx, c.ctxCancel = context.WithCancel(context.Background())

	go c.updateLoop()

	return c
}
source: func TryToDuration(i interface{}) (d time.Duration, err error) {
	switch v := i.(type) {
	case time.Duration:
		d = v
	case *time.Duration:
		d = *v
	case int64:
		d = time.Duration(v)
	case *int64:
		d = time.Duration(*v)
	case string:
		d, err = time.ParseDuration(v)
	case *string:
		d, err = time.ParseDuration(*v)
	default:
		err = castError(i, "time.Duration")
	}
	return
}
source: func (f *MaxReplicasFilter) SetTask(t *api.Task) bool {
	if t.Spec.Placement != nil && t.Spec.Placement.MaxReplicas > 0 {
		f.t = t
		return true
	}

	return false
}
source: func (c *Cluster) GetStoreByAddr(addr string) *metapb.Store {
	c.RLock()
	defer c.RUnlock()

	for _, s := range c.stores {
		if s.meta.GetAddress() == addr {
			return proto.Clone(s.meta).(*metapb.Store)
		}
	}
	return nil
}
source: func NewEvalContext(s State, p *structs.Plan, log log.Logger) *EvalContext {
	ctx := &EvalContext{
		state:   s,
		plan:    p,
		logger:  log,
		metrics: new(structs.AllocMetric),
	}
	return ctx
}
source: func (u *CachedUPAKLoader) Load(arg LoadUserArg) (*keybase1.UserPlusAllKeys, *User, error) {
	ret, user, err := u.loadWithInfo(arg, nil, nil, true)

	// NOTE -- it's OK to return an error and a user, since certain code paths
	// want both (see note in loadWithInfo).
	var converted *keybase1.UserPlusAllKeys
	if ret != nil {
		tmp := keybase1.UPAKFromUPKV2AI(*ret)
		converted = &tmp
	}

	return converted, user, err
}
source: func SetContentEncoding(contentEncoding string) RequestFunc {
	return func(ctx context.Context, pub *amqp.Publishing, _ *amqp.Delivery) context.Context {
		pub.ContentEncoding = contentEncoding
		return ctx
	}
}
source: func addPackageMirrorCmd(cfg CloudConfig, url string) string {
	return fmt.Sprintf(config.ReplaceCentOSMirror, url)
}
source: func NewManager(ts *topo.Server) *Manager {
	return &Manager{
		ts:          ts,
		nodeManager: NewNodeManager(),
		started:     make(chan struct{}),
		workflows:   make(map[string]*runningWorkflow),
	}
}
source: func newConfiguredProducer(logger *logrus.Entry, brokerString string, config *sarama.Config) (sarama.AsyncProducer, error) {
	brokerList := strings.Split(brokerString, ",")

	if len(brokerList) < 1 {
		logger.WithField("addrs", brokerString).Error("No brokers?")
		return nil, errors.New("No brokers in broker list")
	}

	logger.WithField("addrs", brokerList).Info("Connecting to Kafka")
	producer, err := sarama.NewAsyncProducer(brokerList, config)

	if err != nil {
		logger.Error("Error Connecting to Kafka. client error: ", err)
	}

	return producer, nil
}
source: func (s *cinderVolumeSource) DescribeVolumes(ctx context.ProviderCallContext, volumeIds []string) ([]storage.DescribeVolumesResult, error) {
	// In most cases, it is quicker to get all volumes and loop
	// locally than to make several round-trips to the provider.
	cinderVolumes, err := s.storageAdapter.GetVolumesDetail()
	if err != nil {
		common.HandleCredentialError(IsAuthorisationFailure, err, ctx)
		return nil, errors.Trace(err)
	}
	volumesById := make(map[string]*cinder.Volume)
	for i, volume := range cinderVolumes {
		volumesById[volume.ID] = &cinderVolumes[i]
	}
	results := make([]storage.DescribeVolumesResult, len(volumeIds))
	for i, volumeId := range volumeIds {
		cinderVolume, ok := volumesById[volumeId]
		if !ok {
			results[i].Error = errors.NotFoundf("volume %q", volumeId)
			continue
		}
		info := cinderToJujuVolumeInfo(cinderVolume)
		results[i].VolumeInfo = &info
	}
	return results, nil
}
source: func (f *Function) Update(zip []byte) error {
	f.Log.Info("updating function")

	updated, err := f.Service.UpdateFunctionCode(&lambda.UpdateFunctionCodeInput{
		FunctionName: &f.FunctionName,
		Publish:      aws.Bool(true),
		ZipFile:      zip,
	})

	if err != nil {
		return err
	}

	if err := f.CreateOrUpdateAlias(f.Alias, *updated.Version); err != nil {
		return err
	}

	f.Log.WithFields(log.Fields{
		"version": *updated.Version,
		"name":    f.FunctionName,
	}).Info("function updated")

	return f.cleanup()
}
source: func ConnectBucket(serverURL, poolName, bucketName string,
	auth couchbase.AuthHandler) (Bucket, error) {
	var bucket *couchbase.Bucket
	var err error

	if auth != nil {
		bucket, err = couchbase.ConnectWithAuthAndGetBucket(serverURL, poolName, bucketName, auth)
	} else {
		bucket, err = couchbase.GetBucket(serverURL, poolName, bucketName)
	}
	if err != nil {
		return nil, err
	}
	if bucket == nil {
		return nil, fmt.Errorf("unknown bucket,"+
			" serverURL: %s, bucketName: %s", serverURL, bucketName)
	}

	return &bucketWrapper{b: bucket}, nil
}
source: func (s *GlobalConfiguration) SetInputEndAction(v string) *GlobalConfiguration {
	s.InputEndAction = &v
	return s
}
source: func (r *ReaderCloser) Read(p []byte) (int, error) {
	count, err := unix.Read(r.fd, p)
	if count < 0 && err != nil {
		count = 0
	}
	return count, err
}
source: func yaml_parser_set_input_file(parser *yaml_parser_t, file *os.File) {
	if parser.read_handler != nil {
		panic("must set the input source only once")
	}
	parser.read_handler = yaml_file_read_handler
	parser.input_file = file
}
source: func DefaultConfigDir() string {
	// Try to place the data folder in the user's home dir
	home := homeDir()
	if home != "" {
		if runtime.GOOS == "darwin" {
			return filepath.Join(home, "Library", "Signer")
		} else if runtime.GOOS == "windows" {
			appdata := os.Getenv("APPDATA")
			if appdata != "" {
				return filepath.Join(appdata, "Signer")
			} else {
				return filepath.Join(home, "AppData", "Roaming", "Signer")
			}
		} else {
			return filepath.Join(home, ".clef")
		}
	}
	// As we cannot guess a stable location, return empty and handle later
	return ""
}
source: func (s *Scheme) ConvertFieldLabel(gvk schema.GroupVersionKind, label, value string) (string, string, error) {
	conversionFunc, ok := s.fieldLabelConversionFuncs[gvk]
	if !ok {
		return DefaultMetaV1FieldSelectorConversion(label, value)
	}
	return conversionFunc(label, value)
}
source: func NewSession(name, addr, keyfile string) Session {
	return &samSession{
		name:       name,
		addr:       addr,
		minversion: "3.0",
		maxversion: "3.0",
		keys:       NewKeyfile(keyfile),
	}
}
source: func (c *RawKVClient) BatchDelete(keys [][]byte) error {
	start := time.Now()
	defer func() {
		tikvRawkvCmdHistogramWithBatchDelete.Observe(time.Since(start).Seconds())
	}()

	bo := NewBackoffer(context.Background(), rawkvMaxBackoff)
	resp, err := c.sendBatchReq(bo, keys, tikvrpc.CmdRawBatchDelete)
	if err != nil {
		return errors.Trace(err)
	}
	cmdResp := resp.RawBatchDelete
	if cmdResp == nil {
		return errors.Trace(ErrBodyMissing)
	}
	if cmdResp.GetError() != "" {
		return errors.New(cmdResp.GetError())
	}
	return nil
}
source: func IsLoopback(addr string) bool {
	for _, loopback := range loopBackAddrs {
		if strings.Contains(addr, loopback) {
			return true
		}
	}

	return false
}
source: func (c *Client) GetRecordID(domainID, recordName, recordType, data string) (string, error) {
	recordList := &RecordListResponse{}

	err := c.do(http.MethodGet, fmt.Sprintf("/v1/domains/%s/records", domainID), nil, recordList)
	if err != nil {
		return "", err
	}

	for _, record := range recordList.Records {
		if record.Name == recordName && record.Type == recordType && record.Data == data {
			return record.ID, nil
		}
	}
	return "", errors.New("no such record")
}
source: func NewDNSProviderConfig(config *Config) (*DNSProvider, error) {
	if config == nil {
		return nil, errors.New("dnspod: the configuration of the DNS provider is nil")
	}

	if config.LoginToken == "" {
		return nil, fmt.Errorf("dnspod: credentials missing")
	}

	params := dnspod.CommonParams{LoginToken: config.LoginToken, Format: "json"}

	client := dnspod.NewClient(params)
	client.HttpClient = config.HTTPClient

	return &DNSProvider{client: client, config: config}, nil
}
source: func (m *RateLimitDescriptor_Entry) Validate() error {
	if m == nil {
		return nil
	}

	if len(m.GetKey()) < 1 {
		return RateLimitDescriptor_EntryValidationError{
			field:  "Key",
			reason: "value length must be at least 1 bytes",
		}
	}

	if len(m.GetValue()) < 1 {
		return RateLimitDescriptor_EntryValidationError{
			field:  "Value",
			reason: "value length must be at least 1 bytes",
		}
	}

	return nil
}
source: func (b *BoolWrapper) UnmarshalXMLAttr(attr xml.Attr) error {
	*b = false
	if strings.ToLower(attr.Value) == "true" {
		*b = true
	}

	return nil
}
source: func (e *Engine) distributeOverride(o seesaw.Override) {
	// Send VserverOverrides and DestinationOverrides to the appropriate vserver.
	// Send BackendOverrides to all vservers.
	switch override := o.(type) {
	case *seesaw.VserverOverride:
		if vserver, ok := e.vservers[override.VserverName]; ok {
			vserver.queueOverride(o)
		}
	case *seesaw.DestinationOverride:
		if vserver, ok := e.vservers[override.VserverName]; ok {
			vserver.queueOverride(o)
		}
	case *seesaw.BackendOverride:
		for _, vserver := range e.vservers {
			vserver.queueOverride(o)
		}
	}
}
source: func checkControllerInheritedConfig(attrs attrValues) error {
	disallowedCloudConfigAttrs := append(disallowedModelConfigAttrs[:], config.AgentVersionKey)
	for _, attr := range disallowedCloudConfigAttrs {
		if _, ok := attrs[attr]; ok {
			return errors.Errorf("local cloud config cannot contain " + attr)
		}
	}
	for attrName := range attrs {
		if controller.ControllerOnlyAttribute(attrName) {
			return errors.Errorf("local cloud config cannot contain controller attribute %q", attrName)
		}
	}
	return nil
}
source: func NewMockRPCJob(ctrl *gomock.Controller) *MockRPCJob {
	mock := &MockRPCJob{ctrl: ctrl}
	mock.recorder = &MockRPCJobMockRecorder{mock}
	return mock
}
source: func (f Firewall) convertApplicationToPortRange(app response.SecApplication) corenetwork.PortRange {
	appCopy := app
	if appCopy.Value2 == -1 {
		appCopy.Value2 = appCopy.Value1
	}
	return corenetwork.PortRange{
		FromPort: appCopy.Value1,
		ToPort:   appCopy.Value2,
		Protocol: string(appCopy.Protocol),
	}
}
source: func TryConnectEndpoints(service proxy.ServicePortName, srcAddr net.Addr, protocol string, loadBalancer LoadBalancer) (out net.Conn, err error) {
	sessionAffinityReset := false
	for _, dialTimeout := range EndpointDialTimeouts {
		endpoint, err := loadBalancer.NextEndpoint(service, srcAddr, sessionAffinityReset)
		if err != nil {
			klog.Errorf("Couldn't find an endpoint for %s: %v", service, err)
			return nil, err
		}
		klog.V(3).Infof("Mapped service %q to endpoint %s", service, endpoint)
		// TODO: This could spin up a new goroutine to make the outbound connection,
		// and keep accepting inbound traffic.
		outConn, err := net.DialTimeout(protocol, endpoint, dialTimeout)
		if err != nil {
			if isTooManyFDsError(err) {
				panic("Dial failed: " + err.Error())
			}
			klog.Errorf("Dial failed: %v", err)
			sessionAffinityReset = true
			continue
		}
		return outConn, nil
	}
	return nil, fmt.Errorf("failed to connect to an endpoint.")
}
source: func (o *GetDebuginfoParams) WithHTTPClient(client *http.Client) *GetDebuginfoParams {
	o.SetHTTPClient(client)
	return o
}
source: func NewWithPrefix(client *etcd3.Client, prefix string) (*Etcd3Locker, error) {
	lockerOptions := DefaultLockerOptions()
	lockerOptions.SetPrefix(prefix)
	return NewWithLockerOptions(client, lockerOptions)
}
source: func WithDialTimeout(d time.Duration) CallOption {
	return func(o *CallOptions) {
		o.DialTimeout = d
	}
}
source: func (e *Engine) VirtualizationRemove(ctx context.Context, ID string, removeVolumes, force bool) error {
	return e.client.ContainerRemove(ctx, ID, dockertypes.ContainerRemoveOptions{RemoveVolumes: removeVolumes, Force: force})
}
source: func (b *Broker) collectMessages(in <-chan Message) {
	for {
		msg := <-in
		b.queue.Push(&msg)
	}
}
source: func (i *Image) Tags() []string {
	result := make([]string, 0)

	for tag, _ := range i.tags {
		result = append(result, tag)
	}

	return result
}
source: func (enc *Encoder) AddBoolKey(key string, v bool) {
	enc.BoolKey(key, v)
}
source: func GetRouter(ctx ttnlog.Interface) (*grpc.ClientConn, *routerclient.Client) {
	ctx.Info("Discovering Router...")
	dscConn, client := GetDiscovery(ctx)
	defer dscConn.Close()
	routerAnnouncement, err := client.Get(GetContext(ctx), &discovery.GetRequest{
		ServiceName: "router",
		ID:          viper.GetString("router-id"),
	})
	if err != nil {
		ctx.WithError(errors.FromGRPCError(err)).Fatal("Could not get Router from Discovery")
	}
	ctx.Info("Connecting with Router...")
	rtrConn, err := routerAnnouncement.Dial(nil)
	ctx.Info("Connected to Router")
	rtrClient := routerclient.NewClient(routerclient.DefaultClientConfig)
	rtrClient.AddServer(viper.GetString("router-id"), rtrConn)
	return rtrConn, rtrClient
}
source: func (store *store) Leases(keys ...lease.Key) map[lease.Key]lease.Info {
	cfg := store.config
	limit := set.NewStrings()

	// Do a single pass over the keys for model and namespace.
	// This lets us use a set for filtering on lease name when we iterate
	// over the collection of leases.
	filtering := len(keys) > 0
	if filtering {
		for _, key := range keys {
			if key.Namespace == cfg.Namespace && key.ModelUUID == cfg.ModelUUID {
				limit.Add(key.Lease)
			}
		}
	}

	store.mu.Lock()
	localTime := store.config.LocalClock.Now()
	leases := make(map[lease.Key]lease.Info)
	for name, entry := range store.entries {
		if filtering && !limit.Contains(name) {
			continue
		}

		globalExpiry := entry.start.Add(entry.duration)
		remaining := globalExpiry.Sub(store.globalTime)
		localExpiry := localTime.Add(remaining)
		key := lease.Key{
			Namespace: store.config.Namespace,
			ModelUUID: store.config.ModelUUID,
			Lease:     name,
		}
		leases[key] = lease.Info{
			Holder:   entry.holder,
			Expiry:   localExpiry,
			Trapdoor: store.assertOpTrapdoor(name, entry.holder),
		}
	}
	defer store.mu.Unlock()

	return leases
}
source: func (imd *IMDraw) Rectangle(thickness float64) {
	if thickness == 0 {
		imd.fillRectangle()
	} else {
		imd.outlineRectangle(thickness)
	}
}
source: func (r Region) Combine(r2 Region) Region {
	return Region{Min(r.From, r2.From), Max(r.To, r2.To), r.Dir}
}
source: func (f *TranslatorFactory) GetTranslator(localeCode string) (t *Translator, errors []error) {

	fallback := f.getFallback(localeCode)

	if t, ok := f.translators[localeCode]; ok {
		return t, nil
	}

	exists, errs := f.LocaleExists(localeCode)
	if !exists {
		errors = append(errors, translatorError{message: "could not find rules and messages for locale " + localeCode})
	}
	for _, e := range errs {
		errors = append(errors, e)
	}

	rules := new(TranslatorRules)
	files := []string{}

	// TODO: the rules loading logic is fairly complex, and there are some
	// specific cases we are not testing for yet. We need to test that the
	// fallback locale rules do not influence the rules loaded, and that the
	// base rules do.

	// the load the base (default) rule values
	// the step above
	for _, p := range f.rulesPaths {
		p = strings.TrimRight(p, pathSeparator)
		files = append(files, p+pathSeparator+"root.yaml")
	}

	// load less specific fallback locale rules
	parts := strings.Split(localeCode, "-")
	if len(parts) > 1 {
		for i, _ := range parts {
			fb := strings.Join(parts[0:i+1], "-")
			for _, p := range f.rulesPaths {
				p = strings.TrimRight(p, pathSeparator)
				files = append(files, p+pathSeparator+fb+".yaml")
			}
		}
	}

	// finally load files for this specific locale
	for _, p := range f.rulesPaths {
		p = strings.TrimRight(p, pathSeparator)
		files = append(files, p+pathSeparator+localeCode+".yaml")
	}

	errs = rules.load(files)
	for _, err := range errs {
		errors = append(errors, err)
	}

	messages, errs := loadMessages(localeCode, f.messagesPaths)
	for _, err := range errs {
		errors = append(errors, err)
	}

	t = new(Translator)
	t.locale = localeCode
	t.messages = messages
	t.fallback = fallback
	t.rules = rules

	f.translators[localeCode] = t

	return
}
source: func EventTypes() []string {
	es := make([]string, 0, len(eventTypes))
	for k := range eventTypes {
		es = append(es, k)
	}
	return es
}
source: func (c *CloudPersister) ListGameTypes() ([]*models.GameType, error) {
	ctx := context.Background()
	GameTypes := make([]*models.GameType, 0)
	q := datastore.NewQuery("GameType")

	keys, err := c.DatastoreClient().GetAll(ctx, q, &GameTypes)

	if err != nil {
		return nil, fmt.Errorf("datastoredb: could not list GameTypes: %v", err)
	}

	for i, k := range keys {
		GameTypes[i].ID = k.ID()
	}

	return GameTypes, nil
}
source: func GetInfo(name string) (*Info, error) {
	task, err := TaskCreateNamed(deviceInfo, name)
	if task == nil {
		return nil, err
	}
	if err := task.run(); err != nil {
		return nil, err
	}
	return task.getInfo()
}
source: func (filterHandler *FilterHandler) Event(logEvent *event.Event) error {
	for _, filterFunc := range filterHandler.filterFuncs {
		if !filterFunc(logEvent) {
			return nil
		}
	}
	return filterHandler.nextHandler.Event(logEvent)
}
source: func (n *NSQD) channels() []*Channel {
	var channels []*Channel
	n.RLock()
	for _, t := range n.topicMap {
		t.RLock()
		for _, c := range t.channelMap {
			channels = append(channels, c)
		}
		t.RUnlock()
	}
	n.RUnlock()
	return channels
} 45%|████▌     | 2259/5000 [00:02<00:03, 764.72it/s] 
source: func newResponse(msgData []byte, endpoint string, rawResponse *[]byte) (*vstResponse, error) {
	// Decode header
	hdr := velocypack.Slice(msgData)
	if err := hdr.AssertType(velocypack.Array); err != nil {
		return nil, driver.WithStack(err)
	}
	//panic("hdr: " + hex.EncodeToString(hdr))
	var hdrLen velocypack.ValueLength
	if l, err := hdr.Length(); err != nil {
		return nil, driver.WithStack(err)
	} else if l < 3 {
		return nil, driver.WithStack(fmt.Errorf("Expected a header of 3 elements, got %d", l))
	} else {
		hdrLen = l
	}

	resp := &vstResponse{
		endpoint: endpoint,
	}
	// Decode version
	if elem, err := hdr.At(0); err != nil {
		return nil, driver.WithStack(err)
	} else if version, err := elem.GetInt(); err != nil {
		return nil, driver.WithStack(err)
	} else {
		resp.Version = int(version)
	}
	// Decode type
	if elem, err := hdr.At(1); err != nil {
		return nil, driver.WithStack(err)
	} else if tp, err := elem.GetInt(); err != nil {
		return nil, driver.WithStack(err)
	} else {
		resp.Type = int(tp)
	}
	// Decode responseCode
	if elem, err := hdr.At(2); err != nil {
		return nil, driver.WithStack(err)
	} else if code, err := elem.GetInt(); err != nil {
		return nil, driver.WithStack(err)
	} else {
		resp.ResponseCode = int(code)
	}
	// Decode meta
	if hdrLen >= 4 {
		if elem, err := hdr.At(3); err != nil {
			return nil, driver.WithStack(err)
		} else if !elem.IsObject() {
			return nil, driver.WithStack(fmt.Errorf("Expected meta field to be of type Object, got %s", elem.Type()))
		} else {
			resp.meta = elem
		}
	}

	// Fetch body directly after hdr
	if body, err := hdr.Next(); err != nil {
		return nil, driver.WithStack(err)
	} else {
		resp.slice = body
		if rawResponse != nil {
			*rawResponse = body
		}
	}
	//fmt.Printf("got response: code=%d, body=%s\n", resp.ResponseCode, hex.EncodeToString(resp.slice))
	return resp, nil
}
source: func (oe *V1Exporter) Export(ctx context.Context, store content.Provider, desc ocispec.Descriptor, writer io.Writer) error {
	tw := tar.NewWriter(writer)
	defer tw.Close()

	records := []tarRecord{
		ociLayoutFile(""),
		ociIndexRecord(desc),
	}

	algorithms := map[string]struct{}{}
	exportHandler := func(ctx context.Context, desc ocispec.Descriptor) ([]ocispec.Descriptor, error) {
		records = append(records, blobRecord(store, desc))
		algorithms[desc.Digest.Algorithm().String()] = struct{}{}
		return nil, nil
	}

	childrenHandler := images.ChildrenHandler(store)

	if !oe.AllPlatforms {
		// get local default platform to fetch image manifest
		childrenHandler = images.FilterPlatforms(childrenHandler, platforms.Any(platforms.DefaultSpec()))
	}

	handlers := images.Handlers(
		childrenHandler,
		images.HandlerFunc(exportHandler),
	)

	// Walk sequentially since the number of fetchs is likely one and doing in
	// parallel requires locking the export handler
	if err := images.Walk(ctx, handlers, desc); err != nil {
		return err
	}

	if len(algorithms) > 0 {
		records = append(records, directoryRecord("blobs/", 0755))
		for alg := range algorithms {
			records = append(records, directoryRecord("blobs/"+alg+"/", 0755))
		}
	}

	return writeTar(ctx, tw, records)
}
source: func (a *AuthContext) CreateRemoteRelationMacaroon(sourceModelUUID, offerUUID string, username string, rel names.Tag) (*macaroon.Macaroon, error) {
	expiryTime := a.clock.Now().Add(localOfferPermissionExpiryTime)
	bakery, err := a.localOfferBakeryService.ExpireStorageAfter(localOfferPermissionExpiryTime)
	if err != nil {
		return nil, errors.Trace(err)
	}

	offerMacaroon, err := bakery.NewMacaroon(
		[]checkers.Caveat{
			checkers.TimeBeforeCaveat(expiryTime),
			checkers.DeclaredCaveat(sourcemodelKey, sourceModelUUID),
			checkers.DeclaredCaveat(offeruuidKey, offerUUID),
			checkers.DeclaredCaveat(usernameKey, username),
			checkers.DeclaredCaveat(relationKey, rel.Id()),
		})

	return offerMacaroon, err
}
source: func New() *Client {
	return &Client{
		Concurrency:    DefaultClient.Concurrency,
		MaxRetries:     DefaultClient.MaxRetries,
		Backoff:        DefaultClient.Backoff,
		ErrLog:         DefaultClient.ErrLog,
		wg:             &sync.WaitGroup{},
		RetryOnHTTP429: false,
	}
}
source: func (p *OpenPrinter) ClaimPDF() ([]byte, error) {
	data, err := httpGET(&p.auth, p.register.InvitePageURL)
	if err != nil {
		return nil, fmt.Errorf("ClaimPDF: %v", err)
	}
	return data, nil
}
source: func NewTreePool(hasher BaseHasherFunc, segmentCount, capacity int) *TreePool {
	// initialises the zerohashes lookup table
	depth := calculateDepthFor(segmentCount)
	segmentSize := hasher().Size()
	zerohashes := make([][]byte, depth+1)
	zeros := make([]byte, segmentSize)
	zerohashes[0] = zeros
	h := hasher()
	for i := 1; i < depth+1; i++ {
		zeros = doSum(h, nil, zeros, zeros)
		zerohashes[i] = zeros
	}
	return &TreePool{
		c:            make(chan *tree, capacity),
		hasher:       hasher,
		SegmentSize:  segmentSize,
		SegmentCount: segmentCount,
		Capacity:     capacity,
		Size:         segmentCount * segmentSize,
		Depth:        depth,
		zerohashes:   zerohashes,
	}
}
source: func (n *Network) OrgsForOrderers(ordererNames []string) []*Organization {
	orgsByName := map[string]*Organization{}
	for _, name := range ordererNames {
		orgName := n.Orderer(name).Organization
		orgsByName[orgName] = n.Organization(orgName)
	}
	orgs := []*Organization{}
	for _, org := range orgsByName {
		orgs = append(orgs, org)
	}
	return orgs
}
source: func (s *TemplateService) GetUploadParamsForTemplate(p *GetUploadParamsForTemplateParams) (*GetUploadParamsForTemplateResponse, error) {
	resp, err := s.cs.newRequest("getUploadParamsForTemplate", p.toURLValues())
	if err != nil {
		return nil, err
	}

	var r GetUploadParamsForTemplateResponse
	if err := json.Unmarshal(resp, &r); err != nil {
		return nil, err
	}

	return &r, nil
}
source: func DecimalDiv(from1, from2, to *MyDecimal, fracIncr int) error {
	to.resultFrac = myMinInt8(from1.resultFrac+int8(fracIncr), MaxFraction)
	return doDivMod(from1, from2, to, nil, fracIncr)
}
source: func nonBlankLines(text string) []string {
	var out []string
	for _, s := range lines(text) {
		if strings.TrimSpace(s) != "" {
			out = append(out, s)
		}
	}
	return out
}
source: func (h *Holder) monitorCacheFlush() {
	ticker := time.NewTicker(h.cacheFlushInterval)
	defer ticker.Stop()

	for {
		select {
		case <-h.closing:
			return
		case <-ticker.C:
			h.flushCaches()
		}
	}
}
source: func (n *NomadAgent) Destroy() error {
	if err := n.Stop(); err != nil {
		return err
	}
	return os.RemoveAll(n.DataDir)
}
source: func (it *RangeIter) Value() Range {
	if it.cur == nil {
		return Range{}
	}
	return it.cur.Value.(Range)
}
source: func ConvertMaskHexToDotString(hexMask net.IPMask) string {
	var strMask string // dec mask (255.255.255.0 for example)
	var octet int      // octet (255 for example)
	var ok bool
	maxOctet := 4 // IPv4 consists of 4 octets

	for i := 0; i < maxOctet; i++ {
		if octet, ok = HexToDec(fmt.Sprintf("%s", (hexMask[i:i+1])), 0); !ok {
			return ""
			//log.Fatalf("wrong mask is provided %s ", hexMask[:])
		}
		// in case it's the last octet add do not add '.'
		if i == (maxOctet - 1) {
			strMask += fmt.Sprintf("%d", octet)
		} else {
			strMask += fmt.Sprintf("%d.", octet)
		}
	}
	// return mask represented as dec
	return strMask
}
source: func hashish(x string) bool {
	_, err := strconv.Atoi(x)
	return err != nil
}
source: func (r *Reader) ReadString() string {
	tag := r.readByte()
	decoder := stringDecoders[tag]
	if decoder == nil {
		castError(tag, "string")
	}
	return decoder(r)
}
source: func (s *Site) getLanguageTargetPathLang(alwaysInSubDir bool) string {
	if s.h.IsMultihost() {
		return s.Language().Lang
	}

	return s.getLanguagePermalinkLang(alwaysInSubDir)
}
source: func NewEventuallyConsistentTeamQuotaUsage(
	config Config, tid keybase1.TeamID,
	log logger.Logger, vlog *libkb.VDebugLog) *EventuallyConsistentQuotaUsage {
	q := NewEventuallyConsistentQuotaUsage(config, log, vlog)
	q.tid = tid
	return q
}
source: func bytesToUintLittleEndian(b []byte) (res uint64) {
	mul := uint64(1)
	for i := 0; i < len(b); i++ {
		res += uint64(b[i]) * mul
		mul *= 256
	}
	return res
}
source: func (b *BigIP) AddCertificate(cert *Certificate) error {
	return b.post(cert, uriSys, uriFile, uriSslCert)
}
source: func (a *Agent) Start() error {
	a.logger.Printf("[INFO] agent: Serf agent starting")

	// Create serf first
	serf, err := serf.Create(a.conf)
	if err != nil {
		return fmt.Errorf("Error creating Serf: %s", err)
	}
	a.serf = serf

	// Start event loop
	go a.eventLoop()
	return nil
}
source: func (b *BaseCommand) PredictVaultPlugins(pluginTypes ...consts.PluginType) complete.Predictor {
	return NewPredict().VaultPlugins(pluginTypes...)
}
source: func (s *ZoneService) NewDedicateZoneParams(domainid string, zoneid string) *DedicateZoneParams {
	p := &DedicateZoneParams{}
	p.p = make(map[string]interface{})
	p.p["domainid"] = domainid
	p.p["zoneid"] = zoneid
	return p
}
source: func CreateHandlers(rootPath string, provider Provider, summaryProvider SummaryProvider) *restful.WebService {
	h := &handler{provider, summaryProvider}

	ws := &restful.WebService{}
	ws.Path(rootPath).
		Produces(restful.MIME_JSON)

	endpoints := []struct {
		path    string
		handler restful.RouteFunction
	}{
		{"", h.handleStats},
		{"/summary", h.handleSummary},
		{"/container", h.handleSystemContainer},
		{"/{podName}/{containerName}", h.handlePodContainer},
		{"/{namespace}/{podName}/{uid}/{containerName}", h.handlePodContainer},
	}

	for _, e := range endpoints {
		for _, method := range []string{"GET", "POST"} {
			ws.Route(ws.
				Method(method).
				Path(e.path).
				To(e.handler))
		}
	}

	return ws
}
source: func (ac *AddressCache) HistoryChart(addr string, addrChart dbtypes.HistoryChart,
	chartGrouping dbtypes.TimeBasedGrouping) (*dbtypes.ChartsData, *BlockID) {
	aci := ac.addressCacheItem(addr)
	if aci == nil {
		ac.cacheMetrics.HistoryMiss()
		return nil, nil
	}

	cd, blockID := aci.HistoryChart(addrChart, chartGrouping)
	if cd == nil || blockID == nil {
		ac.cacheMetrics.HistoryMiss()
		return nil, nil
	}

	ac.cacheMetrics.HistoryHit()
	return cd, blockID
}
source: func ConvertPath(path string) (*Response, error) {
	mimeType := MimeTypeByExtension(path)

	f, err := os.Open(path)
	if err != nil {
		return nil, err
	}
	defer f.Close()

	return Convert(f, mimeType, true)
}
source: func (tpl *Template) Execute(context Context) (string, error) {
	// Execute template
	buffer, err := tpl.newBufferAndExecute(context)
	if err != nil {
		return "", err
	}

	return buffer.String(), nil

}
source: func (dec *Decoder) Decode() (m *Message, err error) {

	dec.mu.Lock()
	dec.line, err = dec.reader.ReadString(delim)
	dec.mu.Unlock()

	if err != nil {
		return nil, err
	}

	return ParseMessage(dec.line), nil
}
source: func (ot *orderedTree) add(entry Entry) *node {
	var node *node
	list := &ot.top

	for i := uint64(1); i <= ot.dimensions; i++ {
		if isLastDimension(ot.dimensions, i) {
			overwritten := list.add(
				newNode(entry.ValueAtDimension(i), entry, false),
			)
			if overwritten == nil {
				ot.number++
			}
			return overwritten
		}
		node, _ = list.getOrAdd(entry, i, ot.dimensions)
		list = &node.orderedNodes
	}

	return nil
}
source: func (c *Client) StorageGeneration() (string, error) {
	if err := c.condDiscovery(); err != nil {
		return "", err
	}
	if c.storageGen == "" {
		return "", ErrNoStorageGeneration
	}
	return c.storageGen, nil
}
source: func (c *Client) PutMaster(name string, client *redis.Client) {
	c.putCh <- &putReq{name, client}
}
source: func (s *VolumeStatistics) SetProjectedInbox(v int64) *VolumeStatistics {
	s.ProjectedInbox = &v
	return s
}
source: func (l *tomlLexer) lexInsideTableArrayKey() tomlLexStateFn {
	for r := l.peek(); r != eof; r = l.peek() {
		switch r {
		case ']':
			if l.currentTokenStop > l.currentTokenStart {
				l.emit(tokenKeyGroupArray)
			}
			l.next()
			if l.peek() != ']' {
				break
			}
			l.next()
			l.emit(tokenDoubleRightBracket)
			return l.lexVoid
		case '[':
			return l.errorf("table array key cannot contain ']'")
		default:
			l.next()
		}
	}
	return l.errorf("unclosed table array key")
}
source: func (f Filter) NotStartsWith(val interface{}) Filter {
	f.Op = "!^="
	f.Val = val
	return f
}
source: func (s *QueryExecution) SetStatementType(v string) *QueryExecution {
	s.StatementType = &v
	return s
}
source: func NewSchemaValidator(schema *spec.Schema, rootSchema interface{}, root string, formats strfmt.Registry, options ...Option) *SchemaValidator {
	if schema == nil {
		return nil
	}

	if rootSchema == nil {
		rootSchema = schema
	}

	if schema.ID != "" || schema.Ref.String() != "" || schema.Ref.IsRoot() {
		err := spec.ExpandSchema(schema, rootSchema, nil)
		if err != nil {
			msg := invalidSchemaProvidedMsg(err).Error()
			panic(msg)
		}
	}
	s := SchemaValidator{Path: root, in: "body", Schema: schema, Root: rootSchema, KnownFormats: formats, Options: &SchemaValidatorOptions{}}
	for _, o := range options {
		o(s.Options)
	}
	s.validators = []valueValidator{
		s.typeValidator(),
		s.schemaPropsValidator(),
		s.stringValidator(),
		s.formatValidator(),
		s.numberValidator(),
		s.sliceValidator(),
		s.commonValidator(),
		s.objectValidator(),
	}
	return &s
}
source: func ToString(i interface{}) string {
	if i == nil {
		return ""
	}

	if s, ok := i.(string); ok {
		return s
	}

	if sl, ok := i.([]string); ok {
		if len(sl) == 1 {
			return sl[0]
		}
	}

	return ""
}
source: func SVGTriangle(m Marker, b *bytes.Buffer) {
	w := int(m.size / 2)
	h := w * 2
	c := int(float64(h) * 0.33)

	b.WriteString(fmt.Sprintf("<g id=\"%s\"><path d=\"M%d %d l%d 0 l-%d -%d l-%d %d Z\" fill=\"%s\" opacity=\"0.5\">",
		m.id, int(m.x), int(m.y)+c, w, w, h, w, h, m.svgColour))
	b.WriteString(`<desc>` + m.label + `.</desc>`)
	b.WriteString(fmt.Sprint(`<set attributeName="opacity" from="0.5" to="1" begin="mouseover" end="mouseout"  dur="2s"/></path>`))
	b.WriteString(fmt.Sprintf("<path d=\"M%d %d l%d 0 l-%d -%d l-%d %d Z\" stroke=\"%s\" stroke-width=\"1\" fill=\"none\" opacity=\"1\" /></g>",
		int(m.x), int(m.y)+c, w, w, h, w, h, m.svgColour))
}
source: func (f *Factory) BindFlags(flags *pflag.FlagSet) {
	// any flags defined by external projects (not part of pflags)
	flags.AddGoFlagSet(flag.CommandLine)

	// Merge factory's flags
	flags.AddFlagSet(f.flags)

	// Globally persistent flags across all subcommands.
	// TODO Change flag names to consts to allow safer lookup from subcommands.
	// TODO Add a verbose flag that turns on glog logging. Probably need a way
	// to do that automatically for every subcommand.
	flags.BoolVar(&f.clients.matchVersion, FlagMatchBinaryVersion, false, "Require server version to match client version")

	// Normalize all flags that are coming from other packages or pre-configurations
	// a.k.a. change all "_" to "-". e.g. glog package
	flags.SetNormalizeFunc(util.WordSepNormalizeFunc)
}
source: func (s *IndicesAnalyzeService) Attributes(attributes ...string) *IndicesAnalyzeService {
	s.request.Attributes = attributes
	return s
}
source: func addNICCmd(params *Parameters) *subcommands.Command {
	return &subcommands.Command{
		UsageLine: "add-nic -name <name> -machine <machine> -mac <mac address> -switch <switch> [-port <switch port>] [-host <hostname>] [-ip <ip address>]",
		ShortDesc: "adds a NIC",
		LongDesc:  "Adds a network interface to the database.\n\nExample:\ncrimson add-nic -name eth0 -machine xx1-01-720 -mac 00:00:00:00:00:bc -switch switch1.lab -port 30",
		CommandRun: func() subcommands.CommandRun {
			cmd := &AddNICCmd{}
			cmd.Initialize(params)
			cmd.Flags.StringVar(&cmd.nic.Name, "name", "", "The name of the NIC. Required and must be unique per machine within the database.")
			cmd.Flags.StringVar(&cmd.nic.Machine, "machine", "", "The machine this NIC belongs to. Required and must be the name of a machine returned by get-machines.")
			cmd.Flags.StringVar(&cmd.nic.MacAddress, "mac", "", "The MAC address of this NIC. Required and must be a valid MAC-48 address.")
			cmd.Flags.StringVar(&cmd.nic.Switch, "switch", "", "The switch this NIC is connected to. Required and must be the name of a switch returned by get-switches.")
			cmd.Flags.Var(flag.Int32(&cmd.nic.Switchport), "port", "The switchport this NIC is connected to.")
			cmd.Flags.StringVar(&cmd.nic.Hostname, "host", "", "The name of this NIC on the network.")
			cmd.Flags.StringVar(&cmd.nic.Ipv4, "ip", "", "The IPv4 address assigned to this NIC. Must be a free IP address returned by get-ips.")
			return cmd
		},
	}
}
source: func (c *Client) download(path string, in interface{}, r io.Reader) (io.ReadCloser, int64, error) {
	url := "https://content.dropboxapi.com/2" + path

	body, err := json.Marshal(in)
	if err != nil {
		return nil, 0, err
	}

	req, err := http.NewRequest("POST", url, r)
	if err != nil {
		return nil, 0, err
	}
	req.Header.Set("Authorization", "Bearer "+c.AccessToken)
	req.Header.Set("Dropbox-API-Arg", string(body))

	if r != nil {
		req.Header.Set("Content-Type", "application/octet-stream")
	}

	return c.do(req)
}
source: func (c *PrlctlPostConfig) Prepare(ctx *interpolate.Context) []error {
	if c.PrlctlPost == nil {
		c.PrlctlPost = make([][]string, 0)
	}

	return nil
}
source: func (csrStrategy) PrepareForUpdate(ctx context.Context, obj, old runtime.Object) {
	newCSR := obj.(*certificates.CertificateSigningRequest)
	oldCSR := old.(*certificates.CertificateSigningRequest)

	newCSR.Spec = oldCSR.Spec
	newCSR.Status = oldCSR.Status
}
source: func (d *Accessor) GetCertificate(serial, aki string) (crs []certdb.CertificateRecord, err error) {
	err = d.checkDB()
	if err != nil {
		return nil, err
	}

	err = d.db.Select(&crs, fmt.Sprintf(d.db.Rebind(selectSQL), sqlstruct.Columns(certdb.CertificateRecord{})), serial, aki)
	if err != nil {
		return nil, wrapSQLError(err)
	}

	return crs, nil
}
source: func (u *RBDUtil) rbdStatus(image string, pOpts *rbdProvisionOptions) (bool, error) {
	var err error
	var output string
	var cmd []byte

	mon := u.kernelRBDMonitorsOpt(pOpts.monitors)
	// cmd "rbd status" list the rbd client watch with the following output:
	//
	// # there is a watcher (exit=0)
	// Watchers:
	//   watcher=10.16.153.105:0/710245699 client.14163 cookie=1
	//
	// # there is no watcher (exit=0)
	// Watchers: none
	//
	// Otherwise, exit is non-zero, for example:
	//
	// # image does not exist (exit=2)
	// rbd: error opening image kubernetes-dynamic-pvc-<UUID>: (2) No such file or directory
	//
	klog.V(4).Infof("rbd: status %s using mon %s, pool %s id %s key %s", image, mon, pOpts.pool, pOpts.adminID, pOpts.adminSecret)
	args := []string{"status", image, "--pool", pOpts.pool, "-m", mon, "--id", pOpts.adminID, "--key=" + pOpts.adminSecret}
	cmd, err = u.execCommand("rbd", args)
	output = string(cmd)

	// If command never succeed, returns its last error.
	if err != nil {
		return false, err
	}

	if strings.Contains(output, imageWatcherStr) {
		klog.V(4).Infof("rbd: watchers on %s: %s", image, output)
		return true, nil
	}
	klog.Warningf("rbd: no watchers on %s", image)
	return false, nil
}
source: func checkDuplicateFlags(current *CmdClause, flagGroups []*flagGroup) error {
	// Check for duplicates.
	for _, flags := range flagGroups {
		for _, flag := range current.flagOrder {
			if flag.shorthand != 0 {
				if _, ok := flags.short[string(flag.shorthand)]; ok {
					return fmt.Errorf("duplicate short flag -%c", flag.shorthand)
				}
			}
			if _, ok := flags.long[flag.name]; ok {
				return fmt.Errorf("duplicate long flag --%s", flag.name)
			}
		}
	}
	flagGroups = append(flagGroups, current.flagGroup)
	// Check subcommands.
	for _, subcmd := range current.commandOrder {
		if err := checkDuplicateFlags(subcmd, flagGroups); err != nil {
			return err
		}
	}
	return nil
}
source: func (m *Meta) Values(i interface{}, cols ...string) []interface{} {
	ptr := reflects.Ptr(i)
	values := make([]interface{}, len(cols))
	for i, f := range cols {
		values[i] = m.fieldMap[f].Get(ptr)
	}
	return values
}
source: func HashUint32(f func() hash.Hash32) func(uint32) uint32 {
	return func(u uint32) uint32 {
		b := [4]byte{}
		binary.BigEndian.PutUint32(b[:], u)
		h := f()
		h.Write(b[:])
		return h.Sum32()
	}
}
source: func (u *ShareFolderErrorBase) UnmarshalJSON(body []byte) error {
	type wrap struct {
		dropbox.Tagged
		// BadPath : `ShareFolderArg.path` is invalid.
		BadPath json.RawMessage `json:"bad_path,omitempty"`
	}
	var w wrap
	var err error
	if err = json.Unmarshal(body, &w); err != nil {
		return err
	}
	u.Tag = w.Tag
	switch u.Tag {
	case "bad_path":
		err = json.Unmarshal(w.BadPath, &u.BadPath)

		if err != nil {
			return err
		}
	}
	return nil
}
source: func Clear(fg, bg Attribute) error {
	foreground, background = fg, bg
	err := update_size_maybe()
	back_buffer.clear()
	return err
}
source: func (s *IdentityService) GetSAMLConnectors(withSecrets bool) ([]services.SAMLConnector, error) {
	startKey := backend.Key(webPrefix, connectorsPrefix, samlPrefix, connectorsPrefix)
	result, err := s.GetRange(context.TODO(), startKey, backend.RangeEnd(startKey), backend.NoLimit)
	if err != nil {
		return nil, trace.Wrap(err)
	}
	connectors := make([]services.SAMLConnector, len(result.Items))
	for i, item := range result.Items {
		conn, err := services.GetSAMLConnectorMarshaler().UnmarshalSAMLConnector(
			item.Value, services.WithExpires(item.Expires))
		if err != nil {
			return nil, trace.Wrap(err)
		}
		if !withSecrets {
			keyPair := conn.GetSigningKeyPair()
			if keyPair != nil {
				keyPair.PrivateKey = ""
				conn.SetSigningKeyPair(keyPair)
			}
		}
		connectors[i] = conn
	}
	return connectors, nil
}
source: func Use(c context.Context, s Client) context.Context {
	return context.WithValue(c, &contextKey, s)
}
source: func (s *JobDescriptor) SetSuspendedCause(v string) *JobDescriptor {
	s.SuspendedCause = &v
	return s
}
source: func NewCredential(authType AuthType, attributes map[string]string) Credential {
	return Credential{authType: authType, attributes: copyStringMap(attributes)}
}
source: func copyMemory(dest unsafe.Pointer, src unsafe.Pointer, length uint32) {
	procCopyMemory.Call(uintptr(dest), uintptr(src), uintptr(length))
}
source: func (filters Args) Validate(accepted map[string]bool) error {
	for name := range filters.fields {
		if !accepted[name] {
			return fmt.Errorf("Invalid filter '%s'", name)
		}
	}
	return nil
}
source: func (c *Crontab) backendLoop(l loop.Loop) error {
	ticker := time.NewTicker(c.frequency)
	for {
		select {
		case <-l.ShallStop():
			return nil
		case cmd := <-c.commandChan:
			if cmd.add {
				c.jobs[cmd.id] = cmd.job
			} else {
				delete(c.jobs, cmd.id)
			}
		case now := <-ticker.C:
			for id, job := range c.jobs {
				c.do(id, job, now)
			}
		}
	}
}
source: func (t *Template) GetAllAWSDocDBDBClusterParameterGroupResources() map[string]*resources.AWSDocDBDBClusterParameterGroup {
	results := map[string]*resources.AWSDocDBDBClusterParameterGroup{}
	for name, untyped := range t.Resources {
		switch resource := untyped.(type) {
		case *resources.AWSDocDBDBClusterParameterGroup:
			results[name] = resource
		}
	}
	return results
}
source: func NewManager(
	summaryProvider stats.SummaryProvider,
	config Config,
	killPodFunc KillPodFunc,
	mirrorPodFunc MirrorPodFunc,
	imageGC ImageGC,
	containerGC ContainerGC,
	recorder record.EventRecorder,
	nodeRef *v1.ObjectReference,
	clock clock.Clock,
) (Manager, lifecycle.PodAdmitHandler) {
	manager := &managerImpl{
		clock:                        clock,
		killPodFunc:                  killPodFunc,
		mirrorPodFunc:                mirrorPodFunc,
		imageGC:                      imageGC,
		containerGC:                  containerGC,
		config:                       config,
		recorder:                     recorder,
		summaryProvider:              summaryProvider,
		nodeRef:                      nodeRef,
		nodeConditionsLastObservedAt: nodeConditionsObservedAt{},
		thresholdsFirstObservedAt:    thresholdsObservedAt{},
		dedicatedImageFs:             nil,
		thresholdNotifiers:           []ThresholdNotifier{},
	}
	return manager, manager
}
source: func (s *PatchSource) SetProducts(v []*string) *PatchSource {
	s.Products = v
	return s
}
source: func (b *buffer) swap() error {
	if b.pos == b.promptLen {
		return nil
	}

	if b.pos < b.size {
		aux := b.data[b.pos-1]
		b.data[b.pos-1] = b.data[b.pos]
		b.data[b.pos] = aux
		b.pos++
		// End of line
	} else {
		aux := b.data[b.pos-2]
		b.data[b.pos-2] = b.data[b.pos-1]
		b.data[b.pos-1] = aux
	}
	return b.refresh()
}
source: func (c *Client) createRequest() *http.Request {
	req := &http.Request{
		Proto:      "HTTP/1.1",
		ProtoMajor: 1,
		ProtoMinor: 1,
		Header:     make(http.Header),
		Host:       c.url.Host,
	}
	req.Header.Add("Content-Type", "application/json")
	req.Header.Add(tenantHeader, c.Tenant)

	if len(c.Credentials) > 0 {
		req.Header.Add("Authorization", fmt.Sprintf("Basic %s", c.Credentials))
	}

	if len(c.Token) > 0 {
		req.Header.Add("Authorization", fmt.Sprintf("Bearer %s", c.Token))
	}

	return req
}
source: func (l Netlist) MarshalTOML() interface{} {
	list := make([]string, 0, len(l))
	for _, net := range l {
		list = append(list, net.String())
	}
	return list
}
source: func (m *MockAccessRequester) GetGrantedAudience() fosite.Arguments {
	ret := m.ctrl.Call(m, "GetGrantedAudience")
	ret0, _ := ret[0].(fosite.Arguments)
	return ret0
}
source: func NewEcho(Exprs []node.Node) *Echo {
	return &Echo{
		FreeFloating: nil,
		Exprs:        Exprs,
	}
}
source: func GetProposalResponse(prBytes []byte) (*peer.ProposalResponse, error) {
	proposalResponse := &peer.ProposalResponse{}
	err := proto.Unmarshal(prBytes, proposalResponse)
	return proposalResponse, errors.Wrap(err, "error unmarshaling ProposalResponse")
}
source: func (s *Schedule) SetRetainRule(v *RetainRule) *Schedule {
	s.RetainRule = v
	return s
}
source: func GetVMObject(ctx context.Context, conn *vclib.VSphereConnection, vmUUID string) (*vclib.VirtualMachine, error) {
	// TODO change impl below using multiple goroutines and sync.WaitGroup to make it faster
	ctx, cancel := context.WithCancel(context.Background())
	defer cancel()
	if err := conn.Connect(ctx); err != nil {
		return nil, err
	}

	if len(vmUUID) == 0 {
		return nil, fmt.Errorf("virtual machine uuid is required")
	}

	datacenterObjs, err := vclib.GetAllDatacenter(ctx, conn)
	if err != nil {
		return nil, err
	}

	// Lookup in each vsphere datacenter for this virtual machine
	for _, dc := range datacenterObjs {
		vm, err := dc.GetVMByUUID(ctx, vmUUID)
		if err != nil {
			if err != vclib.ErrNoVMFound {
				logrus.Warnf("failed to find vm with uuid: %s in datacenter: %s due to err: %v", vmUUID, dc.Name(), err)
				// don't let one bad egg fail entire search. keep looking.
			} else {
				logrus.Debugf("did not find vm with uuid: %s in datacenter: %s", vmUUID, dc.Name())
			}
			continue
		}

		if vm != nil {
			return vm, nil
		}
	}

	return nil, fmt.Errorf("failed to find vm with uuid: %s in any datacenter for vc: %s", vmUUID, conn.Hostname)
}
source: func (f *Logfile) Close() error {
	f.Lock()
	defer f.Unlock()

	return f.closeLog()
}
source: func NewREST(optsGetter generic.RESTOptionsGetter) (*REST, *StatusREST) {
	store := &genericregistry.Store{
		NewFunc:                  func() runtime.Object { return &apps.ReplicaSet{} },
		NewListFunc:              func() runtime.Object { return &apps.ReplicaSetList{} },
		PredicateFunc:            replicaset.MatchReplicaSet,
		DefaultQualifiedResource: apps.Resource("replicasets"),

		CreateStrategy: replicaset.Strategy,
		UpdateStrategy: replicaset.Strategy,
		DeleteStrategy: replicaset.Strategy,

		TableConvertor: printerstorage.TableConvertor{TableGenerator: printers.NewTableGenerator().With(printersinternal.AddHandlers)},
	}
	options := &generic.StoreOptions{RESTOptions: optsGetter, AttrFunc: replicaset.GetAttrs}
	if err := store.CompleteWithOptions(options); err != nil {
		panic(err) // TODO: Propagate error up
	}

	statusStore := *store
	statusStore.UpdateStrategy = replicaset.StatusStrategy

	return &REST{store, []string{"all"}}, &StatusREST{store: &statusStore}
}
source: func (f FlagSet) String() string {
	flags := make([]string, 0, len(flagNames))
	for k, v := range flagNames {
		if f&k != 0 {
			flags = append(flags, v)
		}
	}
	sort.Strings(flags)
	return "FlagSet(" + strings.Join(flags, "|") + ")"
}
source: func (kz *Kazoo) Topics() (TopicList, error) {
	root := fmt.Sprintf("%s/brokers/topics", kz.conf.Chroot)
	children, _, err := kz.conn.Children(root)
	if err != nil {
		return nil, err
	}

	result := make(TopicList, 0, len(children))
	for _, name := range children {
		result = append(result, kz.Topic(name))
	}
	return result, nil
}
source: func selectionData(selection *goquery.Selection) string {
	var results []string
	selection.Each(func(i int, element *goquery.Selection) {
		if len(element.Nodes) > 0 {
			results = append(results, element.Nodes[0].Data)
		}
	})
	return strings.Join(results, " ")
}
source: func (r *Reader) ReadRest() ([]byte, error) {
	return r.ReadNumBytes(len(r.data) - r.index)
}
source: func (f *fundingManager) processFundingOpen(msg *lnwire.OpenChannel,
	peer lnpeer.Peer) {

	select {
	case f.fundingMsgs <- &fundingOpenMsg{msg, peer}:
	case <-f.quit:
		return
	}
}
source: func NewDigitalPin(key interface{}) (DigitalPin, error) {
	if err := InitGPIO(); err != nil {
		return nil, err
	}

	return gpioDriverInstance.DigitalPin(key)
}
source: func (c *Client) SetUser(u string) *Client {
	c.Username = u
	return c
}
source: func (item *MultiGetItem) FetchSource(fetchSourceContext *FetchSourceContext) *MultiGetItem {
	item.fsc = fetchSourceContext
	return item
}
source: func (i *Index) AddRepo(rname string, ind *repo.IndexFile, all bool) {
	ind.SortEntries()
	for name, ref := range ind.Entries {
		if len(ref) == 0 {
			// Skip chart names that have zero releases.
			continue
		}
		// By convention, an index file is supposed to have the newest at the
		// 0 slot, so our best bet is to grab the 0 entry and build the index
		// entry off of that.
		// Note: Do not use filePath.Join since on Windows it will return \
		//       which results in a repo name that cannot be understood.
		fname := path.Join(rname, name)
		if !all {
			i.lines[fname] = indstr(rname, ref[0])
			i.charts[fname] = ref[0]
			continue
		}

		// If 'all' is set, then we go through all of the refs, and add them all
		// to the index. This will generate a lot of near-duplicate entries.
		for _, rr := range ref {
			versionedName := fname + verSep + rr.Version
			i.lines[versionedName] = indstr(rname, rr)
			i.charts[versionedName] = rr
		}
	}
}
source: func (c *client) ClusterStatus() (*pb.ClusterStatus, error) {
	pbmsg, err := c.SendRPC(hrpc.NewClusterStatus())
	if err != nil {
		return nil, err
	}

	r, ok := pbmsg.(*pb.GetClusterStatusResponse)
	if !ok {
		return nil, fmt.Errorf("sendRPC returned not a ClusterStatusResponse")
	}

	return r.GetClusterStatus(), nil
}
source: func (r *runtimeVerbose) isEnabled(from string) bool {
	isEnabled := false
	for _, reg := range r.VerboseRegs {
		if reg.MatchString(from) {
			isEnabled = true
			break
		}
	}
	return isEnabled
}
source: func mergeChannels(cs []<-chan string) <-chan string {
	var wg sync.WaitGroup
	out := make(chan string)

	output := func(c <-chan string) {
		for n := range c {
			out <- n
		}
		wg.Done()
	}

	wg.Add(len(cs))
	for _, c := range cs {
		go output(c)
	}

	go func() {
		wg.Wait()
		close(out)
	}()
	return out
}
source: func (f PortFeature) String() string {
	var features []string

	// Iterate though all of the port features and check if the
	// respective bit is set.
	for _, feature := range portFeaturesText {
		if feature.mask&f != 0 {
			features = append(features, feature.text)
		}
	}

	// Return space-joined list of the port features.
	return strings.Join(features, " ")
}
source: func (u *User) IsAdminOfRepo(repo *Repository) bool {
	has, err := HasAccess(u.ID, repo, ACCESS_MODE_ADMIN)
	if err != nil {
		log.Error(2, "HasAccess: %v", err)
	}
	return has
}
source: func (s *lockBasedTxSimulator) SetState(ns string, key string, value []byte) error {
	if err := s.checkWritePrecondition(key, value); err != nil {
		return err
	}
	s.rwsetBuilder.AddToWriteSet(ns, key, value)
	return nil
}
source: func GetProcessList(endpoint string) ([]Process, error) {
	var dataSet []map[string]string
	var err error
	if dataSet, err = readDataSet(endpoint, "SHOW PROCESSLIST"); err != nil {
		return nil, err
	}
	processes := make([]Process, 0, len(dataSet))
	for _, row := range dataSet {
		processes = append(processes,
			Process{
				ID:      getInt(row["Id"]),
				User:    row["User"],
				Host:    row["Host"],
				DB:      row["db"],
				Command: row["Command"],
				Time:    getInt(row["Time"]),
				State:   row["State"],
				Info:    row["Info"],
			},
		)
	}
	return processes, nil
}
source: func FilterInt64(s []int64, cb func(s int64) bool) []int64 {
	results := []int64{}

	for _, i := range s {
		result := cb(i)

		if result {
			results = append(results, i)
		}
	}

	return results
}
source: func (tracker *issueTracker) ListStoriesByRelease(v *version.Version) ([]common.Story, error) {
	issues, err := tracker.issuesByRelease(v)
	if err != nil {
		return nil, err
	}
	return toCommonStories(issues, tracker), nil
}
source: func RaftPeers(consenterIDs []uint64) []raft.Peer {
	var peers []raft.Peer

	for _, raftID := range consenterIDs {
		peers = append(peers, raft.Peer{ID: raftID})
	}
	return peers
}
source: func (h *DeployHandler) randomZone(region string) string {
	h.zonesMu.RLock()
	defer h.zonesMu.RUnlock()
	zones, ok := h.zones[region]
	if !ok {
		return fallbackZone
	}
	return region + zones[rand.Intn(len(zones))]
}
source: func (_class PCIClass) GetAll(sessionID SessionRef) (_retval []PCIRef, _err error) {
	_method := "PCI.get_all"
	_sessionIDArg, _err := convertSessionRefToXen(fmt.Sprintf("%s(%s)", _method, "session_id"), sessionID)
	if _err != nil {
		return
	}
	_result, _err := _class.client.APICall(_method, _sessionIDArg)
	if _err != nil {
		return
	}
	_retval, _err = convertPCIRefSetToGo(_method + " -> ", _result.Value)
	return
}
source: func (r Network_Tunnel_Module_Context) DownloadAddressTranslationConfigurations() (resp datatypes.Container_Utility_File_Entity, err error) {
	err = r.Session.DoRequest("SoftLayer_Network_Tunnel_Module_Context", "downloadAddressTranslationConfigurations", nil, &r.Options, &resp)
	return
}
source: func (m *moduleMgr) writeModuleManifestSnapshot() error {
	w, err := m.FS.Create(m.manifestSnapshotPath())
	if err != nil {
		return err
	}

	return m.manifest.WriteSnapshot(w)
}
source: func (p *point) Tags() Tags {
	if p.cachedTags != nil {
		return p.cachedTags
	}
	p.cachedTags = parseTags(p.key, nil)
	return p.cachedTags
}
source: func (c *Client) SignRawTransaction3Async(tx *wire.MsgTx,
	inputs []btcjson.RawTxInput,
	privKeysWIF []string) FutureSignRawTransactionResult {

	txHex := ""
	if tx != nil {
		// Serialize the transaction and convert to hex string.
		buf := bytes.NewBuffer(make([]byte, 0, tx.SerializeSize()))
		if err := tx.Serialize(buf); err != nil {
			return newFutureError(err)
		}
		txHex = hex.EncodeToString(buf.Bytes())
	}

	cmd := btcjson.NewSignRawTransactionCmd(txHex, &inputs, &privKeysWIF,
		nil)
	return c.sendCmd(cmd)
}
source: func (*Namespace) getIf(arg reflect.Value) reflect.Value {
	if truth(arg) {
		return arg
	}
	return reflect.ValueOf("")
}
source: func (c *FakeNodes) Patch(name string, pt types.PatchType, data []byte, subresources ...string) (result *corev1.Node, err error) {
	obj, err := c.Fake.
		Invokes(testing.NewRootPatchSubresourceAction(nodesResource, name, pt, data, subresources...), &corev1.Node{})
	if obj == nil {
		return nil, err
	}
	return obj.(*corev1.Node), err
}
source: func (s *Store) ActiveAddresses() map[btcutil.Address]WalletAddress {
	s.mtx.RLock()
	defer s.mtx.RUnlock()

	addrs := make(map[btcutil.Address]WalletAddress)
	for i := int64(rootKeyChainIdx); i <= s.highestUsed; i++ {
		a := s.chainIdxMap[i]
		addr := s.addrMap[getAddressKey(a)]
		addrs[addr.Address()] = addr
	}
	for _, addr := range s.importedAddrs {
		addrs[addr.Address()] = addr
	}
	return addrs
}
source: func (s *NetworkService) ListNetworkServiceProviders(p *ListNetworkServiceProvidersParams) (*ListNetworkServiceProvidersResponse, error) {
	resp, err := s.cs.newRequest("listNetworkServiceProviders", p.toURLValues())
	if err != nil {
		return nil, err
	}

	var r ListNetworkServiceProvidersResponse
	if err := json.Unmarshal(resp, &r); err != nil {
		return nil, err
	}

	return &r, nil
}
source: func init() {
	// Register the driver.
	driver := &lnwallet.WalletDriver{
		WalletType: walletType,
		New:        createNewWallet,
		BackEnds:   chain.BackEnds,
	}

	if err := lnwallet.RegisterWallet(driver); err != nil {
		panic(fmt.Sprintf("failed to register wallet driver '%s': %v",
			walletType, err))
	}
}
source: func createEP(req *epSpec) (*epAttr, error) {

	// if the ep already exists, treat as error for now.
	netID := req.Network + "." + req.Tenant
	ep, err := utils.GetEndpoint(netID + "-" + req.EndpointID)
	if err == nil {
		return nil, fmt.Errorf("the EP %s already exists", req.EndpointID)
	}

	// Build endpoint request
	mreq := master.CreateEndpointRequest{
		TenantName:   req.Tenant,
		NetworkName:  req.Network,
		ServiceName:  req.Group,
		EndpointID:   req.EndpointID,
		EPCommonName: req.Name,
		ConfigEP: intent.ConfigEP{
			Container:   req.EndpointID,
			Host:        pluginHost,
			ServiceName: req.Group,
		},
	}

	var mresp master.CreateEndpointResponse
	err = cluster.MasterPostReq("/plugin/createEndpoint", &mreq, &mresp)
	if err != nil {
		epCleanUp(req)
		return nil, err
	}

	// this response should contain IPv6 if the underlying network is configured with IPv6
	log.Infof("Got endpoint create resp from master: %+v", mresp)

	// Ask netplugin to create the endpoint
	err = netPlugin.CreateEndpoint(netID + "-" + req.EndpointID)
	if err != nil {
		log.Errorf("Endpoint creation failed. Error: %s", err)
		epCleanUp(req)
		return nil, err
	}

	ep, err = utils.GetEndpoint(netID + "-" + req.EndpointID)
	if err != nil {
		epCleanUp(req)
		return nil, err
	}

	log.Debug(ep)
	// need to get the subnetlen from nw state.
	nw, err := utils.GetNetwork(netID)
	if err != nil {
		epCleanUp(req)
		return nil, err
	}

	epResponse := epAttr{}
	epResponse.PortName = ep.PortName
	epResponse.IPAddress = ep.IPAddress + "/" + strconv.Itoa(int(nw.SubnetLen))
	epResponse.Gateway = nw.Gateway

	if ep.IPv6Address != "" {
		epResponse.IPv6Address = ep.IPv6Address + "/" + strconv.Itoa(int(nw.IPv6SubnetLen))
		epResponse.IPv6Gateway = nw.IPv6Gateway
	}

	return &epResponse, nil
}
source: func (runtime *CRIRuntime) RemoveContainers(containers []string) error {
	errs := []error{}
	for _, container := range containers {
		out, err := runtime.exec.Command("crictl", "-r", runtime.criSocket, "stopp", container).CombinedOutput()
		if err != nil {
			// don't stop on errors, try to remove as many containers as possible
			errs = append(errs, errors.Wrapf(err, "failed to stop running pod %s: output: %s, error", container, string(out)))
		} else {
			out, err = runtime.exec.Command("crictl", "-r", runtime.criSocket, "rmp", container).CombinedOutput()
			if err != nil {
				errs = append(errs, errors.Wrapf(err, "failed to remove running container %s: output: %s, error", container, string(out)))
			}
		}
	}
	return errorsutil.NewAggregate(errs)
}
source: func BackendError(b ServiceBackend, zone string, rcode int, state request.Request, err error, opt Options) (int, error) {
	m := new(dns.Msg)
	m.SetRcode(state.Req, rcode)
	m.Authoritative, m.RecursionAvailable, m.Compress = true, true, true
	m.Ns, _ = SOA(b, zone, state, opt)

	state.SizeAndDo(m)
	state.W.WriteMsg(m)
	// Return success as the rcode to signal we have written to the client.
	return dns.RcodeSuccess, err
}
source: func (api *Client) LeaveGroup(group string) error {
	return api.LeaveGroupContext(context.Background(), group)
}
source: func (fsm *SimpleFSM) Apply(log *raft.Log) interface{} {
	fsm.mu.Lock()
	defer fsm.mu.Unlock()
	fsm.logs = append(fsm.logs, log.Data)
	return len(fsm.logs)
}
source: func (bk *Backend) isExpired(bv bucketItem) bool {
	if bv.ExpiryTime.IsZero() {
		return false
	}
	return bk.Clock().Now().After(bv.ExpiryTime)
}
source: func (m *MockRPCClient) GetRPCClient(contextID string) (*rpcwrapper.RPCHdl, error) {
	ret := m.ctrl.Call(m, "GetRPCClient", contextID)
	ret0, _ := ret[0].(*rpcwrapper.RPCHdl)
	ret1, _ := ret[1].(error)
	return ret0, ret1
}
source: func pack10(src []uint64) uint64 {
	return 7<<60 |
		src[0] |
		src[1]<<6 |
		src[2]<<12 |
		src[3]<<18 |
		src[4]<<24 |
		src[5]<<30 |
		src[6]<<36 |
		src[7]<<42 |
		src[8]<<48 |
		src[9]<<54
}
source: func (r *LambdaResults) ResultsForRegion(region string) []AggData {
	lambdasOfRegion := make([]AggData, 0)
	for _, lambda := range r.Lambdas {
		if lambda.Region == region {
			lambdasOfRegion = append(lambdasOfRegion, lambda)
		}
	}
	return lambdasOfRegion
}
source: func (p *siprng) Seed(k [16]byte) {
	p.k0 = binary.LittleEndian.Uint64(k[0:8])
	p.k1 = binary.LittleEndian.Uint64(k[8:16])
	p.ctr = 1
}
source: func (w *window) Failures() int64 {
	w.bucketLock.RLock()

	var failures int64
	w.buckets.Do(func(x interface{}) {
		b := x.(*bucket)
		failures += b.failure
	})

	w.bucketLock.RUnlock()
	return failures
}
source: func (b *Bucket) CreateBucketIfNotExists(key []byte) (*Bucket, error) {
	child, err := b.CreateBucket(key)
	if err == ErrBucketExists {
		return b.Bucket(key), nil
	} else if err != nil {
		return nil, err
	}
	return child, nil
}
source: func (b Bitmap) IndexesInRange(set bool, from, to uint) []int {
	var indexes []int
	for i := from; i <= to && i < b.Size(); i++ {
		c := b.Check(i)
		if c && set || !c && !set {
			indexes = append(indexes, int(i))
		}
	}

	return indexes
}
source: func (rm *RoomManager) run() {
	for {
		select {
		// Join
		case req := <-rm.join:
			m, ok := rm.rooms[req.name]
			if !ok { // If room was not found for join request, create it!
				m = &managedRoom{
					room:  NewRoom(),
					count: 1, // start with count 1 for first user
				}
				rm.rooms[req.name] = m
				go rm.callbackRoomCreation(req.name)
			} else { // If room exists increase count and join.
				m.count++
			}
			m.room.join <- req.conn
			c, ok := rm.members[req.conn]
			if !ok { // If room association map for connection does not exist, create it!
				c = newConnectionInfo()
				rm.members[req.conn] = c
			}
			c.rooms[req.name] = true // Flag this room on members room map.
		// Leave
		case req := <-rm.leave:
			rm.leaveRoomByName(req.name, req.conn)
		// Leave all
		case conn := <-rm.leaveAll:
			if c, ok := rm.members[conn]; ok {
				for name := range c.rooms { // Iterate over all lobbies this connection joined and leave them.
					rm.leaveRoomByName(name, conn)
				}
				delete(rm.members, conn) // Remove map of joined lobbies
			}
		case name := <-rm.destroy:
			if m, ok := rm.rooms[name]; ok {
				// This should result inthe room being stopped/destroyed when the last
				// connection is dropped
				for conn := range m.room.members {
					rm.leaveRoomByName(name, conn)
				}
			}
		case req := <-rm.options:
			c, ok := rm.members[req.conn]
			if !ok { // If room association map for connection does not exist, create it!
				c = newConnectionInfo()
				rm.members[req.conn] = c
			}
			if req.overwrite {
				c.options = req.options
			} else {
				c.options = req.options | c.options
			}
		// Send
		case rMsg := <-rm.send:
			if m, ok := rm.rooms[rMsg.to]; ok { // If room exists, get it and send data to it.
				m.room.send <- rMsg.msg
			}
		// Stop
		case <-rm.stop:
			for k, m := range rm.rooms { // Stop all lobbies!
				m.room.Stop()
				delete(rm.rooms, k)
			}
			return
		}
	}
}
source: func (s *FileSourceSettings) SetTimeDelta(v int64) *FileSourceSettings {
	s.TimeDelta = &v
	return s
}
source: func (c *ServiceClient) commit(ops *operations) {
	select {
	case c.opCh <- ops:
	case <-c.shutdownCh:
	}
}
source: func (s *serviceLister) Services(namespace string) ServiceNamespaceLister {
	return serviceNamespaceLister{indexer: s.indexer, namespace: namespace}
}
source: func Codec(c codec.MarshalUnmarshaler) func(*Options) error {
	return func(opts *Options) error {
		opts.codec = c
		return nil
	}
}
source: func NewParser(m *Mrb) *Parser {
	p := C.mrb_parser_new(m.state)

	// Set capture_errors to true so we don't go just printing things
	// out to stdout.
	C._go_mrb_parser_set_capture_errors(p, 1)

	return &Parser{
		mrb:    m,
		parser: p,
	}
}
source: func NewOAuth2Tripper(creds *common.Credentials, provider common.Provider) *OAuth2Tripper {
	return &OAuth2Tripper{common.GetRoundTripper(), creds, provider}
}
source: func (b *OpenAPI3Builder) build(document *openapiv3.Document) (err error) {
	// Collect service type descriptions from Components/Schemas.
	if document.Components != nil && document.Components.Schemas != nil {
		for _, pair := range document.Components.Schemas.AdditionalProperties {
			t, err := b.buildTypeFromSchemaOrReference(pair.Name, pair.Value)
			if err != nil {
				return err
			}
			if t != nil {
				b.model.addType(t)
			}
		}
	}
	// Collect service method descriptions from each PathItem.
	if document.Paths != nil {
		for _, pair := range document.Paths.Path {
			b.buildMethodFromPathItem(pair.Name, pair.Value)
		}
	}
	return err
}
source: func (m *HTTPFault) Validate() error {
	if m == nil {
		return nil
	}

	{
		tmp := m.GetDelay()

		if v, ok := interface{}(tmp).(interface{ Validate() error }); ok {

			if err := v.Validate(); err != nil {
				return HTTPFaultValidationError{
					field:  "Delay",
					reason: "embedded message failed validation",
					cause:  err,
				}
			}
		}
	}

	{
		tmp := m.GetAbort()

		if v, ok := interface{}(tmp).(interface{ Validate() error }); ok {

			if err := v.Validate(); err != nil {
				return HTTPFaultValidationError{
					field:  "Abort",
					reason: "embedded message failed validation",
					cause:  err,
				}
			}
		}
	}

	// no validation rules for UpstreamCluster

	for idx, item := range m.GetHeaders() {
		_, _ = idx, item

		{
			tmp := item

			if v, ok := interface{}(tmp).(interface{ Validate() error }); ok {

				if err := v.Validate(); err != nil {
					return HTTPFaultValidationError{
						field:  fmt.Sprintf("Headers[%v]", idx),
						reason: "embedded message failed validation",
						cause:  err,
					}
				}
			}
		}

	}

	{
		tmp := m.GetMaxActiveFaults()

		if v, ok := interface{}(tmp).(interface{ Validate() error }); ok {

			if err := v.Validate(); err != nil {
				return HTTPFaultValidationError{
					field:  "MaxActiveFaults",
					reason: "embedded message failed validation",
					cause:  err,
				}
			}
		}
	}

	{
		tmp := m.GetResponseRateLimit()

		if v, ok := interface{}(tmp).(interface{ Validate() error }); ok {

			if err := v.Validate(); err != nil {
				return HTTPFaultValidationError{
					field:  "ResponseRateLimit",
					reason: "embedded message failed validation",
					cause:  err,
				}
			}
		}
	}

	return nil
}
source: func MakeTLFWriterKeyBundleID(codec kbfscodec.Codec, wkb TLFWriterKeyBundleV3) (
	TLFWriterKeyBundleID, error) {
	if len(wkb.Keys) == 0 {
		return TLFWriterKeyBundleID{}, errors.New(
			"Writer key bundle with no keys (MakeTLFWriterKeyBundleID)")
	}
	buf, err := codec.Encode(wkb)
	if err != nil {
		return TLFWriterKeyBundleID{}, err
	}
	h, err := kbfshash.DefaultHash(buf)
	if err != nil {
		return TLFWriterKeyBundleID{}, err
	}
	return TLFWriterKeyBundleID{h}, nil
}
source: func triggerMatchesBuildImageChange(trigger ImageChangeTrigger, strategyTrigger *ImageChangeTrigger, imageChange *buildv1.ImageChangeTrigger) bool {
	if imageChange == nil {
		return false
	}
	if imageChange.From == nil {
		return strategyTrigger != nil && strategyTrigger.From == trigger.From && strategyTrigger.Namespace == trigger.Namespace
	}
	namespace := imageChange.From.Namespace
	if strategyTrigger != nil {
		namespace = defaultNamespace(namespace, strategyTrigger.Namespace)
	}
	return imageChange.From.Name == trigger.From && namespace == trigger.Namespace
}
source: func Digests() (map[string][sha256.Size]byte, error) {
	mp := make(map[string][sha256.Size]byte, len(_bindata))
	for name := range _bindata {
		a, err := _bindata[name]()
		if err != nil {
			return nil, err
		}
		mp[name] = a.digest
	}
	return mp, nil
}
source: func (c *Client) ListVCLs(i *ListVCLsInput) ([]*VCL, error) {
	if i.Service == "" {
		return nil, ErrMissingService
	}

	if i.Version == 0 {
		return nil, ErrMissingVersion
	}

	path := fmt.Sprintf("/service/%s/version/%d/vcl", i.Service, i.Version)
	resp, err := c.Get(path, nil)
	if err != nil {
		return nil, err
	}

	var vcls []*VCL
	if err := decodeJSON(&vcls, resp.Body); err != nil {
		return nil, err
	}
	sort.Stable(vclsByName(vcls))
	return vcls, nil
}
source: func (sig *Signature) SignKey(pub *PublicKey, priv *PrivateKey, config *Config) error {
	h, err := keySignatureHash(&priv.PublicKey, pub, sig.Hash)
	if err != nil {
		return err
	}
	return sig.Sign(h, priv, config)
}
source: func (api *FlavorsAPI) GetAll(options *FlavorGetOptions) (flavors *FlavorList, err error) {
	uri := api.client.Endpoint + flavorUrl
	if options != nil {
		uri += getQueryString(options)
	}
	res, err := api.client.restClient.GetList(api.client.Endpoint, uri, api.client.options.TokenOptions)
	if err != nil {
		return
	}

	flavors = &FlavorList{}
	err = json.Unmarshal(res, flavors)
	return
}
source: func goGetFiles(dir string, pkgs []string) []string {
	params := []string{
		"Dir",
		"GoFiles",
		"CgoFiles",
	}
	var allFiles []string
	rawTuples := goRun(goList(params, pkgs))
	for _, raw := range rawTuples {
		tuple := goSliceRawTuple(raw)
		moduleDir := filepath.Clean(tuple[0])
		dirSep := fmt.Sprintf("%s%c", dir, filepath.Separator)
		moduleDirSep := fmt.Sprintf("%s%c", moduleDir, filepath.Separator)
		if !strings.HasPrefix(moduleDirSep, dirSep) {
			continue
		}
		relModuleDir, err := filepath.Rel(dir, moduleDir)
		if err != nil {
			common.Die("Could not make a relative path from %q to %q, even if they have the same prefix", moduleDir, dir)
		}
		files := append(goSliceRawSlice(tuple[1]), goSliceRawSlice(tuple[2])...)
		for i := 0; i < len(files); i++ {
			files[i] = filepath.Join(relModuleDir, files[i])
		}
		allFiles = append(allFiles, files...)
	}
	return allFiles
}
source: func getImageStreamTagMarker(g osgraph.Graph, f osgraph.Namer, bcInputNode graph.Node, imageStreamNode graph.Node, tagNode *imagegraph.ImageStreamTagNode, bcNode graph.Node) osgraph.Marker {
	return osgraph.Marker{
		Node: bcNode,
		RelatedNodes: []graph.Node{bcInputNode,
			imageStreamNode},
		Severity:   osgraph.WarningSeverity,
		Key:        MissingImageStreamImageWarning,
		Message:    fmt.Sprintf("%s builds from %s, but the image stream tag does not exist.", f.ResourceName(bcNode), f.ResourceName(bcInputNode)),
		Suggestion: getImageStreamTagSuggestion(g, f, tagNode),
	}
}
source: func BuildConfig(root *Module, walker ModuleWalker) (*Config, hcl.Diagnostics) {
	var diags hcl.Diagnostics
	cfg := &Config{
		Module: root,
	}
	cfg.Root = cfg // Root module is self-referential.
	cfg.Children, diags = buildChildModules(cfg, walker)
	return cfg, diags
}
source: func NewLogger(writer io.Writer, name string) Logger {
	formatter, err := createFormatter(name, logxiFormat)
	if err != nil {
		panic("Could not create formatter")
	}
	return NewLogger3(writer, name, formatter)
}
source: func (p Provider) Retrieve() (credentials.Value, error) {
	creds := credentials.Value{
		ProviderName: ProviderName,
	}

	k, s, t, err := p.RetrieveFn()
	if err != nil {
		return creds, awserr.New(ErrCodePluginProviderRetrieve,
			"failed to retrieve credentials with plugin provider", err)
	}

	creds.AccessKeyID = k
	creds.SecretAccessKey = s
	creds.SessionToken = t

	return creds, nil
}
source: func NewParser(src io.Reader, path string) *Parser {
	lexer := scanner.NewLexer(src, path)

	return &Parser{
		lexer,
		path,
		nil,
		nil,
		nil,
	}
}
source: func projectFieldSelectorKeyConversionFunc(label, value string) (internalLabel, internalValue string, err error) {
	switch label {
	case "status.phase":
		return label, value, nil
	default:
		return runtime.DefaultMetaV1FieldSelectorConversion(label, value)
	}
}
source: func NewHmacAuth(hash crypto.Hash, key []byte, header string,
	headers []string) HmacAuth {
	if hash.Available() == false {
		var name string
		var supported bool
		if name, supported = algorithmName[hash]; !supported {
			name = "#" + strconv.Itoa(int(hash))
		}
		panic("hmacauth: hash algorithm " + name + " is unavailable")
	}
	canonicalHeaders := make([]string, len(headers))
	for i, h := range headers {
		canonicalHeaders[i] = http.CanonicalHeaderKey(h)
	}
	return &hmacAuth{hash, key, header, canonicalHeaders}
}
source: func (prA PortRange) CheckConflicts(prB PortRange) error {
	if err := prA.Validate(); err != nil {
		return err
	}
	if err := prB.Validate(); err != nil {
		return err
	}

	// An exact port range match (including the associated unit name) is not
	// considered a conflict due to the fact that many charms issue commands
	// to open the same port multiple times.
	if prA == prB {
		return nil
	}
	if prA.Protocol != prB.Protocol {
		return nil
	}
	if prA.ToPort >= prB.FromPort && prB.ToPort >= prA.FromPort {
		return errors.Errorf("port ranges %v and %v conflict", prA, prB)
	}
	return nil
}
source: func authorizeCharmStoreEntity(csClient charmstoreForDeploy, curl *charm.URL) (*macaroon.Macaroon, error) {
	endpoint := "/delegatable-macaroon?id=" + url.QueryEscape(curl.String())
	var m *macaroon.Macaroon
	if err := csClient.Get(endpoint, &m); err != nil {
		return nil, errors.Trace(err)
	}
	return m, nil
}
source: func (s *Container) SetAccessLoggingEnabled(v bool) *Container {
	s.AccessLoggingEnabled = &v
	return s
}
source: func (p *Pinger) prepare() error {
	change := mgo.Change{
		Update:    bson.D{{"$inc", bson.D{{"seq", int64(1)}}}},
		Upsert:    true,
		ReturnNew: true,
	}
	session := p.base.Database.Session.Copy()
	defer session.Close()
	base := p.base.With(session)
	seqs := seqsC(base)
	var seq struct{ Seq int64 }
	seqID := docIDStr(p.modelUUID, "beings")
	if _, err := seqs.FindId(seqID).Apply(change, &seq); err != nil {
		return errors.Trace(err)
	}
	p.beingSeq = seq.Seq
	p.fieldKey = fmt.Sprintf("%x", p.beingSeq/63)
	p.fieldBit = 1 << uint64(p.beingSeq%63)
	p.lastSlot = 0
	beings := beingsC(base)
	return errors.Trace(beings.Insert(
		beingInfo{
			DocID: docIDInt64(p.modelUUID, p.beingSeq),
			Seq:   p.beingSeq,
			Key:   p.beingKey,
		},
	))
}
source: func (ap *AuthPermission) Update(db XODB) error {
	var err error

	// if doesn't exist, bail
	if !ap._exists {
		return errors.New("update failed: does not exist")
	}

	// if deleted, bail
	if ap._deleted {
		return errors.New("update failed: marked for deletion")
	}

	// sql query
	const sqlstr = `UPDATE auth_permission SET ` +
		`content_type_id = ?, codename = ?, name = ?` +
		` WHERE id = ?`

	// run query
	XOLog(sqlstr, ap.ContentTypeID, ap.Codename, ap.Name, ap.ID)
	_, err = db.Exec(sqlstr, ap.ContentTypeID, ap.Codename, ap.Name, ap.ID)
	return err
}
source: func reportError(w http.ResponseWriter, r *http.Request, err error) {
	w.WriteHeader(http.StatusInternalServerError)
	log.Printf("[%s] %v\n", time.Now(), err)
	errorTemplate.Execute(w, err)
}
source: func Convert_kops_RBACAuthorizationSpec_To_v1alpha2_RBACAuthorizationSpec(in *kops.RBACAuthorizationSpec, out *RBACAuthorizationSpec, s conversion.Scope) error {
	return autoConvert_kops_RBACAuthorizationSpec_To_v1alpha2_RBACAuthorizationSpec(in, out, s)
}
source: func (s *Service) Stop() {
	eventch, err := s.dispatcher.EventCh()
	if err != nil {
		logger.Warnf("Error stopping event service: %s", err)
		return
	}

	errch := make(chan error)
	eventch <- dispatcher.NewStopEvent(errch)

	select {
	case err := <-errch:
		if err != nil {
			logger.Warnf("Error while stopping dispatcher: %s", err)
		}
	case <-time.After(stopTimeout):
		logger.Infof("Timed out waiting for dispatcher to stop")
	}
}
source: func NewStringSliceResult(val []string, err error) *StringSliceCmd {
	var cmd StringSliceCmd
	cmd.val = val
	cmd.setErr(err)
	return &cmd
}
source: func (c *Debugger) ContinueToLocation(location *DebuggerLocation, targetCallFrames string) (*gcdmessage.ChromeResponse, error) {
	var v DebuggerContinueToLocationParams
	v.Location = location
	v.TargetCallFrames = targetCallFrames
	return c.ContinueToLocationWithParams(&v)
}
source: func NewInmemSink(interval, retain time.Duration) *InmemSink {
	rateTimeUnit := time.Second
	i := &InmemSink{
		interval:     interval,
		retain:       retain,
		maxIntervals: int(retain / interval),
		rateDenom:    float64(interval.Nanoseconds()) / float64(rateTimeUnit.Nanoseconds()),
	}
	i.intervals = make([]*IntervalMetrics, 0, i.maxIntervals)
	return i
}
source: func (c *Cursor) Last() (key []byte, value []byte) {
	_assert(c.bucket.tx.db != nil, "tx closed")
	c.stack = c.stack[:0]
	p, n := c.bucket.pageNode(c.bucket.root)
	ref := elemRef{page: p, node: n}
	ref.index = ref.count() - 1
	c.stack = append(c.stack, ref)
	c.last()
	k, v, flags := c.keyValue()
	if (flags & uint32(bucketLeafFlag)) != 0 {
		return k, nil
	}
	return k, v
}
source: func GetConsoleRows(c context.Context, project string, console *config.Console, commits []string) ([]*ConsoleRow, error) {
	rawCommits := make([][]byte, len(commits))
	for i, c := range commits {
		var err error
		if rawCommits[i], err = hex.DecodeString(c); err != nil {
			return nil, errors.Annotate(err, "bad commit[%d]: %q", i, c).Err()
		}
	}

	// Maps all builderIDs to the indexes of the columns it appears in.
	columnMap := map[string][]int{}
	for columnIdx, b := range console.Builders {
		for _, name := range b.Name {
			columnMap[name] = append(columnMap[name], columnIdx)
		}
	}

	ret := make([]*ConsoleRow, len(commits))
	url := console.RepoUrl
	// HACK(iannucci): This little hack should be removed when console definitions
	// no longer use a manifest name of "REVISION". REVISION was used to index the
	// 'got_revision' value before manifests were implemented.
	if console.ManifestName == "REVISION" {
		url = ""
	}
	partialKey := model.NewPartialManifestKey(project, console.Id, console.ManifestName, url)
	q := datastore.NewQuery("BuildSummary")
	err := parallel.WorkPool(16, func(ch chan<- func() error) {
		for i := range rawCommits {
			i := i
			r := &ConsoleRow{Commit: commits[i]}
			ret[i] = r
			ch <- func() error {
				fullQ := q.Eq("ManifestKeys", partialKey.AddRevision(rawCommits[i]))
				return datastore.Run(c, fullQ, func(bs *model.BuildSummary) {
					if bs.Experimental && !console.IncludeExperimentalBuilds {
						return
					}
					if columnIdxs, ok := columnMap[bs.BuilderID]; ok {
						if r.Builds == nil {
							r.Builds = map[int][]*model.BuildSummary{}
						}
						for _, columnIdx := range columnIdxs {
							r.Builds[columnIdx] = append(r.Builds[columnIdx], bs)
						}
					}
				})
			}
		}
	})

	return ret, err
} 48%|████▊     | 2402/5000 [00:02<00:02, 899.59it/s]
source: func NewProjectRoleCreateTokenCommand(clientOpts *argocdclient.ClientOptions) *cobra.Command {
	var (
		expiresIn string
	)
	var command = &cobra.Command{
		Use:   "create-token PROJECT ROLE-NAME",
		Short: "Create a project token",
		Run: func(c *cobra.Command, args []string) {
			if len(args) != 2 {
				c.HelpFunc()(c, args)
				os.Exit(1)
			}
			projName := args[0]
			roleName := args[1]
			conn, projIf := argocdclient.NewClientOrDie(clientOpts).NewProjectClientOrDie()
			defer util.Close(conn)
			duration, err := timeutil.ParseDuration(expiresIn)
			errors.CheckError(err)
			token, err := projIf.CreateToken(context.Background(), &project.ProjectTokenCreateRequest{Project: projName, Role: roleName, ExpiresIn: int64(duration.Seconds())})
			errors.CheckError(err)
			fmt.Println(token.Token)
		},
	}
	command.Flags().StringVarP(&expiresIn, "expires-in", "e", "0s", "Duration before the token will expire. (Default: No expiration)")

	return command
}
source: func (s *DbSession) FindWithLimit(limit int, query Q, document Document) (interface{}, error) {
	fn := func(q *mgo.Query, result interface{}) error {
		return q.Limit(limit).All(result)
	}
	return s.executeFindAll(query, document, fn)
}
source: func (s *EnvoyApi) clustersHandler(response http.ResponseWriter, req *http.Request, params map[string]string) {
	defer req.Body.Close()

	response.Header().Set("Content-Type", "application/json")

	clusters := s.EnvoyClustersFromState()

	log.Debugf("Reporting Envoy cluster information for cluster '%s' and node '%s'",
		params["service_cluster"], params["service_node"])

	result := CDSResult{clusters}

	jsonBytes, err := result.MarshalJSON()
	defer ffjson.Pool(jsonBytes)
	if err != nil {
		log.Errorf("Error marshaling state in servicesHandler: %s", err.Error())
		sendJsonError(response, 500, "Internal server error")
		return
	}

	response.Write(jsonBytes)
}
source: func lexIncludeStart(lx *lexer) stateFn {
	r := lx.next()
	if isWhitespace(r) {
		return lexSkip(lx, lexIncludeStart)
	}
	lx.backup()
	return lexInclude
}
source: func (daemon *Daemon) CreateManagedNetwork(create clustertypes.NetworkCreateRequest) error {
	_, err := daemon.createNetwork(create.NetworkCreateRequest, create.ID, true)
	return err
}
source: func (s *AddressService) NewAssociateIpAddressParams() *AssociateIpAddressParams {
	p := &AssociateIpAddressParams{}
	p.p = make(map[string]interface{})
	return p
}
source: func (s *UploadMetadata) SetSignedHeaders(v map[string]*string) *UploadMetadata {
	s.SignedHeaders = v
	return s
}
source: func Convert_v1alpha1_WeaveNetworkingSpec_To_kops_WeaveNetworkingSpec(in *WeaveNetworkingSpec, out *kops.WeaveNetworkingSpec, s conversion.Scope) error {
	return autoConvert_v1alpha1_WeaveNetworkingSpec_To_kops_WeaveNetworkingSpec(in, out, s)
}
source: func (r Request) Close() {
	close(r.sendInvalidPassword)
	close(r.sendCreatedUser)
	close(r.sendAuthenticatedUser)
}
source: func (s *UpdateStackInput) SetStackPolicyDuringUpdateURL(v string) *UpdateStackInput {
	s.StackPolicyDuringUpdateURL = &v
	return s
}
source: func getRestorePath(runtime string, option *ptypes.Any) (string, error) {
	if option == nil {
		return "", nil
	}

	var restorePath string
	switch {
	case checkRuntime(runtime, "io.containerd.runc"):
		v, err := typeurl.UnmarshalAny(option)
		if err != nil {
			return "", err
		}
		opts, ok := v.(*options.Options)
		if !ok {
			return "", fmt.Errorf("invalid task create option for %s", runtime)
		}
		restorePath = opts.CriuImagePath
	case runtime == plugin.RuntimeLinuxV1:
		v, err := typeurl.UnmarshalAny(option)
		if err != nil {
			return "", err
		}
		opts, ok := v.(*runctypes.CreateOptions)
		if !ok {
			return "", fmt.Errorf("invalid task create option for %s", runtime)
		}
		restorePath = opts.CriuImagePath
	}

	return restorePath, nil
}
source: func RunStdout(stdout io.Writer, args ...string) error {
	return RunIO(IO{Stdout: stdout}, args...)
}
source: func (n *ExecNode) Stop() error {
	if n.Cmd == nil {
		return nil
	}
	defer func() {
		n.Cmd = nil
	}()

	if n.client != nil {
		n.client.Close()
		n.client = nil
		n.wsAddr = ""
		n.Info = nil
	}

	if err := n.Cmd.Process.Signal(syscall.SIGTERM); err != nil {
		return n.Cmd.Process.Kill()
	}
	waitErr := make(chan error)
	go func() {
		waitErr <- n.Cmd.Wait()
	}()
	select {
	case err := <-waitErr:
		return err
	case <-time.After(5 * time.Second):
		return n.Cmd.Process.Kill()
	}
}
source: func (d *HypervPS4Driver) IpAddress(mac string) (string, error) {
	res, err := hyperv.IpAddress(mac)

	if err != nil {
		return res, err
	}

	if res == "" {
		err := fmt.Errorf("%s", "No ip address.")
		return res, err
	}
	return res, err
}
source: func (p *NetPlugin) Deinit() {
	p.Lock()
	defer p.Unlock()

	if p.NetworkDriver != nil {
		p.NetworkDriver.Deinit()
		p.NetworkDriver = nil
	}
	if p.StateDriver != nil {
		utils.ReleaseStateDriver()
		p.StateDriver = nil
	}
}
source: func (p *Init) Status(ctx context.Context) (string, error) {
	p.mu.Lock()
	defer p.mu.Unlock()

	c, err := p.runtime.State(ctx, p.id)
	if err != nil {
		if strings.Contains(err.Error(), "does not exist") {
			return "stopped", nil
		}
		return "", p.runtimeError(err, "OCI runtime state failed")
	}
	return c.Status, nil
}
source: func (pb *Block) Tombstones() (TombstoneReader, error) {
	if err := pb.startRead(); err != nil {
		return nil, err
	}
	return blockTombstoneReader{TombstoneReader: pb.tombstones, b: pb}, nil
}
source: func (c *Cloud) ResizeDisk(
	diskName KubernetesVolumeID,
	oldSize resource.Quantity,
	newSize resource.Quantity) (resource.Quantity, error) {
	awsDisk, err := newAWSDisk(c, diskName)
	if err != nil {
		return oldSize, err
	}

	volumeInfo, err := awsDisk.describeVolume()
	if err != nil {
		descErr := fmt.Errorf("AWS.ResizeDisk Error describing volume %s with %v", diskName, err)
		return oldSize, descErr
	}
	// AWS resizes in chunks of GiB (not GB)
	requestGiB := volumehelpers.RoundUpToGiB(newSize)
	newSizeQuant := resource.MustParse(fmt.Sprintf("%dGi", requestGiB))

	// If disk already if of greater or equal size than requested we return
	if aws.Int64Value(volumeInfo.Size) >= requestGiB {
		return newSizeQuant, nil
	}
	_, err = awsDisk.modifyVolume(requestGiB)

	if err != nil {
		return oldSize, err
	}
	return newSizeQuant, nil
}
source: func (term *Range) Scan(value interface{}) error {
	if value == nil {
		term.isEmpty = true // NULL should be an empty term
		return nil
	}

	b, ok := value.([]byte)
	if !ok {
		return fmt.Errorf("date: failed to convert date range to []byte")
	}

	// Zero ranges return "empty"
	if isEmptyRange(string(b)) {
		term.isEmpty = true
		return nil
	}

	// Otherwise, parse the given SQL date range
	start, end, err := splitRange(string(b))
	if err != nil {
		return err
	}

	if start == "infinity" || start == "" {
		// do nothing
	} else {
		var startDate Date
		if startDate, err = Parse(start); err != nil {
			return err
		}
		term.Start = startDate
	}

	if end == "infinity" || end == "" {
		return nil
	}

	var endDate Date
	if endDate, err = Parse(end); err != nil {
		return err
	}

	// Remove a single day from the date (it is exclusive - we want inclusive)
	endDate = endDate.AddDays(-1)
	term.End = endDate
	return nil
}
source: func (s *state) walkIncludeNode(node *parse.IncludeNode) (tpl string, ctx map[string]Value, err error) {
	ctx = make(map[string]Value)
	v, err := s.evalExpr(node.Tpl)
	if err != nil {
		return "", nil, err
	}
	tpl = CoerceString(v)
	var with Value
	if n := node.With; n != nil {
		with, err = s.evalExpr(n)
		// TODO: Assert "with" is a hash?
		if err != nil {
			return "", nil, err
		}
	}
	if !node.Only {
		ctx = s.scope.All()
	}
	if with != nil {
		if with, ok := with.(map[string]Value); ok {
			for k, v := range with {
				ctx[k] = v
			}
		}
	}
	return tpl, ctx, err
}
source: func (bs *blobStatter) Stat(ctx context.Context, dgst digest.Digest) (distribution.Descriptor, error) {
	path, err := pathFor(blobDataPathSpec{
		digest: dgst,
	})

	if err != nil {
		return distribution.Descriptor{}, err
	}

	fi, err := bs.driver.Stat(ctx, path)
	if err != nil {
		switch err := err.(type) {
		case driver.PathNotFoundError:
			return distribution.Descriptor{}, distribution.ErrBlobUnknown
		default:
			return distribution.Descriptor{}, err
		}
	}

	if fi.IsDir() {
		// NOTE(stevvooe): This represents a corruption situation. Somehow, we
		// calculated a blob path and then detected a directory. We log the
		// error and then error on the side of not knowing about the blob.
		dcontext.GetLogger(ctx).Warnf("blob path should not be a directory: %q", path)
		return distribution.Descriptor{}, distribution.ErrBlobUnknown
	}

	// TODO(stevvooe): Add method to resolve the mediatype. We can store and
	// cache a "global" media type for the blob, even if a specific repo has a
	// mediatype that overrides the main one.

	return distribution.Descriptor{
		Size: fi.Size(),

		// NOTE(stevvooe): The central blob store firewalls media types from
		// other users. The caller should look this up and override the value
		// for the specific repository.
		MediaType: "application/octet-stream",
		Digest:    dgst,
	}, nil
}
source: func (s *Options) SetVerifyMode(v string) *Options {
	s.VerifyMode = &v
	return s
}
source: func (p *WebPage) ClipRect() (Rect, error) {
	var resp struct {
		Value rectJSON `json:"value"`
	}
	if err := p.ref.process.doJSON("POST", "/webpage/ClipRect", map[string]interface{}{"ref": p.ref.id}, &resp); err != nil {
		return Rect{}, err
	}
	return Rect{
		Top:    resp.Value.Top,
		Left:   resp.Value.Left,
		Width:  resp.Value.Width,
		Height: resp.Value.Height,
	}, nil
}
source: func (n *node) Prefix(fieldName string, prefix string, to interface{}, options ...func(*index.Options)) error {
	sink, err := newListSink(n, to)
	if err != nil {
		return err
	}

	bucketName := sink.bucketName()
	if bucketName == "" {
		return ErrNoName
	}

	ref := reflect.Indirect(reflect.New(sink.elemType))
	cfg, err := extractSingleField(&ref, fieldName)
	if err != nil {
		return err
	}

	opts := index.NewOptions()
	for _, fn := range options {
		fn(opts)
	}

	field, ok := cfg.Fields[fieldName]
	if !ok || (!field.IsID && field.Index == "") {
		query := newQuery(n, q.Re(fieldName, fmt.Sprintf("^%s", prefix)))
		query.Skip(opts.Skip).Limit(opts.Limit)

		if opts.Reverse {
			query.Reverse()
		}

		err = n.readTx(func(tx *bolt.Tx) error {
			return query.query(tx, sink)
		})

		if err != nil {
			return err
		}

		return sink.flush()
	}

	prfx, err := toBytes(prefix, n.codec)
	if err != nil {
		return err
	}

	return n.readTx(func(tx *bolt.Tx) error {
		return n.prefix(tx, bucketName, fieldName, cfg, sink, prfx, opts)
	})
}
source: func (pp *primitiveParser) loadTypeComments() {
	pp.typedecls = make(map[int]string)
	for _, c := range pp.p.Comments {
		cmt := strings.Trim(c.List[0].Text, "/* \t")
		parts := strings.Split(cmt, " ")
		if len(parts) == 2 && parts[0] == "type:" {
			pp.typedecls[pp.fset.Position(c.List[0].Pos()).Line] = parts[1]
		}
	}
}
source: func (c Credential) MarshalYAML() (interface{}, error) {
	return credentialInternal{c.authType, c.attributes}, nil
}
source: func (m *MongoDB) RotateRootCredentials(ctx context.Context, statements []string) (map[string]interface{}, error) {
	return nil, errors.New("root credential rotation is not currently implemented in this database secrets engine")
}
source: func (s Session) Del(key string) {
	sessionJsonMap := s.getSessionJsonMap()
	delete(sessionJsonMap, key)
	delete(s, key)
}
source: func (m *MongoCache) delete(key string) error {
	query := func(c *mgo.Collection) error {
		err := c.RemoveId(key)
		return err
	}

	return m.run(m.CollectionName, query)
}
source: func Convert_v1_PersistentVolumeClaimSpec_To_core_PersistentVolumeClaimSpec(in *v1.PersistentVolumeClaimSpec, out *core.PersistentVolumeClaimSpec, s conversion.Scope) error {
	return autoConvert_v1_PersistentVolumeClaimSpec_To_core_PersistentVolumeClaimSpec(in, out, s)
}
source: func preload(associations ...string) scope {
	var scope composedScope

	for _, a := range associations {
		aa := a
		scope = append(scope, scopeFunc(func(db *gorm.DB) *gorm.DB {
			return db.Preload(aa)
		}))
	}

	return scope
}
source: func (s *server) RemovePeer(deadPeer net.Addr) error {
	if s.IsLeader() {
		return s.raft.RemovePeer(deadPeer).Error()
	} else {
		return nil
	}
}
source: func compactLowerdirOption(opts []string) (string, []string) {
	idx, dirs := findOverlayLowerdirs(opts)
	if idx == -1 || len(dirs) == 1 {
		// no need to compact if there is only one lowerdir
		return "", opts
	}

	// find out common dir
	commondir := longestCommonPrefix(dirs)
	if commondir == "" {
		return "", opts
	}

	// NOTE: the snapshot id is based on digits.
	// in order to avoid to get snapshots/x, should be back to parent dir.
	// however, there is assumption that the common dir is ${root}/io.containerd.v1.overlayfs/snapshots.
	commondir = path.Dir(commondir)
	if commondir == "/" {
		return "", opts
	}
	commondir = commondir + "/"

	newdirs := make([]string, 0, len(dirs))
	for _, dir := range dirs {
		newdirs = append(newdirs, dir[len(commondir):])
	}

	newopts := copyOptions(opts)
	newopts = append(newopts[:idx], newopts[idx+1:]...)
	newopts = append(newopts, fmt.Sprintf("lowerdir=%s", strings.Join(newdirs, ":")))
	return commondir, newopts
}
source: func ListenAndServe(n, addr string, rh Handler) error {
	uaddr, err := net.ResolveUDPAddr(n, addr)
	if err != nil {
		return err
	}

	l, err := net.ListenUDP(n, uaddr)
	if err != nil {
		return err
	}

	return Serve(l, rh)
}
source: func (e forwardError) Error() string {
	return fmt.Sprintf("%s (cause=%s, metrics=%d): %v", e.msg, e.cause,
		e.numMetrics, e.err)
}
source: func EnumName(m map[int32]string, v int32) string {
	s, ok := m[v]
	if ok {
		return s
	}
	return strconv.Itoa(int(v))
}
source: func supplementTimeoutResolver(r *htlcTimeoutResolver,
	htlcMap map[wire.OutPoint]*channeldb.HTLC) error {

	res := r.htlcResolution
	htlcPoint := res.HtlcPoint()
	htlc, ok := htlcMap[htlcPoint]
	if !ok {
		return errors.New(
			"htlc for timeout resolver unavailable",
		)
	}
	r.htlcAmt = htlc.Amt
	return nil
}
source: func (ct CompressionType) toMask() compressionTypeMask {

	switch ct {
	case CompressionTypeV1:
		return compressionTypeV1Mask
	case CompressionTypeV2:
		return compressionTypeV2Mask
	default:
		return compressionTypeNoneMask
	}
}
source: func (c *confirms) Multiple(confirmed Confirmation) {
	c.m.Lock()
	defer c.m.Unlock()

	for c.expecting <= confirmed.DeliveryTag {
		c.confirm(Confirmation{c.expecting, confirmed.Ack})
	}
	c.resequence()
}
source: func (s *Store) Snapshot() (raft.FSMSnapshot, error) {
	s.restoreMu.RLock()
	defer s.restoreMu.RUnlock()

	// Snapshots are not permitted while any connection has a transaction
	// in progress, because it's not possible (not without a lot of extra
	// code anyway) to capture the state of a connection during a transaction
	// on that connection. Since only during Apply() can a connection change
	// its transaction state, and Apply() is never called concurrently with
	// this call, it's safe to check transaction state here across all connections.
	if err := func() error {
		s.connsMu.Lock()
		defer s.connsMu.Unlock()
		for _, c := range s.conns {
			if c.TransactionActive() {
				stats.Add(numSnaphotsBlocked, 1)
				return ErrTransactionActive
			}
		}
		return nil
	}(); err != nil {
		return nil, err
	}

	// Copy the database.
	fsm := &fsmSnapshot{}
	var buf bytes.Buffer
	var err error
	err = s.database(false, &buf)
	if err != nil {
		s.logger.Printf("failed to read database for snapshot: %s", err.Error())
		return nil, err
	}
	fsm.database = buf.Bytes()

	// Copy the node metadata.
	fsm.meta, err = json.Marshal(s.meta)
	if err != nil {
		s.logger.Printf("failed to encode meta for snapshot: %s", err.Error())
		return nil, err
	}

	// Copy the active connections.
	fsm.connections, err = json.Marshal(s.conns)
	if err != nil {
		s.logger.Printf("failed to encode connections for snapshot: %s", err.Error())
		return nil, err
	}
	stats.Add(numSnaphots, 1)

	return fsm, nil
}
source: func NewSTSWebIdentity(stsEndpoint string, getWebIDTokenExpiry func() (*WebIdentityToken, error)) (*Credentials, error) {
	if stsEndpoint == "" {
		return nil, errors.New("STS endpoint cannot be empty")
	}
	if getWebIDTokenExpiry == nil {
		return nil, errors.New("Web ID token and expiry retrieval function should be defined")
	}
	return New(&STSWebIdentity{
		Client: &http.Client{
			Transport: http.DefaultTransport,
		},
		stsEndpoint:         stsEndpoint,
		getWebIDTokenExpiry: getWebIDTokenExpiry,
	}), nil
}
source: func WithName(s string) source.Option {
	return func(o *source.Options) {
		if o.Context == nil {
			o.Context = context.Background()
		}
		o.Context = context.WithValue(o.Context, nameKey{}, s)
	}
}
source: func ScanRow(rows *sql.Rows, dst interface{}) error {
	return Default.ScanRow(rows, dst)
}
source: func (v StrVCS) ReadDir(revision, path string) (files []os.FileInfo, err error) {
	for file := range v.files[revision] {
		files = append(files, fileInfo{
			name: file,
		})
	}
	return files, nil
}
source: func (api *Client) GetConversationReplies(params *GetConversationRepliesParameters) (msgs []Message, hasMore bool, nextCursor string, err error) {
	return api.GetConversationRepliesContext(context.Background(), params)
}
source: func NSFindOneChildCtx(ctx NSContext, el *etree.Element, namespace, tag string) (*etree.Element, error) {
	var found *etree.Element

	err := NSFindChildrenIterateCtx(ctx, el, namespace, tag, func(ctx NSContext, el *etree.Element) error {
		found = el
		return ErrTraversalHalted
	})

	if err != nil && err != ErrTraversalHalted {
		return nil, err
	}

	return found, nil
}
source: func NewBinaryInfo(goos, goarch string) *BinaryInfo {
	r := &BinaryInfo{GOOS: goos, nameOfRuntimeType: make(map[uintptr]nameOfRuntimeTypeEntry), typeCache: make(map[dwarf.Offset]godwarf.Type)}

	// TODO: find better way to determine proc arch (perhaps use executable file info).
	switch goarch {
	case "amd64":
		r.Arch = AMD64Arch(goos)
	}

	return r
}
source: func (s *Stubs) Stub(varToStub interface{}, stubVal interface{}) *Stubs {
	v := reflect.ValueOf(varToStub)
	stub := reflect.ValueOf(stubVal)

	// Ensure varToStub is a pointer to the variable.
	if v.Type().Kind() != reflect.Ptr {
		panic("variable to stub is expected to be a pointer")
	}

	if _, ok := s.stubs[v]; !ok {
		// Store the original value if this is the first time varPtr is being stubbed.
		s.stubs[v] = reflect.ValueOf(v.Elem().Interface())
	}

	// *varToStub = stubVal
	v.Elem().Set(stub)
	return s
}
source: func (service *BaseService) DoFunctionList(context ServiceContext) []byte {
	writer := io.NewWriter(true)
	writer.WriteByte(io.TagFunctions)
	writer.WriteStringSlice(service.MethodNames)
	writer.WriteByte(io.TagEnd)
	return writer.Bytes()
}
source: func (v *VARIANT) ToIDispatch() *IDispatch {
	if v.VT != VT_DISPATCH {
		return nil
	}
	return (*IDispatch)(unsafe.Pointer(uintptr(v.Val)))
}
source: func (o *VSP) CreateNetconfManager(child *NetconfManager) *bambou.Error {

	return bambou.CurrentSession().CreateChild(o, child)
}
source: func (s *ScanService) Types(types ...string) *ScanService {
	if s.types == nil {
		s.types = make([]string, 0)
	}
	s.types = append(s.types, types...)
	return s
}
source: func substituteAsset(ctx context.Context, asset string, substitutions interface{}) (string, error) {
	return substitute(ctx, string(GetAsset(asset)), substitutions)
}
source: func OnTripped(s SideEffect) CircuitBreakerOption {
	return func(c *CircuitBreaker) error {
		c.onTripped = s
		return nil
	}
}
source: func (v *Version) String() string {
	return fmt.Sprintf(
		`Version{Name: %v, Version: %v, Platform: %v, Architecture: %v}`,
		v.Name, v.Version, v.Platform, v.Architecture)
}
source: func (j *Jobs) Revert(jobID string, version uint64, enforcePriorVersion *uint64,
	q *WriteOptions, vaultToken string) (*JobRegisterResponse, *WriteMeta, error) {

	var resp JobRegisterResponse
	req := &JobRevertRequest{
		JobID:               jobID,
		JobVersion:          version,
		EnforcePriorVersion: enforcePriorVersion,
		VaultToken:          vaultToken,
	}
	wm, err := j.client.write("/v1/job/"+jobID+"/revert", req, &resp, q)
	if err != nil {
		return nil, nil, err
	}
	return &resp, wm, nil
}
source: func getVariable(image *api.Image, name string) string {
	envName := name + "="
	for _, v := range image.Config.Env {
		if strings.HasPrefix(v, envName) {
			return strings.TrimSpace(v[len(envName):])
		}
	}

	return ""
}
source: func CompactString(r rbacv1.PolicyRule) string {
	formatStringParts := []string{}
	formatArgs := []interface{}{}
	if len(r.APIGroups) > 0 {
		formatStringParts = append(formatStringParts, "APIGroups:%q")
		formatArgs = append(formatArgs, r.APIGroups)
	}
	if len(r.Resources) > 0 {
		formatStringParts = append(formatStringParts, "Resources:%q")
		formatArgs = append(formatArgs, r.Resources)
	}
	if len(r.NonResourceURLs) > 0 {
		formatStringParts = append(formatStringParts, "NonResourceURLs:%q")
		formatArgs = append(formatArgs, r.NonResourceURLs)
	}
	if len(r.ResourceNames) > 0 {
		formatStringParts = append(formatStringParts, "ResourceNames:%q")
		formatArgs = append(formatArgs, r.ResourceNames)
	}
	if len(r.Verbs) > 0 {
		formatStringParts = append(formatStringParts, "Verbs:%q")
		formatArgs = append(formatArgs, r.Verbs)
	}
	formatString := "{" + strings.Join(formatStringParts, ", ") + "}"
	return fmt.Sprintf(formatString, formatArgs...)
}
source: func (d draw) HistogramSeries(r Renderer, canvasBox Box, xrange, yrange Range, style Style, vs ValuesProvider, barWidths ...int) {
	if vs.Len() == 0 {
		return
	}

	//calculate bar width?
	seriesLength := vs.Len()
	barWidth := int(math.Floor(float64(xrange.GetDomain()) / float64(seriesLength)))
	if len(barWidths) > 0 {
		barWidth = barWidths[0]
	}

	cb := canvasBox.Bottom
	cl := canvasBox.Left

	//foreach datapoint, draw a box.
	for index := 0; index < seriesLength; index++ {
		vx, vy := vs.GetValues(index)
		y0 := yrange.Translate(0)
		x := cl + xrange.Translate(vx)
		y := yrange.Translate(vy)

		d.Box(r, Box{
			Top:    cb - y0,
			Left:   x - (barWidth >> 1),
			Right:  x + (barWidth >> 1),
			Bottom: cb - y,
		}, style)
	}
}
source: func Convert_v1beta2_ClusterStatus_To_kubeadm_ClusterStatus(in *ClusterStatus, out *kubeadm.ClusterStatus, s conversion.Scope) error {
	return autoConvert_v1beta2_ClusterStatus_To_kubeadm_ClusterStatus(in, out, s)
}
source: func WithLocalDiscoveryProvider(discoveryProvider fab.LocalDiscoveryProvider) SDKContextParams {
	return func(ctx *Provider) {
		ctx.localDiscoveryProvider = discoveryProvider
	}
}
source: func (e *Endpoint) GetDockerNetworkID() string {
	e.UnconditionalRLock()
	defer e.RUnlock()

	return e.DockerNetworkID
}
source: func openBucket(
	name string,
	httpConn http.Conn,
	signer auth.Signer,
	clock time.Clock) (Bucket, error) {
	return &bucket{name, httpConn, signer, clock}, nil
}
source: func createVM(c context.Context, payload proto.Message) error {
	task, ok := payload.(*tasks.CreateVM)
	switch {
	case !ok:
		return errors.Reason("unexpected payload type %T", payload).Err()
	case task.GetId() == "":
		return errors.Reason("ID is required").Err()
	case task.GetConfig() == "":
		return errors.Reason("config is required").Err()
	}
	vm := &model.VM{
		ID:       task.Id,
		Config:   task.Config,
		Hostname: fmt.Sprintf("%s-%d-%s", task.Prefix, task.Index, getSuffix(c)),
		Index:    task.Index,
		Lifetime: task.Lifetime,
		Prefix:   task.Prefix,
		Revision: task.Revision,
		Swarming: task.Swarming,
		Timeout:  task.Timeout,
	}
	if task.Attributes != nil {
		vm.Attributes = *task.Attributes
		// TODO(crbug/942301): Auto-select zone if zone is unspecified.
		vm.Attributes.SetZone(vm.Attributes.GetZone())
	}
	// createVM is called repeatedly, so do a fast check outside the transaction.
	// In most cases, this will skip the more expensive transactional check.
	switch err := datastore.Get(c, vm); {
	case err == datastore.ErrNoSuchEntity:
	case err != nil:
		return errors.Annotate(err, "failed to fetch VM").Err()
	default:
		return nil
	}
	return datastore.RunInTransaction(c, func(c context.Context) error {
		switch err := datastore.Get(c, vm); {
		case err == datastore.ErrNoSuchEntity:
		case err != nil:
			return errors.Annotate(err, "failed to fetch VM").Err()
		default:
			return nil
		}
		if err := datastore.Put(c, vm); err != nil {
			return errors.Annotate(err, "failed to store VM").Err()
		}
		return nil
	}, nil)
}
source: func checkLimits(current, newCount, max int) error {
	if newCount > max {
		return fmt.Errorf("Adding specified prefixes would result in too many prefix lengths (current: %d, result: %d, max: %d)",
			current, newCount, max)
	}
	return nil
}
source: func (rl *List) Get(index int64) (string, error) {
	conn := rl.pool.Get(rl.dbindex)
	result, err := conn.Do("LINDEX", rl.id)
	if err != nil {
		panic(err)
	}
	return redis.String(result, err)
}
source: func (o *FlagOption) Run(value string) error {
	if err := o.flags.Parse(value); err != nil {
		return err
	}
	return nil
}
source: func (m *CreateMetaInfo) GetProjectWithName(name string) *MetaProject {
	for _, m := range m.Projects {
		if strings.ToLower(m.Name) == strings.ToLower(name) {
			return m
		}
	}
	return nil
}
source: func (tc *TransCache) RemoveGroup(chID, grpID string, commit bool, transID string) {
	if commit {
		if transID == "" { // Lock locally
			tc.cacheMux.Lock()
			defer tc.cacheMux.Unlock()
		}
		tc.cacheInstance(chID).RemoveGroup(grpID)
	} else {
		tc.transBufMux.Lock()
		tc.transactionBuffer[transID] = append(tc.transactionBuffer[transID],
			&transactionItem{cacheID: chID, verb: RemoveGroup, groupIDs: []string{grpID}})
		tc.transBufMux.Unlock()
	}
}
source: func (net *Network) GetNodeByName(name string) *Node {
	net.lock.RLock()
	defer net.lock.RUnlock()
	return net.getNodeByName(name)
}
source: func (in *MutatingWebhookConfiguration) DeepCopy() *MutatingWebhookConfiguration {
	if in == nil {
		return nil
	}
	out := new(MutatingWebhookConfiguration)
	in.DeepCopyInto(out)
	return out
}
source: func (s *Service) FindMacros(ctx context.Context) ([]*platform.Macro, error) {
	op := OpPrefix + platform.OpFindMacros
	var err error
	var macros []*platform.Macro
	s.macroKV.Range(func(k, v interface{}) bool {
		macro, ok := v.(*platform.Macro)
		if !ok {
			err = &platform.Error{
				Op:  op,
				Msg: fmt.Sprintf("type %T is not a macro", v),
			}
			return false
		}

		macros = append(macros, macro)
		return true
	})

	if err != nil {
		return nil, err
	}

	return macros, nil
}
source: func (l *Logger) Printf(format string, args ...interface{}) {
	l.logf(l.app, logLevelNotice, format, false, args...)
}
source: func (s *Server) setupVaultClient() error {
	v, err := NewVaultClient(s.config.VaultConfig, s.logger, s.purgeVaultAccessors)
	if err != nil {
		return err
	}
	s.vault = v
	return nil
}
source: func (n *Node) String() string {
	return fmt.Sprintf("%v|%d|%d", n.addr, n.cm.count(), n.cm.q.count())
}
source: func messageFromBytes(data []byte) (*message, error) {

	var err error
	var versionData [4]byte
	var typeData [4]byte
	minimumDataSize := 4 + 4
	m := new(message)

	// check if the data is smaller than 36 which is the minimum
	if data == nil {
		return nil, MessageParsingError
	}

	if len(data) < minimumDataSize+1 {
		return nil, MessageParsingError
	}

	version := data[:4]
	typeMsg := data[4:8]
	message := data[8:]

	total := copy(versionData[:], version)
	if total != 4 {
		return nil, MessageParsingError
	}

	total = copy(typeData[:], typeMsg)
	if total != 4 {
		return nil, MessageParsingError
	}

	m.Version = smallendian.FromInt(versionData)
	m.Type = smallendian.FromInt(typeData)
	m.Text = string(message)
	return m, err
}
source: func (v Value) FindMethod(rootMethodName string, version int, objMethodName string) (MethodCaller, error) {
	if !v.IsValid() {
		panic("FindMethod called on invalid Value")
	}
	caller := methodCaller{
		rootValue: v.rootValue,
	}
	var err error
	caller.rootMethod, err = v.rootType.Method(rootMethodName)
	if err != nil {
		return nil, &CallNotImplementedError{
			RootMethod: rootMethodName,
		}
	}
	caller.objMethod, err = caller.rootMethod.ObjType.Method(objMethodName)
	if err != nil {
		return nil, &CallNotImplementedError{
			RootMethod: rootMethodName,
			Method:     objMethodName,
		}
	}
	return caller, nil
}
source: func accountCreate(ctx *cli.Context) error {
	cfg := gethConfig{Node: defaultNodeConfig()}
	// Load config file.
	if file := ctx.GlobalString(configFileFlag.Name); file != "" {
		if err := loadConfig(file, &cfg); err != nil {
			utils.Fatalf("%v", err)
		}
	}
	utils.SetNodeConfig(ctx, &cfg.Node)
	scryptN, scryptP, keydir, err := cfg.Node.AccountConfig()

	if err != nil {
		utils.Fatalf("Failed to read configuration: %v", err)
	}

	password := getPassPhrase("Your new account is locked with a password. Please give a password. Do not forget this password.", true, 0, utils.MakePasswordList(ctx))

	address, err := keystore.StoreKey(keydir, password, scryptN, scryptP)

	if err != nil {
		utils.Fatalf("Failed to create account: %v", err)
	}
	fmt.Printf("Address: {%x}\n", address)
	return nil
}
source: func CleanMinioInternalMetadataKeys(metadata map[string]string) map[string]string {
	var newMeta = make(map[string]string, len(metadata))
	for k, v := range metadata {
		if strings.HasPrefix(k, "X-Amz-Meta-X-Minio-Internal-") {
			newMeta[strings.TrimPrefix(k, "X-Amz-Meta-")] = v
		} else {
			newMeta[k] = v
		}
	}
	return newMeta
}
source: func (bi *BinaryInfo) Types() ([]string, error) {
	types := make([]string, 0, len(bi.types))
	for k := range bi.types {
		types = append(types, k)
	}
	return types, nil
}
source: func (eh eventEventHandler) Handle(s *Session, i interface{}) {
	if t, ok := i.(*Event); ok {
		eh(s, t)
	}
}
source: func (r Hardware_SecurityModule750) GetDownstreamHardwareBindings() (resp []datatypes.Network_Component_Uplink_Hardware, err error) {
	err = r.Session.DoRequest("SoftLayer_Hardware_SecurityModule750", "getDownstreamHardwareBindings", nil, &r.Options, &resp)
	return
}
source: func Convert_v1_SelfSubjectRulesReview_To_authorization_SelfSubjectRulesReview(in *v1.SelfSubjectRulesReview, out *authorization.SelfSubjectRulesReview, s conversion.Scope) error {
	return autoConvert_v1_SelfSubjectRulesReview_To_authorization_SelfSubjectRulesReview(in, out, s)
}
source: func AddKeyspaceIDs(sql string, keyspaceIDs [][]byte, marginComments string) string {
	encodedIDs := make([][]byte, len(keyspaceIDs))
	for i, src := range keyspaceIDs {
		encodedIDs[i] = make([]byte, hex.EncodedLen(len(src)))
		hex.Encode(encodedIDs[i], src)
	}
	return fmt.Sprintf("%s /* vtgate:: keyspace_id:%s */%s",
		sql, bytes.Join(encodedIDs, []byte(",")), marginComments)
}
source: func (s *ListResourceRecordSetsInput) SetStartRecordName(v string) *ListResourceRecordSetsInput {
	s.StartRecordName = &v
	return s
}
source: func (r *addrsRecord) flush(write ds.Write) (err error) {
	key := addrBookBase.ChildString(b32.RawStdEncoding.EncodeToString([]byte(r.Id.ID)))
	if len(r.Addrs) == 0 {
		if err = write.Delete(key); err == nil {
			r.dirty = false
		}
		return err
	}

	data, err := r.Marshal()
	if err != nil {
		return err
	}
	if err = write.Put(key, data); err != nil {
		return err
	}
	// write succeeded; record is no longer dirty.
	r.dirty = false
	return nil
}
source: func (k *Store) Get(key string) interface{} {
	// Read-only lock
	k.mu.RLock()
	defer k.mu.RUnlock()

	// zero value of interface{} is nil so this does what we want
	return k.db[key]
}
source: func NewClientWrapper(b *ratelimit.Bucket, wait bool) client.Wrapper {
	fn := limit(b, wait, "go.micro.client")

	return func(c client.Client) client.Client {
		return &clientWrapper{fn, c}
	}
}
source: func (lc *LightningChannel) getSignedCommitTx() (*wire.MsgTx, error) {
	// Fetch the current commitment transaction, along with their signature
	// for the transaction.
	localCommit := lc.channelState.LocalCommitment
	commitTx := localCommit.CommitTx
	theirSig := append(localCommit.CommitSig, byte(txscript.SigHashAll))

	// With this, we then generate the full witness so the caller can
	// broadcast a fully signed transaction.
	lc.signDesc.SigHashes = txscript.NewTxSigHashes(commitTx)
	ourSigRaw, err := lc.Signer.SignOutputRaw(commitTx, lc.signDesc)
	if err != nil {
		return nil, err
	}

	ourSig := append(ourSigRaw, byte(txscript.SigHashAll))

	// With the final signature generated, create the witness stack
	// required to spend from the multi-sig output.
	ourKey := lc.localChanCfg.MultiSigKey.PubKey.SerializeCompressed()
	theirKey := lc.remoteChanCfg.MultiSigKey.PubKey.SerializeCompressed()

	commitTx.TxIn[0].Witness = input.SpendMultiSig(
		lc.signDesc.WitnessScript, ourKey,
		ourSig, theirKey, theirSig,
	)

	return commitTx, nil
}
source: func (we *WorkflowExecutor) LoadExecutionControl() error {
	err := unmarshalAnnotationField(we.PodAnnotationsPath, common.AnnotationKeyExecutionControl, &we.ExecutionControl)
	if err != nil {
		if errors.IsCode(errors.CodeNotFound, err) {
			return nil
		}
		return err
	}
	return nil
}
source: func (c *Client) StatsWithKey(key string) (map[string]McStats, error) {
	// Variants: Stats
	// Request : MAY HAVE key, MUST NOT value, extra
	// Response: Serries of responses that MUST HAVE key, value; followed by one
	//           response that MUST NOT have key, value. ALL MUST NOT extras.
	m := &msg{
		header: header{
			Op: opStat,
		},
		key: key,
	}

	allStats := make(map[string]McStats)
	for _, s := range c.servers {
		if s.isAlive {
			stats, err := s.performStats(m)
			if err != nil {
				return nil, err
			}
			allStats[s.address] = stats
		}
	}

	return allStats, nil
}
source: func subpathExprInUse(podSpec *api.PodSpec) bool {
	if podSpec == nil {
		return false
	}
	for i := range podSpec.Containers {
		for j := range podSpec.Containers[i].VolumeMounts {
			if len(podSpec.Containers[i].VolumeMounts[j].SubPathExpr) > 0 {
				return true
			}
		}
	}
	for i := range podSpec.InitContainers {
		for j := range podSpec.InitContainers[i].VolumeMounts {
			if len(podSpec.InitContainers[i].VolumeMounts[j].SubPathExpr) > 0 {
				return true
			}
		}
	}
	return false
}
source: func (h *Hooks) Add(f func()) {
	h.mu.Lock()
	defer h.mu.Unlock()
	h.funcs = append(h.funcs, f)
}
source: func (s *IndexField) SetIntArrayOptions(v *IntArrayOptions) *IndexField {
	s.IntArrayOptions = v
	return s
}
source: func (c *Client) CreateWebhook(webhook *Webhook) error {
	path := "webhooks"
	args := Arguments{"idModel": webhook.IDModel, "description": webhook.Description, "callbackURL": webhook.CallbackURL}
	err := c.Post(path, args, webhook)
	if err == nil {
		webhook.client = c
	}
	return err
}
source: func (r *Repository) BlobObjects() (*object.BlobIter, error) {
	iter, err := r.Storer.IterEncodedObjects(plumbing.BlobObject)
	if err != nil {
		return nil, err
	}

	return object.NewBlobIter(r.Storer, iter), nil
}
source: func (c *Client) maybeStartLimiter(wg *sync.WaitGroup, exiting chan struct{}) {
	if c.config.SendLimit == 0 {
		return
	}

	wg.Add(1)

	// If SendBurst is 0, this will be unbuffered, so keep that in mind.
	c.limiter = make(chan struct{}, c.config.SendBurst)
	limitTick := time.NewTicker(c.config.SendLimit)

	go func() {
		defer wg.Done()

		var done bool
		for !done {
			select {
			case <-limitTick.C:
				select {
				case c.limiter <- struct{}{}:
				default:
				}
			case <-exiting:
				done = true
			}
		}

		limitTick.Stop()
		close(c.limiter)
		c.limiter = nil
	}()
}
source: func (o *PetDeleteURL) Must(u *url.URL, err error) *url.URL {
	if err != nil {
		panic(err)
	}
	if u == nil {
		panic("url can't be nil")
	}
	return u
}
source: func ConvertCommentsResourceID(request *http.Request, comments []comment.Comment, additional ...CommentConvertFunc) []*app.Comment {
	var cs = []*app.Comment{}
	for _, c := range comments {
		cs = append(cs, ConvertCommentResourceID(request, c, additional...))
	}
	return cs
}
source: func (s *GetAccountBalanceOutput) SetAvailableBalance(v string) *GetAccountBalanceOutput {
	s.AvailableBalance = &v
	return s
}
source: func New(t *testing.T) *DB {
	// Pick a path for our socket.
	socketDir, err := ioutil.TempDir("", "fakesqldb")
	if err != nil {
		t.Fatalf("ioutil.TempDir failed: %v", err)
	}
	socketFile := path.Join(socketDir, "fakesqldb.sock")

	// Create our DB.
	db := &DB{
		t:            t,
		socketFile:   socketFile,
		name:         "fakesqldb",
		data:         make(map[string]*ExpectedResult),
		rejectedData: make(map[string]error),
		queryCalled:  make(map[string]int),
		connections:  make(map[uint32]*mysql.Conn),
	}

	db.Handler = db

	authServer := &mysql.AuthServerNone{}

	// Start listening.
	db.listener, err = mysql.NewListener("unix", socketFile, authServer, db, 0, 0)
	if err != nil {
		t.Fatalf("NewListener failed: %v", err)
	}

	db.acceptWG.Add(1)
	go func() {
		defer db.acceptWG.Done()
		db.listener.Accept()
	}()

	// Return the db.
	return db
}
source: func (p *FakePeer) RequestReceipts(hashes []common.Hash) error {
	var receipts [][]*types.Receipt
	for _, hash := range hashes {
		receipts = append(receipts, rawdb.ReadRawReceipts(p.db, hash, *p.hc.GetBlockNumber(hash)))
	}
	p.dl.DeliverReceipts(p.id, receipts)
	return nil
}
source: func (b *BitSet) MarshalJSON() ([]byte, error) {
	buffer := bytes.NewBuffer(make([]byte, 0, b.BinaryStorageSize()))
	_, err := b.WriteTo(buffer)
	if err != nil {
		return nil, err
	}

	// URLEncode all bytes
	return json.Marshal(base64Encoding.EncodeToString(buffer.Bytes()))
}
source: func (t *Tool) Run(c context.Context, f Generator) error {
	// Validate arguments.
	if len(t.FileNames) == 0 {
		return fmt.Errorf("files not specified")
	}
	if len(t.Types) == 0 {
		return fmt.Errorf("types not specified")
	}

	// Determine output file name.
	outputName := t.Output
	if outputName == "" {
		if t.Dir == "" {
			return fmt.Errorf("neither output not dir are specified")
		}
		baseName := fmt.Sprintf("%s_%s.go", t.Types[0], t.OutputFilenameSuffix)
		outputName = filepath.Join(t.Dir, strings.ToLower(baseName))
	}

	// Parse Go files and resolve specified types.
	p := &parser{
		fileSet: token.NewFileSet(),
		types:   t.Types,
	}
	if err := p.parsePackage(t.FileNames); err != nil {
		return fmt.Errorf("could not parse .go files: %s", err)
	}
	if err := p.resolveServices(c); err != nil {
		return err
	}

	// Run the generator.
	var buf bytes.Buffer
	genArgs := &GeneratorArgs{
		PackageName:  p.files[0].Name.Name,
		Services:     p.services,
		ExtraImports: importSorted(p.extraImports),
		Out:          &buf,
	}
	if err := f(c, genArgs); err != nil {
		return err
	}

	// Format the output.
	src, err := format.Source(buf.Bytes())
	if err != nil {
		println(buf.String())
		return fmt.Errorf("gofmt: %s", err)
	}

	// Write to file.
	return ioutil.WriteFile(outputName, src, 0644)
}
source: func (z *ConstNumber) Mul(x, y *ConstNumber) *ConstNumber {
	z.Type = promoteConstNumbers(x.Type, y.Type)
	z.Value.Mul(&x.Value, &y.Value)
	return z
}
source: func (p *Parth) Segment(i int, v interface{}) {
	if p.err != nil {
		return
	}

	p.err = Segment(p.path, i, v)
}
source: func (f *ToolsFinder) matchingStorageTools(args params.FindToolsParams) (coretools.List, error) {
	storage, err := f.toolsStorageGetter.ToolsStorage()
	if err != nil {
		return nil, err
	}
	defer storage.Close()
	allMetadata, err := storage.AllMetadata()
	if err != nil {
		return nil, err
	}
	list := make(coretools.List, len(allMetadata))
	for i, m := range allMetadata {
		vers, err := version.ParseBinary(m.Version)
		if err != nil {
			return nil, errors.Annotatef(err, "unexpected bad version %q of agent binary in storage", m.Version)
		}
		list[i] = &coretools.Tools{
			Version: vers,
			Size:    m.Size,
			SHA256:  m.SHA256,
		}
	}
	list, err = list.Match(toolsFilter(args))
	if err != nil {
		return nil, err
	}
	var matching coretools.List
	for _, tools := range list {
		if args.MajorVersion != -1 && tools.Version.Major != args.MajorVersion {
			continue
		}
		if args.MinorVersion != -1 && tools.Version.Minor != args.MinorVersion {
			continue
		}
		matching = append(matching, tools)
	}
	if len(matching) == 0 {
		return nil, coretools.ErrNoMatches
	}
	return matching, nil
}
source: func Procedure(name string, handler UnaryHandler) []transport.Procedure {
	return []transport.Procedure{
		{
			Name:        name,
			HandlerSpec: transport.NewUnaryHandlerSpec(rawUnaryHandler{handler}),
		},
	}
}
source: func (c *Client) AttachReservedIP(ip string, serverID string) error {
	values := url.Values{
		"ip_address":   {ip},
		"attach_SUBID": {serverID},
	}
	return c.post(`reservedip/attach`, values, nil)
}
source: func IsInvalidPatch(err error) bool {
	switch err := err.(type) {
	case *Error:
		return err.Code == InvalidPatchErr
	}
	return false
}
source: func (c *cmdable) SRandMemberN(key string, count int64) *StringSliceCmd {
	cmd := NewStringSliceCmd("srandmember", key, count)
	c.process(cmd)
	return cmd
}
source: func (s *CommandReject) Unmarshal(b []byte) error {
	return binary.Read(bytes.NewBuffer(b), binary.LittleEndian, s)
}
source: func (c *Client) GetSlavesFromLeader() (*State, error) {
	resp, err := c.GetHTTPResponseFromLeader(c.GetURLForSlavesFilePid)
	return c.parseStateResponse(resp, err)
}
source: func (enc *Encoder) AddUint32Key(key string, v uint32) {
	enc.Uint64Key(key, uint64(v))
}
source: func (u *UnlockerService) ChangePassword(ctx context.Context,
	in *lnrpc.ChangePasswordRequest) (*lnrpc.ChangePasswordResponse, error) {

	netDir := btcwallet.NetworkDir(u.chainDir, u.netParams)
	loader := wallet.NewLoader(u.netParams, netDir, 0)

	// First, we'll make sure the wallet exists for the specific chain and
	// network.
	walletExists, err := loader.WalletExists()
	if err != nil {
		return nil, err
	}

	if !walletExists {
		return nil, errors.New("wallet not found")
	}

	publicPw := in.CurrentPassword
	privatePw := in.CurrentPassword

	// If the current password is blank, we'll assume the user is coming
	// from a --noseedbackup state, so we'll use the default passwords.
	if len(in.CurrentPassword) == 0 {
		publicPw = lnwallet.DefaultPublicPassphrase
		privatePw = lnwallet.DefaultPrivatePassphrase
	}

	// Make sure the new password meets our constraints.
	if err := ValidatePassword(in.NewPassword); err != nil {
		return nil, err
	}

	// Load the existing wallet in order to proceed with the password change.
	w, err := loader.OpenExistingWallet(publicPw, false)
	if err != nil {
		return nil, err
	}
	// Unload the wallet to allow lnd to open it later on.
	defer loader.UnloadWallet()

	// Since the macaroon database is also encrypted with the wallet's
	// password, we'll remove all of the macaroon files so that they're
	// re-generated at startup using the new password. We'll make sure to do
	// this after unlocking the wallet to ensure macaroon files don't get
	// deleted with incorrect password attempts.
	for _, file := range u.macaroonFiles {
		err := os.Remove(file)
		if err != nil && !os.IsNotExist(err) {
			return nil, err
		}
	}

	// Attempt to change both the public and private passphrases for the
	// wallet. This will be done atomically in order to prevent one
	// passphrase change from being successful and not the other.
	err = w.ChangePassphrases(
		publicPw, in.NewPassword, privatePw, in.NewPassword,
	)
	if err != nil {
		return nil, fmt.Errorf("unable to change wallet passphrase: "+
			"%v", err)
	}

	// Finally, send the new password across the UnlockPasswords channel to
	// automatically unlock the wallet.
	u.UnlockMsgs <- &WalletUnlockMsg{Passphrase: in.NewPassword}

	return &lnrpc.ChangePasswordResponse{}, nil
}
source: func (alle *assetLruListElement) Next() *assetLruListElement {
	if p := alle.next; alle.list != nil && p != &alle.list.root {
		return p
	}
	return nil
}
source: func writeModelFiles(tables []*Table, mPath string) {
	w := colors.NewColorWriter(os.Stdout)

	for _, tb := range tables {
		filename := getFileName(tb.Name)
		fpath := path.Join(mPath, filename+".go")
		var f *os.File
		var err error
		if utils.IsExist(fpath) {
			beeLogger.Log.Warnf("'%s' already exists. Do you want to overwrite it? [Yes|No] ", fpath)
			if utils.AskForConfirmation() {
				f, err = os.OpenFile(fpath, os.O_RDWR|os.O_TRUNC, 0666)
				if err != nil {
					beeLogger.Log.Warnf("%s", err)
					continue
				}
			} else {
				beeLogger.Log.Warnf("Skipped create file '%s'", fpath)
				continue
			}
		} else {
			f, err = os.OpenFile(fpath, os.O_CREATE|os.O_RDWR, 0666)
			if err != nil {
				beeLogger.Log.Warnf("%s", err)
				continue
			}
		}
		var template string
		if tb.Pk == "" {
			template = StructModelTPL
		} else {
			template = ModelTPL
		}
		fileStr := strings.Replace(template, "{{modelStruct}}", tb.String(), 1)
		fileStr = strings.Replace(fileStr, "{{modelName}}", utils.CamelCase(tb.Name), -1)
		fileStr = strings.Replace(fileStr, "{{tableName}}", tb.Name, -1)

		// If table contains time field, import time.Time package
		timePkg := ""
		importTimePkg := ""
		if tb.ImportTimePkg {
			timePkg = "\"time\"\n"
			importTimePkg = "import \"time\"\n"
		}
		fileStr = strings.Replace(fileStr, "{{timePkg}}", timePkg, -1)
		fileStr = strings.Replace(fileStr, "{{importTimePkg}}", importTimePkg, -1)
		if _, err := f.WriteString(fileStr); err != nil {
			beeLogger.Log.Fatalf("Could not write model file to '%s': %s", fpath, err)
		}
		utils.CloseFile(f)
		fmt.Fprintf(w, "\t%s%screate%s\t %s%s\n", "\x1b[32m", "\x1b[1m", "\x1b[21m", fpath, "\x1b[0m")
		utils.FormatSourceCode(fpath)
	}
}
source: func (t TimeRange) Intersect(other TimeRange) TimeRange {
	if !other.Min.IsZero() {
		if t.Min.IsZero() || other.Min.After(t.Min) {
			t.Min = other.Min
		}
	}
	if !other.Max.IsZero() {
		if t.Max.IsZero() || other.Max.Before(t.Max) {
			t.Max = other.Max
		}
	}
	return t
}
source: func (in *ResourceActionDefinition) DeepCopy() *ResourceActionDefinition {
	if in == nil {
		return nil
	}
	out := new(ResourceActionDefinition)
	in.DeepCopyInto(out)
	return out
}
source: func getListener(uri pilosa.URI, tlsconf *tls.Config) (ln net.Listener, err error) {
	// If bind URI has the https scheme, enable TLS
	if uri.Scheme == "https" && tlsconf != nil {
		ln, err = tls.Listen("tcp", uri.HostPort(), tlsconf)
		if err != nil {
			return nil, errors.Wrap(err, "tls.Listener")
		}
	} else if uri.Scheme == "http" {
		// Open HTTP listener to determine port (if specified as :0).
		ln, err = net.Listen("tcp", uri.HostPort())
		if err != nil {
			return nil, errors.Wrap(err, "net.Listen")
		}
	} else {
		return nil, errors.Errorf("unsupported scheme: %s", uri.Scheme)
	}

	return ln, nil
}
source: func Debug(b bool) Option {
	return func(p *parser) Option {
		old := p.debug
		p.debug = b
		return Debug(old)
	}
}
source: func (client *Client) CaptureError(err error, tags map[string]string, interfaces ...Interface) string {
	if client == nil {
		return ""
	}

	if err == nil {
		return ""
	}

	if client.shouldExcludeErr(err.Error()) {
		return ""
	}

	extra := extractExtra(err)
	cause := Cause(err)

	packet := NewPacketWithExtra(err.Error(), extra, append(append(interfaces, client.context.interfaces()...), NewException(cause, GetOrNewStacktrace(cause, 1, 3, client.includePaths)))...)
	eventID, _ := client.Capture(packet, tags)

	return eventID
}
source: func (c *Client) GetInitiatorGroups() (Refs, error) {
	ig, err := c.api.GetInitiatorGroups()
	if err != nil {
		return nil, err
	}
	return ig.InitiatorGroups, nil
}
source: func (o testOutput) Write(p []byte) (int, error) {
	msg := strings.TrimSpace(string(p))
	o.Log(msg)
	return len(p), nil
}
source: func (hc *halfConn) freeBlock(b *block) {
	b.link = hc.bfree
	hc.bfree = b
}
source: func putTargetStream(ctx context.Context, alias string, urlStr string, reader io.Reader, size int64, metadata map[string]string, progress io.Reader, sse encrypt.ServerSide) (int64, *probe.Error) {
	targetClnt, err := newClientFromAlias(alias, urlStr)
	if err != nil {
		return 0, err.Trace(alias, urlStr)
	}
	n, err := targetClnt.Put(ctx, reader, size, metadata, progress, sse)
	if err != nil {
		return n, err.Trace(alias, urlStr)
	}
	return n, nil
}
source: func NewScriptsInsideImageError(url string) error {
	return Error{
		Message:    fmt.Sprintf("scripts inside the image: %s", url),
		Details:    nil,
		ErrorCode:  ScriptsInsideImageError,
		Suggestion: "",
	}
}
source: func (hook LogrusStackHook) Fire(entry *logrus.Entry) error {
	var skipFrames int
	if len(entry.Data) == 0 {
		// When WithField(s) is not used, we have 8 logrus frames to skip.
		skipFrames = 8
	} else {
		// When WithField(s) is used, we have 6 logrus frames to skip.
		skipFrames = 6
	}

	var frames stack.Stack

	// Get the complete stack track past skipFrames count.
	_frames := stack.Callers(skipFrames)

	// Remove logrus's own frames that seem to appear after the code is through
	// certain hoops. e.g. http handler in a separate package.
	// This is a workaround.
	for _, frame := range _frames {
		if !strings.Contains(frame.File, "github.com/sirupsen/logrus") {
			frames = append(frames, frame)
		}
	}

	if len(frames) > 0 {
		// If we have a frame, we set it to "caller" field for assigned levels.
		for _, level := range hook.CallerLevels {
			if entry.Level == level {
				entry.Data["caller"] = frames[0]
				break
			}
		}

		// Set the available frames to "stack" field.
		for _, level := range hook.StackLevels {
			if entry.Level == level {
				entry.Data["stack"] = frames
				break
			}
		}
	}

	return nil
}
source: func RegisterHandlerConstructor(typ string, ctor HandlerConstructor) {
	mapLock.Lock()
	defer mapLock.Unlock()
	if _, ok := handlerConstructors[typ]; ok {
		panic("blobserver: HandlerConstrutor already registered for type: " + typ)
	}
	handlerConstructors[typ] = ctor
}
source: func (in *InstanceGroupList) DeepCopy() *InstanceGroupList {
	if in == nil {
		return nil
	}
	out := new(InstanceGroupList)
	in.DeepCopyInto(out)
	return out
}
source: func (md *MulticastDispose) Add(f ...func()) {
	md.list = append(md.list, f...)
}
source: func (c *cursor) rawKey() []byte {
	// Nothing to return if cursor is exhausted.
	if c.currentIter == nil {
		return nil
	}

	return copySlice(c.currentIter.Key())
}
source: func (t *TSCache) Put(key string, time time.Time) {
	t.mux.Lock()
	defer t.mux.Unlock()
	t.table[key] = time
}
source: func dragStep(xu *xgbutil.XUtil, ev xevent.MotionNotifyEvent) {
	// If for whatever reason we don't have any *piece* of a grab,
	// we've gotta back out.
	if !mouseDrag(xu) || mouseDragStep(xu) == nil || mouseDragEnd(xu) == nil {
		dragUngrab(xu)
		mouseDragStepSet(xu, nil)
		mouseDragEndSet(xu, nil)
		return
	}

	// The most recent MotionNotify event that we'll end up returning.
	laste := ev

	// We force a round trip request so that we make sure to read all
	// available events.
	xu.Sync()
	xevent.Read(xu, false)

	// Compress MotionNotify events.
	for i, ee := range xevent.Peek(xu) {
		if ee.Err != nil { // This is an error, skip it.
			continue
		}

		// Use type assertion to make sure this is a MotionNotify event.
		if mn, ok := ee.Event.(xproto.MotionNotifyEvent); ok {
			// Now make sure all appropriate fields are equivalent.
			if ev.Event == mn.Event && ev.Child == mn.Child &&
				ev.Detail == mn.Detail && ev.State == mn.State &&
				ev.Root == mn.Root && ev.SameScreen == mn.SameScreen {

				// Set the most recent/valid motion notify event.
				laste = xevent.MotionNotifyEvent{&mn}

				// We cheat and use the stack semantics of defer to dequeue
				// most recent motion notify events first, so that the indices
				// don't become invalid. (If we dequeued oldest first, we'd
				// have to account for all future events shifting to the left
				// by one.)
				defer func(i int) { xevent.DequeueAt(xu, i) }(i)
			}
		}
	}
	xu.TimeSet(laste.Time)

	// now actually run the step
	mouseDragStep(xu)(xu, int(laste.RootX), int(laste.RootY),
		int(laste.EventX), int(laste.EventY))
} 51%|█████     | 2540/5000 [00:02<00:02, 1007.06it/s]
source: func New(cfg Config) (*Memory, error) {
	if err := cfg.CheckAndSetDefaults(); err != nil {
		return nil, trace.Wrap(err)
	}
	ctx, cancel := context.WithCancel(cfg.Context)
	buf, err := backend.NewCircularBuffer(ctx, cfg.BufferSize)
	if err != nil {
		cancel()
		return nil, trace.Wrap(err)
	}
	m := &Memory{
		Mutex: &sync.Mutex{},
		Entry: log.WithFields(log.Fields{
			trace.Component: teleport.ComponentMemory,
		}),
		Config: cfg,
		tree:   btree.New(cfg.BTreeDegree),
		heap:   newMinHeap(),
		cancel: cancel,
		ctx:    ctx,
		buf:    buf,
	}
	return m, nil
}
source: func NewLock(log Logger, api Agency, key []string, id string, ttl time.Duration) (Lock, error) {
	if ttl < minLockTTL {
		ttl = minLockTTL
	}
	if id == "" {
		randBytes := make([]byte, 16)
		rand.Read(randBytes)
		id = hex.EncodeToString(randBytes)
	}
	return &lock{
		log: log,
		api: api,
		key: key,
		id:  id,
		ttl: ttl,
	}, nil
}
source: func CreateArchive(path string, opts *ArchiveOpts) (*Archive, error) {
	log.Printf("[INFO] creating archive from %s", path)

	// Dereference any symlinks and determine the real path and info
	fi, err := os.Lstat(path)
	if err != nil {
		return nil, err
	}
	if fi.Mode()&os.ModeSymlink != 0 {
		path, fi, err = readLinkFull(path, fi)
		if err != nil {
			return nil, err
		}
	}

	// Windows
	path = filepath.ToSlash(path)

	// Direct file paths cannot have archive options
	if !fi.IsDir() && opts.IsSet() {
		return nil, fmt.Errorf(
			"options such as exclude, include, and VCS can't be set when " +
				"the path is a file.")
	}

	if fi.IsDir() {
		return archiveDir(path, opts)
	} else {
		return archiveFile(path)
	}
}
source: func escapeStringQuotes(buf []byte, v string) []byte {
	pos := len(buf)
	buf = reserveBuffer(buf, len(v)*2)

	for i := 0; i < len(v); i++ {
		c := v[i]
		if c == '\'' {
			buf[pos] = '\''
			buf[pos+1] = '\''
			pos += 2
		} else {
			buf[pos] = c
			pos++
		}
	}

	return buf[:pos]
}
source: func (m *Mgr) iter(fn func(*mgr.Service) error) (first error) {
	svcs, err := m.services()
	if err != nil {
		return err
	}
	var mu sync.Mutex
	var wg sync.WaitGroup
	wg.Add(len(svcs))
	for _, s := range svcs {
		go func(s *mgr.Service) {
			defer wg.Done()
			defer s.Close()
			if err := fn(s); err != nil {
				mu.Lock()
				if first == nil {
					first = err
				}
				mu.Unlock()
			}
		}(s)
	}
	wg.Wait()
	return
}
source: func (s *FirewallService) NewDeleteEgressFirewallRuleParams(id string) *DeleteEgressFirewallRuleParams {
	p := &DeleteEgressFirewallRuleParams{}
	p.p = make(map[string]interface{})
	p.p["id"] = id
	return p
}
source: func MarshalIndent(v interface{}, prefix, indent string) ([]byte, error) {
	b, err := Marshal(v)
	if err != nil {
		return nil, err
	}
	if !isatty.IsTerminal(os.Stdout.Fd()) {
		return b, err
	}
	var buf bytes.Buffer
	err = Indent(&buf, b, prefix, indent)
	if err != nil {
		return nil, err
	}
	return buf.Bytes(), nil
}
source: func (b *MultiHandler) SetFormatter(f Formatter) {
	for _, h := range b.handlers {
		h.SetFormatter(f)
	}
}
source: func (p Partition) Services() map[string]Service {
	ss := map[string]Service{}
	for id := range p.p.Services {
		ss[id] = Service{
			id: id,
			p:  p.p,
		}
	}

	return ss
}
source: func (w *GzipResponseWriter) WriteNow(contents []byte) (int, error) {
	if w.disabled {
		// type noOp struct{}
		//
		// func (n noOp) Write([]byte) (int, error) {
		// 	return 0, nil
		// }
		//
		// var noop = noOp{}
		// problem solved with w.gzipWriter.Reset(noop):
		//
		// the below Write called multiple times but not from here,
		// the gzip writer does something to the writer, even if we don't call the
		// w.gzipWriter.Write it does call the underline http.ResponseWriter
		// multiple times, and therefore it changes the content-length
		// the problem that results to the #723.
		//
		// Or a better idea, acquire and adapt the gzip writer on-time when is not disabled.
		// So that is not needed any more:
		// w.gzipWriter.Reset(noop)

		return w.ResponseWriter.Write(contents)
	}

	AddGzipHeaders(w.ResponseWriter)
	// if not `WriteNow` but "Content-Length" header
	// is exists, then delete it before `.Write`
	// Content-Length should not be there.
	// no, for now at least: w.ResponseWriter.Header().Del(contentLengthHeaderKey)
	return writeGzip(w.ResponseWriter, contents)
}
source: func (fs *TermvectorsFilterSettings) MaxWordLength(value int64) *TermvectorsFilterSettings {
	fs.maxWordLength = &value
	return fs
}
source: func (i *Issue) GetLocked() bool {
	if i == nil || i.Locked == nil {
		return false
	}
	return *i.Locked
}
source: func PolicyDetach(epg *contivModel.EndpointGroup, policy *contivModel.Policy) error {
	// Dont install policies in ACI mode
	if !isPolicyEnabled() {
		return nil
	}

	epgpKey := epg.Key + ":" + policy.Key

	// find the policy
	gp := mastercfg.FindEpgPolicy(epgpKey)
	if gp == nil {
		log.Errorf("Epg policy %s does not exist", epgpKey)
		return core.Errorf("epg policy does not exist")
	}

	// Delete all rules within the policy
	for ruleKey := range policy.LinkSets.Rules {
		// find the rule
		rule := contivModel.FindRule(ruleKey)
		if rule == nil {
			log.Errorf("Error finding the rule %s", ruleKey)
			continue
		}

		log.Infof("Deleting Rule %s from epgp policy %s", ruleKey, epgpKey)

		// Add the rule to epg Policy
		err := gp.DelRule(rule)
		if err != nil {
			log.Errorf("Error deleting rule %s from epg polict %s. Err: %v", ruleKey, epgpKey, err)
		}
	}

	// delete it
	return gp.Delete()
}
source: func (t *Team) InviteMember(ctx context.Context, username string, role keybase1.TeamRole, resolvedUsername libkb.NormalizedUsername, uv keybase1.UserVersion) (keybase1.TeamAddMemberResult, error) {
	// if a user version was previously loaded, then there is a keybase user for username, but
	// without a PUK or without any keys.
	if uv.Uid.Exists() {
		return t.inviteKeybaseMember(ctx, uv, role, resolvedUsername)
	}

	// If a social, or email, or other type of invite, assert it's not an owner.
	if role.IsOrAbove(keybase1.TeamRole_OWNER) {
		return keybase1.TeamAddMemberResult{}, errors.New("You cannot invite an owner to a team.")
	}

	return t.inviteSBSMember(ctx, username, role)
}
source: func (sm *SSMuxer) SecureOutbound(ctx context.Context, insecure net.Conn, p peer.ID) (connsec.Conn, error) {
	tpt, err := sm.selectProto(ctx, insecure, false)
	if err != nil {
		return nil, err
	}
	return tpt.SecureOutbound(ctx, insecure, p)
}
source: func AnyBool(c *cli.Context, key string) bool {
	return c.Bool(key) || c.GlobalBool(key)
}
source: func (d *Downloader) DownloadConfig(dir string) (map[string]string, error) {
	if err := os.MkdirAll(dir, 0755); err != nil {
		return nil, fmt.Errorf("error creating config dir: %s", err)
	}
	paths := make(map[string]string, len(config))
	for _, conf := range config {
		path, err := d.downloadGzippedFile(conf, dir, false)
		if err != nil {
			return nil, err
		}
		paths[conf] = path
	}
	return paths, nil
}
source: func (l *Line) Decode(b []byte) error {
	delimiter := bytes.IndexRune(b, lineDelimiter)
	if delimiter == -1 {
		reason := `delimiter "=" not found`
		err := newDecodeError("line", reason)
		return errors.Wrap(err, "failed to decode")
	}
	if len(b) <= (delimiter + 1) {
		reason := fmt.Sprintf(
			"len(b) %d < (%d + 1), no value found after delimiter",
			len(b), delimiter,
		)
		err := newDecodeError("line", reason)
		return errors.Wrap(err, "failed to decode")
	}
	r, _ := utf8.DecodeRune(b[:delimiter])
	l.Type = Type(r)
	l.Value = append(l.Value, b[delimiter+1:]...)
	return nil
}
source: func baseShader(c *Canvas) {
	gs := &glShader{
		vf: defaultCanvasVertexFormat,
		vs: baseCanvasVertexShader,
		fs: baseCanvasFragmentShader,
	}

	gs.setUniform("uTransform", &gs.uniformDefaults.transform)
	gs.setUniform("uColorMask", &gs.uniformDefaults.colormask)
	gs.setUniform("uBounds", &gs.uniformDefaults.bounds)
	gs.setUniform("uTexBounds", &gs.uniformDefaults.texbounds)

	c.shader = gs
}
source: func RetrieveTxnsVinsVoutsByBlock(ctx context.Context, db *sql.DB, blockHash string, onlyRegular bool) (vinDbIDs, voutDbIDs []dbtypes.UInt64Array,
	areMainchain []bool, err error) {
	stmt := internal.SelectTxnsVinsVoutsByBlock
	if onlyRegular {
		stmt = internal.SelectRegularTxnsVinsVoutsByBlock
	}

	var rows *sql.Rows
	rows, err = db.QueryContext(ctx, stmt, blockHash)
	if err != nil {
		return
	}
	defer closeRows(rows)

	for rows.Next() {
		var vinIDs, voutIDs dbtypes.UInt64Array
		var isMainchain bool
		err = rows.Scan(&vinIDs, &voutIDs, &isMainchain)
		if err != nil {
			break
		}

		vinDbIDs = append(vinDbIDs, vinIDs)
		voutDbIDs = append(voutDbIDs, voutIDs)
		areMainchain = append(areMainchain, isMainchain)
	}
	return
}
source: func (se *Engine) Close() {
	se.mu.Lock()
	defer se.mu.Unlock()
	if !se.isOpen {
		return
	}
	se.ticks.Stop()
	se.conns.Close()
	se.tables = make(map[string]*Table)
	se.notifiers = make(map[string]notifier)
	se.isOpen = false
}
source: func NewUpdateSource(cfg *config, log Log) UpdateSource {
	return newUpdateSource(cfg, defaultEndpoints.update, log)
}
source: func buildMatrix(dataShards, totalShards int) (matrix, error) {
	// Start with a Vandermonde matrix.  This matrix would work,
	// in theory, but doesn't have the property that the data
	// shards are unchanged after encoding.
	vm, err := vandermonde(totalShards, dataShards)
	if err != nil {
		return nil, err
	}

	// Multiply by the inverse of the top square of the matrix.
	// This will make the top square be the identity matrix, but
	// preserve the property that any square subset of rows is
	// invertible.
	top, err := vm.SubMatrix(0, 0, dataShards, dataShards)
	if err != nil {
		return nil, err
	}

	topInv, err := top.Invert()
	if err != nil {
		return nil, err
	}

	return vm.Multiply(topInv)
}
source: func (r *Repo) FindCustom(ctx context.Context, callback func(*mgo.Collection) *mgo.Query) ([]interface{}, error) {
	sess := r.session.Copy()
	defer sess.Close()

	if r.factoryFn == nil {
		return nil, eh.RepoError{
			Err:       ErrModelNotSet,
			Namespace: eh.NamespaceFromContext(ctx),
		}
	}

	collection := sess.DB(r.dbName(ctx)).C(r.collection)
	query := callback(collection)
	if query == nil {
		return nil, eh.RepoError{
			Err:       ErrInvalidQuery,
			Namespace: eh.NamespaceFromContext(ctx),
		}
	}

	iter := query.Iter()
	result := []interface{}{}
	entity := r.factoryFn()
	for iter.Next(entity) {
		result = append(result, entity)
		entity = r.factoryFn()
	}
	if err := iter.Close(); err != nil {
		return nil, eh.RepoError{
			Err:       err,
			Namespace: eh.NamespaceFromContext(ctx),
		}
	}

	return result, nil
}
source: func NewPolynomialFunction(coefficients []float64) *PolynomialFunction {
	if len(coefficients) < 1 {
		return nil
	}
	pf := &PolynomialFunction{
		coefficients: coefficients,
	}
	return pf
}
source: func BucketAlreadyExistsError(b *influxdb.Bucket) error {
	return &influxdb.Error{
		Code: influxdb.EConflict,
		Op:   "kv/bucket",
		Msg:  fmt.Sprintf("bucket with name %s already exists", b.Name),
	}
}
source: func (window *Window) Wmove(y, x int) {
	C.wmove(window.cwin, C.int(y), C.int(x))
}
source: func (s *Service) Initialize(ctx context.Context) error {
	return s.kv.Update(ctx, func(tx Tx) error {
		if err := s.initializeAuths(ctx, tx); err != nil {
			return err
		}

		if err := s.initializeDocuments(ctx, tx); err != nil {
			return err
		}

		if err := s.initializeBuckets(ctx, tx); err != nil {
			return err
		}

		if err := s.initializeDashboards(ctx, tx); err != nil {
			return err
		}

		if err := s.initializeKVLog(ctx, tx); err != nil {
			return err
		}

		if err := s.initializeLabels(ctx, tx); err != nil {
			return err
		}

		if err := s.initializeOnboarding(ctx, tx); err != nil {
			return err
		}

		if err := s.initializeOrgs(ctx, tx); err != nil {
			return err
		}

		if err := s.initializeTasks(ctx, tx); err != nil {
			return err
		}

		if err := s.initializePasswords(ctx, tx); err != nil {
			return err
		}

		if err := s.initializeScraperTargets(ctx, tx); err != nil {
			return err
		}

		if err := s.initializeSecrets(ctx, tx); err != nil {
			return err
		}

		if err := s.initializeSessions(ctx, tx); err != nil {
			return err
		}

		if err := s.initializeSources(ctx, tx); err != nil {
			return err
		}

		if err := s.initializeTelegraf(ctx, tx); err != nil {
			return err
		}

		if err := s.initializeURMs(ctx, tx); err != nil {
			return err
		}

		if err := s.initializeVariables(ctx, tx); err != nil {
			return err
		}

		return s.initializeUsers(ctx, tx)
	})
}
source: func (m *MockZonedEnviron) Provider() environs.EnvironProvider {
	ret := m.ctrl.Call(m, "Provider")
	ret0, _ := ret[0].(environs.EnvironProvider)
	return ret0
}
source: func Leave(fn func(res *Response) error) handler {
	return &Handler{Method: LEAVE, Run: fn}
}
source: func DoesFileExist(fileName string) bool {
	_, err := os.Stat(fileName)
	if os.IsNotExist(err) {
		return false
	}
	return true
}
source: func GetFollowers(client ClientInterface, name string, offset, limit uint) (*FollowerList, error) {
	params := setParamsUint(uint64(offset), url.Values{}, "offset")
	params = setParamsUint(uint64(limit), params, "limit")
	response, err := client.GetWithParams(blogPath("/blog/%s/followers", name), params)
	if err != nil {
		return nil, err
	}
	followers := struct {
		Followers FollowerList `json:"response"`
	}{
		Followers: FollowerList{
			client: client,
			name:   name,
			limit:  limit,
			offset: offset,
		},
	}
	if err = json.Unmarshal(response.body, &followers); err == nil {
		return &followers.Followers, nil
	}
	return nil, err
}
source: func (s *Category) SetCategoryName(v string) *Category {
	s.CategoryName = &v
	return s
}
source: func hkdfExpand(key, info []byte) []byte {
	mac := hmac.New(sha256.New, key)
	mac.Write(info)
	mac.Write([]byte{0x01}[:])
	return mac.Sum(nil)[:aeadKeyLen]
}
source: func (m *icmpMessage) Marshal() ([]byte, error) {
	b := []byte{byte(m.Type), byte(m.Code), 0, 0}
	if m.Body != nil && m.Body.Len() != 0 {
		mb, err := m.Body.Marshal()
		if err != nil {
			return nil, err
		}
		b = append(b, mb...)
	}
	switch m.Type {
	case icmpv6EchoRequest, icmpv6EchoReply:
		return b, nil
	}
	csumcv := len(b) - 1 // checksum coverage
	s := uint32(0)
	for i := 0; i < csumcv; i += 2 {
		s += uint32(b[i+1])<<8 | uint32(b[i])
	}
	if csumcv&1 == 0 {
		s += uint32(b[csumcv])
	}
	s = s>>16 + s&0xffff
	s = s + s>>16
	// Place checksum back in header; using ^= avoids the
	// assumption the checksum bytes are zero.
	b[2] ^= byte(^s & 0xff)
	b[3] ^= byte(^s >> 8)
	return b, nil
}
source: func (m *ChanStatusManager) signAndSendNextUpdate(outpoint wire.OutPoint,
	disabled bool) error {

	// Retrieve the latest update for this channel. We'll use this
	// as our starting point to send the new update.
	chanUpdate, err := m.fetchLastChanUpdateByOutPoint(outpoint)
	if err != nil {
		return err
	}

	err = SignChannelUpdate(
		m.cfg.MessageSigner, m.cfg.OurPubKey, chanUpdate,
		ChannelUpdateSetDisable(disabled),
	)
	if err != nil {
		return err
	}

	return m.cfg.ApplyChannelUpdate(chanUpdate)
}
source: func DeleteTeam(t *Team) error {
	if err := t.GetRepositories(); err != nil {
		return err
	}

	// Get organization.
	org, err := GetUserByID(t.OrgID)
	if err != nil {
		return err
	}

	sess := x.NewSession()
	defer sess.Close()
	if err = sess.Begin(); err != nil {
		return err
	}

	// Delete all accesses.
	for _, repo := range t.Repos {
		if err = repo.recalculateTeamAccesses(sess, t.ID); err != nil {
			return err
		}
	}

	// Delete team-user.
	if _, err = sess.Where("org_id=?", org.ID).Where("team_id=?", t.ID).Delete(new(TeamUser)); err != nil {
		return err
	}

	// Delete team.
	if _, err = sess.ID(t.ID).Delete(new(Team)); err != nil {
		return err
	}
	// Update organization number of teams.
	if _, err = sess.Exec("UPDATE `user` SET num_teams=num_teams-1 WHERE id=?", t.OrgID); err != nil {
		return err
	}

	return sess.Commit()
}
source: func (s *M2tsSettings) SetAudioStreamType(v string) *M2tsSettings {
	s.AudioStreamType = &v
	return s
}
source: func getConns(d *Daemon, w http.ResponseWriter, r *http.Request) *HttpErr {
	d.connections.RLock()
	data, err := json.Marshal(d.connections.rm)
	d.connections.RUnlock()

	if err != nil {
		return &HttpErr{http.StatusInternalServerError, err.Error()}
	}
	w.Header().Set("Content-Type", "application/json; charset=utf-8")
	w.Write(data)

	return nil
}
source: func NewAttribute(typ uint, x interface{}) *Attribute {
	// This function nicely transforms *to* an attribute, but there is
	// no corresponding function that transform back *from* an attribute,
	// which in PKCS#11 is just an byte array.
	a := new(Attribute)
	a.Type = typ
	if x == nil {
		return a
	}
	switch v := x.(type) {
	case bool:
		if v {
			a.Value = []byte{1}
		} else {
			a.Value = []byte{0}
		}
	case int:
		a.Value = uintToBytes(uint64(v))
	case uint:
		a.Value = uintToBytes(uint64(v))
	case string:
		a.Value = []byte(v)
	case []byte:
		a.Value = v
	case time.Time: // for CKA_DATE
		a.Value = cDate(v)
	default:
		panic("pkcs11: unhandled attribute type")
	}
	return a
}
source: func (b *stdBackend) SetVariable(id string, v int64) {
	if b.ssvFilter != nil && !b.ssvFilter(id) {
		return
	}
	b.ssvChangeC <- &stdSSVChange{id, true, v}
}
source: func (as AtomicWebSocketSet) NotifySockets(uid uint64, cmd, ret string) error {
	s := as.Get(uid)
	if s == nil {
		// Trainer is not online.
		return nil
	}
	t := time.Now()
	data := []struct {
		Sentence  string
		AvaSent   bool
		CreatedAt *time.Time
	}{
		{
			Sentence:  cmd,
			AvaSent:   false,
			CreatedAt: &t,
		},
	}
	if len(ret) > 0 {
		data = append(data, struct {
			Sentence  string
			AvaSent   bool
			CreatedAt *time.Time
		}{
			Sentence:  ret,
			AvaSent:   true,
			CreatedAt: &t,
		})
	}
	return websocket.JSON.Send(s, &data)
}
source: func NewHeredoc(Label string, Parts []node.Node) *Heredoc {
	return &Heredoc{
		FreeFloating: nil,
		Label:        Label,
		Parts:        Parts,
	}
}
source: func Command(argv []string) (returnCode int) {
	usage := `
Updates the current semantic version number to a new one in the specified
source and doc files.

Usage:
  bumpver [-f <current>] <version> <files>...

Options:
  -f --from=<current>  An explicit version string to replace. Otherwise, use
                       the first semantic version found in the first file.
 `
	argv = parseArgs(argv)
	// parse command-line arguments
	args, err := docopt.Parse(usage, argv, true, "bumpversion 0.1.0", true, false)
	if err != nil {
		return 1
	}
	if len(args) == 0 {
		return 0
	}
	re := regexp.MustCompile(`(\d{1,3}\.\d{1,3}\.\d{1,3})`)
	// validate that <version> is a proper semver string
	version := (args["<version>"].(string))
	if version != re.FindString(version) {
		return onError(fmt.Errorf("Error: '%s' is not a valid semantic version string", version))
	}
	files := args["<files>"].([]string)
	var from []byte
	var data []byte
	if args["--from"] != nil {
		from = []byte(args["--from"].(string))
	}
	for _, name := range files {
		src, err := ioutil.ReadFile(name)
		if err != nil {
			return onError(err)
		}
		if len(from) == 0 {
			// find the first semver match in the file, if any
			from = re.Find(src)
			if from = re.Find(src); len(from) == 0 {
				fmt.Printf("Skipped %s\n", name)
				continue
			}
		}
		// replace all occurrences in source and doc files
		data = bytes.Replace(src, from, []byte(version), -1)
		f, err := os.Create(name)
		if err != nil {
			return onError(err)
		}
		if _, err = f.Write(data); err != nil {
			return onError(err)
		}
		fmt.Printf("Bumped %s\n", name)
	}
	return 0
}
source: func NewVersion(parent *Versions) *Version {
	version := &Version{parent: parent}
	version.Init()

	return version
}
source: func (env *Env) Destroy() {
	C.rocksdb_env_destroy(env.c)
	env.c = nil
}
source: func (sr *Receiver) Sizes() []int {
	sr.Lock()
	defer sr.Unlock()
	sizes := make([]int, 0, len(sr.Have))
	for _, size := range sr.Have {
		sizes = append(sizes, int(size))
	}
	sort.Ints(sizes)
	return sizes
}
source: func BroadcastReceive(broadcast Broadcast, addr string, responses chan common.Status, errs chan error) {
	logger.Infof("calling OrdererClient.broadcastReceive")
	for {
		broadcastResponse, err := broadcast.Recv()
		if err == io.EOF {
			close(responses)
			return
		}

		if err != nil {
			rpcStatus, _ := status.FromError(err)
			errs <- errors.Wrapf(err, "broadcast recv error from orderer %s, rpcStatus=%+v", addr, rpcStatus)
			close(responses)
			return
		}

		if broadcastResponse.Status == common.Status_SUCCESS {
			responses <- broadcastResponse.Status
		} else {
			errs <- errors.Errorf("broadcast response error %d from orderer %s", int32(broadcastResponse.Status), addr)
		}
	}
}
source: func (batcher *DownloadObjectsIterator) DownloadObject() BatchDownloadObject {
	object := batcher.Objects[batcher.index]
	return object
}
source: func (cm *CompanyManager) Exists(globalId string) bool {
	count, _ := cm.collection.Find(bson.M{"globalid": globalId}).Count()

	return count != 1
}
source: func (shardSwap *shardSchemaSwap) undrainSeedTablet(seedTablet *topodatapb.Tablet, tabletType topodatapb.TabletType) error {
	_, err := shardSwap.parent.topoServer.UpdateTabletFields(shardSwap.parent.ctx, seedTablet.Alias,
		func(tablet *topodatapb.Tablet) error {
			delete(tablet.Tags, "drain_reason")
			return nil
		})
	if err != nil {
		// This is not a critical error, we'll just log it.
		log.Errorf("Got error trying to set drain_reason on tablet %v: %v", seedTablet.Alias, err)
	}
	err = shardSwap.parent.tabletClient.ChangeType(shardSwap.parent.ctx, seedTablet, tabletType)
	if err != nil {
		return err
	}
	return nil
}
source: func (b *Builder) Connector(zkConnector ZkConnector) *Builder {
	b.zkConnector = zkConnector
	return b
}
source: func GetTokenSource(c context.Context, kind RPCAuthorityKind, opts ...RPCOption) (oauth2.TokenSource, error) {
	if kind != AsSelf && kind != AsCredentialsForwarder && kind != AsActor {
		return nil, fmt.Errorf("auth: GetTokenSource can only be used with AsSelf, AsCredentialsForwarder or AsActor authorization kind")
	}
	options, err := makeRPCOptions(kind, opts)
	if err != nil {
		return nil, err
	}
	if options.checkCtx != nil {
		if err := options.checkCtx(c); err != nil {
			return nil, err
		}
	}
	return &tokenSource{c, options}, nil
}
source: func MustCompile(expr string) *Expr {
	exp, err := Compile(expr)
	if err != nil {
		return nil
	}
	return exp
}
source: func (node *ComparisonExpr) IsImpossible() bool {
	var left, right *SQLVal
	var ok bool
	if left, ok = node.Left.(*SQLVal); !ok {
		return false
	}
	if right, ok = node.Right.(*SQLVal); !ok {
		return false
	}
	if node.Operator == NotEqualStr && left.Type == right.Type {
		if len(left.Val) != len(right.Val) {
			return false
		}

		for i := range left.Val {
			if left.Val[i] != right.Val[i] {
				return false
			}
		}
		return true
	}
	return false
}
source: func (tl *TeeLogger) InfoDepth(depth int, s string) {
	tl.One.InfoDepth(1+depth, s)
	tl.Two.InfoDepth(1+depth, s)
}
source: func (s *Store) ACLTokenList(ws memdb.WatchSet, local, global bool, policy, role, methodName string) (uint64, structs.ACLTokens, error) {
	tx := s.db.Txn(false)
	defer tx.Abort()

	var iter memdb.ResultIterator
	var err error

	// Note global == local works when both are true or false. It is not valid to set both
	// to false but for defaulted structs (zero values for both) we want it to list out
	// all tokens so our checks just ensure that global == local

	needLocalityFilter := false
	if policy == "" && role == "" && methodName == "" {
		if global == local {
			iter, err = tx.Get("acl-tokens", "id")
		} else if global {
			iter, err = tx.Get("acl-tokens", "local", false)
		} else {
			iter, err = tx.Get("acl-tokens", "local", true)
		}

	} else if policy != "" && role == "" && methodName == "" {
		iter, err = tx.Get("acl-tokens", "policies", policy)
		needLocalityFilter = true

	} else if policy == "" && role != "" && methodName == "" {
		iter, err = tx.Get("acl-tokens", "roles", role)
		needLocalityFilter = true

	} else if policy == "" && role == "" && methodName != "" {
		iter, err = tx.Get("acl-tokens", "authmethod", methodName)
		needLocalityFilter = true

	} else {
		return 0, nil, fmt.Errorf("can only filter by one of policy, role, or methodName at a time")
	}

	if err != nil {
		return 0, nil, fmt.Errorf("failed acl token lookup: %v", err)
	}

	if needLocalityFilter && global != local {
		iter = memdb.NewFilterIterator(iter, func(raw interface{}) bool {
			token, ok := raw.(*structs.ACLToken)
			if !ok {
				return true
			}

			if global && !token.Local {
				return false
			} else if local && token.Local {
				return false
			}

			return true
		})
	}

	ws.Add(iter.WatchCh())

	var result structs.ACLTokens
	for raw := iter.Next(); raw != nil; raw = iter.Next() {
		token := raw.(*structs.ACLToken)
		token, err := s.fixupTokenPolicyLinks(tx, token)
		if err != nil {
			return 0, nil, err
		}
		token, err = s.fixupTokenRoleLinks(tx, token)
		if err != nil {
			return 0, nil, err
		}
		result = append(result, token)
	}

	// Get the table index.
	idx := maxIndexTxn(tx, "acl-tokens")

	return idx, result, nil
}
source: func (l *Scanner) Peek2() (a, b byte) {
	if l.pos == len(l.data) {
		return 0, 0
	}
	if l.pos+1 == len(l.data) {
		return l.data[l.pos], 0
	}
	return l.data[l.pos], l.data[l.pos+1]
}
source: func checkBufferGenFlags(flags int) error {
	if flags < 0 && flags > 4 {
		return fmt.Errorf("unsupported buffer flags %d", flags)
	}
	return nil
}
source: func Reverse(list []*rspb.Release, sortFn func([]*rspb.Release)) {
	sortFn(list)
	for i, j := 0, len(list)-1; i < j; i, j = i+1, j-1 {
		list[i], list[j] = list[j], list[i]
	}
}
source: func (c *Conn) receive() ([]Message, error) {
	// NB: All non-nil errors returned from this function *must* be of type
	// OpError in order to maintain the appropriate contract with callers of
	// this package.
	//
	// This contract also applies to functions called within this function,
	// such as checkMessage.

	var res []Message
	for {
		msgs, err := c.sock.Receive()
		if err != nil {
			return nil, newOpError("receive", err)
		}

		// If this message is multi-part, we will need to perform an recursive call
		// to continue draining the socket
		var multi bool

		for _, m := range msgs {
			if err := checkMessage(m); err != nil {
				return nil, err
			}

			// Does this message indicate a multi-part message?
			if m.Header.Flags&Multi == 0 {
				// No, check the next messages.
				continue
			}

			// Does this message indicate the last message in a series of
			// multi-part messages from a single read?
			multi = m.Header.Type != Done
		}

		res = append(res, msgs...)

		if !multi {
			// No more messages coming.
			return res, nil
		}
	}
}
source: func (s *Schema) PropertyWithName(name string) *Schema {
	return namedSchemaArrayElementWithName(s.Properties, name)
}
source: func (h HashVal) ToMap() map[interface{}]interface{} {
	mp := make(map[interface{}]interface{}, len(h))
	for k, v := range h {
		switch actual := v.(type) {
		case ArrayVal:
			mp[k] = actual.ToSlice()
		case HashVal:
			mp[k] = actual.ToMap()
		default:
			mp[k] = actual
		}
	}
	return mp
}
source: func (queue *redisQueue) AddBatchConsumerWithTimeout(tag string, batchSize int, timeout time.Duration, consumer BatchConsumer) string {
	queue.stopWg.Add(1)
	name := queue.addConsumer(tag)
	go queue.consumerBatchConsume(batchSize, timeout, consumer)
	return name
}
source: func (b *Bucket) GetReaderWithRange(ctx context.Context, path string, begin, end int64) (rc io.ReadCloser, err error) {
	header := make(http.Header)
	header.Add("Range", fmt.Sprintf("bytes=%d-%d", begin, end-1))
	resp, err := b.GetResponseWithHeaders(ctx, path, header)
	if resp != nil {
		return resp.Body, err
	}
	return nil, err
}
source: func (c *Target) SetRemoteLocations(locations []*TargetRemoteLocation) (*gcdmessage.ChromeResponse, error) {
	var v TargetSetRemoteLocationsParams
	v.Locations = locations
	return c.SetRemoteLocationsWithParams(&v)
}
source: func (m *HilOpticalFlow) Pack() []byte {
	data := new(bytes.Buffer)
	binary.Write(data, binary.LittleEndian, m.TIME_USEC)
	binary.Write(data, binary.LittleEndian, m.FLOW_COMP_M_X)
	binary.Write(data, binary.LittleEndian, m.FLOW_COMP_M_Y)
	binary.Write(data, binary.LittleEndian, m.GROUND_DISTANCE)
	binary.Write(data, binary.LittleEndian, m.FLOW_X)
	binary.Write(data, binary.LittleEndian, m.FLOW_Y)
	binary.Write(data, binary.LittleEndian, m.SENSOR_ID)
	binary.Write(data, binary.LittleEndian, m.QUALITY)
	return data.Bytes()
}
source: func (s Services) MarshalYAML() (interface{}, error) {
	services := map[string]ServiceConfig{}
	for _, service := range s {
		services[service.Name] = service
	}
	return services, nil
}
source: func WaitForPodDelete(c kubernetes.Interface, ns string, label labels.Selector) error {
	return wait.PollImmediate(constants.APICallRetryInterval, ReasonableMutateTime, func() (bool, error) {
		listOpts := metav1.ListOptions{LabelSelector: label.String()}
		pods, err := c.CoreV1().Pods(ns).List(listOpts)
		if err != nil {
			glog.Infof("error getting Pods with label selector %q [%v]\n", label.String(), err)
			return false, nil
		}
		return len(pods.Items) == 0, nil
	})
}
source: func (a *PipelineAggregation) MarshalJSON() ([]byte, error) {
	root := map[string]interface{}{
		"buckets_path": a.BucketPath,
	}

	for k, v := range a.Settings {
		if k != "" && v != nil {
			root[k] = v
		}
	}

	return json.Marshal(root)
}
source: func New(address string, extra ...string) (*Pool, error) {
	pool := &redis.Pool{
		MaxIdle:     1024,
		MaxActive:   1024,
		IdleTimeout: 300 * time.Second,
		Wait:        true,
		Dial: func() (redis.Conn, error) {
			c, err := redis.Dial("tcp", address)
			if err != nil {
				return nil, err
			}
			return c, err
		},
		TestOnBorrow: func(c redis.Conn, t time.Time) error {
			_, err := c.Do("PING")
			return err
		},
	}

	return &Pool{redis: pool}, nil
}
source: func NewKVRead(key string, version *version.Height) *kvrwset.KVRead {
	return &kvrwset.KVRead{Key: key, Version: newProtoVersion(version)}
}
source: func (m *MockCluster) ObjectStoreInspect(arg0 string) (*api.ObjectstoreInfo, error) {
	ret := m.ctrl.Call(m, "ObjectStoreInspect", arg0)
	ret0, _ := ret[0].(*api.ObjectstoreInfo)
	ret1, _ := ret[1].(error)
	return ret0, ret1
}
source: func VtctldTablet(aliasName string) template.HTML {
	return MakeVtctldRedirect(aliasName, map[string]string{
		"type":  "tablet",
		"alias": aliasName,
	})
}
source: func activeInterfaceAddresses() ([]net.Addr, error) {
	var upAddrs []net.Addr
	var loAddrs []net.Addr

	interfaces, err := net.Interfaces()
	if err != nil {
		return nil, fmt.Errorf("Failed to get interfaces: %v", err)
	}

	for _, iface := range interfaces {
		// Require interface to be up
		if iface.Flags&net.FlagUp == 0 {
			continue
		}

		addresses, err := iface.Addrs()
		if err != nil {
			return nil, fmt.Errorf("Failed to get interface addresses: %v", err)
		}

		if iface.Flags&net.FlagLoopback != 0 {
			loAddrs = append(loAddrs, addresses...)
			continue
		}

		upAddrs = append(upAddrs, addresses...)
	}

	if len(upAddrs) == 0 {
		return loAddrs, nil
	}

	return upAddrs, nil
}
source: func (c *RolesStore) Update(ctx context.Context, u *chronograf.Role) error {
	if u.Permissions != nil {
		perms := ToEnterprise(u.Permissions)
		if err := c.Ctrl.SetRolePerms(ctx, u.Name, perms); err != nil {
			return err
		}
	}
	if u.Users != nil {
		users := make([]string, len(u.Users))
		for i, u := range u.Users {
			users[i] = u.Name
		}
		return c.Ctrl.SetRoleUsers(ctx, u.Name, users)
	}
	return nil
}
source: func (b *Backend) InvalidateKey(ctx context.Context, key string) {
	if b.Invalidate != nil {
		b.Invalidate(ctx, key)
	}
}
source: func (g *Gatherer) Gather(client *Client, acc telegraf.Accumulator) error {
	var tags map[string]string

	if client.config.ProxyConfig != nil {
		tags = map[string]string{"jolokia_proxy_url": client.URL}
	} else {
		tags = map[string]string{"jolokia_agent_url": client.URL}
	}

	requests := makeReadRequests(g.metrics)
	responses, err := client.read(requests)
	if err != nil {
		return err
	}

	g.gatherResponses(responses, tags, acc)
	return nil
}
source: func IncludingDimensions(dims map[string]string, sink Sink) Sink {
	if len(dims) == 0 {
		return sink
	}
	return NextWrap(&WithDimensions{
		Dimensions: dims,
	})(sink)
}
source: func Walk(root string, walkFn filepath.WalkFunc) error {
	info, err := os.Lstat(root)
	if err != nil {
		err = walkFn(root, nil, err)
	} else {
		err = symwalk(root, info, walkFn)
	}
	if err == filepath.SkipDir {
		return nil
	}
	return err
}
source: func (a *ContinueRequestArgs) SetURL(url string) *ContinueRequestArgs {
	a.URL = &url
	return a
}
source: func (iter *Iterator) ReadFloat32() (ret float32) {
	c := iter.nextToken()
	if c == '-' {
		return -iter.readPositiveFloat32()
	}
	iter.unreadByte()
	return iter.readPositiveFloat32()
}
source: func ParseRequestStillQueuedError(msg string) *RequestStillQueuedError {
	var s, e string
	n, err := fmt.Sscanf(msg, fmtRequestStillQueued, &s, &e)
	if err != nil || n != 2 {
		return nil
	}

	start, err := time.Parse(time.RFC3339, s)
	if err != nil {
		return nil
	}

	end, err := time.Parse(time.RFC3339, e)
	if err != nil {
		return nil
	}

	return &RequestStillQueuedError{Start: start.Unix(), End: end.Unix()}
}
source: func (a *assertion) Nil(obtained interface{}, msgs ...string) bool {
	if !a.IsNil(obtained) {
		return a.failer.Fail(Nil, obtained, nil, msgs...)
	}
	return true
}
source: func (c *Ctrie) rdcssReadRoot(abort bool) *iNode {
	r := (*iNode)(atomic.LoadPointer((*unsafe.Pointer)(unsafe.Pointer(&c.root))))
	if r.rdcss != nil {
		return c.rdcssComplete(abort)
	}
	return r
}
source: func NewFromSnapshot(snap *api.RangeAllocation) (*PortAllocator, error) {
	pr, err := net.ParsePortRange(snap.Range)
	if err != nil {
		return nil, err
	}
	r := NewPortAllocator(*pr)
	if err := r.Restore(*pr, snap.Data); err != nil {
		return nil, err
	}
	return r, nil
}
source: func New(clientProvider context.ClientProvider, opts ...ClientOption) (*Client, error) {

	ctx, err := clientProvider()
	if err != nil {
		return nil, errors.WithMessage(err, "failed to create Client")
	}

	msp := Client{
		ctx: ctx,
	}

	for _, param := range opts {
		err := param(&msp)
		if err != nil {
			return nil, errors.WithMessage(err, "failed to create Client")
		}
	}

	if msp.orgName == "" {
		msp.orgName = ctx.IdentityConfig().Client().Organization
	}
	if msp.orgName == "" {
		return nil, errors.New("organization is not provided")
	}

	caConfig, ok := ctx.IdentityConfig().CAConfig(msp.orgName)
	if ok {
		msp.caName = caConfig.CAName
	}

	networkConfig := ctx.EndpointConfig().NetworkConfig()
	_, ok = networkConfig.Organizations[strings.ToLower(msp.orgName)]
	if !ok {
		return nil, fmt.Errorf("non-existent organization: '%s'", msp.orgName)
	}
	return &msp, nil
}
source: func (q *ContainsPointQuery) ContainingShapes(p Point) []Shape {
	var shapes []Shape
	q.visitContainingShapes(p, func(shape Shape) bool {
		shapes = append(shapes, shape)
		return true
	})
	return shapes
}
source: func (s *parentStack) At(n int) *treapNode {
	index := s.index - n - 1
	if index < 0 {
		return nil
	}

	if index < staticDepth {
		return s.items[index]
	}

	return s.overflow[index-staticDepth]
}
source: func GenerateDocs(apiDef *raml.APIDefinition, format, output string) error {
	switch format {
	case formatMarkdown:
		md := &markdownDocs{
			api:    apiDef,
			output: output,
		}
		return md.generate()
	default:
		return fmt.Errorf("unknown format '%s'", format)
	}
}
source: func (a AzureCLI) ShowAccount(subscription string) (*Account, error) {
	cmd := []string{"account", "show"}
	if subscription != "" {
		cmd = append(cmd, "--subscription", subscription)
	}
	var acc showAccount
	if err := a.run(&acc, cmd...); err != nil {
		return nil, errors.Trace(err)
	}
	if acc.Account.CloudName == "" {
		acc.Account.CloudName = acc.EnvironmentName
	}
	return &acc.Account, nil
}
source: func (d *NvidiaDevice) fingerprintChanged(allDevices []*nvml.FingerprintDeviceData) bool {
	d.deviceLock.Lock()
	defer d.deviceLock.Unlock()

	changeDetected := false
	// check if every device in allDevices is in d.devices
	for _, device := range allDevices {
		if _, ok := d.devices[device.UUID]; !ok {
			changeDetected = true
		}
	}

	// check if every device in d.devices is in allDevices
	fingerprintDeviceMap := make(map[string]struct{})
	for _, device := range allDevices {
		fingerprintDeviceMap[device.UUID] = struct{}{}
	}
	for id := range d.devices {
		if _, ok := fingerprintDeviceMap[id]; !ok {
			changeDetected = true
		}
	}

	d.devices = fingerprintDeviceMap
	return changeDetected
}
source: func (m *ClientManager) Add(client *Client) {
	m.initInternals()
	m.mu.Lock()
	defer m.mu.Unlock()

	key := cacheKey(client.Certificate)
	now := time.Now()
	if ele, hit := m.cache[key]; hit {
		item := ele.Value.(*managerItem)
		item.client = client
		item.lastUsed = now
		m.ll.MoveToFront(ele)
		return
	}
	ele := m.ll.PushFront(&managerItem{key, client, now})
	m.cache[key] = ele
	if m.MaxSize != 0 && m.ll.Len() > m.MaxSize {
		m.mu.Unlock()
		m.removeOldest()
		m.mu.Lock()
	}
}
source: func NewBuilderCommand(dockerCli command.Cli) *cobra.Command {
	cmd := &cobra.Command{
		Use:         "builder",
		Short:       "Manage builds",
		Args:        cli.NoArgs,
		RunE:        command.ShowHelp(dockerCli.Err()),
		Annotations: map[string]string{"version": "1.31"},
	}
	cmd.AddCommand(
		NewPruneCommand(dockerCli),
		image.NewBuildCommand(dockerCli),
	)
	return cmd
}
source: func WriteResponse(writer io.Writer, response *plugin_go.CodeGeneratorResponse) error {
	buf, err := proto.Marshal(response)
	if err != nil {
		return err
	}
	if _, err := writer.Write(buf); err != nil {
		return err
	}
	return nil
}
source: func All(err error) []error {
	if ec, ok := err.(*errorCollection); ok {
		all := make([]error, len(ec.errs))
		copy(all, ec.errs)
		return all
	}
	return []error{err}
}
source: func NewFromDB(service *badger.DB) *Database {
	db := &Database{Service: service}

	runtime.SetFinalizer(db, closeDB)
	return db
}
source: func (c *Counter) AddEvents(ctx context.Context, events []*event.Event, next Sink) error {
	atomic.AddInt64(&c.TotalEvents, int64(len(events)))
	atomic.AddInt64(&c.TotalProcessCalls, 1)
	atomic.AddInt64(&c.CallsInFlight, 1)
	start := time.Now()
	err := next.AddEvents(ctx, events)
	atomic.AddInt64(&c.TotalProcessTimeNs, time.Since(start).Nanoseconds())
	atomic.AddInt64(&c.CallsInFlight, -1)
	if err != nil {
		atomic.AddInt64(&c.TotalProcessErrors, 1)
		atomic.AddInt64(&c.ProcessErrorEvents, int64(len(events)))
		c.logErrMsg(ctx, err, "Unable to process events")
	}
	return err
}
source: func (Encoder) AppendInts16(dst []byte, vals []int16) []byte {
	if len(vals) == 0 {
		return append(dst, '[', ']')
	}
	dst = append(dst, '[')
	dst = strconv.AppendInt(dst, int64(vals[0]), 10)
	if len(vals) > 1 {
		for _, val := range vals[1:] {
			dst = strconv.AppendInt(append(dst, ','), int64(val), 10)
		}
	}
	dst = append(dst, ']')
	return dst
}
source: func (d *DNSServer) nodeLookup(cfg *dnsConfig, network, datacenter, node string, req, resp *dns.Msg, maxRecursionLevel int) {
	// Only handle ANY, A, AAAA, and TXT type requests
	qType := req.Question[0].Qtype
	if qType != dns.TypeANY && qType != dns.TypeA && qType != dns.TypeAAAA && qType != dns.TypeTXT {
		return
	}

	// Make an RPC request
	args := &structs.NodeSpecificRequest{
		Datacenter: datacenter,
		Node:       node,
		QueryOptions: structs.QueryOptions{
			Token:      d.agent.tokens.UserToken(),
			AllowStale: cfg.AllowStale,
		},
	}
	out, err := d.lookupNode(cfg, args)
	if err != nil {
		d.logger.Printf("[ERR] dns: rpc error: %v", err)
		resp.SetRcode(req, dns.RcodeServerFailure)
		return
	}

	// If we have no address, return not found!
	if out.NodeServices == nil {
		d.addSOA(cfg, resp)
		resp.SetRcode(req, dns.RcodeNameError)
		return
	}

	generateMeta := false
	metaInAnswer := false
	if qType == dns.TypeANY || qType == dns.TypeTXT {
		generateMeta = true
		metaInAnswer = true
	} else if cfg.NodeMetaTXT {
		generateMeta = true
	}

	// Add the node record
	n := out.NodeServices.Node
	edns := req.IsEdns0() != nil
	addr := d.agent.TranslateAddress(datacenter, n.Address, n.TaggedAddresses)
	records, meta := d.formatNodeRecord(cfg, out.NodeServices.Node, addr, req.Question[0].Name, qType, cfg.NodeTTL, edns, maxRecursionLevel, generateMeta)
	if records != nil {
		resp.Answer = append(resp.Answer, records...)
	}
	if meta != nil && metaInAnswer && generateMeta {
		resp.Answer = append(resp.Answer, meta...)
	} else if meta != nil && cfg.NodeMetaTXT {
		resp.Extra = append(resp.Extra, meta...)
	}
}
source: func (g *Gauge) Add(delta float64) {
	g.gv.With(makeLabels(g.lvs...)).Add(delta)
}
source: func (s *MatcherSession) AllocateSections(bit uint, count int) []uint64 {
	fetcher := make(chan *Retrieval)

	select {
	case <-s.quit:
		return nil
	case s.matcher.retrievals <- fetcher:
		task := &Retrieval{
			Bit:      bit,
			Sections: make([]uint64, count),
		}
		fetcher <- task
		return (<-fetcher).Sections
	}
}
source: func (c *dependency) String() string {
	s := c.name

	switch {
	case DepFlagLesserOrEqual == (c.flags & DepFlagLesserOrEqual):
		s = fmt.Sprintf("%s <=", s)

	case DepFlagLesser == (c.flags & DepFlagLesser):
		s = fmt.Sprintf("%s <", s)

	case DepFlagGreaterOrEqual == (c.flags & DepFlagGreaterOrEqual):
		s = fmt.Sprintf("%s >=", s)

	case DepFlagGreater == (c.flags & DepFlagGreater):
		s = fmt.Sprintf("%s >", s)

	case DepFlagEqual == (c.flags & DepFlagEqual):
		s = fmt.Sprintf("%s =", s)
	}

	if c.version != "" {
		s = fmt.Sprintf("%s %s", s, c.version)
	}

	if c.release != "" {
		s = fmt.Sprintf("%s.%s", s, c.release)
	}

	return s
}
source: func (g *Graph) DebugEdgeInfo(e Edge, info string) {
	ea := newEdgeInfo(typeEdgeInfo, e, info)
	g.debug.Encode(ea)
}
source: func (Attr *CategoricalAttribute) String() string {
	return fmt.Sprintf("CategoricalAttribute(\"%s\", %s)", Attr.Name, Attr.values)
}
source: func (_m *DFS) DfPath(path string, excludes []string) (uint64, error) {
	ret := _m.Called(path, excludes)

	var r0 uint64
	if rf, ok := ret.Get(0).(func(string, []string) uint64); ok {
		r0 = rf(path, excludes)
	} else {
		if ret.Get(0) != nil {
			r0 = ret.Get(0).(uint64)
		}
	}

	var r1 error
	if rf, ok := ret.Get(1).(func(string, []string) error); ok {
		r1 = rf(path, excludes)
	} else {
		r1 = ret.Error(1)
	}

	return r0, r1
}
source: func (d *ddl) Stats(vars *variable.SessionVars) (map[string]interface{}, error) {
	m := make(map[string]interface{})
	m[serverID] = d.uuid
	var ddlInfo *admin.DDLInfo

	err := kv.RunInNewTxn(d.store, false, func(txn kv.Transaction) error {
		var err1 error
		ddlInfo, err1 = admin.GetDDLInfo(txn)
		if err1 != nil {
			return errors.Trace(err1)
		}
		return errors.Trace(err1)
	})
	if err != nil {
		return nil, errors.Trace(err)
	}

	m[ddlSchemaVersion] = ddlInfo.SchemaVer
	// TODO: Get the owner information.
	if len(ddlInfo.Jobs) == 0 {
		return m, nil
	}
	// TODO: Add all job information if needed.
	job := ddlInfo.Jobs[0]
	m[ddlJobID] = job.ID
	m[ddlJobAction] = job.Type.String()
	m[ddlJobStartTS] = job.StartTS / 1e9 // unit: second
	m[ddlJobState] = job.State.String()
	m[ddlJobRows] = job.RowCount
	if job.Error == nil {
		m[ddlJobError] = ""
	} else {
		m[ddlJobError] = job.Error.Error()
	}
	m[ddlJobSchemaState] = job.SchemaState.String()
	m[ddlJobSchemaID] = job.SchemaID
	m[ddlJobTableID] = job.TableID
	m[ddlJobSnapshotVer] = job.SnapshotVer
	m[ddlJobReorgHandle] = ddlInfo.ReorgHandle
	m[ddlJobArgs] = job.Args
	return m, nil
}
source: func (s Seeds) count() int {
	return len(s.Artists) + len(s.Tracks) + len(s.Genres)
}
source: func (vrsConnection *VRSConnection) SetEntityState(uuid string, state entity.State, subState entity.SubState) error {

	row := make(map[string]interface{})
	row[ovsdb.NuageVMTableColumnState] = int(state)
	row[ovsdb.NuageVMTableColumnReason] = int(subState)

	condition := []string{ovsdb.NuageVMTableColumnVMUUID, "==", uuid}

	if err := vrsConnection.vmTable.UpdateRow(vrsConnection.ovsdbClient, row, condition); err != nil {
		return fmt.Errorf("Unable to update the state %s %v %v %v", uuid, state, subState, err)
	}

	return nil
}
source: func (m *MultiFormatter) SetFormatters(formatters []Formatter) {
	m.mutex.Lock()
	m.formatters = formatters
	m.mutex.Unlock()
}
source: func (ss copyStrategies) Copy(source, destination *PathSpec, out, errOut io.Writer) error {
	var err error
	foundStrategy := false

	for _, s := range ss {
		errBuf := &bytes.Buffer{}
		err = s.Copy(source, destination, out, errBuf)
		if _, isSetupError := err.(strategySetupError); isSetupError {
			klog.V(4).Infof("Error output:\n%s", errBuf.String())
			fmt.Fprintf(errOut, "WARNING: cannot use %s: %v\n", s.String(), err.Error())
			continue
		}

		io.Copy(errOut, errBuf)
		foundStrategy = true
		break
	}

	if !foundStrategy {
		err = strategySetupError("No available strategies to copy.")
	}

	return err
}
source: func (a Alphabet) Validate(s string) bool {
	t := s[:len(s)-1]
	c, err := a.Generate(t)
	if err != nil {
		return false
	}
	return rune(s[len(s)-1]) == c
}
source: func (p *Ports) AllPortRanges() map[network.PortRange]string {
	result := make(map[network.PortRange]string)
	for _, portRange := range p.doc.Ports {
		rawRange := network.PortRange{
			FromPort: portRange.FromPort,
			ToPort:   portRange.ToPort,
			Protocol: portRange.Protocol,
		}
		result[rawRange] = portRange.UnitName
	}
	return result
}
source: func NewOrganizationService() *OrganizationService {
	return &OrganizationService{
		FindOrganizationByIDF: func(ctx context.Context, id platform.ID) (*platform.Organization, error) { return nil, nil },
		FindOrganizationF: func(ctx context.Context, filter platform.OrganizationFilter) (*platform.Organization, error) {
			return nil, nil
		},
		FindOrganizationsF: func(ctx context.Context, filter platform.OrganizationFilter, opt ...platform.FindOptions) ([]*platform.Organization, int, error) {
			return nil, 0, nil
		},
		CreateOrganizationF: func(ctx context.Context, b *platform.Organization) error { return nil },
		UpdateOrganizationF: func(ctx context.Context, id platform.ID, upd platform.OrganizationUpdate) (*platform.Organization, error) {
			return nil, nil
		},
		DeleteOrganizationF: func(ctx context.Context, id platform.ID) error { return nil },
	}
}
source: func NewReindexer(client *Client, source string, reindexerFunc ReindexerFunc) *Reindexer {
	return &Reindexer{
		sourceClient:  client,
		sourceIndex:   source,
		reindexerFunc: reindexerFunc,
		statsOnly:     true,
	}
}
source: func (a *Agent) Start() error {
	if !atomic.CompareAndSwapUint32(&a.started, 0, 1) {
		return nil
	}

	rand.Seed(time.Now().Unix())
	log.Infof("Autopilot Agent starting")

	a.wg.Add(1)
	go a.controller()

	return nil
}
source: func (p *proofSetT) AddNeededHappensBeforeProof(ctx context.Context, a proofTerm, b proofTerm, reason string) {

	var action string
	defer func() {
		if action != "discard-easy" && !ShouldSuppressLogging(ctx) {
			p.G().Log.CDebugf(ctx, "proofSet add(%v --> %v) [%v] '%v'", a.shortForm(), b.shortForm(), action, reason)
		}
	}()

	idx := newProofIndex(a.leafID, b.leafID)

	if idx.a.Equal(idx.b) {
		// If both terms are on the same chain
		if a.lessThanOrEqual(b) {
			// The proof is self-evident.
			// Discard it.
			action = "discard-easy"
			return
		}
		// The proof is self-evident FALSE.
		// Add it and return immediately so the rest of this function doesn't have to trip over it.
		// It should be failed later by the checker.
		action = "added-easy-false"
		p.proofs[idx] = append(p.proofs[idx], proof{a, b, reason})
		return
	}

	set := p.proofs[idx]
	for i := len(set) - 1; i >= 0; i-- {
		existing := set[i]
		if existing.a.lessThanOrEqual(a) && b.lessThanOrEqual(existing.b) {
			// If the new proof is surrounded by the old proof.
			existing.a = existing.a.max(a)
			existing.b = existing.b.min(b)
			set[i] = existing
			action = "collapsed"
			return
		}
		if existing.a.equal(a) && existing.b.lessThanOrEqual(b) {
			// If the new proof is the same on the left and weaker on the right.
			// Discard the new proof, as it is implied by the existing one.
			action = "discard-weak"
			return
		}
	}
	action = "added"
	p.proofs[idx] = append(p.proofs[idx], proof{a, b, reason})
	return
}
source: func (e TabletStats) GetTabletHostPort() string {
	vtPort := e.Tablet.PortMap["vt"]
	return netutil.JoinHostPort(e.Tablet.Hostname, vtPort)
}
source: func autoscalingTagDescriptionsToSlice(ts []*autoscaling.TagDescription) []map[string]interface{} {
	tags := make([]map[string]interface{}, 0, len(ts))
	for _, t := range ts {
		tags = append(tags, map[string]interface{}{
			"key":                 *t.Key,
			"value":               *t.Value,
			"propagate_at_launch": *t.PropagateAtLaunch,
		})
	}

	return tags
}
source: func handleImport(s *Server) http.Handler {
	return contextHandler(func(ctx context.Context, w http.ResponseWriter, r *http.Request) {
		span, jsonMetrics, err := unmarshalMetricsFromHTTP(ctx, s.TraceClient, w, r)
		if err != nil {
			log.WithError(err).Error("Error unmarshalling metrics in global import")
			span.Add(ssf.Count("import.unmarshal.errors_total", 1, nil))
			return
		}
		// the server usually waits for this to return before finalizing the
		// response, so this part must be done asynchronously
		go s.ImportMetrics(span.Attach(ctx), jsonMetrics)
	})
}
source: func SSHForwardHandler(opts ...HandlerOption) Handler {
	h := &sshForwardHandler{}
	h.Init(opts...)

	return h
}
source: func SetInt(m config.MinikubeConfig, name string, val string) error {
	i, err := strconv.Atoi(val)
	if err != nil {
		return err
	}
	m[name] = i
	return nil
}
source: func ReadFile(filename string) (Etc, error) {
	source, err := ioutil.ReadFile(filename)
	if err != nil {
		return nil, errors.Annotate(err, ErrCannotReadFile, errorMessages, filename)
	}
	return ReadString(string(source))
} 53%|█████▎    | 2660/5000 [00:03<00:02, 950.41it/s] 
source: func (kubernetesEnvironProvider) ParsePodSpec(in string) (*caas.PodSpec, error) {
	spec, err := parseK8sPodSpec(in)
	if err != nil {
		return nil, errors.Trace(err)
	}
	return spec, spec.Validate()
}
source: func (f *Form) ClickByValue(name, value string) error {
	if _, ok := f.buttons[name]; !ok {
		return errors.NewInvalidFormValue(
			"Form does not contain a button with the name '%s'.", name)
	}
	valueNotFound := true
	for _, val := range f.buttons[name] {
		if val == value {
			valueNotFound = false
			break
		}
	}
	if valueNotFound {
		return errors.NewInvalidFormValue(
			"Form does not contain a button with the name '%s' and value '%s'.", name, value)
	}
	return f.send(name, value)
}
source: func (upc *UDPPacketConn) WriteTo(b []byte, addr net.Addr) (int, error) {
	udpAddr, ok := addr.(*net.UDPAddr)
	if !ok {
		return 0, fmt.Errorf("must supply UDPAddr")
	}

	// Using the boundAddr is not quite right here, but it works.
	packet := udp4pkt(b, udpAddr, upc.boundAddr)
	return upc.PacketConn.WriteTo(packet, &raw.Addr{HardwareAddr: BroadcastMac})
}
source: func (d *Document) GetLayout(ctx context.Context) (*Layout, APIResponse) {
	var layout Layout

	resp, err := d.client.makeAPIRequest(ctx, "GET", d.Links.Layout, nil, nil, "")

	if err != nil {
		return nil, apiResponse(ErrHTTPGetFailed, d.ID, resp, err)
	}

	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		return nil, apiResponse(ErrDocumentLayout, d.ID, resp, errors.New(ErrDocumentLayout))
	}

	if err := json.NewDecoder(resp.Body).Decode(&layout); err != nil {
		return nil, apiResponse("decoding failed", d.ID, resp, err)
	}

	return &layout, apiResponse("layout completed", d.ID, resp, err)
}
source: func (m LinearFloatMapper) ID(fi ...interface{}) (rowIDs []int64, err error) {
	f := fi[0].(float64)
	externalID := int64(m.Res)

	// bounds check
	if f < m.Min || f > m.Max {
		if m.allowExternal {
			return []int64{externalID}, nil
		}
		return []int64{0}, fmt.Errorf("float %v out of range", f)
	}

	// compute bin
	rowID := int64(m.Res * (f - m.Min) / (m.Max - m.Min))
	return []int64{rowID}, nil
}
source: func (s *Server) join(roomName string, connID string) {
	if s.rooms[roomName] == nil {
		s.rooms[roomName] = make([]string, 0)
	}
	s.rooms[roomName] = append(s.rooms[roomName], connID)
}
source: func (h *DBHeader) ValidateHmacSha256(hmacKey []byte, hash [32]byte) error {
	hmacSha := h.GetHmacSha256(hmacKey)
	if !reflect.DeepEqual(hmacSha, hash) {
		return errors.New("HMAC-Sha256 of header mismatching")
	}
	return nil
}
source: func IsBuilderImage(image *dockerv10.DockerImage) bool {
	if image == nil || image.Config == nil {
		return false
	}
	// Has the scripts annotation
	if _, ok := image.Config.Labels[s2iScriptsLabel]; ok {
		return true
	}
	// Has the legacy environment variables
	for _, env := range image.Config.Env {
		for _, name := range s2iEnvironmentNames {
			if strings.HasPrefix(env, name+"=") {
				return true
			}
		}
	}
	return false
}
source: func (m *MonitorFormatter) FormatSample(data []byte, cpu int) {
	prefix := fmt.Sprintf("CPU %02d:", cpu)
	messageType := data[0]

	switch messageType {
	case monitorAPI.MessageTypeDrop:
		m.dropEvents(prefix, data)
	case monitorAPI.MessageTypeDebug:
		m.debugEvents(prefix, data)
	case monitorAPI.MessageTypeCapture:
		m.captureEvents(prefix, data)
	case monitorAPI.MessageTypeTrace:
		m.traceEvents(prefix, data)
	case monitorAPI.MessageTypeAccessLog:
		m.logRecordEvents(prefix, data)
	case monitorAPI.MessageTypeAgent:
		m.agentEvents(prefix, data)
	default:
		fmt.Printf("%s Unknown event: %+v\n", prefix, data)
	}
}
source: func (t *terminal) Wait() (*ExecResult, error) {
	err := t.cmd.Wait()
	if err != nil {
		if exitErr, ok := err.(*exec.ExitError); ok {
			status := exitErr.Sys().(syscall.WaitStatus)
			return &ExecResult{Code: status.ExitStatus(), Command: t.cmd.Path}, nil
		}
		return nil, err
	}

	status, ok := t.cmd.ProcessState.Sys().(syscall.WaitStatus)
	if !ok {
		return nil, trace.Errorf("unknown exit status: %T(%v)", t.cmd.ProcessState.Sys(), t.cmd.ProcessState.Sys())
	}

	return &ExecResult{
		Code:    status.ExitStatus(),
		Command: t.cmd.Path,
	}, nil
}
source: func StreamServerInterceptor(logger *zap.Logger, opts ...Option) grpc.StreamServerInterceptor {
	o := evaluateServerOpt(opts)
	return func(srv interface{}, stream grpc.ServerStream, info *grpc.StreamServerInfo, handler grpc.StreamHandler) error {
		startTime := time.Now()
		newCtx := newLoggerForCall(stream.Context(), logger, info.FullMethod, startTime)
		wrapped := grpc_middleware.WrapServerStream(stream)
		wrapped.WrappedContext = newCtx

		err := handler(srv, wrapped)
		if !o.shouldLog(info.FullMethod, err) {
			return err
		}
		code := o.codeFunc(err)
		level := o.levelFunc(code)

		// re-extract logger from newCtx, as it may have extra fields that changed in the holder.
		ctx_zap.Extract(newCtx).Check(level, "finished streaming call with code "+code.String()).Write(
			zap.Error(err),
			zap.String("grpc.code", code.String()),
			o.durationFunc(time.Since(startTime)),
		)

		return err
	}
}
source: func (e *Elector) getIdentFromNode(node string) (ident string, err error) {
	nodePath := path.Join(e.basePath, node)
	b, _, err := e.conn.Get(nodePath)
	return string(b), err
}
source: func (a *Allocations) GarbageCollect(args *nstructs.AllocSpecificRequest, reply *nstructs.GenericResponse) error {
	defer metrics.MeasureSince([]string{"client", "allocations", "garbage_collect"}, time.Now())

	// Check submit job permissions
	if aclObj, err := a.c.ResolveToken(args.AuthToken); err != nil {
		return err
	} else if aclObj != nil && !aclObj.AllowNsOp(args.Namespace, acl.NamespaceCapabilitySubmitJob) {
		return nstructs.ErrPermissionDenied
	}

	if !a.c.CollectAllocation(args.AllocID) {
		// Could not find alloc
		return nstructs.NewErrUnknownAllocation(args.AllocID)
	}

	return nil
}
source: func (cmd *Command) Serve(listeners ...net.Listener) (err error) {
	cmd.SetIsServer(true)
	var g sync.WaitGroup
	for _, ln := range listeners {
		g.Add(1)
		go func(ln net.Listener) {
			if e := http.Serve(ln, cmd); e != nil {
				panic(e.Error())
			}
			g.Done()
		}(ln)
	}
	g.Wait()
	return
}
source: func (r *Registry) GetServerFunc(stream string) (func(*Peer, string, bool) (Server, error), error) {
	r.serverMu.RLock()
	defer r.serverMu.RUnlock()

	f := r.serverFuncs[stream]
	if f == nil {
		return nil, fmt.Errorf("stream %v not registered", stream)
	}
	return f, nil
}
source: func (r *BulkDeleteRequest) Version(version int64) *BulkDeleteRequest {
	r.version = version
	r.source = nil
	return r
}
source: func (d *Decoder) Decode(idx *MemoryIndex) error {
	if err := validateHeader(d); err != nil {
		return err
	}

	flow := []func(*MemoryIndex, io.Reader) error{
		readVersion,
		readFanout,
		readObjectNames,
		readCRC32,
		readOffsets,
		readChecksums,
	}

	for _, f := range flow {
		if err := f(idx, d); err != nil {
			return err
		}
	}

	return nil
}
source: func (s *Snapshot) Tombstones() (memdb.ResultIterator, error) {
	return s.store.kvsGraveyard.DumpTxn(s.tx)
}
source: func (i *macIdentity) Sign(rand io.Reader, digest []byte, opts crypto.SignerOpts) ([]byte, error) {
	hash := opts.HashFunc()

	if len(digest) != hash.Size() {
		return nil, errors.New("bad digest for hash")
	}

	kref, err := i.getKeyRef()
	if err != nil {
		return nil, err
	}

	cdigest, err := bytesToCFData(digest)
	if err != nil {
		return nil, err
	}
	defer C.CFRelease(C.CFTypeRef(cdigest))

	algo, err := i.getAlgo(hash)
	if err != nil {
		return nil, err
	}

	// sign the digest
	var cerr C.CFErrorRef
	csig := C.SecKeyCreateSignature(kref, algo, cdigest, &cerr)

	if err := cfErrorError(cerr); err != nil {
		defer C.CFRelease(C.CFTypeRef(cerr))

		return nil, err
	}

	if csig == nilCFDataRef {
		return nil, errors.New("nil signature from SecKeyCreateSignature")
	}

	defer C.CFRelease(C.CFTypeRef(csig))

	sig := cfDataToBytes(csig)

	return sig, nil
}
source: func (d *API) WithJSONDefaults() *API {
	d.DefaultConsumes = runtime.JSONMime
	d.DefaultProduces = runtime.JSONMime
	d.consumers[runtime.JSONMime] = runtime.JSONConsumer()
	d.producers[runtime.JSONMime] = runtime.JSONProducer()
	return d
}
source: func (m *NamedMethod) ResolveReferences(root string) (interface{}, error) {
	errors := make([]error, 0)
	if m.Value != nil {
		_, err := m.Value.ResolveReferences(root)
		if err != nil {
			errors = append(errors, err)
		}
	}
	return nil, compiler.NewErrorGroupOrNil(errors)
}
source: func (engine *Engine) SecureJsonPrefix(prefix string) *Engine {
	engine.secureJsonPrefix = prefix
	return engine
}
source: func (j *Jenkins) GetQueue() (*Queue, error) {
	q := &Queue{Jenkins: j, Raw: new(queueResponse), Base: j.GetQueueUrl()}
	_, err := q.Poll()
	if err != nil {
		return nil, err
	}
	return q, nil
}
source: func (g *GraphQuery) Normalize() error {
	if err := g.AttemptList.Normalize(); err != nil {
		return err
	}
	if len(g.AttemptRange) > 0 {
		lme := errors.NewLazyMultiError(len(g.AttemptRange))
		for i, rng := range g.AttemptRange {
			lme.Assign(i, rng.Normalize())
		}
		if err := lme.Get(); err != nil {
			return err
		}
	}
	if len(g.Search) > 0 {
		lme := errors.NewLazyMultiError(len(g.Search))
		for i, s := range g.Search {
			lme.Assign(i, s.Normalize())
		}
		if err := lme.Get(); err != nil {
			return err
		}
	}
	return nil
}
source: func (o CustomResourceDefinitionsServerOptions) Validate() error {
	errors := []error{}
	errors = append(errors, o.RecommendedOptions.Validate()...)
	errors = append(errors, o.APIEnablement.Validate(apiserver.Scheme)...)
	return utilerrors.NewAggregate(errors)
}
source: func (r *Request) Body(reader io.Reader) *Request {
	r.Use(body.Reader(reader))
	return r
}
source: func ResponseError(format string, a ...interface{}) {
	response := ErrorResponse{Error: fmt.Sprintf(format, a...)}
	j, err := json.MarshalIndent(&response, "", "\t")
	if err != nil {
		panic(fmt.Sprintf("Failed to generate response for error:", err))
	}
	fmt.Println(string(j[:]))
}
source: func (stor *maas1Storage) Get(name string) (io.ReadCloser, error) {
	name = stor.prefixWithPrivateNamespace(name)
	fileObj, err := stor.retrieveFileObject(name)
	if err != nil {
		return nil, err
	}
	data, err := fileObj.GetField("content")
	if err != nil {
		return nil, fmt.Errorf("could not extract file content for %s: %v", name, err)
	}
	buf, err := base64.StdEncoding.DecodeString(data)
	if err != nil {
		return nil, fmt.Errorf("bad data in file '%s': %v", name, err)
	}
	return ioutil.NopCloser(bytes.NewReader(buf)), nil
}
source: func (c *Config) Save() error {
	if err := c.checkDefaults(); err != nil {
		return err
	}

	buf, err := yaml.Marshal(c)
	if err != nil {
		return errors.Wrapf(err, "failed to marshal YAML")
	}

	cfgLoc := configLocation()
	cfgDir := filepath.Dir(cfgLoc)
	if !fsutil.IsDir(cfgDir) {
		if err := os.MkdirAll(cfgDir, 0700); err != nil {
			return errors.Wrapf(err, "failed to create dir '%s'", cfgDir)
		}
	}
	if err := ioutil.WriteFile(cfgLoc, buf, 0600); err != nil {
		return errors.Wrapf(err, "failed to write config file to '%s'", cfgLoc)
	}
	if debug {
		fmt.Printf("[DEBUG] Saved config to %s: %+v\n", cfgLoc, c)
	}
	return nil
}
source: func (r *DynamicRouter) HandleFunc(pattern string, handler Handler, filters ...HttpFilter) {
	r.registerHandler(SplitPath(pattern), handler, filters...)
}
source: func (f *Freq) Update(d time.Duration, now time.Time) int {
	earliest := now.Add(-1 * d)
	f.Lock()
	defer f.Unlock()
	if f.last.Before(earliest) {
		f.last = now
		f.hits = 1
		return f.hits
	}
	f.last = now
	f.hits++
	return f.hits
}
source: func (g *Graph) Walk(walker GraphWalker) tfdiags.Diagnostics {
	return g.walk(walker)
}
source: func NewInsecureClient() *EzClient {
	tr := &http.Transport{
		TLSClientConfig: &tls.Config{InsecureSkipVerify: true},
	}
	return &EzClient{Client: &http.Client{Transport: tr}}
}
source: func (pc ProviderConfig) StringCompact() string {
	if pc.Alias != "" {
		return fmt.Sprintf("%s.%s", pc.Type, pc.Alias)
	}
	return pc.Type
}
source: func validateIPSources(srcs []string) error {
	if len(srcs) == 0 {
		return fmt.Errorf("empty ip sources")
	}
	if len(srcs) != len(unique(srcs)) {
		return fmt.Errorf("duplicate ip source specified")
	}
	for _, src := range srcs {
		switch src {
		case "host", "docker", "mesos", "netinfo":
		default:
			return fmt.Errorf("invalid ip source %q", src)
		}
	}

	return nil
}
source: func (c command) match(cmdstr string) bool {
	for _, v := range c.aliases {
		if v == cmdstr {
			return true
		}
	}
	return false
}
source: func NewProxyExecMode(raw string) (ProxyExecMode, error) {
	switch raw {
	case "":
		return ProxyExecModeUnspecified, nil
	case "daemon":
		return ProxyExecModeDaemon, nil
	case "script":
		return ProxyExecModeScript, nil
	default:
		return 0, fmt.Errorf("invalid exec mode: %s", raw)
	}
}
source: func NewCmdNamespace(streams genericclioptions.IOStreams) *cobra.Command {
	o := NewNamespaceOptions(streams)

	cmd := &cobra.Command{
		Use:          "ns [new-namespace] [flags]",
		Short:        "View or set the current namespace",
		Example:      fmt.Sprintf(namespaceExample, "kubectl"),
		SilenceUsage: true,
		RunE: func(c *cobra.Command, args []string) error {
			if err := o.Complete(c, args); err != nil {
				return err
			}
			if err := o.Validate(); err != nil {
				return err
			}
			if err := o.Run(); err != nil {
				return err
			}

			return nil
		},
	}

	cmd.Flags().BoolVar(&o.listNamespaces, "list", o.listNamespaces, "if true, print the list of all namespaces in the current KUBECONFIG")
	o.configFlags.AddFlags(cmd.Flags())

	return cmd
}
source: func MarshalTimeOfDay(v TimeOfDay) (string, error) {
	d := int64(v.FromMidnight / time.Second)
	hour := d / 3600
	d = d % 3600
	minute := d / 60
	second := d % 60

	return fmt.Sprintf("%02d:%02d:%02d", hour, minute, second), nil
}
source: func StrToInt(sc *variable.StatementContext, str string) (int64, error) {
	str = strings.TrimSpace(str)
	validPrefix, err := getValidIntPrefix(sc, str)
	iVal, err1 := strconv.ParseInt(validPrefix, 10, 64)
	if err1 != nil {
		return iVal, errors.Trace(ErrOverflow)
	}
	return iVal, errors.Trace(err)
}
source: func (cli *OpsGenieClient) NotificationV2() (*OpsGenieNotificationV2Client, error) {
	cli.makeHTTPTransportSettings()

	notificationClient := new(OpsGenieNotificationV2Client)
	notificationClient.SetOpsGenieClient(*cli)

	if cli.opsGenieAPIURL == "" {
		notificationClient.SetOpsGenieAPIUrl(endpointURL)
	}

	return notificationClient, nil
}
source: func Convert_rbac_RoleList_To_v1_RoleList(in *rbac.RoleList, out *v1.RoleList, s conversion.Scope) error {
	return autoConvert_rbac_RoleList_To_v1_RoleList(in, out, s)
}
source: func (s *AccountService) NewDeleteAccountParams(id string) *DeleteAccountParams {
	p := &DeleteAccountParams{}
	p.p = make(map[string]interface{})
	p.p["id"] = id
	return p
}
source: func runProvisionScript(script string, cli manual.WinrmClientAPI, stdin, stderr io.Writer) (err error) {
	script64 := base64.StdEncoding.EncodeToString([]byte(script))
	input := bytes.NewBufferString(script64) // make new buffer out of script
	// we must make sure to buffer the entire script
	// in a sequential write fashion first into a script
	// decouple the provisioning script into little 1024 byte chunks
	// we are doing this in order to append into a .ps1 file.
	var buf [1024]byte

	// if the file dosen't exist ,create it
	// if the file exists just clear/reset it
	script, err = shell.NewPSEncodedCommand(initChunk)
	if err != nil {
		return err
	}
	if err = cli.Run(script, stdin, stderr); err != nil {
		return errors.Trace(err)
	}

	// sequential read.
	for input.Len() != 0 {
		n, err := input.Read(buf[:])
		if err != nil && err != io.EOF {
			return errors.Trace(err)
		}
		script, err = shell.NewPSEncodedCommand(
			fmt.Sprintf(saveChunk, string(buf[:n])),
		)
		if err != nil {
			return errors.Trace(err)
		}
		if err = cli.Run(script, stdin, stderr); err != nil {
			return errors.Trace(err)
		}
	}

	// after the sendAndSave script is successfully done
	// we must execute the newly writed script
	script, err = shell.NewPSEncodedCommand(runCmdProv)
	if err != nil {
		return err
	}
	logger.Debugf("Running the provisioningScript")
	var outerr bytes.Buffer
	if err = cli.Run(script, stdin, &outerr); err != nil {
		return errors.Trace(err)
	}

	if outerr.Len() != 0 {
		return fmt.Errorf("%v ", strings.TrimSpace(outerr.String()))
	}

	return err
}
source: func (k Key) EndsWith(other Key) bool {
	if other.Len() > k.Len() {
		return false
	}
	for i := range other {
		part := other[other.Len()-1-i]
		if k[k.Len()-1-i] != part {
			return false
		}
	}
	return true
}
source: func (c *Client) GetIGFolder(id string, name string) (InitiatorGroupFolder, error) {
	igf, err := c.api.GetIGFolder(id, name)
	if err != nil {
		return nil, err
	}
	return InitiatorGroupFolder(igf.Content), nil
}
source: func Convert_v1_Key_To_config_Key(in *Key, out *config.Key, s conversion.Scope) error {
	return autoConvert_v1_Key_To_config_Key(in, out, s)
}
source: func convertArray(in []interface{}) []interface{} {
  rtn := []interface{}{}
  for _, val := range in {
    var newValue interface{}
    switch val.(type) {
      case []interface{}:
        newValue = convertArray(val.([]interface{}))
      case map[interface{}]interface{}:
        newValue = convertMap(val.(map[interface{}]interface{}))
      default:
        newValue = val
    } 
    rtn = append(rtn, newValue)  
  }
  return rtn
}
source: func (c *Client) SetServers(in []string) (int, error) {
	return c.setServersImpl(in, false)
}
source: func (s *MonitoringConfigurationUpdate) SetLogLevelUpdate(v string) *MonitoringConfigurationUpdate {
	s.LogLevelUpdate = &v
	return s
}
source: func (p Principal) MarshalJSON() ([]byte, error) {
	if !p.IsValid() {
		return nil, fmt.Errorf("invalid principal %v", p)
	}

	// subtype to avoid recursive call to MarshalJSON()
	type subPrincipal Principal
	sp := subPrincipal(p)
	return json.Marshal(sp)
}
source: func (in *Workflow) DeepCopy() *Workflow {
	if in == nil {
		return nil
	}
	out := new(Workflow)
	in.DeepCopyInto(out)
	return out
}
source: func (b *Bar) Value(n float64) {
	if n > b.Total {
		panic("Bar update value cannot be greater than the total")
	}
	b.value = n
}
source: func (e *Env) SetValue(v interface{}) {
	if reflect.TypeOf(v).Kind() == reflect.Ptr {
		e.Value = reflect.ValueOf(v).Elem()
	} else {
		e.Value = reflect.ValueOf(v)
	}
}
source: func (p *Packet) GetUDPData() []byte {
	return p.ipHdr.Buffer[p.ipHdr.ipHeaderLen+UDPDataPos:]
}
source: func ButtonModifiers(modifiers ...input.Modifier) MouseOption {
	return func(p *input.DispatchMouseEventParams) *input.DispatchMouseEventParams {
		for _, m := range modifiers {
			p.Modifiers |= m
		}
		return p
	}
}
source: func OptServerNodeID(nodeID string) ServerOption {
	return func(s *Server) error {
		s.nodeID = nodeID
		return nil
	}
}
source: func (db *usersDB) GetByEmail(email string) (schema.User, error) {
	defer db.mutex.RUnlock()
	db.mutex.RLock()

	user, ok := db.users[email]
	if !ok {
		return schema.User{}, app.ErrNotFound
	}

	return user, nil
}
source: func (d Datastore) HostContext(ctx context.Context, host *HostSystem) context.Context {
	return context.WithValue(ctx, datastoreServiceTicketHostKey{}, host)
}
source: func calcDigest(inputs map[string][]byte) string {
	keys := make([]string, 0, len(inputs))
	for k := range inputs {
		keys = append(keys, k)
	}
	sort.Strings(keys)
	h := sha1.New()
	for _, k := range keys {
		v := inputs[k]
		fmt.Fprintf(h, "%s\n%d\n", k, len(v))
		h.Write(v)
	}
	blob := h.Sum(nil)
	return hex.EncodeToString(blob[:])
}
source: func (g *GoogleCloud) Publish(ctx context.Context, topic string, m *ps.Msg) error {
	t, err := g.getTopic(topic)
	if err != nil {
		return err
	}

	logr.WithCtx(ctx).Debug("Google Pubsub: Publishing")
	res := t.Publish(context.Background(), &pubsub.Message{
		Data:       m.Data,
		Attributes: m.Metadata,
	})

	_, err = res.Get(context.Background())
	if err != nil {
		logr.WithCtx(ctx).Error(errors.Wrap(err, "publish get failed"))
	} else {
		logr.WithCtx(ctx).Debug("Google Pubsub: Publish confirmed")
	}

	return err
}
source: func loadConfig() (*config, []string, error) {
	// Default config.
	cfg := config{
		DataDir:       defaultDataDir,
		DbType:        defaultDbType,
		NumCandidates: defaultNumCandidates,
	}

	// Parse command line options.
	parser := flags.NewParser(&cfg, flags.Default)
	remainingArgs, err := parser.Parse()
	if err != nil {
		if e, ok := err.(*flags.Error); !ok || e.Type != flags.ErrHelp {
			parser.WriteHelp(os.Stderr)
		}
		return nil, nil, err
	}

	// Multiple networks can't be selected simultaneously.
	funcName := "loadConfig"
	numNets := 0
	// Count number of network flags passed; assign active network params
	// while we're at it
	if cfg.TestNet3 {
		numNets++
		activeNetParams = &chaincfg.TestNet3Params
	}
	if cfg.RegressionTest {
		numNets++
		activeNetParams = &chaincfg.RegressionNetParams
	}
	if cfg.SimNet {
		numNets++
		activeNetParams = &chaincfg.SimNetParams
	}
	if numNets > 1 {
		str := "%s: The testnet, regtest, and simnet params can't be " +
			"used together -- choose one of the three"
		err := fmt.Errorf(str, funcName)
		fmt.Fprintln(os.Stderr, err)
		parser.WriteHelp(os.Stderr)
		return nil, nil, err
	}

	// Validate database type.
	if !validDbType(cfg.DbType) {
		str := "%s: The specified database type [%v] is invalid -- " +
			"supported types %v"
		err := fmt.Errorf(str, "loadConfig", cfg.DbType, knownDbTypes)
		fmt.Fprintln(os.Stderr, err)
		parser.WriteHelp(os.Stderr)
		return nil, nil, err
	}

	// Append the network type to the data directory so it is "namespaced"
	// per network.  In addition to the block database, there are other
	// pieces of data that are saved to disk such as address manager state.
	// All data is specific to a network, so namespacing the data directory
	// means each individual piece of serialized data does not have to
	// worry about changing names per network and such.
	cfg.DataDir = filepath.Join(cfg.DataDir, netName(activeNetParams))

	// Validate the number of candidates.
	if cfg.NumCandidates < minCandidates || cfg.NumCandidates > maxCandidates {
		str := "%s: The specified number of candidates is out of " +
			"range -- parsed [%v]"
		err = fmt.Errorf(str, "loadConfig", cfg.NumCandidates)
		fmt.Fprintln(os.Stderr, err)
		parser.WriteHelp(os.Stderr)
		return nil, nil, err
	}

	return &cfg, remainingArgs, nil
}
source: func (b *Bundle) OrdererConfig() (Orderer, bool) {
	result := b.channelConfig.OrdererConfig()
	return result, result != nil
}
source: func Random() Balancer {
	logger.Debugf("Creating Random balancer")
	return func(peers []fab.Peer) []fab.Peer {
		logger.Debugf("Load balancing %d peers using Random strategy...", len(peers))

		balancedPeers := make([]fab.Peer, len(peers))
		for i, index := range rand.Perm(len(peers)) {
			balancedPeers[i] = peers[index]
		}
		return balancedPeers
	}
}
source: func (s *Sandbox) UserNsPath() string {
	if s.infraContainer != nil {
		return fmt.Sprintf("/proc/%v/ns/user", s.infraContainer.State().Pid)
	}
	return ""
}
source: func SetupLogging(loggers []string, logOpts map[string]string, tag string, debug bool) error {
	// Set default logger to output to stdout if no loggers are provided.
	if len(loggers) == 0 {
		// TODO: switch to a per-logger version when we upgrade to logrus >1.0.3
		logrus.SetOutput(os.Stdout)
	}

	SetLogLevel(DefaultLogLevel)
	ToggleDebugLogs(debug)

	// always suppress the default logger so libraries don't print things
	logrus.SetLevel(logrus.PanicLevel)

	// Iterate through all provided loggers and configure them according
	// to user-provided settings.
	for _, logger := range loggers {
		switch logger {
		case Syslog:
			valuesToValidate := getLogDriverConfig(Syslog, logOpts)
			err := validateOpts(Syslog, valuesToValidate, syslogOpts)
			if err != nil {
				return err
			}
			setupSyslog(valuesToValidate, tag, debug)
		default:
			return fmt.Errorf("provided log driver %q is not a supported log driver", logger)
		}
	}

	return nil
}
source: func (l *WAL) SetDefaultMetricLabels(labels prometheus.Labels) {
	l.defaultMetricLabels = make(prometheus.Labels, len(labels))
	for k, v := range labels {
		l.defaultMetricLabels[k] = v
	}
}
source: func (s *LoadBalancerService) NewListSslCertsParams() *ListSslCertsParams {
	p := &ListSslCertsParams{}
	p.p = make(map[string]interface{})
	return p
}
source: func (r Ticket) GetLastViewedDate() (resp datatypes.Time, err error) {
	err = r.Session.DoRequest("SoftLayer_Ticket", "getLastViewedDate", nil, &r.Options, &resp)
	return
}
source: func (m *ExpirationManager) renewEntry(ctx context.Context, le *leaseEntry, increment time.Duration) (*logical.Response, error) {
	secret := *le.Secret
	secret.IssueTime = le.IssueTime
	secret.Increment = increment
	secret.LeaseID = ""

	// Make sure we're operating in the right namespace
	nsCtx := namespace.ContextWithNamespace(ctx, le.namespace)

	req := logical.RenewRequest(le.Path, &secret, le.Data)
	resp, err := m.router.Route(nsCtx, req)
	if err != nil || (resp != nil && resp.IsError()) {
		return nil, errwrap.Wrapf(fmt.Sprintf("failed to renew entry: resp: %#v err: {{err}}", resp), err)
	}
	return resp, nil
}
source: func StringToBondMode(s string) BondMode {
	mode, ok := StringToBondModeMap[s]
	if !ok {
		return BOND_MODE_UNKNOWN
	}
	return mode
}
source: func New(i interface{}) *Nulls {
	if _, ok := i.(nullable); !ok {
		return nil
	}
	return &Nulls{Value: i}
}
source: func (c *ConsulAlertClient) NewAlerts() []Check {
	allChecks, _, _ := c.api.KV().List("consul-alerts/checks", nil)
	var alerts []Check
	for _, kvpair := range allChecks {
		key := kvpair.Key
		if strings.HasSuffix(key, "/") {
			continue
		}
		var status Status
		json.Unmarshal(kvpair.Value, &status)
		if status.ForNotification {
			status.ForNotification = false
			data, _ := json.Marshal(status)
			c.api.KV().Put(&consulapi.KVPair{Key: key, Value: data}, nil)
			// check if blacklisted

			if !c.IsBlacklisted(status.HealthCheck) {
				alerts = append(alerts, *status.HealthCheck)
			}
		}
	}
	return alerts
}
source: func DiffSchemaToArray(leftName string, left *tabletmanagerdatapb.SchemaDefinition, rightName string, right *tabletmanagerdatapb.SchemaDefinition) (result []string) {
	er := concurrency.AllErrorRecorder{}
	DiffSchema(leftName, left, rightName, right, &er)
	if er.HasErrors() {
		return er.ErrorStrings()
	}
	return nil
}
source: func (t Type) requiresLengthPrefix() bool {
	return t.T == StringTy || t.T == BytesTy || t.T == SliceTy
}
source: func (c *ClientConfig) Load(d *distconf.Distconf) {
	c.SourceName = d.Str("signalfuse.sourceName", "")
	c.AuthToken = d.Str("sf.metrics.auth_token", "")
	c.Endpoint = d.Str("sf.metrics.statsendpoint", "")
	c.ReportingInterval = d.Duration("sf.metrics.report_interval", time.Second)
	c.TimeKeeper = timekeeper.RealTime{}
	c.OsHostname = os.Hostname
	c.DisableCompression = d.Bool("sf.metrics.disableCompression", false)
}
source: func (p *parser) consumeCommentGroup() (comments *ast.CommentGroup, endline int) {
	var list []*ast.Comment
	endline = p.file.Line(p.pos)
	for p.tok == token.COMMENT && endline+1 >= p.file.Line(p.pos) {
		var comment *ast.Comment
		comment, endline = p.consumeComment()
		list = append(list, comment)
	}

	// add comment group to the comments list
	comments = &ast.CommentGroup{list}
	p.comments = append(p.comments, comments)

	return
}
source: func (d *digest) Sum(in []byte) []byte {
	// Make a copy of d0 so that caller can keep writing and summing.
	d0 := *d
	hash := d0.checkSum()
	return append(in, hash[:]...)
}
source: func (iter *Iterx) Select(dest interface{}) error {
	iter.scanAll(dest, false)
	iter.Close()

	return iter.err
}
source: func (ls LogicalSort) Init(ctx sessionctx.Context) *LogicalSort {
	ls.baseLogicalPlan = newBaseLogicalPlan(ctx, TypeSort, &ls)
	return &ls
}
source: func (e *ebsProvider) Supports(k storage.StorageKind) bool {
	return k == storage.StorageKindBlock
}
source: func (fn Function) LaunchAndSync(gridDimX, gridDimY, gridDimZ, blockDimX, blockDimY, blockDimZ, sharedMemBytes int, stream Stream, kernelParams []unsafe.Pointer) error {
	argv := C.malloc(C.size_t(len(kernelParams) * pointerSize))
	argp := C.malloc(C.size_t(len(kernelParams) * pointerSize))
	defer C.free(argv)
	defer C.free(argp)
	for i := range kernelParams {
		*((*unsafe.Pointer)(offset(argp, i))) = offset(argv, i)       // argp[i] = &argv[i]
		*((*uint64)(offset(argv, i))) = *((*uint64)(kernelParams[i])) // argv[i] = *kernelParams[i]
	}

	err := result(C.cuLaunchAndSync(
		fn.fn,
		C.uint(gridDimX),
		C.uint(gridDimY),
		C.uint(gridDimZ),
		C.uint(blockDimX),
		C.uint(blockDimY),
		C.uint(blockDimZ),
		C.uint(sharedMemBytes),
		stream.c(),
		(*unsafe.Pointer)(argp),
		(*unsafe.Pointer)(nil)))
	return err
}
source: func makeHandler(binding interface{}, o *Options) martini.Handler {

	return func(context martini.Context, resp http.ResponseWriter, req *http.Request) {
		// Upgrade the request to a websocket connection
		ws, status, err := upgradeRequest(resp, req, o)
		if err != nil {
			resp.WriteHeader(status)
			resp.Write([]byte(err.Error()))
			return
		}

		// Set up the connection
		c := newBinding(binding, ws, o)

		// Set the options for the gorilla websocket package
		c.setSocketOptions()

		// Map the sending and receiving channels
		c.mapChannels(context)

		// Map the Channels <-chan error, <-chan bool and chan<- bool
		c.mapDefaultChannels(context)

		// start the send and receive goroutines
		go c.send()
		go c.recv()
		go waitForDisconnect(c)

		// call the next handler, which must block
		context.Next()
	}
}
source: func GetType(err error, v interface{}) error {
	es := GetAllType(err, v)
	if len(es) > 0 {
		return es[len(es)-1]
	}

	return nil
}
source: func NewClient(appID, apiKey string) *Client {
	return NewClientWithConfig(
		Configuration{
			AppID:  appID,
			APIKey: apiKey,
		},
	)
}
source: func (s *Certificate) SetValidFrom(v time.Time) *Certificate {
	s.ValidFrom = &v
	return s
}
source: func (a *Application) AddGroup(name string) string {
	a.Groups = append(a.Groups, Group{Name: name})
	return name
}
source: func (s *session) ExecutePreparedStmt(ctx context.Context, stmtID uint32, args ...interface{}) (sqlexec.RecordSet, error) {
	err := checkArgs(args...)
	if err != nil {
		return nil, err
	}

	s.PrepareTxnCtx(ctx)
	st, err := executor.CompileExecutePreparedStmt(s, stmtID, args...)
	if err != nil {
		return nil, err
	}
	logQuery(st.OriginText(), s.sessionVars)
	r, err := runStmt(ctx, s, st)
	return r, err
}
source: func (c *Commands) UnmarshalBinary(uplink bool, data []byte) error {
	var i int

	for i < len(data) {
		var cmd Command
		if err := cmd.UnmarshalBinary(uplink, data[i:]); err != nil {
			return err
		}
		i += cmd.Size()
		*c = append(*c, cmd)
	}

	return nil
}
source: func (win *Window) Label(str string, alignment label.Align) {
	win.LabelColored(str, alignment, win.ctx.Style.Text.Color)
}
source: func (s *Service) BuildCreate(ctx context.Context, appIdentity string, o BuildCreateOpts) (*Build, error) {
	var build Build
	return &build, s.Post(ctx, &build, fmt.Sprintf("/apps/%v/builds", appIdentity), o)
}
source: func (am *AxisMouse) Value() float32 {
	var diff float32

	if am.direction == AxisMouseHori {
		diff = (Input.Mouse.X - am.old + (ResizeXOffset / (2 * GetGlobalScale().X * CanvasScale())))
		am.old = (Input.Mouse.X + (ResizeXOffset / (2 * GetGlobalScale().X * CanvasScale())))
	} else {
		diff = (Input.Mouse.Y - am.old + (ResizeYOffset / (2 * GetGlobalScale().Y * CanvasScale())))
		am.old = (Input.Mouse.Y + (ResizeYOffset / (2 * GetGlobalScale().Y * CanvasScale())))
	}

	return diff
}
source: func (s *sequenceDecs) initialize(br *bitReader, hist *history, literals, out []byte) error {
	if err := s.litLengths.init(br); err != nil {
		return errors.New("litLengths:" + err.Error())
	}
	if err := s.offsets.init(br); err != nil {
		return errors.New("litLengths:" + err.Error())
	}
	if err := s.matchLengths.init(br); err != nil {
		return errors.New("matchLengths:" + err.Error())
	}
	s.literals = literals
	s.hist = hist.b
	s.prevOffset = hist.recentOffsets
	s.maxBits = s.litLengths.fse.maxBits + s.offsets.fse.maxBits + s.matchLengths.fse.maxBits
	s.out = out
	return nil
}
source: func finishRestore(newClient ClientConnection) error {
	var err, remoteError error
	for a := restoreStrategy.Start(); a.Next(); {
		logger.Debugf("Attempting finishRestore")
		var finishClient *Client
		finishClient, err = newClient()
		if err != nil {
			return errors.Trace(err)
		}

		err, remoteError = finishAttempt(finishClient)
		if err == nil && remoteError == nil {
			return nil
		}

		if !params.IsCodeUpgradeInProgress(err) || remoteError != nil {
			return errors.Annotatef(err, "cannot complete restore: %v", remoteError)
		}
	}
	return errors.Annotatef(err, "cannot complete restore: %v", remoteError)
}
source: func InitDriverIfExists(directory string) (volume.Driver, error) {
	log.WithFields(log.Fields{
		"directory": directory,
	}).Debug("Checking driver")
	driverType, err := volume.DetectDriverType(directory)
	if err != nil {
		return nil, err
	}
	logger := log.WithFields(log.Fields{
		"directory": directory,
		"type":      driverType,
	})
	logger.Debug("Found existing storage")
	if err := volume.InitDriver(driverType, directory, App.Options.Options); err != nil {
		return nil, err
	}
	logger.Debug("Loaded storage driver")
	return volume.GetDriver(directory)
}
source: func VerifyConfig() error {
	if err := Config.verifyTransactionLimitConfig(); err != nil {
		return err
	}
	if actual, dryRun := Config.EnableHotRowProtection, Config.EnableHotRowProtectionDryRun; actual && dryRun {
		return errors.New("only one of two flags allowed: -enable_hot_row_protection or -enable_hot_row_protection_dry_run")
	}
	if v := Config.HotRowProtectionMaxQueueSize; v <= 0 {
		return fmt.Errorf("-hot_row_protection_max_queue_size must be > 0 (specified value: %v)", v)
	}
	if v := Config.HotRowProtectionMaxGlobalQueueSize; v <= 0 {
		return fmt.Errorf("-hot_row_protection_max_global_queue_size must be > 0 (specified value: %v)", v)
	}
	if globalSize, size := Config.HotRowProtectionMaxGlobalQueueSize, Config.HotRowProtectionMaxQueueSize; globalSize < size {
		return fmt.Errorf("global queue size must be >= per row (range) queue size: -hot_row_protection_max_global_queue_size < hot_row_protection_max_queue_size (%v < %v)", globalSize, size)
	}
	if v := Config.HotRowProtectionConcurrentTransactions; v <= 0 {
		return fmt.Errorf("-hot_row_protection_concurrent_transactions must be > 0 (specified value: %v)", v)
	}
	return nil
}
source: func mainComplete() error {
	// Recursively register all commands and subcommands
	// along with global and local flags
	var complCmds = make(complete.Commands)
	for _, cmd := range appCmds {
		complCmds[cmd.Name] = cmdToCompleteCmd(cmd, "")
	}
	complFlags := flagsToCompleteFlags(globalFlags)
	mcComplete := complete.Command{
		Sub:         complCmds,
		GlobalFlags: complFlags,
	}
	// Answer to bash completion call
	complete.New("mc", mcComplete).Run()
	return nil
}
source: func (t *TextBar) SetView(view View) {
	t.initialize()
	t.view = view
	t.lview.SetView(view)
	t.rview.SetView(view)
	t.cview.SetView(view)
	t.changed = true
}
source: func generationsToString(generations []keybase1.PerTeamKeyGeneration) string {
	var tmp []string
	for _, k := range generations {
		tmp = append(tmp, fmt.Sprintf("%d", int(k)))
	}
	return strings.Join(tmp, ",")
}
source: func fetchNetworkInterfaces(st Backend) (map[string][]*state.Address, map[string]map[string]set.Strings, map[string][]*state.LinkLayerDevice, error) {
	ipAddresses := make(map[string][]*state.Address)
	spaces := make(map[string]map[string]set.Strings)
	subnets, err := st.AllSubnets()
	if err != nil {
		return nil, nil, nil, err
	}
	subnetsByCIDR := make(map[string]*state.Subnet)
	for _, subnet := range subnets {
		subnetsByCIDR[subnet.CIDR()] = subnet
	}
	// For every machine, track what devices have addresses so we can filter linklayerdevices later
	devicesWithAddresses := make(map[string]set.Strings)
	ipAddrs, err := st.AllIPAddresses()
	if err != nil {
		return nil, nil, nil, err
	}
	for _, ipAddr := range ipAddrs {
		if ipAddr.LoopbackConfigMethod() {
			continue
		}
		machineID := ipAddr.MachineID()
		ipAddresses[machineID] = append(ipAddresses[machineID], ipAddr)
		if subnet, ok := subnetsByCIDR[ipAddr.SubnetCIDR()]; ok {
			if spaceName := subnet.SpaceName(); spaceName != "" {
				devices, ok := spaces[machineID]
				if !ok {
					devices = make(map[string]set.Strings)
					spaces[machineID] = devices
				}
				deviceName := ipAddr.DeviceName()
				spacesSet, ok := devices[deviceName]
				if !ok {
					spacesSet = make(set.Strings)
					devices[deviceName] = spacesSet
				}
				spacesSet.Add(spaceName)
			}
		}
		deviceSet, ok := devicesWithAddresses[machineID]
		if ok {
			deviceSet.Add(ipAddr.DeviceName())
		} else {
			devicesWithAddresses[machineID] = set.NewStrings(ipAddr.DeviceName())
		}
	}

	linkLayerDevices := make(map[string][]*state.LinkLayerDevice)
	llDevs, err := st.AllLinkLayerDevices()
	if err != nil {
		return nil, nil, nil, err
	}
	for _, llDev := range llDevs {
		if llDev.IsLoopbackDevice() {
			continue
		}
		machineID := llDev.MachineID()
		machineDevs, ok := devicesWithAddresses[machineID]
		if !ok {
			// This machine ID doesn't seem to have any devices with IP Addresses
			continue
		}
		if !machineDevs.Contains(llDev.Name()) {
			// this device did not have any IP Addresses
			continue
		}
		// This device had an IP Address, so include it in the list of devices for this machine
		linkLayerDevices[machineID] = append(linkLayerDevices[machineID], llDev)
	}

	return ipAddresses, spaces, linkLayerDevices, nil
}
source: func NewBench(threads, count int, cp ConnParams, query string) *Bench {
	bench := Bench{
		Threads:    threads,
		Count:      count,
		ConnParams: cp,
		Query:      query,
		Rows:       stats.NewCounter("", ""),
		Timings:    stats.NewTimings("", "", ""),
	}
	return &bench
}
source: func LevelFilter(threshold Level, sender send.Sender) send.Sender {
	l := sender.Level()
	l.Threshold = threshold.Priority()
	_ = sender.SetLevel(l)

	return sender
}
source: func loadKeyPairs(id string) ([keySize]byte, [keySize]byte, error) {

	var private [keySize]byte
	var public [keySize]byte
	var err error

	// try to load the private key
	privateFile := fmt.Sprintf(privateSuffixFormat, id)
	if keyFileExists(privateFile) {
		if private, err = readKey(privateFile, keysFolderPrefixFormat); err != nil {
			return public, private, err
		}
	}
	// try to load the public key and if it succeed, then return both the keys
	publicFile := fmt.Sprintf(publicKeySuffixFormat, id)
	if keyFileExists(publicFile) {
		if public, err = readKey(publicFile, keysFolderPrefixFormat); err != nil {
			return public, private, err
		}

		// if we reached here, it means that both the private and the public key
		// existed and loaded successfully
		return public, private, err
	}

	// if we reached here then, we need to cerate the key pair
	tempPublic, tempPrivate, err := box.GenerateKey(rand.Reader)

	// check for errors first, otherwise continue and store the keys to files
	if err != nil {
		return public, private, err
	}
	// dereference the pointers
	public = *tempPublic
	private = *tempPrivate

	// write the public key first
	if err := writeKey(publicFile, keysFolderPrefixFormat, public[:]); err != nil {
		return public, private, err
	}

	// write the private
	if err := writeKey(privateFile, keysFolderPrefixFormat, private[:]); err != nil {
		// delete the public key, otherwise we remain in an unwanted state
		// the delete can fail as well, therefore we print an error
		if err := deleteFile(publicFile); err != nil {
			log.Printf("[SEVERE] - The private key for asymmetric encryption, %s, failed to be persisted. \nWhile trying to cleanup also the public key previosuly stored, %s, the operation failed as well.\nWe are now in an unrecoverable state.Please delete both files manually: %s - %s", privateFile, publicFile, privateFile, publicFile)
			return public, private, err
		}
		return public, private, err
	}

	// return the data
	return public, private, err

}
source: func (fbo *folderBranchOps) SyncAll(
	ctx context.Context, folderBranch data.FolderBranch) (err error) {
	startTime, timer := fbo.startOp(ctx, "SyncAll")
	defer func() {
		fbo.endOp(ctx, startTime, timer, "SyncAll done: %+v", err)
	}()

	if folderBranch != fbo.folderBranch {
		return WrongOpsError{fbo.folderBranch, folderBranch}
	}

	return fbo.doMDWriteWithRetryUnlessCanceled(ctx,
		func(lState *kbfssync.LockState) error {
			return fbo.syncAllLocked(ctx, lState, NoExcl)
		})
}
source: func Mknod(path string, mode uint32, dev int) error {
	if ExistsFile(path) {
		return nil
	}
	if err := syscall.Mknod(path, mode, dev); err != nil {
		return err
	}
	return nil
}
source: func (s *fsCacheStore) GC() error {
	s.mu.Lock()
	defer s.mu.Unlock()
	var size uint64

	ctx := context.Background()
	cutoff := time.Now().Add(-s.gcPolicy.MaxKeepDuration)
	var blacklist []*cachedSource

	for id, snap := range s.sources {
		if len(snap.refs) == 0 {
			if cutoff.After(snap.CachePolicy.LastUsed) {
				if err := s.delete(id); err != nil {
					return errors.Wrapf(err, "failed to delete %s", id)
				}
			} else {
				ss, err := snap.getSize(ctx)
				if err != nil {
					return err
				}
				size += uint64(ss)
				blacklist = append(blacklist, snap)
			}
		}
	}

	sort.Sort(sortableCacheSources(blacklist))
	for _, snap := range blacklist {
		if size <= s.gcPolicy.MaxSize {
			break
		}
		ss, err := snap.getSize(ctx)
		if err != nil {
			return err
		}
		if err := s.delete(snap.id); err != nil {
			return errors.Wrapf(err, "failed to delete %s", snap.id)
		}
		size -= uint64(ss)
	}
	return nil
} 55%|█████▌    | 2769/5000 [00:03<00:02, 976.96it/s]
source: func (adm *AdminClient) GetConfig() ([]byte, error) {
	// Execute GET on /minio/admin/v1/config to get config of a setup.
	resp, err := adm.executeMethod("GET",
		requestData{relPath: "/v1/config"})
	defer closeResponse(resp)
	if err != nil {
		return nil, err
	}

	if resp.StatusCode != http.StatusOK {
		return nil, httpRespToErrorResponse(resp)
	}
	defer closeResponse(resp)

	return DecryptData(adm.secretAccessKey, resp.Body)
}
source: func CritNoRepeat(template string, params ...interface{}) {
	msg := fmt.Sprintf(template, params...)
	critLock.Lock()
	if _, exists := critHistory[msg]; !exists {
		log.Print(msg)
		critHistory[msg] = struct{}{}
	}
	if len(critHistory) > limitCritHistory {
		critHistory = make(map[string]struct{})
	}
	critLock.Unlock()
}
source: func NewFSCache(opt Opt) (*FSCache, error) {
	store, err := newFSCacheStore(opt)
	if err != nil {
		return nil, err
	}
	return &FSCache{
		store:      store,
		opt:        opt,
		transports: make(map[string]Transport),
	}, nil
}
source: func EvalUnion(exprs []interface{}, src *Col, result *map[int]struct{}) (err error) {
	for _, subExpr := range exprs {
		if err = evalQuery(subExpr, src, result, false); err != nil {
			return
		}
	}
	return
}
source: func newVserver(e *Engine) *vserver {
	return &vserver{
		engine: e,
		ncc:    ncclient.NewNCC(e.config.NCCSocket),

		fwm:        make(map[seesaw.AF]uint32),
		active:     make(map[seesaw.IP]bool),
		lbVservers: make(map[seesaw.IP]*seesaw.Vserver),
		vips:       make(map[seesaw.VIP]bool),

		overrideChan: make(chan seesaw.Override, 5),

		notify:  make(chan *checkNotification, 20),
		update:  make(chan *config.Vserver, 1),
		quit:    make(chan bool, 1),
		stopped: make(chan bool, 1),
	}
}
source: func newEncryptionKey(cmd *cobra.Command, client *http.Client) (ek encrypta.EncryptionKey, encryptSecret bool, err error) {
	if client == nil {
		client = http.DefaultClient
	}

	pgpKey := flagx.MustGetString(cmd, "pgp-key")
	pgpKeyURL := flagx.MustGetString(cmd, "pgp-key-url")
	keybaseUsername := flagx.MustGetString(cmd, "keybase")

	if pgpKey != "" {
		ek, err = encrypta.NewPublicKeyFromBase64Encoded(pgpKey)
		encryptSecret = true
		return
	}

	if pgpKeyURL != "" {
		ek, err = encrypta.NewPublicKeyFromURL(pgpKeyURL, encrypta.HTTPClientOption(client))
		encryptSecret = true
		return
	}

	if keybaseUsername != "" {
		ek, err = encrypta.NewPublicKeyFromKeybase(keybaseUsername, encrypta.HTTPClientOption(client))
		encryptSecret = true
		return
	}

	return nil, false, nil
}
source: func (es *EventStream) Stop() {
	if es.stream != nil {
		stop(es.stream, es.rlref)
		es.stream = nil
	}

	// Remove eventstream from the registry
	registry.Delete(es.registryID)
	es.registryID = 0
}
source: func buildChange(action string, rrs dnsprovider.ResourceRecordSet) *route53.Change {
	change := &route53.Change{
		Action: aws.String(action),
		ResourceRecordSet: &route53.ResourceRecordSet{
			Name: aws.String(rrs.Name()),
			Type: aws.String(string(rrs.Type())),
			TTL:  aws.Int64(rrs.Ttl()),
		},
	}

	for _, rrdata := range rrs.Rrdatas() {
		rr := &route53.ResourceRecord{
			Value: aws.String(rrdata),
		}
		change.ResourceRecordSet.ResourceRecords = append(change.ResourceRecordSet.ResourceRecords, rr)
	}
	return change
}
source: func allTokens(input io.Reader) ([]Token, error) {
	l := new(lexer)
	err := l.load(input)
	if err != nil {
		return nil, err
	}
	var tokens []Token
	for l.next() {
		tokens = append(tokens, l.token)
	}
	return tokens, nil
}
source: func (c *FakeSecrets) Watch(opts v1.ListOptions) (watch.Interface, error) {
	return c.Fake.
		InvokesWatch(testing.NewWatchAction(secretsResource, c.ns, opts))

}
source: func (o *SetSelectorOptions) Complete(f cmdutil.Factory, cmd *cobra.Command, args []string) error {
	var err error

	o.RecordFlags.Complete(cmd)
	o.Recorder, err = o.RecordFlags.ToRecorder()
	if err != nil {
		return err
	}

	o.dryrun = cmdutil.GetDryRunFlag(cmd)

	o.resources, o.selector, err = getResourcesAndSelector(args)
	if err != nil {
		return err
	}

	o.ResourceFinder = o.ResourceBuilderFlags.ToBuilder(f, o.resources)
	o.WriteToServer = !(*o.ResourceBuilderFlags.Local || o.dryrun)

	if o.dryrun {
		o.PrintFlags.Complete("%s (dry run)")
	}
	printer, err := o.PrintFlags.ToPrinter()
	if err != nil {
		return err
	}
	o.PrintObj = printer.PrintObj

	return err
}
source: func (in *BuildSpec) DeepCopy() *BuildSpec {
	if in == nil {
		return nil
	}
	out := new(BuildSpec)
	in.DeepCopyInto(out)
	return out
}
source: func (daemon *Daemon) ContainerStatPath(name string, path string) (stat *types.ContainerPathStat, err error) {
	container, err := daemon.GetContainer(name)
	if err != nil {
		return nil, err
	}

	// Make sure an online file-system operation is permitted.
	if err := daemon.isOnlineFSOperationPermitted(container); err != nil {
		return nil, errdefs.System(err)
	}

	stat, err = daemon.containerStatPath(container, path)
	if err == nil {
		return stat, nil
	}

	if os.IsNotExist(err) {
		return nil, containerFileNotFound{path, name}
	}
	return nil, errdefs.System(err)
}
source: func (c *DefaultClient) SubscribeAppActivations(appID string, handler ActivationHandler) Token {
	return c.SubscribeDeviceActivations(appID, "", handler)
}
source: func SnapshotT(t TestingT, i ...interface{}) {
	t.Helper()
	Global.SnapshotT(t, i...)
}
source: func cssTag(relpath string) template.HTML {
	return template.HTML(fmt.Sprintf("<link href=\"%s\" rel=\"stylesheet\">", relpath))
}
source: func FriendlyTypeName(s *spec.Schema) string {
	refType := RefType(s)
	if refType == "" { // a base type, e.g. "string"
		return s.Type[0]
	}

	// convert, e.g. "io.k8s.kubernetes.pkg.api.v1.Pod" -> "v1.Pod"
	parts := strings.Split(refType, ".")
	return strings.Join(parts[len(parts)-2:], ".")
}
source: func fetchChunkFromReader(r io.ReadSeeker, offset int64) (evtx.Chunk, error) {
	var err error
	c := evtx.NewChunk()
	evtx.GoToSeeker(r, offset)
	c.Offset = offset
	c.Data = make([]byte, evtx.ChunkSize)
	if _, err = r.Read(c.Data); err != nil {
		return c, err
	}
	reader := bytes.NewReader(c.Data)
	c.ParseChunkHeader(reader)
	if err = c.Header.Validate(); err != nil {
		return c, err
	}
	// Go to after Header
	evtx.GoToSeeker(reader, int64(c.Header.SizeHeader))
	c.ParseStringTable(reader)
	err = c.ParseTemplateTable(reader)
	if err != nil {
		return c, err
	}
	err = c.ParseEventOffsets(reader)
	if err != nil {
		return c, err
	}
	return c, nil
}
source: func (d *DirtyBlockCacheDisk) Get(
	ctx context.Context, tlfID tlf.ID, ptr data.BlockPointer, branch data.BranchName) (
	data.Block, error) {
	if branch != d.branch {
		return nil, errors.Errorf(
			"Branch %s doesn't match branch %s", branch, d.branch)
	}

	info, ok := d.getInfo(ptr)
	if !ok {
		return nil, data.NoSuchBlockError{ID: ptr.ID}
	}

	// Look it up under the temp ID, which is an actual hash that can
	// be verified.
	data, serverHalf, _, err := d.diskCache.Get(ctx, tlfID, info.tmpPtr.ID)
	if err != nil {
		return nil, err
	}

	block := info.newBlock()
	err = assembleBlock(
		ctx, d.config.keyGetter(), d.config.Codec(),
		d.config.cryptoPure(), d.kmd, info.tmpPtr, block, data, serverHalf)
	if err != nil {
		return nil, err
	}
	return block, nil
}
source: func (c *DeploymentsController) ShowDeploymentStatSeries(ctx *app.ShowDeploymentStatSeriesDeploymentsContext) error {

	endTime := time.Now()
	startTime := endTime.Add(-8 * time.Hour) // default: start time is 8 hours before end time
	limit := -1                              // default: No limit

	if ctx.Limit != nil {
		limit = *ctx.Limit
	}

	if ctx.Start != nil {
		startTime = convertToTime(int64(*ctx.Start))
	}

	if ctx.End != nil {
		endTime = convertToTime(int64(*ctx.End))
	}

	if endTime.Before(startTime) {
		return jsonapi.JSONErrorResponse(ctx, errors.NewBadParameterError("end", *ctx.End))
	}

	kc, err := c.GetKubeClient(ctx)
	defer cleanup(kc)
	if err != nil {
		return jsonapi.JSONErrorResponse(ctx, err)
	}

	kubeSpaceName, err := c.getSpaceNameFromSpaceID(ctx, ctx.SpaceID)
	if err != nil {
		return jsonapi.JSONErrorResponse(ctx, err)
	}

	statSeries, err := kc.GetDeploymentStatSeries(*kubeSpaceName, ctx.AppName, ctx.DeployName,
		startTime, endTime, limit)
	if err != nil {
		return jsonapi.JSONErrorResponse(ctx, err)
	} else if statSeries == nil {
		return jsonapi.JSONErrorResponse(ctx, errors.NewNotFoundError("deployment", ctx.DeployName))
	}

	res := &app.SimpleDeploymentStatSeriesSingle{
		Data: statSeries,
	}

	return ctx.OK(res)
}
source: func (mysqld *Mysqld) PromoteSlave(hookExtraEnv map[string]string) (mysql.Position, error) {
	ctx := context.TODO()
	conn, err := getPoolReconnect(ctx, mysqld.dbaPool)
	if err != nil {
		return mysql.Position{}, err
	}
	defer conn.Recycle()

	// Since we handle replication, just stop it.
	cmds := []string{
		conn.StopSlaveCommand(),
		"RESET SLAVE ALL", // "ALL" makes it forget master host:port.
		// When using semi-sync and GTID, a replica first connects to the new master with a given GTID set,
		// it can take a long time to scan the current binlog file to find the corresponding position.
		// This can cause commits that occur soon after the master is promoted to take a long time waiting
		// for a semi-sync ACK, since replication is not fully set up.
		// More details in: https://github.com/vitessio/vitess/issues/4161
		"FLUSH BINARY LOGS",
	}

	if err := mysqld.executeSuperQueryListConn(ctx, conn, cmds); err != nil {
		return mysql.Position{}, err
	}
	return conn.MasterPosition()
}
source: func (s *DynamodbDataSourceConfig) SetUseCallerCredentials(v bool) *DynamodbDataSourceConfig {
	s.UseCallerCredentials = &v
	return s
}
source: func (s *GuestOSService) NewListGuestOsMappingParams() *ListGuestOsMappingParams {
	p := &ListGuestOsMappingParams{}
	p.p = make(map[string]interface{})
	return p
}
source: func OpenReadSegment(fn string) (*Segment, error) {
	k, err := strconv.Atoi(filepath.Base(fn))
	if err != nil {
		return nil, errors.New("not a valid filename")
	}
	f, err := os.Open(fn)
	if err != nil {
		return nil, err
	}
	return &Segment{File: f, i: k, dir: filepath.Dir(fn)}, nil
}
source: func (s *RelationalDatabase) SetMasterEndpoint(v *RelationalDatabaseEndpoint) *RelationalDatabase {
	s.MasterEndpoint = v
	return s
}
source: func (q *FunctionScoreQuery) Filter(filter Query) *FunctionScoreQuery {
	q.filter = filter
	return q
}
source: func NewTreeWalkPool(timeout time.Duration) *TreeWalkPool {
	tPool := &TreeWalkPool{
		pool:    make(map[listParams][]treeWalk),
		timeOut: timeout,
		lock:    &sync.Mutex{},
	}
	return tPool
}
source: func (c *client) open(rawurl, method string, in, out interface{}) (io.ReadCloser, error) {
	uri, err := url.Parse(rawurl)
	if err != nil {
		return nil, err
	}

	// creates a new http request to bitbucket.
	req, err := http.NewRequest(method, uri.String(), nil)
	if err != nil {
		return nil, err
	}

	// if we are posting or putting data, we need to
	// write it to the body of the request.
	if in != nil {
		rc, ok := in.(io.ReadCloser)
		if ok {
			req.Body = rc
			req.Header.Set("Content-Type", "plain/text")
		} else {
			inJson, err := json.Marshal(in)
			if err != nil {
				return nil, err
			}

			buf := bytes.NewBuffer(inJson)
			req.Body = ioutil.NopCloser(buf)

			req.ContentLength = int64(len(inJson))
			req.Header.Set("Content-Length", strconv.Itoa(len(inJson)))
			req.Header.Set("Content-Type", "application/json")
		}
	}
	resp, err := c.client.Do(req)
	if err != nil {
		return nil, err
	}
	if resp.StatusCode > http.StatusPartialContent {
		defer resp.Body.Close()
		out, _ := ioutil.ReadAll(resp.Body)
		return nil, fmt.Errorf("client error %d: %s", resp.StatusCode, string(out))
	}
	return resp.Body, nil
}
source: func forwardRunhcsLogs(ctx context.Context, c net.Conn, fields logrus.Fields) {
	defer c.Close()
	j := json.NewDecoder(c)

	for {
		e := logrus.Entry{}
		err := j.Decode(&e.Data)
		if err == io.EOF || err == errorConnectionAborted {
			break
		}
		if err != nil {
			// Likely the last message wasn't complete at closure. Just read all
			// data and forward as error.
			data, _ := ioutil.ReadAll(io.MultiReader(j.Buffered(), c))
			if len(data) != 0 {
				log.G(ctx).WithFields(fields).Error(string(data))
			}
			break
		}

		msg := e.Data[logrus.FieldKeyMsg]
		delete(e.Data, logrus.FieldKeyMsg)

		level, err := logrus.ParseLevel(e.Data[logrus.FieldKeyLevel].(string))
		if err != nil {
			log.G(ctx).WithFields(fields).WithError(err).Debug("invalid log level")
			level = logrus.DebugLevel
		}
		delete(e.Data, logrus.FieldKeyLevel)

		// TODO: JTERRY75 maybe we need to make this configurable so we know
		// that runhcs is using the same one we are deserializing.
		ti, err := time.Parse(time.RFC3339, e.Data[logrus.FieldKeyTime].(string))
		if err != nil {
			log.G(ctx).WithFields(fields).WithError(err).Debug("invalid time stamp format")
			ti = time.Time{}
		}
		delete(e.Data, logrus.FieldKeyTime)

		etr := log.G(ctx).WithFields(fields).WithFields(e.Data)
		etr.Time = ti
		switch level {
		case logrus.PanicLevel:
			etr.Panic(msg)
		case logrus.FatalLevel:
			etr.Fatal(msg)
		case logrus.ErrorLevel:
			etr.Error(msg)
		case logrus.WarnLevel:
			etr.Warn(msg)
		case logrus.InfoLevel:
			etr.Info(msg)
		case logrus.DebugLevel:
			etr.Debug(msg)
		}
	}
}
source: func defaultClusterObject(
	clusterID string,
	initialCAConfig api.CAConfig,
	raftCfg api.RaftConfig,
	encryptionConfig api.EncryptionConfig,
	initialUnlockKeys []*api.EncryptionKey,
	rootCA *ca.RootCA,
	fips bool,
	defaultAddressPool []string,
	subnetSize uint32,
	vxlanUDPPort uint32) *api.Cluster {
	var caKey []byte
	if rcaSigner, err := rootCA.Signer(); err == nil {
		caKey = rcaSigner.Key
	}

	return &api.Cluster{
		ID: clusterID,
		Spec: api.ClusterSpec{
			Annotations: api.Annotations{
				Name: store.DefaultClusterName,
			},
			Orchestration: api.OrchestrationConfig{
				TaskHistoryRetentionLimit: defaultTaskHistoryRetentionLimit,
			},
			Dispatcher: api.DispatcherConfig{
				HeartbeatPeriod: gogotypes.DurationProto(dispatcher.DefaultHeartBeatPeriod),
			},
			Raft:             raftCfg,
			CAConfig:         initialCAConfig,
			EncryptionConfig: encryptionConfig,
		},
		RootCA: api.RootCA{
			CAKey:      caKey,
			CACert:     rootCA.Certs,
			CACertHash: rootCA.Digest.String(),
			JoinTokens: api.JoinTokens{
				Worker:  ca.GenerateJoinToken(rootCA, fips),
				Manager: ca.GenerateJoinToken(rootCA, fips),
			},
		},
		UnlockKeys:         initialUnlockKeys,
		FIPS:               fips,
		DefaultAddressPool: defaultAddressPool,
		SubnetSize:         subnetSize,
		VXLANUDPPort:       vxlanUDPPort,
	}
}
source: func (se *Engine) MakeNonMaster() {
	// This function is tested through endtoend test.
	se.mu.Lock()
	defer se.mu.Unlock()
	for _, t := range se.tables {
		if t.SequenceInfo != nil {
			t.SequenceInfo.Lock()
			t.SequenceInfo.NextVal = 0
			t.SequenceInfo.LastVal = 0
			t.SequenceInfo.Unlock()
		}
	}
}
source: func (a *AggregateResult) Reduction(result interface{}) {
	resultVal := reflect.ValueOf(result)

	if resultVal.Kind() != reflect.Ptr || resultVal.Elem().Kind() != reflect.Slice {
		panic("result argument must be a slice address")
	}

	sliceVal := resultVal.Elem()

	elType := sliceVal.Type().Elem()

	for i := range a.reduction {
		if elType.Kind() == reflect.Ptr {
			sliceVal = reflect.Append(sliceVal, a.reduction[i])
		} else {
			sliceVal = reflect.Append(sliceVal, a.reduction[i].Elem())
		}
	}

	resultVal.Elem().Set(sliceVal.Slice(0, sliceVal.Len()))
}
source: func (self *AuthHandler) ServeHTTP(w http.ResponseWriter, r *http.Request) {

	// Redirect the user, if required
	if self.provider.RedirectRequired(r) == true {
		self.provider.Redirect(w, r)
		return
	}

	// Get the authenticated user Id
	u, t, err := self.provider.GetAuthenticatedUser(w, r)
	if err != nil {
		// If there was a problem, invoke failure
		if self.Failure == nil {
			DefaultFailure(w, r, err)
		} else {
			self.Failure(w, r, err)
		}
		return
	}

	// Invoke the success function
	if self.Success == nil {
		DefaultSuccess(w, r, u, t)
	} else {
		self.Success(w, r, u, t)
	}
}
source: func (h *fs) Symlink(oldname, newname string) error {
	return os.Symlink(oldname, newname)
}
source: func (k RSAPrivateKey) Sign(rand io.Reader, msg []byte, opts crypto.SignerOpts) (signature []byte, err error) {
	hashed := sha256.Sum256(msg)
	if opts == nil {
		opts = &rsa.PSSOptions{
			SaltLength: rsa.PSSSaltLengthEqualsHash,
			Hash:       crypto.SHA256,
		}
	}
	return k.CryptoSigner().Sign(rand, hashed[:], opts)
}
source: func marshalModules(
	s *states.State,
	schemas *terraform.Schemas,
	modules []addrs.ModuleInstance,
	moduleMap map[string][]addrs.ModuleInstance,
) ([]module, error) {
	var ret []module
	for _, child := range modules {
		stateMod := s.Module(child)
		// cm for child module, naming things is hard.
		cm := module{Address: stateMod.Addr.String()}
		rs, err := marshalResources(stateMod.Resources, schemas)
		if err != nil {
			return nil, err
		}
		cm.Resources = rs
		if moduleMap[child.String()] != nil {
			moreChildModules, err := marshalModules(s, schemas, moduleMap[child.String()], moduleMap)
			if err != nil {
				return nil, err
			}
			cm.ChildModules = moreChildModules
		}

		ret = append(ret, cm)
	}

	return ret, nil
}
source: func (p *Parser) onCDemoPacket(m *dota.CDemoPacket) error {
	// Create a slice to store pending mesages. Messages are read first as
	// pending messages then sorted before dispatch.
	ms := make(pendingMessages, 0, 2)

	// Read all messages from the buffer. Messages are packed serially as
	// {type, size, data}. We keep reading until until less than a byte remains.
	r := newReader(m.GetData())
	for r.remBytes() > 0 {
		t := int32(r.readUBitVar())
		size := r.readVarUint32()
		buf := r.readBytes(size)
		ms = append(ms, &pendingMessage{p.Tick, t, buf})
	}

	// Sort messages to ensure dependencies are met. For example, we need to
	// process string tables before game events that may reference them.
	sort.Sort(ms)

	// Dispatch messages in order, returning on handler error.
	for _, m := range ms {
		if err := p.Callbacks.callByPacketType(m.t, m.buf); err != nil {
			return err
		}
	}

	return nil
}
source: func NewFileReadCloseResetter(name string) (ReadCloseResetter, error) {
	f := &FileReadCloseResetter{filename: name}
	if err := f.open(); err != nil {
		return nil, err
	}
	return f, nil
}
source: func NewDecoder(r io.Reader, format Format) Decoder {
	switch format {
	case FmtProtoDelim:
		return &protoDecoder{r: r}
	}
	return &textDecoder{r: r}
}
source: func (o *NSGateway) NSGatewayMonitors(info *bambou.FetchingInfo) (NSGatewayMonitorsList, *bambou.Error) {

	var list NSGatewayMonitorsList
	err := bambou.CurrentSession().FetchChildren(o, NSGatewayMonitorIdentity, &list, info)
	return list, err
}
source: func (tracer Tracer) InjectHeader(t *Trace, h http.Header) error {
	carrier := opentracing.HTTPHeadersCarrier(h)
	return tracer.Inject(t.context(), opentracing.HTTPHeaders, carrier)
}
source: func (b Bucket) Aggregation(name string) Aggregation {
	if agg, ok := b[name]; ok {
		return agg.(map[string]interface{})
	} else {
		return Aggregation{}
	}
}
source: func (pool *TxPool) enqueueTx(hash common.Hash, tx *types.Transaction) (bool, error) {
	// Try to insert the transaction into the future queue
	from, _ := types.Sender(pool.signer, tx) // already validated
	if pool.queue[from] == nil {
		pool.queue[from] = newTxList(false)
	}
	inserted, old := pool.queue[from].Add(tx, pool.config.PriceBump)
	if !inserted {
		// An older transaction was better, discard this
		queuedDiscardCounter.Inc(1)
		return false, ErrReplaceUnderpriced
	}
	// Discard any previous transaction and mark this
	if old != nil {
		pool.all.Remove(old.Hash())
		pool.priced.Removed()
		queuedReplaceCounter.Inc(1)
	}
	if pool.all.Get(hash) == nil {
		pool.all.Add(tx)
		pool.priced.Put(tx)
	}
	return old != nil, nil
}
source: func (h *HLL) MarshalBinary() ([]byte, error) {
	var buf bytes.Buffer
	ts := h.tempSet
	if ts == nil {
		ts = &tempSet{}
	}
	sl := h.sparseList
	if sl == nil {
		sl = &sparseList{}
	}
	err := gob.NewEncoder(&buf).Encode(
		serializable{
			P:          h.P,
			M1:         h.m1,
			M2:         h.m2,
			Alpha:      h.alpha,
			Format:     h.format,
			TempSet:    *ts,
			SparseList: *sl,
			Registers:  h.registers,
		})
	if err != nil {
		return nil, err
	}
	return buf.Bytes(), nil
}
source: func (d *Dispatch) GetId(name string) (id int32, err error) {
	var dispid []int32
	dispid, err = d.Object.GetIDsOfName([]string{name})
	if err != nil {
		return
	}
	id = dispid[0]
	return
}
source: func (api *Client) CreateCall(data *CreateCallData) (string, error) {
	_, headers, err := api.makeRequest(http.MethodPost, api.concatUserPath(callsPath), nil, data)
	if err != nil {
		return "", err
	}
	return getIDFromLocationHeader(headers), nil
}
source: func (i *item) Less(b btree.Item) bool {
	j, ok := b.(*item)
	if !ok {
		return false
	}

	return bytes.Compare(i.key, j.key) < 0
}
source: func (ar *ActionRepository) ApplyKeyspaceAction(ctx context.Context, actionName, keyspace string, r *http.Request) *ActionResult {
	result := &ActionResult{Name: actionName, Parameters: keyspace}

	action, ok := ar.keyspaceActions[actionName]
	if !ok {
		result.error("Unknown keyspace action")
		return result
	}

	ctx, cancel := context.WithTimeout(ctx, *actionTimeout)
	wr := wrangler.New(logutil.NewConsoleLogger(), ar.ts, tmclient.NewTabletManagerClient())
	output, err := action(ctx, wr, keyspace, r)
	cancel()
	if err != nil {
		result.error(err.Error())
		return result
	}
	result.Output = output
	return result
}
source: func (m *MockNetworkEntity) Kick(ctx context.Context) error {
	ret := m.ctrl.Call(m, "Kick", ctx)
	ret0, _ := ret[0].(error)
	return ret0
}
source: func Rsv(r1, r2, r3 bool) (rsv byte) {
	if r1 {
		rsv |= bit5
	}
	if r2 {
		rsv |= bit6
	}
	if r3 {
		rsv |= bit7
	}
	return rsv
}
source: func (p *proofSetT) check(ctx context.Context, world LoaderContext, parallel bool) (err error) {
	defer p.G().CTrace(ctx, "TeamLoader proofSet check", func() error { return err })()

	if parallel {
		return p.checkParallel(ctx, world)
	}

	var total int
	for _, v := range p.proofs {
		total += len(v)
	}

	var i int
	for _, v := range p.proofs {
		for _, proof := range v {
			p.G().Log.CDebugf(ctx, "TeamLoader proofSet check [%v / %v]", i, total)
			err = proof.check(ctx, p.G(), world, p)
			if err != nil {
				return err
			}
			i++
		}
	}
	return nil
}
source: func (c *Client) SetLogPrefix(prefix string) *Client {
	c.logPrefix = prefix
	c.Log.SetPrefix(prefix)
	return c
}
source: func (c cacheObjects) GetObjectInfo(ctx context.Context, bucket, object string, opts ObjectOptions) (ObjectInfo, error) {
	getObjectInfoFn := c.GetObjectInfoFn
	if c.isCacheExclude(bucket, object) {
		return getObjectInfoFn(ctx, bucket, object, opts)
	}
	// fetch cacheFSObjects if object is currently cached or nearest available cache drive
	dcache, err := c.cache.getCachedFSLoc(ctx, bucket, object)
	if err != nil {
		return getObjectInfoFn(ctx, bucket, object, opts)
	}
	objInfo, err := getObjectInfoFn(ctx, bucket, object, opts)
	if err != nil {
		if _, ok := err.(ObjectNotFound); ok {
			// Delete the cached entry if backend object was deleted.
			dcache.Delete(ctx, bucket, object)
			return ObjectInfo{}, err
		}
		if !backendDownError(err) {
			return ObjectInfo{}, err
		}
		// when backend is down, serve from cache.
		cachedObjInfo, cerr := dcache.GetObjectInfo(ctx, bucket, object, opts)
		if cerr == nil {
			return cachedObjInfo, nil
		}
		return ObjectInfo{}, BackendDown{}
	}
	// when backend is up, do a sanity check on cached object
	cachedObjInfo, err := dcache.GetObjectInfo(ctx, bucket, object, opts)
	if err != nil {
		return objInfo, nil
	}
	if cachedObjInfo.ETag != objInfo.ETag {
		// Delete the cached entry if the backend object was replaced.
		dcache.Delete(ctx, bucket, object)
	}
	return objInfo, nil
}
source: func (e *ErrorClass) New(format string, args ...interface{}) error {
	return e.wrap(fmt.Errorf(format, args...), nil, nil)
}
source: func (eng *Engine) Register(handler Handler) {
	if eng.Handler == Discard {
		eng.Handler = handler
	} else {
		eng.Handler = MultiHandler(eng.Handler, handler)
	}
}
source: func (a *ACLTokens) Info(accessorID string, q *QueryOptions) (*ACLToken, *QueryMeta, error) {
	if accessorID == "" {
		return nil, nil, fmt.Errorf("missing accessor ID")
	}
	var resp ACLToken
	wm, err := a.client.query("/v1/acl/token/"+accessorID, &resp, q)
	if err != nil {
		return nil, nil, err
	}
	return &resp, wm, nil
}
source: func (f *Frame) Duration() time.Duration {
	if !f.Header.IsValid() {
		return 0
	}
	ms := (1000 / float64(f.Header.SampleRate())) * float64(f.Header.Samples())
	dur := time.Duration(int(float64(time.Millisecond) * ms))
	if dur < 0 {
		// we have bad data, let's ignore it
		dur = 0
	}
	return dur
}
source: func (bow *Browser) Stylesheets() []*Stylesheet {
	stylesheets := make([]*Stylesheet, 0, InitialAssetsSliceSize)
	bow.Find("link").Each(func(_ int, s *goquery.Selection) {
		rel, ok := s.Attr("rel")
		if ok && rel == "stylesheet" {
			href, err := bow.attrToResolvedUrl("href", s)
			if err == nil {
				stylesheets = append(stylesheets, NewStylesheetAsset(
					href,
					bow.attrOrDefault("id", "", s),
					bow.attrOrDefault("media", "all", s),
					bow.attrOrDefault("type", "text/css", s),
				))
			}
		}
	})

	return stylesheets
}
source: func (c *Client) ComputeResources(ctx context.Context) ([]*mo.ComputeResource, error) {
	_, datacenter, err := c.finder(ctx)
	if err != nil {
		return nil, errors.Trace(err)
	}
	folders, err := datacenter.Folders(ctx)
	if err != nil {
		return nil, errors.Trace(err)
	}

	es, err := c.lister(folders.HostFolder.Reference()).List(ctx)
	if err != nil {
		return nil, errors.Trace(err)
	}

	var cprs []*mo.ComputeResource
	for _, e := range es {
		switch o := e.Object.(type) {
		case mo.ClusterComputeResource:
			cprs = append(cprs, &o.ComputeResource)
		case mo.ComputeResource:
			cprs = append(cprs, &o)
		}
	}
	return cprs, nil
}
source: func (endpoint *HostComputeEndpoint) Delete() error {
	logrus.Debugf("hcn::HostComputeEndpoint::Delete id=%s", endpoint.Id)

	if err := deleteEndpoint(endpoint.Id); err != nil {
		return err
	}
	return nil
}
source: func Sum128(msg []byte, key *[KeySize]byte) [16]byte {
	k0 := binary.LittleEndian.Uint64(key[0:])
	k1 := binary.LittleEndian.Uint64(key[8:])

	var hVal [4]uint64
	hVal[0] = k0 ^ c0
	hVal[1] = k1 ^ c1 ^ 0xee
	hVal[2] = k0 ^ c2
	hVal[3] = k1 ^ c3

	n := len(msg)
	ctr := byte(n)

	if n >= BlockSize {
		n &= (^(BlockSize - 1))
		core(&hVal, msg[:n])
		msg = msg[n:]
	}

	var block [BlockSize]byte
	copy(block[:], msg)
	block[7] = ctr

	var out [16]byte
	finalize128(&out, &hVal, &block)
	return out
}
source: func FromArchive(tarStream io.Reader) (builder.Source, error) {
	root, err := ioutils.TempDir("", "docker-builder")
	if err != nil {
		return nil, err
	}

	// Assume local file system. Since it's coming from a tar file.
	tsc := &archiveContext{root: containerfs.NewLocalContainerFS(root)}

	// Make sure we clean-up upon error.  In the happy case the caller
	// is expected to manage the clean-up
	defer func() {
		if err != nil {
			tsc.Close()
		}
	}()

	decompressedStream, err := archive.DecompressStream(tarStream)
	if err != nil {
		return nil, err
	}

	sum, err := tarsum.NewTarSum(decompressedStream, true, tarsum.Version1)
	if err != nil {
		return nil, err
	}

	err = chrootarchive.Untar(sum, root, nil)
	if err != nil {
		return nil, err
	}

	tsc.sums = sum.GetSums()
	return tsc, nil
}
source: func (t *Template) GetAWSGuardDutyIPSetWithName(name string) (*resources.AWSGuardDutyIPSet, error) {
	if untyped, ok := t.Resources[name]; ok {
		switch resource := untyped.(type) {
		case *resources.AWSGuardDutyIPSet:
			return resource, nil
		}
	}
	return nil, fmt.Errorf("resource %q of type AWSGuardDutyIPSet not found", name)
}
source: func (r *runner) printJournalStatus(
	ctx context.Context, jManager *libkbfs.JournalManager, tlfID tlf.ID,
	doneCh <-chan struct{}) {
	r.printStageEndIfNeeded(ctx)
	// Note: the "first" status here gets us the number of unflushed
	// bytes left at the time we started printing.  However, we don't
	// have the total number of bytes being flushed to the server
	// throughout the whole operation, which would be more
	// informative.  It would be better to have that as the
	// denominator, but there's no easy way to get it right now.
	firstStatus, err := jManager.JournalStatus(tlfID)
	if err != nil {
		r.log.CDebugf(ctx, "Error getting status: %+v", err)
		return
	}
	if firstStatus.UnflushedBytes == 0 {
		return
	}
	adj := "encrypted"
	if r.h.Type() == tlf.Public {
		adj = "signed"
	}
	if r.verbosity >= 1 {
		r.printStageStart(ctx,
			[]byte(fmt.Sprintf("Syncing %s data to Keybase: ", adj)),
			"mem.flush.prof", "")
	}
	r.log.CDebugf(ctx, "Waiting for %d journal bytes to flush",
		firstStatus.UnflushedBytes)

	bytesFmt := "(%.2f%%) %s... "
	str := fmt.Sprintf(
		bytesFmt, float64(0), humanizeBytes(0, firstStatus.UnflushedBytes))
	lastByteCount := len(str)
	if r.progress {
		r.errput.Write([]byte(str))
	}

	ticker := time.NewTicker(1 * time.Second)
	defer ticker.Stop()
	for {
		select {
		case <-ticker.C:
			status, err := jManager.JournalStatus(tlfID)
			if err != nil {
				r.log.CDebugf(ctx, "Error getting status: %+v", err)
				return
			}

			if r.verbosity >= 1 && r.progress {
				eraseStr := strings.Repeat("\b", lastByteCount)
				flushed := firstStatus.UnflushedBytes - status.UnflushedBytes
				str := fmt.Sprintf(
					bytesFmt, percent(flushed, firstStatus.UnflushedBytes),
					humanizeBytes(flushed, firstStatus.UnflushedBytes))
				lastByteCount = len(str)
				r.errput.Write([]byte(eraseStr + str))
			}
		case <-doneCh:
			if r.verbosity >= 1 && r.progress {
				eraseStr := strings.Repeat("\b", lastByteCount)
				// doneCh is closed. So assume journal flushing is done and
				// take the shortcut.
				flushed := firstStatus.UnflushedBytes
				str := fmt.Sprintf(
					bytesFmt, percent(flushed, firstStatus.UnflushedBytes),
					humanizeBytes(flushed, firstStatus.UnflushedBytes))
				lastByteCount = len(str)
				r.errput.Write([]byte(eraseStr + str))
			}

			if r.verbosity >= 1 {
				r.printStageEndIfNeeded(ctx)
			}
			return
		}
	}
}
source: func (c *PCPClient) MustRegister(m Metric) {
	if err := c.Register(m); err != nil {
		panic(err)
	}
}
source: func ChainKeyAlgoUbiquity(chain []*x509.Certificate) KeyAlgoUbiquity {
	ret := math.MaxInt32
	for _, cert := range chain {
		uscore := int(keyAlgoUbiquity(cert))
		if ret > uscore {
			ret = uscore
		}
	}
	return KeyAlgoUbiquity(ret)
}
source: func (b *Builder) addString(v string) {
	strLen := uint(len(v))
	if strLen > 126 {
		// long string
		dst := b.buf.Grow(1 + 8 + strLen)
		dst[0] = 0xbf
		setLength(dst[1:], ValueLength(strLen), 8) // string length
		copy(dst[9:], v)                           // string data
	} else {
		dst := b.buf.Grow(1 + strLen)
		dst[0] = byte(0x40 + strLen) // short string (with length)
		copy(dst[1:], v)             // string data
	}
}
source: func (m *Manager) GetGrantsForUser(username string, globalID string) (*SavedGrants, error) {
	var sg SavedGrants

	err := m.collection.Find(bson.M{"username": username, "globalid": globalID}).One(&sg)

	return &sg, err
}
source: func (bot *BotAPI) SetWebhook(config WebhookConfig) (APIResponse, error) {

	if config.Certificate == nil {
		v := url.Values{}
		v.Add("url", config.URL.String())
		if config.MaxConnections != 0 {
			v.Add("max_connections", strconv.Itoa(config.MaxConnections))
		}

		return bot.MakeRequest("setWebhook", v)
	}

	params := make(map[string]string)
	params["url"] = config.URL.String()
	if config.MaxConnections != 0 {
		params["max_connections"] = strconv.Itoa(config.MaxConnections)
	}

	resp, err := bot.UploadFile("setWebhook", params, "certificate", config.Certificate)
	if err != nil {
		return APIResponse{}, err
	}

	return resp, nil
}
source: func WithInitialConnWindowSize(s int32) DialOption {
	return newFuncDialOption(func(o *dialOptions) {
		o.copts.InitialConnWindowSize = s
	})
}
source: func (a *GetPartialAXTreeArgs) SetNodeID(nodeID dom.NodeID) *GetPartialAXTreeArgs {
	a.NodeID = &nodeID
	return a
}
source: func (g *Graph) String() string {
	var s []string

	nodeIndex := make(map[*Node]int, len(g.Nodes))

	for i, n := range g.Nodes {
		nodeIndex[n] = i + 1
	}

	for i, n := range g.Nodes {
		name := n.Info.PrintableName()
		var in, out []int

		for _, from := range n.In {
			in = append(in, nodeIndex[from.Src])
		}
		for _, to := range n.Out {
			out = append(out, nodeIndex[to.Dest])
		}
		s = append(s, fmt.Sprintf("%d: %s[flat=%d cum=%d] %x -> %v ", i+1, name, n.Flat, n.Cum, in, out))
	}
	return strings.Join(s, "\n")
}
source: func (fn HandlerFunc) Handle(ctx context.Context, desc ocispec.Descriptor) (subdescs []ocispec.Descriptor, err error) {
	return fn(ctx, desc)
}
source: func (addr *Address) Machine() (*Machine, error) {
	return addr.st.Machine(addr.doc.MachineID)
}
source: func ShowCommitRange(revisionRange string) ([]*Commit, error) {
	args := []string{
		"log",
		"--source",
		"--abbrev-commit",
		"--pretty=fuller",
		revisionRange,
	}
	stdout, err := Run(args...)
	if err != nil {
		return nil, err
	}

	return ParseCommits(stdout.Bytes())
}
source: func ReadTimeout(d time.Duration) func(*Term) error {
	return func(t *Term) error {
		return t.setReadTimeout(d)
	}
}
source: func (h *Handler) notifyRegistry(err error) {
	if err == nil {
		err = h.sendReady()
	}

	if err != nil {
		h.Registry.Failed(h.chaincodeID.Name, err)
		chaincodeLogger.Errorf("failed to start %s", h.chaincodeID)
		return
	}

	h.Registry.Ready(h.chaincodeID.Name)
}
source: func (c *Clientset) AppsV1beta2() appsv1beta2.AppsV1beta2Interface {
	return &fakeappsv1beta2.FakeAppsV1beta2{Fake: &c.Fake}
}
source: func (d *domainClient) Read(ctx context.Context, args *ReadArgs) (reply *ReadReply, err error) {
	reply = new(ReadReply)
	if args != nil {
		err = rpcc.Invoke(ctx, "IO.read", args, reply, d.conn)
	} else {
		err = rpcc.Invoke(ctx, "IO.read", nil, reply, d.conn)
	}
	if err != nil {
		err = &internal.OpError{Domain: "IO", Op: "Read", Err: err}
	}
	return
}
source: func (p *Scan) GetAllSessions() []*Session {
	result := []*Session{}
	result = append(result, p.Sessions...)
	for _, child := range p.Sessions {
		result = append(result, child.GetAllChildren()...)
	}
	return result
}
source: func (rs *RowSplitter) StartSplit() [][][]sqltypes.Value {
	return make([][][]sqltypes.Value, len(rs.KeyRanges))
}
source: func (c *Chunk) ParseStringTable(reader io.ReadSeeker) {
	strOffset := int32(0)
	for i := int64(0); i < sizeStringBucket*4; i += 4 {
		encoding.Unmarshal(reader, &strOffset, Endianness)
		if strOffset > 0 {
			cs, err := StringAt(reader, int64(strOffset))
			if err != nil {
				if !ModeCarving {
					panic(err)
				}
			}
			c.StringTable[strOffset] = cs
		}
	}
	return
}
source: func setBrokerOption(k, v interface{}) broker.Option {
	return func(o *broker.Options) {
		if o.Context == nil {
			o.Context = context.Background()
		}
		o.Context = context.WithValue(o.Context, k, v)
	}
}
source: func (s *Block) GetWord(address rune) (res float64, err error) {
	found := false
	for _, m := range s.Nodes {
		if word, ok := m.(*Word); ok {
			if word.Address == address {
				if found {
					return res, errors.New(fmt.Sprintf("Multiple instances of address '%c' in block", address))
				}
				found = true
				res = word.Command
			}
		}
	}
	if !found {
		return res, errors.New(fmt.Sprintf("'%c' not found in block", address))
	}
	return res, nil
}
source: func (s *EventsService) Delete(e EventKey) (*http.Response, error) {
	return s.client.delete(e.URI(), nil)
}
source: func SetExpiry(expiry time.Duration) Option {
	return OptionFunc(func(m *Mutex) {
		m.expiry = expiry
	})
}
source: func (s *movieService) GetByID(id int64) (datamodels.Movie, bool) {
	return s.repo.Select(func(m datamodels.Movie) bool {
		return m.ID == id
	})
}
source: func (db *Dashboard) apiHandler(conn *websocket.Conn) {
	id := atomic.AddUint32(&db.nextConnID, 1)
	client := &client{
		conn:   conn,
		msg:    make(chan *Message, 128),
		logger: log.New("id", id),
	}
	done := make(chan struct{})

	// Start listening for messages to send.
	db.wg.Add(1)
	go func() {
		defer db.wg.Done()

		for {
			select {
			case <-done:
				return
			case msg := <-client.msg:
				if err := websocket.JSON.Send(client.conn, msg); err != nil {
					client.logger.Warn("Failed to send the message", "msg", msg, "err", err)
					client.conn.Close()
					return
				}
			}
		}
	}()

	// Send the past data.
	db.sysLock.RLock()
	db.peerLock.RLock()
	db.logLock.RLock()

	h := deepcopy.Copy(db.history).(*Message)

	db.sysLock.RUnlock()
	db.peerLock.RUnlock()
	db.logLock.RUnlock()

	client.msg <- h

	// Start tracking the connection and drop at connection loss.
	db.lock.Lock()
	db.conns[id] = client
	db.lock.Unlock()
	defer func() {
		db.lock.Lock()
		delete(db.conns, id)
		db.lock.Unlock()
	}()
	for {
		r := new(Request)
		if err := websocket.JSON.Receive(conn, r); err != nil {
			if err != io.EOF {
				client.logger.Warn("Failed to receive request", "err", err)
			}
			close(done)
			return
		}
		if r.Logs != nil {
			db.handleLogRequest(r.Logs, client)
		}
	}
}
source: func (a *allocReconciler) markStop(allocs allocSet, clientStatus, statusDescription string) {
	for _, alloc := range allocs {
		a.result.stop = append(a.result.stop, allocStopResult{
			alloc:             alloc,
			clientStatus:      clientStatus,
			statusDescription: statusDescription,
		})
	}
}
source: func (t *Template) GetAllAWSCloudTrailTrailResources() map[string]*resources.AWSCloudTrailTrail {
	results := map[string]*resources.AWSCloudTrailTrail{}
	for name, untyped := range t.Resources {
		switch resource := untyped.(type) {
		case *resources.AWSCloudTrailTrail:
			results[name] = resource
		}
	}
	return results
}
source: func (c *Connector) MultiRead(ctx context.Context, ei *dosa.EntityInfo, values []map[string]dosa.FieldValue, minimumFields []string) ([]*dosa.FieldValuesOrError, error) {
	var fvoes []*dosa.FieldValuesOrError
	for _, v := range values {
		fieldValue, err := c.Read(ctx, ei, v, minimumFields)
		fvoe := &dosa.FieldValuesOrError{}
		if err != nil {
			fvoe.Error = err
		} else {
			fvoe.Values = fieldValue
		}

		fvoes = append(fvoes, fvoe)
	}

	return fvoes, nil
}
source: func UnmarshalTimeOfDayTz(s string) (tod TimeOfDay, err error) {
	zoneIndex := strings.IndexAny(s, "Z+-")
	var timePart string
	var hasOffset bool
	var offset int
	if zoneIndex == -1 {
		hasOffset = false
		timePart = s
	} else {
		hasOffset = true
		timePart = s[:zoneIndex]
		if offset, err = parseTimezone(s[zoneIndex:]); err != nil {
			return
		}
	}

	hour, minute, second, err := parseTimeParts(timePart)
	if err != nil {
		return
	}

	fromMidnight := time.Duration(hour*3600+minute*60+second) * time.Second

	// ISO8601 special case - values up to 24:00:00 are allowed, so using
	// strictly greater-than for the maximum value.
	if fromMidnight > 24*time.Hour || minute >= 60 || second >= 60 {
		return TimeOfDay{}, fmt.Errorf("soap time.tz: value %q has value(s) out of range", s)
	}

	return TimeOfDay{
		FromMidnight: time.Duration(hour*3600+minute*60+second) * time.Second,
		HasOffset:    hasOffset,
		Offset:       offset,
	}, nil
}
source: func (cloudstack CloudstackClient) New(apiurl string, apikey string, secretkey string, insecureskipverify bool) *CloudstackClient {
	c := &CloudstackClient{
		client: &http.Client{
			Transport: &http.Transport{
				TLSClientConfig: &tls.Config{InsecureSkipVerify: insecureskipverify},
				Proxy:           http.ProxyFromEnvironment,
			},
		},
		BaseURL:   apiurl,
		APIKey:    apikey,
		SecretKey: secretkey,
	}
	return c
}
source: func (s *TerminologyProperties) SetTargetLanguageCodes(v []*string) *TerminologyProperties {
	s.TargetLanguageCodes = v
	return s
}
source: func NewPathLinkMetadata(Url string, Visibility *Visibility, Path string) *PathLinkMetadata {
	s := new(PathLinkMetadata)
	s.Url = Url
	s.Visibility = Visibility
	s.Path = Path
	return s
}
source: func LeaseSwitchedPassthroughBackend(ctx context.Context, conf *logical.BackendConfig, leases bool) (logical.Backend, error) {
	var b PassthroughBackend
	b.generateLeases = leases
	b.Backend = &framework.Backend{
		Help: strings.TrimSpace(passthroughHelp),

		PathsSpecial: &logical.Paths{
			SealWrapStorage: []string{
				"*",
			},
		},

		Paths: []*framework.Path{
			{
				Pattern: ".*",

				Callbacks: map[logical.Operation]framework.OperationFunc{
					logical.ReadOperation:   b.handleRead,
					logical.CreateOperation: b.handleWrite,
					logical.UpdateOperation: b.handleWrite,
					logical.DeleteOperation: b.handleDelete,
					logical.ListOperation:   b.handleList,
				},

				ExistenceCheck: b.handleExistenceCheck,

				HelpSynopsis:    strings.TrimSpace(passthroughHelpSynopsis),
				HelpDescription: strings.TrimSpace(passthroughHelpDescription),
			},
		},
		BackendType: logical.TypeLogical,
	}

	b.Backend.Secrets = []*framework.Secret{
		&framework.Secret{
			Type: "kv",

			Renew:  b.handleRead,
			Revoke: b.handleRevoke,
		},
	}

	if conf == nil {
		return nil, fmt.Errorf("configuration passed into backend is nil")
	}
	b.Backend.Setup(ctx, conf)

	return &b, nil
}
source: func MustParseExpr(input string) *Expr {
	parsed, err := ParseExpr(input)
	if err != nil {
		panic(err)
	}
	return parsed
}
source: func (u *UpgraderAPI) WatchAPIVersion(args params.Entities) (params.NotifyWatchResults, error) {
	result := params.NotifyWatchResults{
		Results: make([]params.NotifyWatchResult, len(args.Entities)),
	}
	for i, agent := range args.Entities {
		tag, err := names.ParseTag(agent.Tag)
		if err != nil {
			return params.NotifyWatchResults{}, errors.Trace(err)
		}
		err = common.ErrPerm
		if u.authorizer.AuthOwner(tag) {
			watch := u.m.WatchForModelConfigChanges()
			// Consume the initial event. Technically, API
			// calls to Watch 'transmit' the initial event
			// in the Watch response. But NotifyWatchers
			// have no state to transmit.
			if _, ok := <-watch.Changes(); ok {
				result.Results[i].NotifyWatcherId = u.resources.Register(watch)
				err = nil
			} else {
				err = watcher.EnsureErr(watch)
			}
		}
		result.Results[i].Error = common.ServerError(err)
	}
	return result, nil
}
source: func (c *Client) CreateUserWithOTP(token, password, otpToken string) (services.WebSession, error) {
	out, err := c.PostJSON(c.Endpoint("signuptokens", "users"), createUserWithTokenReq{
		Token:    token,
		Password: password,
		OTPToken: otpToken,
	})
	if err != nil {
		return nil, trace.Wrap(err)
	}
	return services.GetWebSessionMarshaler().UnmarshalWebSession(out.Bytes())
} 58%|█████▊    | 2877/5000 [00:03<00:02, 971.05it/s]
source: func (b *UpdateService) Pretty(pretty bool) *UpdateService {
	b.pretty = pretty
	return b
}
source: func (t textMapReaderWriter) Clone() textMapReaderWriter {
	clone := textMapReaderWriter(map[string]string{})
	t.CloneTo(clone)
	return clone
}
source: func New() (agent.Agent, net.Conn, error) {
	if !Available() {
		return nil, nil, errors.New("SSH agent requested but SSH_AUTH_SOCK not-specified")
	}

	sshAuthSock := os.Getenv("SSH_AUTH_SOCK")

	conn, err := net.Dial("unix", sshAuthSock)
	if err != nil {
		return nil, nil, fmt.Errorf("Error connecting to SSH_AUTH_SOCK: %v", err)
	}

	return agent.NewClient(conn), conn, nil
}
source: func readS3ObjectLockConfiguration(conn *s3.S3, bucket string) (interface{}, error) {
	resp, err := retryOnAwsCode(s3.ErrCodeNoSuchBucket, func() (interface{}, error) {
		return conn.GetObjectLockConfiguration(&s3.GetObjectLockConfigurationInput{
			Bucket: aws.String(bucket),
		})
	})
	if err != nil {
		if isAWSErr(err, "ObjectLockConfigurationNotFoundError", "") {
			return nil, nil
		}
		return nil, err
	}

	return flattenS3ObjectLockConfiguration(resp.(*s3.GetObjectLockConfigurationOutput).ObjectLockConfiguration), nil
}
source: func (hc *HealthCheckImpl) updateHealth(ts *TabletStats, conn queryservice.QueryService) {
	// Unconditionally send the received update at the end.
	defer func() {
		if hc.listener != nil {
			hc.listener.StatsUpdate(ts)
		}
	}()

	hc.mu.Lock()
	th, ok := hc.addrToHealth[ts.Key]
	if !ok {
		// This can happen on delete because the entry is removed first,
		// or if HealthCheckImpl has been closed.
		hc.mu.Unlock()
		return
	}
	oldts := th.latestTabletStats
	th.latestTabletStats = *ts
	th.conn = conn
	hc.mu.Unlock()

	// In the case where a tablet changes type (but not for the
	// initial message), we want to log it, and maybe advertise it too.
	if oldts.Target.TabletType != topodatapb.TabletType_UNKNOWN && oldts.Target.TabletType != ts.Target.TabletType {
		// Log and maybe notify
		log.Infof("HealthCheckUpdate(Type Change): %v, tablet: %s, target %+v => %+v, reparent time: %v",
			oldts.Name, topotools.TabletIdent(oldts.Tablet), topotools.TargetIdent(oldts.Target), topotools.TargetIdent(ts.Target), ts.TabletExternallyReparentedTimestamp)
		if hc.listener != nil && hc.sendDownEvents {
			oldts.Up = false
			hc.listener.StatsUpdate(&oldts)
		}

		// Track how often a tablet gets promoted to master. It is used for
		// comparing against the variables in go/vtgate/buffer/variables.go.
		if oldts.Target.TabletType != topodatapb.TabletType_MASTER && ts.Target.TabletType == topodatapb.TabletType_MASTER {
			hcMasterPromotedCounters.Add([]string{ts.Target.Keyspace, ts.Target.Shard}, 1)
		}
	}
}
source: func New() *FileSystem {
	return &FileSystem{
		mutex: &sync.RWMutex{},
		root:  node{"", map[string]node{}, dirStat(""), ""},
	}
}
source: func (bA *BitArray) PickRandom() (int, bool) {
	if bA == nil {
		return 0, false
	}

	bA.mtx.Lock()
	trueIndices := bA.getTrueIndices()
	bA.mtx.Unlock()

	if len(trueIndices) == 0 { // no bits set to true
		return 0, false
	}

	return trueIndices[RandIntn(len(trueIndices))], true
}
source: func (bb *Builder) SetClaimDate(t time.Time) *Builder {
	if !bb.IsClaimType() {
		// This is a little gross, using panic here, but I
		// don't want all callers to check errors.  This is
		// really a programming error, not a runtime error
		// that would arise from e.g. random user data.
		panic("SetClaimDate called on non-claim *Builder; camliType=" + bb.Type())
	}
	bb.m["claimDate"] = RFC3339FromTime(t)
	return bb
}
source: func NewCmdCreateRoute(fullName string, f kcmdutil.Factory, streams genericclioptions.IOStreams) *cobra.Command {
	cmd := &cobra.Command{
		Use:   "route",
		Short: "Expose containers externally via secured routes",
		Long:  fmt.Sprintf(routeLong, fullName),
		Run:   kcmdutil.DefaultSubCommandRun(streams.ErrOut),
	}

	cmd.AddCommand(NewCmdCreateEdgeRoute(fullName, f, streams))
	cmd.AddCommand(NewCmdCreatePassthroughRoute(fullName, f, streams))
	cmd.AddCommand(NewCmdCreateReencryptRoute(fullName, f, streams))

	return cmd
}
source: func NewVar(field reflect.StructField) (*Var, error) {
	// spew.Dump(new(Var).Default == reflect.ValueOf(nil))
	newVar := &Var{} //Default: reflect.ValueOf(nil)}
	newVar.Parse(field)

	value, err := convert(newVar.Type, os.Getenv(newVar.Key))
	if err != nil {
		return newVar, err
	}
	newVar.SetValue(value)

	if value == reflect.ValueOf(nil) {
		if newVar.Required {
			return newVar, fmt.Errorf("%s required", newVar.Key)
		}

		// Check if we have a default value to set, otherwise set the type's zero value
		if newVar.Default != reflect.ValueOf(nil) {
			// fmt.Println("setting default:", newVar.Default.String())
			newVar.SetValue(newVar.Default)
		} else {
			// fmt.Println("No default; setting zero value")
			newVar.SetValue(reflect.Zero(newVar.Type))
		}
	}

	if len(newVar.Options) > 0 {
		if !newVar.optionsContains(newVar.Value) {
			return newVar, fmt.Errorf(`%v="%v" not in allowed options: %v`, newVar.Key, newVar.Value, newVar.Options)
		}
	}

	return newVar, nil
}
source: func Ungrab(xu *xgbutil.XUtil, win xproto.Window,
	mods uint16, key xproto.Keycode) {

	for _, m := range xevent.IgnoreMods {
		xproto.UngrabKeyChecked(xu.Conn(), key, win, mods|m).Check()
	}
}
source: func NewAMD64Registers(context *CONTEXT, TebBaseAddress uint64, floatingPoint bool) *AMD64Registers {
	regs := &AMD64Registers{
		rax:    uint64(context.Rax),
		rbx:    uint64(context.Rbx),
		rcx:    uint64(context.Rcx),
		rdx:    uint64(context.Rdx),
		rdi:    uint64(context.Rdi),
		rsi:    uint64(context.Rsi),
		rbp:    uint64(context.Rbp),
		rsp:    uint64(context.Rsp),
		r8:     uint64(context.R8),
		r9:     uint64(context.R9),
		r10:    uint64(context.R10),
		r11:    uint64(context.R11),
		r12:    uint64(context.R12),
		r13:    uint64(context.R13),
		r14:    uint64(context.R14),
		r15:    uint64(context.R15),
		rip:    uint64(context.Rip),
		eflags: uint64(context.EFlags),
		cs:     uint64(context.SegCs),
		fs:     uint64(context.SegFs),
		gs:     uint64(context.SegGs),
		tls:    TebBaseAddress,
	}

	if floatingPoint {
		regs.fltSave = &context.FltSave
	}
	regs.Context = context

	return regs
}
source: func getFieldInfo(typ reflect.Type) fieldInfo {
	finfoLock.RLock()
	finfo, ok := finfos[typ]
	finfoLock.RUnlock()
	if ok {
		return finfo
	}

	finfo = make(fieldInfo)

	n := typ.NumField()
	for i := 0; i < n; i++ {
		f := typ.Field(i)
		tag := f.Tag.Get(TagName)

		// Skip unexported fields or fields marked with "-"
		if f.PkgPath != "" || tag == "-" {
			continue
		}

		// Handle embedded structs
		if f.Anonymous && f.Type.Kind() == reflect.Struct {
			for k, v := range getFieldInfo(f.Type) {
				finfo[k] = append([]int{i}, v...)
			}
			continue
		}

		// Use field name for untagged fields
		if tag == "" {
			tag = f.Name
		}
		tag = NameMapper(tag)

		finfo[tag] = []int{i}
	}

	finfoLock.Lock()
	finfos[typ] = finfo
	finfoLock.Unlock()

	return finfo
}
source: func interpolationFuncContains() ast.Function {
	return ast.Function{
		ArgTypes:   []ast.Type{ast.TypeList, ast.TypeString},
		ReturnType: ast.TypeBool,
		Callback: func(args []interface{}) (interface{}, error) {
			_, err := interpolationFuncIndex().Callback(args)
			if err != nil {
				return false, nil
			}
			return true, nil
		},
	}
}
source: func (c *FakePods) Watch(opts v1.ListOptions) (watch.Interface, error) {
	return c.Fake.
		InvokesWatch(testing.NewWatchAction(podsResource, c.ns, opts))

}
source: func (c *ChatRPC) ChatTLFResolve(
	_ context.Context, _ chat1.ChatTLFResolveArg) error {
	return nil
}
source: func (s *Application) Status(unitName string) (params.ApplicationStatusResult, error) {
	tag := names.NewUnitTag(unitName)
	var results params.ApplicationStatusResults
	args := params.Entities{
		Entities: []params.Entity{
			{
				Tag: tag.String(),
			},
		},
	}
	err := s.st.facade.FacadeCall("ApplicationStatus", args, &results)
	if err != nil {
		return params.ApplicationStatusResult{}, errors.Trace(err)
	}
	result := results.Results[0]
	if result.Error != nil {
		return params.ApplicationStatusResult{}, result.Error
	}
	return result, nil
}
source: func (s *Server) notifier() {
	var timer <-chan time.Time
	for {
		var err error
		select {
		case notification := <-s.notify:
			s.batch = append(s.batch, notification)
			// Collect until BatchDelay passes, or BatchSize are queued.
			switch len(s.batch) {
			case 1:
				timer = time.After(s.config.BatchDelay)
			case s.config.BatchSize:
				err = s.send()
				timer = nil
			}

		case <-timer:
			err = s.send()
		}

		if err != nil {
			log.Fatal(err)
		}
	}
}
source: func (slice TagSlice) TagIndex(tagCode int, startingIndex int, endIndex int) int {
	for index := startingIndex; index < endIndex; index++ {
		if slice[index].Code == tagCode {
			return index
		}
	}
	return -1
}
source: func Initialize(home helmpath.Home, out io.Writer, skipRefresh bool, settings helm_env.EnvSettings, stableRepositoryURL, localRepositoryURL string) error {
	if err := ensureDirectories(home, out); err != nil {
		return err
	}
	if err := ensureDefaultRepos(home, out, skipRefresh, settings, stableRepositoryURL, localRepositoryURL); err != nil {
		return err
	}

	return ensureRepoFileFormat(home.RepositoryFile(), out)
}
source: func (f *ScmpFilter) SetBadArchAction(action ScmpAction) error {
	if err := sanitizeAction(action); err != nil {
		return err
	}

	return f.setFilterAttr(filterAttrActBadArch, action.toNative())
}
source: func (s *podSecurityPolicy) Watch(opts api.ListOptions) (watch.Interface, error) {
	return s.client.Get().
		Prefix("watch").
		Resource("podsecuritypolicies").
		VersionedParams(&opts, api.ParameterCodec).
		Watch()
}
source: func (t *TestTLSServer) CloneClient(clt *Client) *Client {
	addr := []utils.NetAddr{{Addr: t.Addr().String(), AddrNetwork: t.Addr().Network()}}
	newClient, err := NewTLSClient(ClientConfig{Addrs: addr, TLS: clt.TLSConfig()})
	if err != nil {
		panic(err)
	}
	return newClient
}
source: func (a *Archivist) ArchiveTask(c context.Context, task *logdog.ArchiveTask) error {
	c = log.SetFields(c, log.Fields{
		"project": task.Project,
		"id":      task.Id,
	})
	log.Debugf(c, "Received archival task.")

	err := a.archiveTaskImpl(c, task)

	failure := isFailure(err)
	log.Fields{
		log.ErrorKey: err,
		"failure":    failure,
	}.Infof(c, "Finished archive task.")

	// Add a result metric.
	tsCount.Add(c, 1, !failure)

	return err
}
source: func (l builtList) Has(name string) bool {
	_, ok := l[name]
	return ok
}
source: func pruneManifests(
	registryClient *http.Client,
	registryURL *url.URL,
	crs ComponentRetentions,
	manifestPruner ManifestDeleter,
) (deletions []Deletion, failures []Failure) {
	manifestType := imagegraph.ImageComponentTypeManifest
	enumerateImageStreamComponents(crs, &manifestType, false, func(
		manifestNode *imagegraph.ImageComponentNode,
		stream *imagegraph.ImageStreamNode,
		_ bool,
	) {
		repoName := getName(stream.ImageStream)

		klog.V(4).Infof("Pruning manifest %s in the repository %s/%s", manifestNode.Component, registryURL.Host, repoName)
		err := manifestPruner.DeleteManifest(registryClient, registryURL, repoName, manifestNode.Component)
		if err != nil {
			failures = append(failures, Failure{Node: manifestNode, Parent: stream, Err: err})
		} else {
			deletions = append(deletions, Deletion{Node: manifestNode, Parent: stream})
		}
	})

	return
}
source: func aclVersion(ch api.Channel) {
	fmt.Println("ACL getting version")

	req := &acl.ACLPluginGetVersion{}
	reply := &acl.ACLPluginGetVersionReply{}

	if err := ch.SendRequest(req).ReceiveReply(reply); err != nil {
		fmt.Println("ERROR:", err)
	} else {
		fmt.Printf("ACL version reply: %+v\n", reply)
	}
}
source: func (s *SecurityConfig) updateTLSCredentials(certificate *tls.Certificate, issuerInfo *IssuerInfo) error {
	certs := []tls.Certificate{*certificate}
	clientConfig, err := NewClientTLSConfig(certs, s.rootCA.Pool, ManagerRole)
	if err != nil {
		return errors.Wrap(err, "failed to create a new client config using the new root CA")
	}

	serverConfig, err := NewServerTLSConfig(certs, s.rootCA.Pool)
	if err != nil {
		return errors.Wrap(err, "failed to create a new server config using the new root CA")
	}

	if err := s.ClientTLSCreds.loadNewTLSConfig(clientConfig); err != nil {
		return errors.Wrap(err, "failed to update the client credentials")
	}

	if err := s.ServerTLSCreds.loadNewTLSConfig(serverConfig); err != nil {
		return errors.Wrap(err, "failed to update the server TLS credentials")
	}

	s.certificate = certificate
	s.issuerInfo = issuerInfo
	if s.queue != nil {
		s.queue.Publish(&api.NodeTLSInfo{
			TrustRoot:           s.rootCA.Certs,
			CertIssuerPublicKey: s.issuerInfo.PublicKey,
			CertIssuerSubject:   s.issuerInfo.Subject,
		})
	}
	return nil
}
source: func (m *Mux) Handle(method, pattern string, handler http.HandlerFunc) {
	if method == "" {
		panic(fmt.Errorf("invalid method"))
	}
	m.trie.Parse(pattern).Handle(strings.ToUpper(method), handler)
}
source: func (b *Builder) Bytes() ([]byte, error) {
	if !b.IsClosed() {
		return nil, WithStack(BuilderNotClosedError)
	}
	return b.buf, nil
}
source: func sysContextID(fs fs, cid *uint32) error {
	f, err := fs.Open(devVsock)
	if err != nil {
		return err
	}
	defer f.Close()

	// Retrieve the context ID of this machine from /dev/vsock.
	return fs.Ioctl(f.Fd(), unix.IOCTL_VM_SOCKETS_GET_LOCAL_CID, unsafe.Pointer(cid))
}
source: func (s *Serf) handleNodeUpdate(n *memberlist.Node) {
	s.memberLock.Lock()
	defer s.memberLock.Unlock()

	member, ok := s.members[n.Name]
	if !ok {
		// We've never even heard of this node that is updating.
		// Just ignore it completely.
		return
	}

	// Update the member attributes
	member.Addr = net.IP(n.Addr)
	member.Port = n.Port
	member.Tags = s.decodeTags(n.Meta)

	// Snag the latest versions. NOTE - the current memberlist code will NOT
	// fire an update event if the metadata (for Serf, tags) stays the same
	// and only the protocol versions change. If we wake any Serf-level
	// protocol changes where we want to get this event under those
	// circumstances, we will need to update memberlist to do a check of
	// versions as well as the metadata.
	member.ProtocolMin = n.PMin
	member.ProtocolMax = n.PMax
	member.ProtocolCur = n.PCur
	member.DelegateMin = n.DMin
	member.DelegateMax = n.DMax
	member.DelegateCur = n.DCur

	// Update some metrics
	metrics.IncrCounter([]string{"serf", "member", "update"}, 1)

	// Send an event along
	s.logger.Printf("[INFO] serf: EventMemberUpdate: %s", member.Member.Name)
	if s.config.EventCh != nil {
		s.config.EventCh <- MemberEvent{
			Type:    EventMemberUpdate,
			Members: []Member{member.Member},
		}
	}
}
source: func processResource(stateDriver core.StateDriver, rsrcName, rsrcVal string) error {
	// Read global config
	gCfg := gstate.Cfg{}
	gCfg.StateDriver = stateDriver
	err := gCfg.Read("")
	if err != nil {
		log.Errorf("error reading tenant cfg state. Error: %s", err)
		return err
	}

	// process resource based on name
	if rsrcName == "vlan" {
		numVlans, vlansInUse := gCfg.GetVlansInUse()
		fmt.Printf("Num Vlans: %d\n Current Vlans in Use: %s\n", numVlans, vlansInUse)

		// see if we need to set the resource
		if rsrcVal != "" {
			values, err := parseRange(rsrcVal)
			if err != nil {
				log.Errorf("Error parsing range: %v", err)
				return err
			}
			log.Infof("Setting vlan values: %v", values)

			// set vlan values
			for _, val := range values {
				_, err = gCfg.AllocVLAN(val)
				if err != nil {
					log.Errorf("Error setting vlan: %d. Err: %v", val, err)
				}
			}

			log.Infof("Finished setting VLANs")
		}
	} else if rsrcName == "vxlan" {
		numVxlans, vxlansInUse := gCfg.GetVxlansInUse()
		fmt.Printf("Num Vxlans: %d\n Current Vxlans in Use: %s\n", numVxlans, vxlansInUse)

		// see if we need to set the resource
		if rsrcVal != "" {
			values, err := parseRange(rsrcVal)
			if err != nil {
				log.Errorf("Error parsing range: %v", err)
				return err
			}
			log.Infof("Setting vxlan values: %v", values)

			// set vlan values
			for _, val := range values {
				_, _, err = gCfg.AllocVXLAN(val)
				if err != nil {
					log.Errorf("Error setting vxlan: %d. Err: %v", val, err)
				}
			}

			log.Infof("Finished setting VXLANs")
		}
	} else {
		log.Errorf("Unknown resource: %v", rsrcName)
		return fmt.Errorf("unknown resource")
	}

	return nil
}
source: func (c *ChannelGraph) pruneGraphNodes(nodes *bbolt.Bucket,
	edgeIndex *bbolt.Bucket) error {

	log.Trace("Pruning nodes from graph with no open channels")

	// We'll retrieve the graph's source node to ensure we don't remove it
	// even if it no longer has any open channels.
	sourceNode, err := c.sourceNode(nodes)
	if err != nil {
		return err
	}

	// We'll use this map to keep count the number of references to a node
	// in the graph. A node should only be removed once it has no more
	// references in the graph.
	nodeRefCounts := make(map[[33]byte]int)
	err = nodes.ForEach(func(pubKey, nodeBytes []byte) error {
		// If this is the source key, then we skip this
		// iteration as the value for this key is a pubKey
		// rather than raw node information.
		if bytes.Equal(pubKey, sourceKey) || len(pubKey) != 33 {
			return nil
		}

		var nodePub [33]byte
		copy(nodePub[:], pubKey)
		nodeRefCounts[nodePub] = 0

		return nil
	})
	if err != nil {
		return err
	}

	// To ensure we never delete the source node, we'll start off by
	// bumping its ref count to 1.
	nodeRefCounts[sourceNode.PubKeyBytes] = 1

	// Next, we'll run through the edgeIndex which maps a channel ID to the
	// edge info. We'll use this scan to populate our reference count map
	// above.
	err = edgeIndex.ForEach(func(chanID, edgeInfoBytes []byte) error {
		// The first 66 bytes of the edge info contain the pubkeys of
		// the nodes that this edge attaches. We'll extract them, and
		// add them to the ref count map.
		var node1, node2 [33]byte
		copy(node1[:], edgeInfoBytes[:33])
		copy(node2[:], edgeInfoBytes[33:])

		// With the nodes extracted, we'll increase the ref count of
		// each of the nodes.
		nodeRefCounts[node1]++
		nodeRefCounts[node2]++

		return nil
	})
	if err != nil {
		return err
	}

	// Finally, we'll make a second pass over the set of nodes, and delete
	// any nodes that have a ref count of zero.
	var numNodesPruned int
	for nodePubKey, refCount := range nodeRefCounts {
		// If the ref count of the node isn't zero, then we can safely
		// skip it as it still has edges to or from it within the
		// graph.
		if refCount != 0 {
			continue
		}

		// If we reach this point, then there are no longer any edges
		// that connect this node, so we can delete it.
		if err := c.deleteLightningNode(nodes, nodePubKey[:]); err != nil {
			log.Warnf("Unable to prune node %x from the "+
				"graph: %v", nodePubKey, err)
			continue
		}

		log.Infof("Pruned unconnected node %x from channel graph",
			nodePubKey[:])

		numNodesPruned++
	}

	if numNodesPruned > 0 {
		log.Infof("Pruned %v unconnected nodes from the channel graph",
			numNodesPruned)
	}

	return nil
}
source: func (cip *cachedSelectorPolicy) getPolicy() *policy.SelectorPolicy {
	return (*policy.SelectorPolicy)(atomic.LoadPointer(&cip.policy))
}
source: func Convert_v1alpha1_VolumeConfiguration_To_config_VolumeConfiguration(in *v1alpha1.VolumeConfiguration, out *config.VolumeConfiguration, s conversion.Scope) error {
	return autoConvert_v1alpha1_VolumeConfiguration_To_config_VolumeConfiguration(in, out, s)
}
source: func (c CloudinaryService) ResourceURL(fileName string) string {
	if c.Service != nil {
		return ""
	}
	return c.Service.Url(fileName, gocloud.ImageType)
}
source: func (c *InternalClient) FragmentBlocks(ctx context.Context, uri *pilosa.URI, index, field, view string, shard uint64) ([]pilosa.FragmentBlock, error) {
	span, ctx := tracing.StartSpanFromContext(ctx, "InternalClient.FragmentBlocks")
	defer span.Finish()

	if uri == nil {
		uri = c.defaultURI
	}
	u := uriPathToURL(uri, "/internal/fragment/blocks")
	u.RawQuery = url.Values{
		"index": {index},
		"field": {field},
		"view":  {view},
		"shard": {strconv.FormatUint(shard, 10)},
	}.Encode()

	// Build request.
	req, err := http.NewRequest("GET", u.String(), nil)
	if err != nil {
		return nil, errors.Wrap(err, "creating request")
	}

	req.Header.Set("User-Agent", "pilosa/"+pilosa.Version)
	req.Header.Set("Accept", "application/json")

	// Execute request.
	resp, err := c.executeRequest(req.WithContext(ctx))
	if err != nil {
		// Return the appropriate error.
		if resp != nil && resp.StatusCode == http.StatusNotFound {
			return nil, pilosa.ErrFragmentNotFound
		}
		return nil, err
	}
	defer resp.Body.Close()

	// Decode response object.
	var rsp getFragmentBlocksResponse
	if err := json.NewDecoder(resp.Body).Decode(&rsp); err != nil {
		return nil, errors.Wrap(err, "decoding")
	}
	return rsp.Blocks, nil
}
source: func New(path string) (*PIDFile, error) {
	if err := checkPIDFileAlreadyExists(path); err != nil {
		return nil, err
	}
	// Note MkdirAll returns nil if a directory already exists
	if err := system.MkdirAll(filepath.Dir(path), os.FileMode(0755), ""); err != nil {
		return nil, err
	}
	if err := ioutil.WriteFile(path, []byte(fmt.Sprintf("%d", os.Getpid())), 0644); err != nil {
		return nil, err
	}

	return &PIDFile{path: path}, nil
}
source: func GetEwmhWM(xu *xgbutil.XUtil) (string, error) {
	childCheck, err := SupportingWmCheckGet(xu, xu.RootWin())
	if err != nil {
		return "", fmt.Errorf("GetEwmhWM: Failed because: %s", err)
	}

	childCheck2, err := SupportingWmCheckGet(xu, childCheck)
	if err != nil {
		return "", fmt.Errorf("GetEwmhWM: Failed because: %s", err)
	}

	if childCheck != childCheck2 {
		return "", fmt.Errorf(
			"GetEwmhWM: _NET_SUPPORTING_WM_CHECK value on the root window "+
				"(%x) does not match _NET_SUPPORTING_WM_CHECK value "+
				"on the child window (%x).", childCheck, childCheck2)
	}

	return WmNameGet(xu, childCheck)
}
source: func (vs Values) Strings() []string {
	ss := make([]string, len(vs))
	for i, v := range vs {
		ss[i] = v.String()
	}
	return ss
}
source: func (v *Validator) Validate(x interface{}) error {
	jsv, err := v.validator()
	if err != nil {
		return err
	}
	return jsv.Validate(x)
}
source: func NewContextCommand(dockerCli command.Cli) *cobra.Command {
	cmd := &cobra.Command{
		Use:   "context",
		Short: "Manage contexts",
		Args:  cli.NoArgs,
		RunE:  command.ShowHelp(dockerCli.Err()),
	}
	cmd.AddCommand(
		newCreateCommand(dockerCli),
		newListCommand(dockerCli),
		newUseCommand(dockerCli),
		newExportCommand(dockerCli),
		newImportCommand(dockerCli),
		newRemoveCommand(dockerCli),
		newUpdateCommand(dockerCli),
		newInspectCommand(dockerCli),
	)
	return cmd
}
source: func (s *QueryInput) SetKeyConditions(v map[string]*Condition) *QueryInput {
	s.KeyConditions = v
	return s
}
source: func DecompressContent(content []byte) ([]byte, error) {

	buf := bytes.NewReader(content)
	gZipReader, _ := gzip.NewReader(buf)
	defer close(gZipReader)
	return ioutil.ReadAll(gZipReader)
}
source: func (s *ServiceLastAccessed) SetTotalAuthenticatedEntities(v int64) *ServiceLastAccessed {
	s.TotalAuthenticatedEntities = &v
	return s
}
source: func (s *stopChan) IfStopped(execute func()) {
	if s == nil {
		execute()
		return
	}
	s.cond.L.Lock()
	defer s.cond.L.Unlock()
	if !s.stopped {
		return
	}
	execute()
}
source: func handleOtherModes(fp *flag.Parser, modes OtherModes) {
	if modes.Version {
		fmt.Println("Honeytail version", version)
		os.Exit(0)
	}
	if modes.Help {
		fp.WriteHelp(os.Stdout)
		fmt.Println("")
		os.Exit(0)
	}
	if modes.WriteManPage {
		fp.WriteManPage(os.Stdout)
		os.Exit(0)
	}
	if modes.WriteDefaultConfig {
		ip := flag.NewIniParser(fp)
		ip.Write(os.Stdout, flag.IniIncludeDefaults|flag.IniCommentDefaults|flag.IniIncludeComments)
		os.Exit(0)
	}
	if modes.WriteCurrentConfig {
		ip := flag.NewIniParser(fp)
		ip.Write(os.Stdout, flag.IniIncludeComments)
		os.Exit(0)
	}

	if modes.ListParsers {
		fmt.Println("Available parsers:", strings.Join(validParsers, ", "))
		os.Exit(0)
	}
}
source: func NewStateAPI(ctx facade.Context) (*ExternalControllerUpdaterAPI, error) {
	return NewAPI(
		ctx.Auth(),
		ctx.Resources(),
		state.NewExternalControllers(ctx.State()),
	)
}
source: func (c *Tx) TxPipelined(fn func(Pipeliner) error) ([]Cmder, error) {
	return c.Pipelined(fn)
}
source: func (f *freelist) copyall(dst []pgid) {
	m := make(pgids, 0, f.pending_count())
	for _, list := range f.pending {
		m = append(m, list...)
	}
	sort.Sort(m)
	mergepgids(dst, f.ids, m)
}
source: func (m *memberlist) NumPingableMembers() (n int) {
	m.members.RLock()
	for _, member := range m.members.list {
		if m.Pingable(*member) {
			n++
		}
	}
	m.members.RUnlock()

	return n
}
source: func (fs DummyFS) ReadDir(path string) ([]os.FileInfo, error) {
	return nil, fs.err
}
source: func (d *indirectIndex) DeletePrefix(prefix []byte, minTime, maxTime int64, dead func([]byte)) bool {
	if dead == nil {
		dead = func([]byte) {}
	}

	// If we're deleting everything, we won't need to worry about partial deletes.
	partial := !(minTime <= d.minTime && maxTime >= d.maxTime)

	// Is the range passed in outside of the time range for the file?
	if minTime > d.maxTime || maxTime < d.minTime {
		return false
	}

	d.mu.RLock()
	var (
		ok        bool
		trbuf     []TimeRange
		entries   []IndexEntry
		err       error
		mustTrack bool
	)

	// seek to the earliest key with the prefix, and start iterating. we can't call
	// next until after we've checked the key, so keep a "first" flag.
	first := true
	iter := d.ro.Iterator()
	for {
		if first {
			if _, ok := iter.Seek(prefix, &d.b); !ok {
				break
			}
		} else if !iter.Next() {
			break
		}

		first = false
		key := iter.Key(&d.b)
		if !bytes.HasPrefix(key, prefix) {
			break
		}

		// if we're not doing a partial delete, we don't need to read the entries and
		// can just delete the key and move on.
		if !partial {
			dead(key)
			iter.Delete()
			continue
		}

		entryOffset := iter.EntryOffset(&d.b)
		entries, err = readEntriesTimes(d.b.access(entryOffset, 0), entries)
		if err != nil {
			// If we have an error reading the entries for a key, we should just pretend
			// the whole key is deleted. Maybe a better idea is to report this up somehow
			// but that's for another time.
			dead(key)
			iter.Delete()
			continue
		}

		// Is the time range passed outside the range we have stored for the key?
		min, max := entries[0].MinTime, entries[len(entries)-1].MaxTime
		if minTime > max || maxTime < min {
			continue
		}

		// Does the range passed cover every value for the key?
		if minTime <= min && maxTime >= max {
			dead(key)
			iter.Delete()
			continue
		}

		// Does adding the minTime and maxTime cover the entries?
		trbuf, ok = d.coversEntries(iter.Offset(), iter.Key(&d.b), trbuf, entries, minTime, maxTime)
		if ok {
			dead(key)
			iter.Delete()
			continue
		}

		// Otherwise, we have to track it in the prefix tombstones list.
		mustTrack = true
	}
	d.mu.RUnlock()

	// Check and abort if nothing needs to be done.
	if !mustTrack && !iter.HasDeletes() {
		return false
	}

	d.mu.Lock()
	defer d.mu.Unlock()

	if mustTrack {
		d.prefixTombstones.Append(prefix, TimeRange{Min: minTime, Max: maxTime})
	}

	if iter.HasDeletes() {
		iter.Done()
	}

	return true
}
source: func (s *KeyGen) Get(user string) (res string, err error) {
	var r interface{}
	search := fmt.Sprintf("%s:*", user)

	if r, err = s.store().Do("KEYS", search); r != nil && err == nil {
		res, _, _, err = parseKeysResponse(r)
	}
	return
}
source: func writeUniqueXLMetadata(ctx context.Context, disks []StorageAPI, bucket, prefix string, xlMetas []xlMetaV1, quorum int) ([]StorageAPI, error) {
	var wg = &sync.WaitGroup{}
	var mErrs = make([]error, len(disks))

	// Start writing `xl.json` to all disks in parallel.
	for index, disk := range disks {
		if disk == nil {
			mErrs[index] = errDiskNotFound
			continue
		}
		wg.Add(1)
		// Write `xl.json` in a routine.
		go func(index int, disk StorageAPI) {
			defer wg.Done()

			// Pick one xlMeta for a disk at index.
			xlMetas[index].Erasure.Index = index + 1

			// Write unique `xl.json` for a disk at index.
			err := writeXLMetadata(ctx, disk, bucket, prefix, xlMetas[index])
			if err != nil {
				mErrs[index] = err
			}
		}(index, disk)
	}

	// Wait for all the routines.
	wg.Wait()

	err := reduceWriteQuorumErrs(ctx, mErrs, objectOpIgnoredErrs, quorum)
	return evalDisks(disks, mErrs), err
}
source: func (e *Encoder) Order(ord marshalOrder) *Encoder {
	e.order = ord
	return e
}
source: func WriteJSONOnce(r Registry, w io.Writer) {
	json.NewEncoder(w).Encode(r)
}
source: func (ln *LocalNode) Delete(e enr.Entry) {
	ln.mu.Lock()
	defer ln.mu.Unlock()

	ln.delete(e)
}
source: func generateStoredMessageUrl(m Mailgun, endpoint, id string) string {
	return generateDomainApiUrl(m, fmt.Sprintf("%s/%s", endpoint, id))
	// return fmt.Sprintf("%s/domains/%s/%s/%s", apiBase, m.Domain(), endpoint, id)
}
source: func (c *Cache) Remove(u interface{}) (err error) {

	return c.removeNotify(u, false)
}
source: func (s *intSet) has(i int) bool {
	if s == nil {
		return false
	}
	_, present := s.members[i]
	return present
}
source: func (cs *clientStore) register(info *spb.ClientInfo) (*client, error) {
	cs.Lock()
	defer cs.Unlock()
	c := cs.clients[info.ID]
	if c != nil {
		return nil, ErrInvalidClient
	}
	sc, err := cs.store.AddClient(info)
	if err != nil {
		return nil, err
	}
	c = &client{info: sc, subs: make([]*subState, 0, 4)}
	cs.clients[c.info.ID] = c
	if len(c.info.ConnID) > 0 {
		cs.connIDs[string(c.info.ConnID)] = c
	}
	delete(cs.knownInvalid, getKnownInvalidKey(info.ID, info.ConnID))
	if cs.waitOnRegister != nil {
		ch := cs.waitOnRegister[c.info.ID]
		if ch != nil {
			ch <- struct{}{}
			delete(cs.waitOnRegister, c.info.ID)
		}
	}
	return c, nil
}
source: func (e *Endpoint) runIPIdentitySync(endpointIP addressing.CiliumIP) {

	if !endpointIP.IsSet() {
		return
	}

	addressFamily := endpointIP.GetFamilyString()

	e.controllers.UpdateController(fmt.Sprintf("sync-%s-identity-mapping (%d)", addressFamily, e.ID),
		controller.ControllerParams{
			DoFunc: func(ctx context.Context) error {
				if err := e.RLockAlive(); err != nil {
					return controller.NewExitReason("Endpoint disappeared")
				}

				if e.SecurityIdentity == nil {
					e.RUnlock()
					return nil
				}

				IP := endpointIP.IP()
				ID := e.SecurityIdentity.ID
				hostIP := node.GetExternalIPv4()
				key := node.GetIPsecKeyIdentity()
				metadata := e.FormatGlobalEndpointID()

				// Release lock as we do not want to have long-lasting key-value
				// store operations resulting in lock being held for a long time.
				e.RUnlock()

				if err := ipcache.UpsertIPToKVStore(ctx, IP, hostIP, ID, key, metadata); err != nil {
					return fmt.Errorf("unable to add endpoint IP mapping '%s'->'%d': %s", IP.String(), ID, err)
				}
				return nil
			},
			StopFunc: func(ctx context.Context) error {
				ip := endpointIP.String()
				if err := ipcache.DeleteIPFromKVStore(ctx, ip); err != nil {
					return fmt.Errorf("unable to delete endpoint IP '%s' from ipcache: %s", ip, err)
				}
				return nil
			},
			RunInterval: 5 * time.Minute,
		},
	)
}
source: func checkSignatureFromCreator(creatorBytes []byte, sig []byte, msg []byte, ChainID string) error {
	putilsLogger.Debugf("begin")

	// check for nil argument
	if creatorBytes == nil || sig == nil || msg == nil {
		return errors.New("nil arguments")
	}

	mspObj := mspmgmt.GetIdentityDeserializer(ChainID)
	if mspObj == nil {
		return errors.Errorf("could not get msp for channel [%s]", ChainID)
	}

	// get the identity of the creator
	creator, err := mspObj.DeserializeIdentity(creatorBytes)
	if err != nil {
		return errors.WithMessage(err, "MSP error")
	}

	putilsLogger.Debugf("creator is %s", creator.GetIdentifier())

	// ensure that creator is a valid certificate
	err = creator.Validate()
	if err != nil {
		return errors.WithMessage(err, "creator certificate is not valid")
	}

	putilsLogger.Debugf("creator is valid")

	// validate the signature
	err = creator.Verify(msg, sig)
	if err != nil {
		return errors.WithMessage(err, "creator's signature over the proposal is not valid")
	}

	putilsLogger.Debugf("exits successfully")

	return nil
}
source: func (l Log) PutOffset(offset int64) {
	encoding.PutUint64(l[offsetPos:sizePos], uint64(offset))
}
source: func (s *PutLogEventsOutput) SetRejectedLogEventsInfo(v *RejectedLogEventsInfo) *PutLogEventsOutput {
	s.RejectedLogEventsInfo = v
	return s
}
source: func dataSourceAwsInstanceRead(d *schema.ResourceData, meta interface{}) error {
	conn := meta.(*AWSClient).ec2conn

	filters, filtersOk := d.GetOk("filter")
	instanceID, instanceIDOk := d.GetOk("instance_id")
	tags, tagsOk := d.GetOk("instance_tags")

	if !filtersOk && !instanceIDOk && !tagsOk {
		return fmt.Errorf("One of filters, instance_tags, or instance_id must be assigned")
	}

	// Build up search parameters
	params := &ec2.DescribeInstancesInput{}
	if filtersOk {
		params.Filters = buildAwsDataSourceFilters(filters.(*schema.Set))
	}
	if instanceIDOk {
		params.InstanceIds = []*string{aws.String(instanceID.(string))}
	}
	if tagsOk {
		params.Filters = append(params.Filters, buildEC2TagFilterList(
			tagsFromMap(tags.(map[string]interface{})),
		)...)
	}

	log.Printf("[DEBUG] Reading IAM Instance: %s", params)
	resp, err := conn.DescribeInstances(params)
	if err != nil {
		return err
	}

	// If no instances were returned, return
	if len(resp.Reservations) == 0 {
		return fmt.Errorf("Your query returned no results. Please change your search criteria and try again.")
	}

	var filteredInstances []*ec2.Instance

	// loop through reservations, and remove terminated instances, populate instance slice
	for _, res := range resp.Reservations {
		for _, instance := range res.Instances {
			if instance.State != nil && *instance.State.Name != "terminated" {
				filteredInstances = append(filteredInstances, instance)
			}
		}
	}

	var instance *ec2.Instance
	if len(filteredInstances) < 1 {
		return fmt.Errorf("Your query returned no results. Please change your search criteria and try again.")
	}

	// (TODO: Support a list of instances to be returned)
	// Possibly with a different data source that returns a list of individual instance data sources
	if len(filteredInstances) > 1 {
		return fmt.Errorf("Your query returned more than one result. Please try a more " +
			"specific search criteria.")
	} else {
		instance = filteredInstances[0]
	}

	log.Printf("[DEBUG] aws_instance - Single Instance ID found: %s", *instance.InstanceId)
	if err := instanceDescriptionAttributes(d, instance, conn); err != nil {
		return err
	}

	if d.Get("get_password_data").(bool) {
		passwordData, err := getAwsEc2InstancePasswordData(*instance.InstanceId, conn)
		if err != nil {
			return err
		}
		d.Set("password_data", passwordData)
	}

	// ARN
	arn := arn.ARN{
		Partition: meta.(*AWSClient).partition,
		Region:    meta.(*AWSClient).region,
		Service:   "ec2",
		AccountID: meta.(*AWSClient).accountid,
		Resource:  fmt.Sprintf("instance/%s", d.Id()),
	}
	d.Set("arn", arn.String())

	return nil
}
source: func (b *Breaker) fallback(err error, fb ...Fallback) error {
	var final error
	if len(fb) == 0 {
		final = err
		b.stat.update(err, nil, false)
	} else {
		final = fb[0](err)
		b.stat.update(final, err, true)
	}

	if final != nil && b.cond(b.stat.counter) && atomic.CompareAndSwapInt32(&b.state, Closed, Open) {
		b.expiry = time.Now().Add(b.opts.Window)
		b.stat.reset(false, true)
		b.logger.Warn("breaker > open circuit: ", b.name)
	}
	return final
}
source: func ParseConfig(body []byte) (*Config, error) {
	var config Config
	err := json.Unmarshal(body, &config)
	return &config, err
}
source: func (d *devicePluginClient) handleStats(
	reqCtx context.Context,
	stream proto.DevicePlugin_StatsClient,
	out chan *StatsResponse) {

	defer close(out)
	for {
		resp, err := stream.Recv()
		if err != nil {
			if err != io.EOF {
				out <- &StatsResponse{
					Error: grpcutils.HandleReqCtxGrpcErr(err, reqCtx, d.doneCtx),
				}
			}

			// End the stream
			return
		}

		// Send the response
		s := &StatsResponse{
			Groups: convertProtoDeviceGroupsStats(resp.GetGroups()),
		}
		select {
		case <-reqCtx.Done():
			return
		case out <- s:
		}
	}
}
source: func NewUserProfileService(context servicecontext.ServiceContext) service.UserProfileService {
	return &userProfileService{
		client: http.DefaultClient,
	}
}
source: func (b *Backend) Copy(c *Backend) {
	b.Enabled = c.Enabled
	b.InService = c.InService
	b.Weight = c.Weight
	b.Host.Copy(&c.Host)
}
source: func (c *Container) countRange(start, end int32) (n int32) {
	if c.isArray() {
		return c.arrayCountRange(start, end)
	} else if c.isRun() {
		return c.runCountRange(start, end)
	}
	return c.bitmapCountRange(start, end)
}
source: func (in *ExternalDNSConfig) DeepCopy() *ExternalDNSConfig {
	if in == nil {
		return nil
	}
	out := new(ExternalDNSConfig)
	in.DeepCopyInto(out)
	return out
}
source: func (options *Options) FnCtxData(ctx interface{}, data *DataFrame) string {
	return options.evalBlock(ctx, data, nil)
}
source: func (t *Text) ClickedCharacter(xPos, offset float64) (index int, side CharacterSide) {
	// transform from screen coordinates to... window coordinates?
	xPos = xPos - float64(t.Font.WindowWidth/2) - offset

	// could do a binary search...
	at := float64(t.X1.X)
	for i, cs := range t.CharSpacing {
		at = float64(cs) + at
		if i == 0 && xPos <= at-float64(cs) {
			return i, CSLeft
		}
		if i == len(t.CharSpacing)-1 && xPos > at {
			return i, CSRight
		}
		if xPos <= at && xPos > at-float64(cs) {
			if xPos-(at-float64(cs)) > float64(cs)/2 {
				return i, CSRight
			} else {
				return i, CSLeft
			}
		}
	}
	return -1, CSUnknown
}
source: func EncodeBody(res *sawyer.Response, bodyWriter io.Writer) error {
	if res.ContentLength == 0 {
		return nil
	}

	buf := &bytes.Buffer{}
	writer := io.MultiWriter(bodyWriter, buf)
	_, err := io.Copy(writer, res.Body)
	if err == nil {
		res.Body = ioutil.NopCloser(buf)
	}

	return err
}
source: func (prod *BatchedProducer) appendMessage(msg *Message) {
	prod.Batch.AppendOrFlush(msg, prod.flushBatch, prod.IsActiveOrStopping, prod.TryFallback)
}
source: func NewMembersSetProfileArg(User *UserSelectorArg) *MembersSetProfileArg {
	s := new(MembersSetProfileArg)
	s.User = User
	return s
}
source: func (r *Repository) GetAssigneesURL() string {
	if r == nil || r.AssigneesURL == nil {
		return ""
	}
	return *r.AssigneesURL
}
source: func (mr *MockSupervisorMockRecorder) Supervise(contextID, puInfo interface{}) *gomock.Call {
	return mr.mock.ctrl.RecordCallWithMethodType(mr.mock, "Supervise", reflect.TypeOf((*MockSupervisor)(nil).Supervise), contextID, puInfo)
}
source: func (w *writer) Write(p []byte) (n int, err error) {
	n, err = w.Writer.Write(p)
	if err != nil {
		return
	}

	err = w.Limiter.Count(n)
	return
}
source: func (g *MultiPolygon) Length() float64 {
	return length3(g.flatCoords, 0, g.endss, g.stride)
}
source: func NewDecoratedVisitor(v Visitor, fn ...VisitorFunc) Visitor {
	if len(fn) == 0 {
		return v
	}
	return DecoratedVisitor{v, fn}
}
source: func (g *Github) PrincipalID(provider *http.Client) (string, error) {
	client := github.NewClient(provider)
	// If we need to restrict to a set of organizations, we first get the org
	// and filter.
	if len(g.Orgs) > 0 {
		orgs, err := getOrganizations(client, g.Logger)
		if err != nil {
			return "", err
		}
		// Not a member, so, deny permission
		if ok := isMember(g.Orgs, orgs); !ok {
			g.Logger.Error("Not a member of required github organization")
			return "", err
		}
	}

	email, err := getPrimaryEmail(client, g.Logger)
	if err != nil {
		return "", nil
	}
	return email, nil
}
source: func (d *driver) Stat(ctx context.Context, path string) (storagedriver.FileInfo, error) {
	d.mutex.RLock()
	defer d.mutex.RUnlock()

	normalized := normalize(path)
	found := d.root.find(normalized)

	if found.path() != normalized {
		return nil, storagedriver.PathNotFoundError{Path: path}
	}

	fi := storagedriver.FileInfoFields{
		Path:    path,
		IsDir:   found.isdir(),
		ModTime: found.modtime(),
	}

	if !fi.IsDir {
		fi.Size = int64(len(found.(*file).data))
	}

	return storagedriver.FileInfoInternal{FileInfoFields: fi}, nil
}
source: func (re *Regexp) FindStringMatchStartingAt(s string, startAt int) (*Match, error) {
	if startAt > len(s) {
		return nil, errors.New("startAt must be less than the length of the input string")
	}
	r, startAt := re.getRunesAndStart(s, startAt)
	if startAt == -1 {
		// we didn't find our start index in the string -- that's a problem
		return nil, errors.New("startAt must align to the start of a valid rune in the input string")
	}

	return re.run(false, startAt, r)
}
source: func (c *DOM) RemoveNode(nodeId int) (*gcdmessage.ChromeResponse, error) {
	var v DOMRemoveNodeParams
	v.NodeId = nodeId
	return c.RemoveNodeWithParams(&v)
}
source: func HTTPProvider(servers map[string]string, cache cache.Cache) Provider {
	return &httpProvider{
		servers: servers,
		cache:   cache,
	}
}
source: func (w *Worker) On(e Event, cb func(*Package, ...interface{})) {
	if _, exists := w.events[e]; !exists {
		w.events[e] = make([]func(*Package, ...interface{}), 0)
	}

	w.events[e] = append(w.events[e], cb)
}
source: func (s *DbSession) findQuery(d Document, q Q) *mgo.Query {
	//collection pointer for the given document
	return s.collection(d.CollectionName()).Find(q)
}
source: func New(cfg ...Config) *Editor {
	c := DefaultConfig()
	if len(cfg) > 0 {
		c = cfg[0]
	}
	c.WorkingDir = validateWorkingDir(c.WorkingDir) // add "/" if not exists

	return &Editor{
		enabled: true,
		config:  &c,
	}
}
source: func IsMissingVersion(err error) bool {
	if err == nil {
		return false
	}
	_, ok := err.(*missingVersionErr)
	return ok
}
source: func NewIdempotencyKey() string {
	now := time.Now().UnixNano()
	buf := make([]byte, 4)
	rand.Read(buf)
	return fmt.Sprintf("%v_%v", now, base64.URLEncoding.EncodeToString(buf)[:6])
}
source: func ClientAddressDialer(defaultPort string) func(string, time.Duration) (net.Conn, error) {
	return func(addr string, timeout time.Duration) (net.Conn, error) {
		parsedAddr, err := ParseAddressString(
			addr, defaultPort, net.ResolveTCPAddr,
		)
		if err != nil {
			return nil, err
		}

		return net.DialTimeout(
			parsedAddr.Network(), parsedAddr.String(), timeout,
		)
	}
}
source: func (i *InputField) SetText(text string) *InputField {
	i.text = text
	i.cursorPos = len(text)
	if i.changed != nil {
		i.changed(text)
	}
	return i
}
source: func (s *HistoryEvent) SetScheduleActivityTaskFailedEventAttributes(v *ScheduleActivityTaskFailedEventAttributes) *HistoryEvent {
	s.ScheduleActivityTaskFailedEventAttributes = v
	return s
}
source: func (o *IKEGatewayConnection) AssignPerformanceMonitors(children PerformanceMonitorsList) *bambou.Error {

	list := []bambou.Identifiable{}
	for _, c := range children {
		list = append(list, c)
	}

	return bambou.CurrentSession().AssignChildren(o, list, PerformanceMonitorIdentity)
}
source: func NewQueue(dst Sink) *Queue {
	eq := Queue{
		dst:    dst,
		events: list.New(),
	}

	eq.cond = sync.NewCond(&eq.mu)
	go eq.run()
	return &eq
}
source: func (l *Linode) Batch(action string, params Parameters, result interface{}) {
	params.Set(apiAction, action)
	l.actions = append(l.actions, Action{
		parameters: params,
		result:     result,
	})
}
source: func Copy(ctx context.Context, cw Writer, r io.Reader, size int64, expected digest.Digest, opts ...Opt) error {
	ws, err := cw.Status()
	if err != nil {
		return errors.Wrap(err, "failed to get status")
	}

	if ws.Offset > 0 {
		r, err = seekReader(r, ws.Offset, size)
		if err != nil {
			return errors.Wrapf(err, "unable to resume write to %v", ws.Ref)
		}
	}

	if _, err := copyWithBuffer(cw, r); err != nil {
		return errors.Wrap(err, "failed to copy")
	}

	if err := cw.Commit(ctx, size, expected, opts...); err != nil {
		if !errdefs.IsAlreadyExists(err) {
			return errors.Wrapf(err, "failed commit on ref %q", ws.Ref)
		}
	}

	return nil
}
source: func MakeDeleteSessionsByOwnerTokenEndpoint(s Service) endpoint.Endpoint {
	return func(ctx context.Context, request interface{}) (interface{}, error) {
		req := request.(deleteSessionsByOwnerTokenRequest)
		sessions, err := s.DeleteSessionsByOwnerToken(ctx, req.OwnerToken)
		return deleteSessionsByOwnerTokenResponse{
			Sessions: sessions,
			Err:      err,
		}, nil
	}
}
source: func NewNodeHandler(datapathConfig DatapathConfiguration, nodeAddressing datapath.NodeAddressing) datapath.NodeHandler {
	return &linuxNodeHandler{
		nodeAddressing: nodeAddressing,
		datapathConfig: datapathConfig,
		nodes:          map[node.Identity]*node.Node{},
	}
}
source: func parse(expr string) node {
	r := &scanner{text: expr}
	r.nextChar()
	r.nextItem()
	p := &parser{r: r}
	return p.parseExpression(nil)
}
source: func (exp *FuncExpr) String() string {
	return fmt.Sprintf("FuncExpr(%s, %s)", exp.Name, exp.Args)
}
source: func (s *Server) Close() error {
	conns := []io.Closer{
		s.sconn,
		s.clientConn,
		s.serverConn,
		s.targetConn,
		s.remoteClient,
	}

	var errs []error

	for _, c := range conns {
		if c == nil {
			continue
		}

		err := c.Close()
		if err != nil {
			errs = append(errs, err)
		}
	}

	// Signal to waiting goroutines that the server is closing (for example,
	// the keep alive loop).
	s.closeCancel()

	return trace.NewAggregate(errs...)
}
source: func (m *MachineTokenAuthMethod) Authenticate(c context.Context, r *http.Request) (*auth.User, error) {
	token := r.Header.Get(MachineTokenHeader)
	if token == "" {
		return nil, nil // no token -> the auth method is not applicable
	}

	// Deserialize both envelope and the body.
	envelope, body, err := deserialize(token)
	if err != nil {
		logTokenError(c, r, body, err, "Failed to deserialize the token")
		return nil, ErrBadToken
	}

	// Construct an identity of a token server that signed the token to check that
	// it belongs to "auth-token-servers" group.
	signerServiceAccount, err := identity.MakeIdentity("user:" + body.IssuedBy)
	if err != nil {
		logTokenError(c, r, body, err, "Bad issued_by field - %q", body.IssuedBy)
		return nil, ErrBadToken
	}

	// Reject tokens from unknown token servers right away.
	db, err := auth.GetDB(c)
	if err != nil {
		return nil, transient.Tag.Apply(err)
	}
	ok, err := db.IsMember(c, signerServiceAccount, []string{TokenServersGroup})
	if err != nil {
		return nil, transient.Tag.Apply(err)
	}
	if !ok {
		logTokenError(c, r, body, nil, "Unknown token issuer - %q", body.IssuedBy)
		return nil, ErrBadToken
	}

	// Check the expiration time before doing any heavier checks.
	if err = checkExpiration(body, clock.Now(c)); err != nil {
		logTokenError(c, r, body, err, "Token has expired or not yet valid")
		return nil, ErrBadToken
	}

	// Check the token was actually signed by the server.
	if err = m.checkSignature(c, body.IssuedBy, envelope); err != nil {
		if transient.Tag.In(err) {
			return nil, err
		}
		logTokenError(c, r, body, err, "Bad signature")
		return nil, ErrBadToken
	}

	// The token is valid. Construct the bot identity.
	botIdent, err := identity.MakeIdentity("bot:" + body.MachineFqdn)
	if err != nil {
		logTokenError(c, r, body, err, "Bad machine_fqdn - %q", body.MachineFqdn)
		return nil, ErrBadToken
	}
	return &auth.User{Identity: botIdent}, nil
}
source: func (a AddrSpec) Address() string {
	if 0 != len(a.IP) {
		return net.JoinHostPort(a.IP.String(), strconv.Itoa(a.Port))
	}
	return net.JoinHostPort(a.FQDN, strconv.Itoa(a.Port))
}
source: func (v VolumePathHandler) GetDeviceSymlinkRefs(devPath string, mapPath string) ([]string, error) {
	var refs []string
	files, err := ioutil.ReadDir(mapPath)
	if err != nil {
		return nil, fmt.Errorf("Directory cannot read %v", err)
	}
	for _, file := range files {
		if file.Mode()&os.ModeSymlink != os.ModeSymlink {
			continue
		}
		filename := file.Name()
		fp, err := os.Readlink(filepath.Join(mapPath, filename))
		if err != nil {
			return nil, fmt.Errorf("Symbolic link cannot be retrieved %v", err)
		}
		klog.V(5).Infof("GetDeviceSymlinkRefs: filepath: %v, devPath: %v", fp, devPath)
		if fp == devPath {
			refs = append(refs, filepath.Join(mapPath, filename))
		}
	}
	klog.V(5).Infof("GetDeviceSymlinkRefs: refs %v", refs)
	return refs, nil
}
source: func ParseRequest(r io.Reader) (*plugin.CodeGeneratorRequest, error) {
	input, err := ioutil.ReadAll(r)
	if err != nil {
		return nil, fmt.Errorf("failed to read code generator request: %v", err)
	}
	req := new(plugin.CodeGeneratorRequest)
	if err = proto.Unmarshal(input, req); err != nil {
		return nil, fmt.Errorf("failed to unmarshal code generator request: %v", err)
	}
	return req, nil
}
source: func (k *KeybaseServiceBase) CreateTeamTLF(
	ctx context.Context, teamID keybase1.TeamID, tlfID tlf.ID) (err error) {
	return k.kbfsClient.CreateTLF(ctx, keybase1.CreateTLFArg{
		TeamID: teamID,
		TlfID:  keybase1.TLFID(tlfID.String()),
	})
}
source: func anyRune(s string) runeFn {
	return func(r rune) bool {
		return strings.IndexRune(s, r) > -1
	}
}
source: func handleTaskGroup(snap *state.StateSnapshot, batch bool, tg *structs.TaskGroup,
	allocs []*structs.Allocation, lastHandledIndex uint64, result *jobResult) error {

	// Determine how many allocations can be drained
	drainingNodes := make(map[string]bool, 4)
	healthy := 0
	remainingDrainingAlloc := false
	var drainable []*structs.Allocation

	for _, alloc := range allocs {
		// Check if the alloc is on a draining node.
		onDrainingNode, ok := drainingNodes[alloc.NodeID]
		if !ok {
			// Look up the node
			node, err := snap.NodeByID(nil, alloc.NodeID)
			if err != nil {
				return err
			}

			// Check if the node exists and whether it has a drain strategy
			onDrainingNode = node != nil && node.DrainStrategy != nil
			drainingNodes[alloc.NodeID] = onDrainingNode
		}

		// Check if the alloc should be considered migrated. A migrated
		// allocation is one that is terminal, is on a draining
		// allocation, and has only happened since our last handled index to
		// avoid emitting many duplicate migrate events.
		if alloc.TerminalStatus() &&
			onDrainingNode &&
			alloc.ModifyIndex > lastHandledIndex {
			result.migrated = append(result.migrated, alloc)
			continue
		}

		// If the service alloc is running and has its deployment status set, it
		// is considered healthy from a migration standpoint.
		if !batch && !alloc.TerminalStatus() && alloc.DeploymentStatus.HasHealth() {
			healthy++
		}

		// An alloc can't be considered for migration if:
		// - It isn't on a draining node
		// - It is already terminal
		if !onDrainingNode || alloc.TerminalStatus() {
			continue
		}

		// Capture the fact that there is an allocation that is still draining
		// for this job.
		remainingDrainingAlloc = true

		// If we haven't marked this allocation for migration already, capture
		// it as eligible for draining.
		if !batch && !alloc.DesiredTransition.ShouldMigrate() {
			drainable = append(drainable, alloc)
		}
	}

	// Update the done status
	if remainingDrainingAlloc {
		result.done = false
	}

	// We don't mark batch for drain so exit
	if batch {
		return nil
	}

	// Determine how many we can drain
	thresholdCount := tg.Count - tg.Migrate.MaxParallel
	numToDrain := healthy - thresholdCount
	numToDrain = helper.IntMin(len(drainable), numToDrain)
	if numToDrain <= 0 {
		return nil
	}

	result.drain = append(result.drain, drainable[0:numToDrain]...)
	return nil
}
source: func (h StandardHeaders) PopulateMap(m map[string]interface{}) error {
	for k, v := range h.privateParams {
		m[k] = v
	}
	if v, ok := h.Get(AlgorithmKey); ok {
		m[AlgorithmKey] = v
	}
	if v, ok := h.Get(KeyIDKey); ok {
		m[KeyIDKey] = v
	}
	if v, ok := h.Get(KeyTypeKey); ok {
		m[KeyTypeKey] = v
	}
	if v, ok := h.Get(KeyUsageKey); ok {
		m[KeyUsageKey] = v
	}
	if v, ok := h.Get(KeyOpsKey); ok {
		m[KeyOpsKey] = v
	}
	if v, ok := h.Get(X509CertChainKey); ok {
		m[X509CertChainKey] = v
	}
	if v, ok := h.Get(X509CertThumbprintKey); ok {
		m[X509CertThumbprintKey] = v
	}
	if v, ok := h.Get(X509CertThumbprintS256Key); ok {
		m[X509CertThumbprintS256Key] = v
	}
	if v, ok := h.Get(X509URLKey); ok {
		m[X509URLKey] = v
	}

	return nil
}
source: func GetAccessModesFromString(modes string) []core.PersistentVolumeAccessMode {
	strmodes := strings.Split(modes, ",")
	accessModes := []core.PersistentVolumeAccessMode{}
	for _, s := range strmodes {
		s = strings.Trim(s, " ")
		switch {
		case s == "RWO":
			accessModes = append(accessModes, core.ReadWriteOnce)
		case s == "ROX":
			accessModes = append(accessModes, core.ReadOnlyMany)
		case s == "RWX":
			accessModes = append(accessModes, core.ReadWriteMany)
		}
	}
	return accessModes
} 60%|█████▉    | 2981/5000 [00:03<00:04, 439.77it/s]
source: func packageApp(c *model.CommandConfig) (err error) {

	// Determine the run mode.
	mode := DefaultRunMode
	if len(c.Package.Mode) >= 0 {
		mode = c.Package.Mode
	}

	appImportPath := c.ImportPath
	revel_paths, err := model.NewRevelPaths(mode, appImportPath, "", model.NewWrappedRevelCallback(nil, c.PackageResolver))
	if err != nil {
		return
	}

	// Remove the archive if it already exists.
	destFile := filepath.Join(c.AppPath, filepath.Base(revel_paths.BasePath)+".tar.gz")
	if c.Package.TargetPath != "" {
		if filepath.IsAbs(c.Package.TargetPath) {
			destFile = c.Package.TargetPath
		} else {
			destFile = filepath.Join(c.AppPath, c.Package.TargetPath)
		}
	}
	if err := os.Remove(destFile); err != nil && !os.IsNotExist(err) {
		return utils.NewBuildError("Unable to remove target file", "error", err, "file", destFile)
	}

	// Collect stuff in a temp directory.
	tmpDir, err := ioutil.TempDir("", filepath.Base(revel_paths.BasePath))
	utils.PanicOnError(err, "Failed to get temp dir")

	// Build expects the command the build to contain the proper data
	if len(c.Package.Mode) >= 0 {
		c.Build.Mode = c.Package.Mode
	}
	c.Build.TargetPath = tmpDir
	c.Build.CopySource = c.Package.CopySource
	buildApp(c)

	// Create the zip file.

	archiveName, err := utils.TarGzDir(destFile, tmpDir)
	if err != nil {
		return
	}

	fmt.Println("Your archive is ready:", archiveName)
	return
}
source: func (bb BBox) Valid() bool {
	if bb == nil {
		return false
	}

	return len(bb) >= 4 && len(bb)%2 == 0
}
source: func (client *BaseClient) GetClientContext(
	settings *InvokeSettings) (context *ClientContext) {
	context = client.contextPool.Get().(*ClientContext)
	context.InitBaseContext()
	context.Client = client
	context.Retried = 0
	if client.UserData != nil {
		for k, v := range client.UserData {
			context.SetInterface(k, v)
		}
	}
	if settings == nil {
		context.InvokeSettings = InvokeSettings{
			Timeout: client.timeout,
			Retry:   client.retry,
		}
	} else {
		if settings.userData != nil {
			for k, v := range settings.userData {
				context.SetInterface(k, v)
			}
		}
		context.InvokeSettings = *settings
		if settings.Timeout <= 0 {
			context.Timeout = client.timeout
		}
		if settings.Retry <= 0 {
			context.Retry = client.retry
		}
	}
	return context
}
source: func (c *statefulSets) GetScale(statefulSetName string, options metav1.GetOptions) (result *autoscalingv1.Scale, err error) {
	result = &autoscalingv1.Scale{}
	err = c.client.Get().
		Namespace(c.ns).
		Resource("statefulsets").
		Name(statefulSetName).
		SubResource("scale").
		VersionedParams(&options, scheme.ParameterCodec).
		Do().
		Into(result)
	return
}
source: func NewDatacenter(f *Folder) *Datacenter {
	dc := &Datacenter{
		isESX: f.Self == esx.RootFolder.Self,
	}

	if dc.isESX {
		dc.Datacenter = esx.Datacenter
	}

	f.putChild(dc)

	dc.createFolders()

	return dc
}
source: func (L *State) IsGoStruct(index int) bool {
	return C.clua_isgostruct(L.s, C.int(index)) != 0
}
source: func newRows(qr *sqltypes.Result, c *converter) driver.Rows {
	return &rows{qr: qr, convert: c}
}
source: func (s *DescribeTrailsInput) SetTrailNameList(v []*string) *DescribeTrailsInput {
	s.TrailNameList = v
	return s
}
source: func (c *limitRanges) Watch(opts api.ListOptions) (watch.Interface, error) {
	return c.r.Get().
		Prefix("watch").
		Namespace(c.ns).
		Resource("limitRanges").
		VersionedParams(&opts, api.Scheme).
		Watch()
}
source: func (db *DB) SMembers(key []byte) ([][]byte, error) {
	if err := checkKeySize(key); err != nil {
		return nil, err
	}

	start := db.sEncodeStartKey(key)
	stop := db.sEncodeStopKey(key)

	v := make([][]byte, 0, 16)

	it := db.bucket.RangeLimitIterator(start, stop, store.RangeROpen, 0, -1)
	defer it.Close()

	for ; it.Valid(); it.Next() {
		_, m, err := db.sDecodeSetKey(it.Key())
		if err != nil {
			return nil, err
		}

		v = append(v, m)
	}

	return v, nil
}
source: func (i *Instance) configureLinuxRules(cfg *ACLInfo) error {

	// These checks are for rather unusal error scenarios. We should
	// never see errors here. But better safe than sorry.
	if cfg.CgroupMark == "" {
		return errors.New("no mark value found")
	}

	if cfg.TCPPortSet == "" {
		return fmt.Errorf("port set was not found for the contextID. This should not happen")
	}

	return i.addChainRules(cfg)
}
source: func validator(req *csr.CertificateRequest) error {
	if req.CN != "" {
		return nil
	}

	if len(req.Names) == 0 {
		return cferr.Wrap(cferr.PolicyError, cferr.InvalidRequest, errors.New("missing subject information"))
	}

	for i := range req.Names {
		if csr.IsNameEmpty(req.Names[i]) {
			return cferr.Wrap(cferr.PolicyError, cferr.InvalidRequest, errors.New("missing subject information"))
		}
	}

	return nil
}
source: func (engine *Engine) NoAutoCondition(no ...bool) *Session {
	session := engine.NewSession()
	session.isAutoClose = true
	return session.NoAutoCondition(no...)
}
source: func (s *ShareResult) SetInviteePrincipalId(v string) *ShareResult {
	s.InviteePrincipalId = &v
	return s
}
source: func (app *App) SetCookieExpire(d time.Duration) {
	if d != 0 {
		app.cookieExpire = d
	}
}
source: func (p *blockPrefetcher) handleCriticalRequests() {
	for {
		// Fulfill any status requests since the user could be waiting
		// for them.
		select {
		case req := <-p.prefetchStatusCh.Out():
			p.handleStatusRequest(req.(*prefetchStatusRequest))
		default:
			return
		}
	}
}
source: func (cs *CredentialSupport) GetDeliverServiceCredentials(
	channelID string,
	appendStaticRoots bool,
) (credentials.TransportCredentials, error) {
	cs.RLock()
	defer cs.RUnlock()

	var creds credentials.TransportCredentials
	tlsConfig := &tls.Config{
		Certificates: []tls.Certificate{cs.clientCert},
	}
	certPool := x509.NewCertPool()

	rootCACerts, exists := cs.OrdererRootCAsByChain[channelID]
	if !exists {
		commLogger.Errorf("Attempted to obtain root CA certs of a non existent channel: %s", channelID)
		return nil, fmt.Errorf("didn't find any root CA certs for channel %s", channelID)
	}

	for _, cert := range rootCACerts {
		block, _ := pem.Decode(cert)
		if block != nil {
			cert, err := x509.ParseCertificate(block.Bytes)
			if err == nil {
				certPool.AddCert(cert)
			} else {
				commLogger.Warningf("Failed to add root cert to credentials: %s", err)
			}
		} else {
			commLogger.Warning("Failed to add root cert to credentials")
		}
	}
	if appendStaticRoots {
		for _, cert := range cs.ServerRootCAs {
			block, _ := pem.Decode(cert)
			if block != nil {
				cert, err := x509.ParseCertificate(block.Bytes)
				if err == nil {
					certPool.AddCert(cert)
				} else {
					commLogger.Warningf("Failed to add root cert to credentials: %s", err)
				}
			} else {
				commLogger.Warning("Failed to add root cert to credentials")
			}
		}
	}
	tlsConfig.RootCAs = certPool
	creds = credentials.NewTLS(tlsConfig)
	return creds, nil
}
source: func (f *FakeDocker) IsImageInLocalRegistry(imageName string) (bool, error) {
	f.LocalRegistryImage = imageName
	return f.LocalRegistryResult, f.LocalRegistryError
}
source: func (c Cap) AddCap(other Cap) Cap {
	if c.IsEmpty() {
		return other
	}
	if other.IsEmpty() {
		return c
	}

	// We round up the distance to ensure that the cap is actually contained.
	// TODO(roberts): Do some error analysis in order to guarantee this.
	dist := ChordAngleBetweenPoints(c.center, other.center).Add(other.radius)
	if newRad := dist.Expanded(dblEpsilon * float64(dist)); newRad > c.radius {
		c.radius = newRad
	}
	return c
}
source: func New(dispatcher Dispatcher, opts ...options.Opt) *Service {
	params := defaultParams()
	options.Apply(params, opts)

	return &Service{
		params:     *params,
		dispatcher: dispatcher,
	}
}
source: func (c Client) RemoveAllBucketNotification(bucketName string) error {
	return c.SetBucketNotification(bucketName, BucketNotification{})
}
source: func APIVersions(resp *http.Response, versionHeader string) []APIVersion {
	versions := []APIVersion{}
	if versionHeader != "" {
		for _, supportedVersions := range resp.Header[http.CanonicalHeaderKey(versionHeader)] {
			for _, version := range strings.Fields(supportedVersions) {
				versions = append(versions, ParseAPIVersion(version))
			}
		}
	}
	return versions
}
source: func (spec *ContainerSpec) Validate() error {
	if spec.Name == "" {
		return errors.New("spec name is missing")
	}
	if spec.Image == "" && spec.ImageDetails.ImagePath == "" {
		return errors.New("spec image details is missing")
	}
	for _, fs := range spec.Files {
		if fs.Name == "" {
			return errors.New("file set name is missing")
		}
		if fs.MountPath == "" {
			return errors.Errorf("mount path is missing for file set %q", fs.Name)
		}
	}
	if spec.ProviderContainer != nil {
		return spec.ProviderContainer.Validate()
	}
	return nil
}
source: func LookupIdent(ident string) Type {
	if tok, ok := keywords[ident]; ok {
		return tok
	}
	return IDENT
}
source: func (m *clusterQuotaMapper) removeQuota(quotaName string) {
	m.lock.Lock()
	defer m.lock.Unlock()

	delete(m.requiredQuotaToSelector, quotaName)
	delete(m.completedQuotaToSelector, quotaName)
	delete(m.quotaToNamespaces, quotaName)
	for namespaceName, quotas := range m.namespaceToQuota {
		if quotas.Has(quotaName) {
			quotas.Delete(quotaName)
			for _, listener := range m.listeners {
				listener.RemoveMapping(quotaName, namespaceName)
			}
		}
	}
}
source: func (c MultiLogger) Log(keyvals ...interface{}) {
	for _, l := range c {
		if !IsDisabled(l) {
			l.Log(keyvals...)
		}
	}
}
source: func identifyGroups(stmt *influxql.SelectStatement) ([]*groupInfo, error) {
	v := &groupVisitor{}
	influxql.Walk(v, stmt.Fields)
	if v.err != nil {
		return nil, v.err
	}

	// Attempt to take the calls and variables and put them into groups.
	if len(v.refs) > 0 {
		// If any of the calls are not selectors, we have an error message.
		for _, fn := range v.calls {
			if !influxql.IsSelector(fn.call) {
				return nil, errors.New("mixing aggregate and non-aggregate queries is not supported")
			}
		}

		// All of the functions are selectors. If we have more than 1, then we have another error message.
		if len(v.calls) > 1 {
			return nil, errors.New("mixing multiple selector functions with tags or fields is not supported")
		}

		// Otherwise, we create a single group.
		var call *influxql.Call
		if len(v.calls) == 1 {
			call = v.calls[0].call
		}
		return []*groupInfo{{
			call:     call,
			refs:     v.refs,
			selector: true, // Always a selector if we are here.
		}}, nil
	}

	// We do not have any auxiliary fields so each of the function calls goes into
	// its own group.
	groups := make([]*groupInfo, 0, len(v.calls))
	for _, fn := range v.calls {
		groups = append(groups, &groupInfo{call: fn.call})
	}

	// If there is exactly one group and that contains a selector, then mark it as so.
	if len(groups) == 1 && influxql.IsSelector(groups[0].call) {
		groups[0].selector = true
	}
	return groups, nil
}
source: func mergeDigitalWalletAuthorizationMap(newAuths []DigitalWalletAuthorization, oldAuths []DigitalWalletAuthorization) []DigitalWalletAuthorization {
OLDAUTHS:
	for _, oldAuth := range oldAuths {
		// check all new auths to make sure it isn't overwritten
		for _, newAuth := range newAuths {
			// overwritten, continue with the next oldAuth
			if oldAuth.RequestedLabel == newAuth.RequestedLabel {
				continue OLDAUTHS
			}
		}
		// All new auths checked and no match, so lets append it
		newAuths = append(newAuths, oldAuth)
	}

	return newAuths
}
source: func (m *Debug) Pack() []byte {
	data := new(bytes.Buffer)
	binary.Write(data, binary.LittleEndian, m.TIME_BOOT_MS)
	binary.Write(data, binary.LittleEndian, m.VALUE)
	binary.Write(data, binary.LittleEndian, m.IND)
	return data.Bytes()
}
source: func (d *domainClient) CompositingReasons(ctx context.Context, args *CompositingReasonsArgs) (reply *CompositingReasonsReply, err error) {
	reply = new(CompositingReasonsReply)
	if args != nil {
		err = rpcc.Invoke(ctx, "LayerTree.compositingReasons", args, reply, d.conn)
	} else {
		err = rpcc.Invoke(ctx, "LayerTree.compositingReasons", nil, reply, d.conn)
	}
	if err != nil {
		err = &internal.OpError{Domain: "LayerTree", Op: "CompositingReasons", Err: err}
	}
	return
}
source: func (in *NetworkPolicySpec) DeepCopy() *NetworkPolicySpec {
	if in == nil {
		return nil
	}
	out := new(NetworkPolicySpec)
	in.DeepCopyInto(out)
	return out
}
source: func New(dsn string, pex bool) (*Amqp, error) {
	conn, ch, err := createConnAndChan(dsn)
	if err != nil {
		return nil, err
	}

	return &Amqp{
		conn:            conn,
		ch:              ch,
		passiveExchange: pex,
	}, nil
}
source: func (s *DescribeCacheOutput) SetCacheMissPercentage(v float64) *DescribeCacheOutput {
	s.CacheMissPercentage = &v
	return s
}
source: func (p *Pipe) Push(procs ...Filter) *Pipe {
	for _, proc := range procs {
		if proc == nil {
			continue
		}

		err := make(chan error, 1)
		p.errors = append(p.errors, err)

		r, w := io.Pipe()

		go func(p Filter, r io.Reader, w *io.PipeWriter, err chan error) {
			err <- p(r, w)
			w.Close()
		}(proc, p.reader, w, err)

		p.reader = r
	}
	return p
}
source: func (s *Span) SetOperationName(name string) opentracing.Span {
	s.Trace.Resource = name
	return s
}
source: func NewTeam(Id string, Name string) *Team {
	s := new(Team)
	s.Id = Id
	s.Name = Name
	return s
}
source: func (s *ProductionBranch) SetLastDeployTime(v time.Time) *ProductionBranch {
	s.LastDeployTime = &v
	return s
}
source: func MakePreimageFromStr(newPreimage string) (Preimage, error) {
	// Return error if preimage string is of incorrect length.
	if len(newPreimage) != PreimageSize*2 {
		return Preimage{}, fmt.Errorf("invalid preimage string length "+
			"of %v, want %v", len(newPreimage), PreimageSize*2)
	}

	preimage, err := hex.DecodeString(newPreimage)
	if err != nil {
		return Preimage{}, err
	}

	return MakePreimage(preimage)
}
source: func (sp *serverPeer) OnGetBlocks(_ *peer.Peer, msg *wire.MsgGetBlocks) {
	// Find the most recent known block in the best chain based on the block
	// locator and fetch all of the block hashes after it until either
	// wire.MaxBlocksPerMsg have been fetched or the provided stop hash is
	// encountered.
	//
	// Use the block after the genesis block if no other blocks in the
	// provided locator are known.  This does mean the client will start
	// over with the genesis block if unknown block locators are provided.
	//
	// This mirrors the behavior in the reference implementation.
	chain := sp.server.chain
	hashList := chain.LocateBlocks(msg.BlockLocatorHashes, &msg.HashStop,
		wire.MaxBlocksPerMsg)

	// Generate inventory message.
	invMsg := wire.NewMsgInv()
	for i := range hashList {
		iv := wire.NewInvVect(wire.InvTypeBlock, &hashList[i])
		invMsg.AddInvVect(iv)
	}

	// Send the inventory message if there is anything to send.
	if len(invMsg.InvList) > 0 {
		invListLen := len(invMsg.InvList)
		if invListLen == wire.MaxBlocksPerMsg {
			// Intentionally use a copy of the final hash so there
			// is not a reference into the inventory slice which
			// would prevent the entire slice from being eligible
			// for GC as soon as it's sent.
			continueHash := invMsg.InvList[invListLen-1].Hash
			sp.continueHash = &continueHash
		}
		sp.QueueMessage(invMsg, nil)
	}
}
source: func newResponseStats() *responseStats {
	r := &responseStats{}
	r.totalStatusCodes = make(map[int]int)
	r.lock = &sync.Mutex{}
	r.reset()
	return r
}
source: func IsNotAlive(err error) bool {
	_, ok := errors.Cause(err).(notAliveError)
	return ok
}
source: func reportAgentError(u *Uniter, userMessage string, err error) {
	// If a non-nil error is reported (e.g. due to an operation failing),
	// set the agent status to Failed.
	if err == nil {
		return
	}
	logger.Errorf("%s: %v", userMessage, err)
	err2 := setAgentStatus(u, status.Failed, userMessage, nil)
	if err2 != nil {
		logger.Errorf("updating agent status: %v", err2)
	}
}
source: func complete(s *awsxray.Segment, status int) {
	switch {
	case status >= 500:
		s.Fault = true
	case status >= 400:
		s.Error = true
	}
	s.HTTP.Response.Status = status
	s.EndTime = float64(time.Now().Truncate(time.Millisecond).UnixNano()) / 1e9
}
source: func (t *transacter) Stop() {
	t.stopped = true
	t.endingWg.Wait()
	for _, c := range t.conns {
		c.Close()
	}
}
source: func NewMessagesReceivedTotalStatsHandler(sub Subsystem, vec *prometheus.CounterVec) *MessagesReceivedTotalStatsHandler {
	return &MessagesReceivedTotalStatsHandler{
		baseStatsHandler: baseStatsHandler{
			subsystem: sub,
			collector: vec,
		},
		vec: vec,
	}
}
source: func (c *TCP) Subscribe(tags []string) error {

	if len(tags) == 0 {
		return fmt.Errorf("Unable to subscribe - missing tags")
	}

	return c.encoder.Encode(&mist.Message{Command: "subscribe", Tags: tags})
}
source: func (r *REST) NewGetOptions() (runtime.Object, bool, string) {
	return &buildapi.BuildLogOptions{}, false, ""
}
source: func ParseImageStreamImageName(input string) (name string, id string, err error) {
	segments := strings.SplitN(input, "@", 3)
	switch len(segments) {
	case 2:
		name = segments[0]
		id = segments[1]
		if len(name) == 0 || len(id) == 0 {
			err = fmt.Errorf("image stream image name %q must have a name and ID", input)
		}
	default:
		err = fmt.Errorf("expected exactly one @ in the isimage name %q", input)
	}
	return
}
source: func Start(config Config) {
	/*
	 *  Start the Reaper with configuration options. This allows you to
	 *  reap processes even if the current pid isn't running as pid 1.
	 *  So ... use with caution!!
	 *
	 *  In most cases, you are better off just using Reap() as that
	 *  checks if we are running as Pid 1.
	 */
	if !config.DisablePid1Check {
		mypid := os.Getpid()
		if 1 != mypid {
			fmt.Printf(" - Grim reaper disabled, pid not 1\n")
			return
		}
	}

	/*
	 *  Ok, so either pid 1 checks are disabled or we are the grandma
	 *  of 'em all, either way we get to play the grim reaper.
	 *  You will be missed, Terry Pratchett!! RIP
	 */
	go reapChildren(config)

}
source: func AuthUserUserPermissionByUserIDPermissionID(db XODB, userID float64, permissionID float64) (*AuthUserUserPermission, error) {
	var err error

	// sql query
	const sqlstr = `SELECT ` +
		`id, user_id, permission_id ` +
		`FROM django.auth_user_user_permissions ` +
		`WHERE user_id = :1 AND permission_id = :2`

	// run query
	XOLog(sqlstr, userID, permissionID)
	auup := AuthUserUserPermission{
		_exists: true,
	}

	err = db.QueryRow(sqlstr, userID, permissionID).Scan(&auup.ID, &auup.UserID, &auup.PermissionID)
	if err != nil {
		return nil, err
	}

	return &auup, nil
}
source: func GetCRDStorageVersion(crd *CustomResourceDefinition) (string, error) {
	for _, v := range crd.Spec.Versions {
		if v.Storage {
			return v.Name, nil
		}
	}
	// This should not happened if crd is valid
	return "", fmt.Errorf("invalid CustomResourceDefinition, no storage version")
}
source: func (r Virtual_Guest) GetOperatingSystem() (resp datatypes.Software_Component_OperatingSystem, err error) {
	err = r.Session.DoRequest("SoftLayer_Virtual_Guest", "getOperatingSystem", nil, &r.Options, &resp)
	return
}
source: func (a *Agent) ListKeys() (*KeyringResponse, error) {
	var resp KeyringResponse
	_, err := a.client.query("/v1/agent/keyring/list", &resp, nil)
	if err != nil {
		return nil, err
	}
	return &resp, nil
}
source: func WaitUntilAMIAvailable(ctx aws.Context, conn *ec2.EC2, imageId string) error {
	imageInput := ec2.DescribeImagesInput{
		ImageIds: []*string{&imageId},
	}

	waitOpts := getWaiterOptions()
	if len(waitOpts) == 0 {
		// Bump this default to 30 minutes because the aws default
		// of ten minutes doesn't work for some of our long-running copies.
		waitOpts = append(waitOpts, request.WithWaiterMaxAttempts(120))
	}
	err := conn.WaitUntilImageAvailableWithContext(
		ctx,
		&imageInput,
		waitOpts...)
	return err
}
source: func GetEditMode(w http.ResponseWriter, req *http.Request) bool {
	return admin.ActionBar.EditMode(w, req)
}
source: func GetCmdPath(cmd string) (string, error) {
	if filepath.IsAbs(cmd) {
		return cmd, nil
	}
	return exec.LookPath(cmd)
}
source: func SetupPluginEnv(settings helm_env.EnvSettings,
	shortName, base string) {
	for key, val := range map[string]string{
		"HELM_PLUGIN_NAME": shortName,
		"HELM_PLUGIN_DIR":  base,
		"HELM_BIN":         os.Args[0],

		// Set vars that may not have been set, and save client the
		// trouble of re-parsing.
		"HELM_PLUGIN": settings.PluginDirs(),
		"HELM_HOME":   settings.Home.String(),

		// Set vars that convey common information.
		"HELM_PATH_REPOSITORY":       settings.Home.Repository(),
		"HELM_PATH_REPOSITORY_FILE":  settings.Home.RepositoryFile(),
		"HELM_PATH_CACHE":            settings.Home.Cache(),
		"HELM_PATH_LOCAL_REPOSITORY": settings.Home.LocalRepository(),
		"HELM_PATH_STARTER":          settings.Home.Starters(),

		"TILLER_HOST":      settings.TillerHost,
		"TILLER_NAMESPACE": settings.TillerNamespace,
	} {
		os.Setenv(key, val)
	}

	if settings.Debug {
		os.Setenv("HELM_DEBUG", "1")
	}
}
source: func CreateCustomResourceDefinitions(clientset apiextensionsclient.Interface) error {
	if err := createCNPCRD(clientset); err != nil {
		return err
	}

	if err := createCEPCRD(clientset); err != nil {
		return err
	}

	return nil
}
source: func ToLower(src []byte) []byte {
	for i, c := range src {
		if c >= 'A' && c <= 'Z' {
			src[i] = c + ('a' - 'A')
		}
	}
	return src
}
source: func (module *BBPWMModule) EnablePin(pin Pin, enabled bool) error {
	if module.definedPins[pin] == nil {
		return fmt.Errorf("Pin %d is not known as a PWM pin on module %s", pin, module.GetName())
	}

	openPin := module.openPins[pin]
	if enabled {
		// ensure pin is enabled by creating an open pin
		if openPin == nil {
			p, e := module.makeOpenPin(pin)
			if e != nil {
				return e
			}
			module.openPins[pin] = p
			return p.enabled(true)
		}
	} else {
		// disable the pin if enabled
		if openPin != nil {
			return openPin.enabled(false)
		}
	}
	return nil
}
source: func checkContentType(contentType string) error {
	if contentType == "" {
		return nil
	}

	mType, mParams, err := mime.ParseMediaType(contentType)
	if err != nil {
		return err
	}

	if mType != "text/xml" && mType != "application/xml" {
		return fmt.Errorf("unsupported content type %q", mType)
	}

	charset, _ := mParams["charset"]
	if charset != "" && strings.ToLower(charset) != "utf-8" {
		return fmt.Errorf("unsupported content charset %q", charset)
	}

	return nil
}
source: func (f Form) RadioButton(opts tags.Options) *tags.Tag {
	return f.RadioButtonTag(opts)
}
source: func ListIPChannels(client *TwilioIPMessagingClient, serviceSid string) (*IPChannelList, error) {
	var channelList *IPChannelList

	body, err := client.get(nil, "/Services/"+serviceSid+"/Channels.json")

	if err != nil {
		return channelList, err
	}

	channelList = new(IPChannelList)
	channelList.Client = client
	err = json.Unmarshal(body, channelList)

	return channelList, err
}
source: func (eh guildBanRemoveEventHandler) Handle(s *Session, i interface{}) {
	if t, ok := i.(*GuildBanRemove); ok {
		eh(s, t)
	}
}
source: func Convert_template_TemplateInstanceList_To_v1_TemplateInstanceList(in *template.TemplateInstanceList, out *v1.TemplateInstanceList, s conversion.Scope) error {
	return autoConvert_template_TemplateInstanceList_To_v1_TemplateInstanceList(in, out, s)
}
source: func Newe(err error) Goof {

	// check to see if the provided error is already a Goof
	gerr, ok := err.(Goof)

	// if the provided error is not a Goof we need to
	// wrap it as a Goof by creating a new Goof
	// instance using the provided error's message
	if !ok {
		return New(err.Error())
	}

	// check to see if there is an inner error
	ierr, ok := gerr.Fields()["inner"].(error)
	if !ok {
		return gerr
	}

	// recurse with the inner error
	gerr.Fields()["inner"] = Newe(ierr)
	return gerr
}
source: func (d *defaultSCCMatcher) FindApplicableSCCs(namespace string, users ...user.Info) ([]*securityapi.SecurityContextConstraints, error) {
	var matchedConstraints []*securityv1.SecurityContextConstraints
	constraints, err := d.cache.List(labels.Everything())
	if err != nil {
		return nil, err
	}

	// filter out SCCs if we got some users, leave as is if not
	if len(users) == 0 {
		matchedConstraints = constraints
	} else {
		for _, constraint := range constraints {
			for _, user := range users {
				if ConstraintAppliesTo(constraint.Name, constraint.Users, constraint.Groups, user, namespace, d.authorizer) {
					matchedConstraints = append(matchedConstraints, constraint)
					break
				}
			}
		}
	}

	sort.Sort(sccsort.ByPriority(matchedConstraints))

	internalMatchedConstraints := []*securityapi.SecurityContextConstraints{}
	for _, externalConstraint := range matchedConstraints {
		internalConstraint := &securityapi.SecurityContextConstraints{}
		if err := securityapiv1.Convert_v1_SecurityContextConstraints_To_security_SecurityContextConstraints(externalConstraint, internalConstraint, nil); err != nil {
			return nil, err
		}
		internalMatchedConstraints = append(internalMatchedConstraints, internalConstraint)
	}

	return internalMatchedConstraints, nil
}
source: func ReadSliceNoNest(rd io.Reader) (s Slice, err error) {
	// Just in case of programming mistake. Not intentionally used.
	defer func() {
		if r := recover(); r != nil {
			err = errors.New(fmt.Sprint(r))
		}
	}()

	return decodeSlice(rd, "", false)
}
source: func SetOutput(domain string, level Level, w io.WriteCloser, commiter func(sl *Slog), formatter func(l *Slog) ([]byte, error), nl int) error {
	log = &Slog{
		Commit:    commiter,
		Formatter: formatter,
		Writter:   w,
		Level:     level,
	}
	err := log.Init(domain, nl)
	if err != nil {
		return e.Forward(err)
	}
	return nil
}
source: func buildEphemeralDevices(cloud awsup.AWSCloud, machineType string) (map[string]*BlockDeviceMapping, error) {
	mt, err := awsup.GetMachineTypeInfo(machineType)
	if err != nil {
		return nil, fmt.Errorf("failed to find instance type details on: %s, error: %s", machineType, err)
	}

	blockDeviceMappings := make(map[string]*BlockDeviceMapping)

	for _, ed := range mt.EphemeralDevices() {
		blockDeviceMappings[ed.DeviceName] = &BlockDeviceMapping{VirtualName: fi.String(ed.VirtualName)}
	}

	return blockDeviceMappings, nil
}
source: func (uuid UUID) Array() Array {
	if len(uuid) != 16 {
		panic("invalid uuid")
	}
	var a Array
	copy(a[:], uuid)
	return a
}
source: func ListClearOp(binName string) *Operation {
	return &Operation{opType: _CDT_MODIFY, binName: binName, binValue: ListValue{_CDT_LIST_CLEAR}, encoder: listGenericOpEncoder}
}
source: func (i *FuncInterceptor) AfterTaskComplete(activity *swf.PollForActivityTaskOutput, result interface{}) {
	if i.AfterTaskCompleteFn != nil {
		i.AfterTaskCompleteFn(activity, result)
	}
}
source: func (self *OAuth1Mixin) RedirectRequired(r *http.Request) bool {
	return r.URL.Query().Get("oauth_verifier") == ""
}
source: func (a *MetricsAPIInstaller) NewWebService() *restful.WebService {
	ws := new(restful.WebService)
	ws.Path(a.prefix)
	// a.prefix contains "prefix/group/version"
	ws.Doc("API at " + a.prefix)
	// Backwards compatibility, we accepted objects with empty content-type at V1.
	// If we stop using go-restful, we can default empty content-type to application/json on an
	// endpoint by endpoint basis
	ws.Consumes("*/*")
	mediaTypes, streamMediaTypes := negotiation.MediaTypesForSerializer(a.group.Serializer)
	ws.Produces(append(mediaTypes, streamMediaTypes...)...)
	ws.ApiVersion(a.group.GroupVersion.String())

	return ws
}
source: func (s *orderService) Get(ctx context.Context, req *orderpb.GetRequest) (*orderpb.Order, error) {
	// validate input
	if err := validation.Validate(req); err != nil {
		return nil, err
	}
	// order wrapper
	o := &order{
		Order: orderpb.Order{
			Id: req.GetId(),
		},
	}

	// acquire order lock
	unlock, err := locker.Handler().TryLock(o, locker.DefaultTimeout)
	if err != nil {
		return nil, err
	}
	defer unlock()

	// get and return order
	return &o.Order, storage.Handler().One(o)
}
source: func ProxyConfigMap(proxySettings proxy.Settings) map[string]interface{} {
	settings := make(map[string]interface{})
	addIfNotEmpty(settings, HTTPProxyKey, proxySettings.Http)
	addIfNotEmpty(settings, HTTPSProxyKey, proxySettings.Https)
	addIfNotEmpty(settings, FTPProxyKey, proxySettings.Ftp)
	addIfNotEmpty(settings, NoProxyKey, proxySettings.NoProxy)
	return settings
}
source: func (c *Carbon) Eq(carb *Carbon) bool {
	return c.Equal(carb.Time)
}
source: func (uvm *UtilityVM) Wait() error {
	err := uvm.hcsSystem.Wait()

	// outputProcessingCancel will only cancel waiting for the vsockexec
	// connection, it won't stop output processing once the connection is
	// established.
	if uvm.outputProcessingCancel != nil {
		uvm.outputProcessingCancel()
	}
	uvm.waitForOutput()

	return err
}
source: func AnalyticsEqual(o1, o2 *AnalyticsOption) bool {
	if o1 != nil {
		return o1.Equal(o2)
	}
	if o2 != nil {
		return o2.Equal(o1)
	}
	return true
}
source: func (dd *DirData) RemoveEntry(ctx context.Context, name string) (
	unrefs []BlockInfo, err error) {
	topBlock, err := dd.GetTopBlock(ctx, BlockWrite)
	if err != nil {
		return nil, err
	}

	off := StringOffset(name)
	ptr, parentBlocks, block, _, _, _, err := dd.tree.getBlockAtOffset(
		ctx, topBlock, &off, BlockWrite)
	if err != nil {
		return nil, err
	}
	dblock := block.(*DirBlock)

	if _, exists := dblock.Children[name]; !exists {
		// Nothing to do.
		return nil, nil
	}
	delete(dblock.Children, name)

	// For now, just leave the block empty, at its current place in
	// the tree.  TODO: remove empty blocks all the way up the tree
	// and shift parent pointers around as needed.
	return dd.processModifiedBlock(ctx, ptr, parentBlocks, dblock)
}
source: func (self *simplePBundle) IntQueryParameter(name string, def int64) int64 {
	raw, ok := self.Query(name)
	if !ok {
		return def
	}
	i, err := strconv.ParseInt(raw, 10, 64)
	if err != nil {
		return def
	}
	return i
}
source: func newAdminRoot(h *apiHandler, adminAPIs map[int]interface{}) *adminRoot {
	r := &adminRoot{
		apiHandler: h,
		adminAPIs:  adminAPIs,
	}
	return r
}
source: func (c *Controller) updateParamsLocked(params ControllerParams) {
	c.params = params

	maxInterval := time.Duration(option.Config.MaxControllerInterval) * time.Second
	if maxInterval > 0 && params.RunInterval > maxInterval {
		c.getLogger().Infof("Limiting interval to %s", maxInterval)
		c.params.RunInterval = maxInterval
	}
}
source: func (c *Controller) ensureModel(modelUUID string) *Model {
	c.mu.Lock()

	model, found := c.models[modelUUID]
	if !found {
		model = newModel(c.metrics, c.hub, c.manager.new())
		c.models[modelUUID] = model
	} else {
		model.setStale(false)
	}

	c.mu.Unlock()
	return model
}
source: func (s *ListCustomVerificationEmailTemplatesOutput) SetCustomVerificationEmailTemplates(v []*CustomVerificationEmailTemplate) *ListCustomVerificationEmailTemplatesOutput {
	s.CustomVerificationEmailTemplates = v
	return s
}
source: func (in *RawExtension) DeepCopy() *RawExtension {
	if in == nil {
		return nil
	}
	out := new(RawExtension)
	in.DeepCopyInto(out)
	return out
}
source: func (c *MockProducer) Close() {
	if !atomic.CompareAndSwapInt32(&c.closed, 0, 1) {
		// Already closed
		return
	}

	c.ledger.Unregister(c.rcvch)
	close(c.rcvch)
}
source: func (r Ticket_Attachment_File) GetUpdate() (resp datatypes.Ticket_Update, err error) {
	err = r.Session.DoRequest("SoftLayer_Ticket_Attachment_File", "getUpdate", nil, &r.Options, &resp)
	return
}
source: func Connect(port string, verbose bool, options ...ConnectOption) (*RemoteDebugger, error) {
	client := httpclient.NewHttpClient("http://" + port)

	for _, setOption := range options {
		setOption(client)
	}

	remote := &RemoteDebugger{
		http:      client,
		requests:  make(chan Params),
		responses: map[int]chan json.RawMessage{},
		callbacks: map[string]EventCallback{},
		events:    make(chan wsMessage, 256),
		closed:    make(chan bool),
		verbose:   verbose,
	}

	// remote.http.Verbose = verbose
	if verbose {
		httpclient.StartLogging(false, true, false)
	}

	if err := remote.connectWs(nil); err != nil {
		return nil, err
	}

	go remote.sendMessages()
	go remote.processEvents()
	return remote, nil
}
source: func (decoder *HTTPDecoder) Decode(v interface{}, body io.Reader, contentType string) error {
	now := time.Now()
	defer MeasureSince([]string{"goa", "decode", contentType}, now)
	var p *decoderPool
	if contentType == "" {
		// Default to JSON
		contentType = "application/json"
	} else {
		if mediaType, _, err := mime.ParseMediaType(contentType); err == nil {
			contentType = mediaType
		}
	}
	p = decoder.pools[contentType]
	if p == nil {
		p = decoder.pools["*/*"]
	}
	if p == nil {
		return nil
	}

	// the decoderPool will handle whether or not a pool is actually in use
	d := p.Get(body)
	defer p.Put(d)
	return d.Decode(v)
}
source: func (o *oracleInstance) Addresses(ctx context.ProviderCallContext) ([]network.Address, error) {
	addresses := []network.Address{}

	ips, err := o.publicAddressesAssociations()
	if err != nil {
		return nil, errors.Trace(err)
	}

	if len(o.machine.Attributes.Network) > 0 {
		for name, val := range o.machine.Attributes.Network {
			if _, ip, err := oraclenetwork.GetMacAndIP(val.Address); err == nil {
				address := network.NewScopedAddress(ip, network.ScopeCloudLocal)
				addresses = append(addresses, address)
			} else {
				logger.Errorf("failed to get IP address for NIC %q: %q", name, err)
			}
		}
	}

	for _, val := range ips {
		address := network.NewScopedAddress(val.Ip, network.ScopePublic)
		addresses = append(addresses, address)
	}

	return addresses, nil
}
source: func (s *AuthorizationService) FindAuthorizations(ctx context.Context, filter platform.AuthorizationFilter, opts ...platform.FindOptions) ([]*platform.Authorization, int, error) {
	return s.FindAuthorizationsFn(ctx, filter, opts...)
}
source: func ParseDSAPrivateKey(der []byte) (*dsa.PrivateKey, error) {
	var k struct {
		Version int
		P       *big.Int
		Q       *big.Int
		G       *big.Int
		Priv    *big.Int
		Pub     *big.Int
	}
	rest, err := asn1.Unmarshal(der, &k)
	if err != nil {
		return nil, errors.New("ssh: failed to parse DSA key: " + err.Error())
	}
	if len(rest) > 0 {
		return nil, errors.New("ssh: garbage after DSA key")
	}

	return &dsa.PrivateKey{
		PublicKey: dsa.PublicKey{
			Parameters: dsa.Parameters{
				P: k.P,
				Q: k.Q,
				G: k.G,
			},
			Y: k.Priv,
		},
		X: k.Pub,
	}, nil
}
source: func buildConnectionString(username, password string, hasPassword bool, host, port, dbname, args string) string {
	// Build a new connection string
	var buf bytes.Buffer

	if !strings.HasPrefix(username, "postgres://") {
		buf.WriteString("postgres://")
	}

	if (username != "") && hasPassword {
		buf.WriteString(username + ":" + password + "@")
	} else if username != "" {
		buf.WriteString(username + "@")
	} else if hasPassword {
		buf.WriteString(":" + password + "@")
	}

	if host != "" {
		buf.WriteString(host)
	}
	if port != "" {
		buf.WriteString(":" + port)
	}

	buf.WriteString("/" + dbname)

	if args != "" {
		buf.WriteString("?" + args)
	} else {
		buf.WriteString("?sslmode=disable")
	}

	if Verbose {
		log.Println("Connection string:", buf.String())
	}

	return buf.String()
}
source: func (gq *Schema) AddExtensions(e ...Extension) {
	gq.extensions = append(gq.extensions, e...)
}
source: func NewPointFromQuadkeyString(key string) *Point {
	i, _ := strconv.ParseInt(key, 4, 64)
	return NewPointFromQuadkey(i, len(key))
}
source: func (p *PathObserver) Follow(path, hash string) {
	p.FollowSpec(PathSpec{Hash: hash, Path: path, Sequence: p.sequencer(path, hash)})
}
source: func ResolveAuthPerHost(authPerHost map[string]Headerer) map[string]http.Header {
	hostHeaders := make(map[string]http.Header, len(authPerHost))
	for k, v := range authPerHost {
		hostHeaders[k] = v.GetHeader()
	}
	return hostHeaders
}
source: func (c *Client) ErrorWithExtrasAndContext(ctx context.Context, level string, err error, extras map[string]interface{}) {
	c.ErrorWithStackSkipWithExtrasAndContext(ctx, level, err, 1, extras)
}
source: func (s *State) Middleware(c *router.Context, next router.Handler) {
	state, settings := s.checkSettings(c.Context)
	if settings.Enabled {
		started := clock.Now(c.Context)
		req := c.Request
		userAgent, ok := req.Header["User-Agent"]
		if !ok || len(userAgent) == 0 {
			userAgent = []string{"Unknown"}
		}
		ctx := c.Context
		contentLength := c.Request.ContentLength
		nrw := newResponseWriter(c.Writer)
		c.Writer = nrw
		defer func() {
			dur := clock.Now(ctx).Sub(started)
			metric.UpdateServerMetrics(ctx, c.HandlerPath, nrw.Status(), dur,
				contentLength, nrw.Size(), userAgent[0])
		}()
		next(c)
		s.flushIfNeeded(ctx, req, state, settings)
	} else {
		next(c)
	}
}
source: func CreateDriver(ci common.ResourceInterface, art *wfv1.HDFSArtifact) (*ArtifactDriver, error) {
	var krbConfig string
	var krbOptions *KrbOptions
	var err error

	namespace := ci.GetNamespace()

	if art.KrbConfigConfigMap != nil && art.KrbConfigConfigMap.Name != "" {
		krbConfig, err = ci.GetConfigMapKey(namespace, art.KrbConfigConfigMap.Name, art.KrbConfigConfigMap.Key)
		if err != nil {
			return nil, err
		}
	}
	if art.KrbCCacheSecret != nil && art.KrbCCacheSecret.Name != "" {
		bytes, err := ci.GetSecretFromVolMount(art.KrbCCacheSecret.Name, art.KrbCCacheSecret.Key)
		if err != nil {
			return nil, err
		}
		ccache, err := credentials.ParseCCache(bytes)
		if err != nil {
			return nil, err
		}
		krbOptions = &KrbOptions{
			CCacheOptions: &CCacheOptions{
				CCache: ccache,
			},
			Config:               krbConfig,
			ServicePrincipalName: art.KrbServicePrincipalName,
		}
	}
	if art.KrbKeytabSecret != nil && art.KrbKeytabSecret.Name != "" {
		bytes, err := ci.GetSecretFromVolMount(art.KrbKeytabSecret.Name, art.KrbKeytabSecret.Key)
		if err != nil {
			return nil, err
		}
		ktb, err := keytab.Parse(bytes)
		if err != nil {
			return nil, err
		}
		krbOptions = &KrbOptions{
			KeytabOptions: &KeytabOptions{
				Keytab:   ktb,
				Username: art.KrbUsername,
				Realm:    art.KrbRealm,
			},
			Config:               krbConfig,
			ServicePrincipalName: art.KrbServicePrincipalName,
		}
	}

	driver := ArtifactDriver{
		Addresses:  art.Addresses,
		Path:       art.Path,
		Force:      art.Force,
		HDFSUser:   art.HDFSUser,
		KrbOptions: krbOptions,
	}
	return &driver, nil
}
source: func (rule MergeFromRangeRule) Pattern() plan.Pattern {
	return plan.Pat(universe.RangeKind, plan.Pat(PhysicalFromKind))
}
source: func (sl *SchemaLoader) AddSchema(url string, loader JSONLoader) error {

	ref, err := gojsonreference.NewJsonReference(url)

	if err != nil {
		return err
	}

	doc, err := loader.LoadJSON()

	if err != nil {
		return err
	}

	if sl.Validate {
		if err := sl.validateMetaschema(doc); err != nil {
			return err
		}
	}

	return sl.pool.parseReferences(doc, ref, true)
}
source: func (nbd *NBD) Size(size int64) (err error) {
	if err = ioctl(nbd.deviceFile.Fd(), NBD_SET_BLKSIZE, 4096); err != nil {
		err = &os.PathError{
			Op:   nbd.deviceFile.Name(),
			Path: "ioctl NBD_SET_BLKSIZE",
			Err:  err,
		}
	} else if err = ioctl(nbd.deviceFile.Fd(), NBD_SET_SIZE_BLOCKS, uintptr(size/4096)); err != nil {
		err = &os.PathError{
			Op:   nbd.deviceFile.Name(),
			Path: "ioctl NBD_SET_SIZE_BLOCKS",
			Err:  err,
		}
	}

	return err
}
source: func New(*SmartSampleConfig, log.Logger, dtsink) (*SmartSampler, error) {
	return nil, errors.New("you are attempting to configure a regular SignalFx Gateway with the config of a Smart Gateway. This is an unsupported configuration")
}
source: func (g *gossipServiceImpl) Gossip(msg *proto.GossipMessage) {
	// Educate developers to Gossip messages with the right tags.
	// See IsTagLegal() for wanted behavior.
	if err := msg.IsTagLegal(); err != nil {
		panic(errors.WithStack(err))
	}

	sMsg := &proto.SignedGossipMessage{
		GossipMessage: msg,
	}

	var err error
	if sMsg.IsDataMsg() {
		sMsg, err = sMsg.NoopSign()
	} else {
		_, err = sMsg.Sign(func(msg []byte) ([]byte, error) {
			return g.mcs.Sign(msg)
		})
	}

	if err != nil {
		g.logger.Warningf("Failed signing message: %+v", errors.WithStack(err))
		return
	}

	if msg.IsChannelRestricted() {
		gc := g.chanState.getGossipChannelByChainID(msg.Channel)
		if gc == nil {
			g.logger.Warning("Failed obtaining gossipChannel of", msg.Channel, "aborting")
			return
		}
		if msg.IsDataMsg() {
			gc.AddToMsgStore(sMsg)
		}
	}

	if g.conf.PropagateIterations == 0 {
		return
	}
	g.emitter.Add(&emittedGossipMessage{
		SignedGossipMessage: sMsg,
		filter: func(_ common.PKIidType) bool {
			return true
		},
	})
}
source: func (a *Agent) handleEvents() {
	for {
		select {
		case e := <-a.eventCh:
			// Decode the event
			msg := new(UserEvent)
			if err := decodeMsgPack(e.Payload, msg); err != nil {
				a.logger.Printf("[ERR] agent: Failed to decode event: %v", err)
				continue
			}
			msg.LTime = uint64(e.LTime)

			// Skip if we don't pass filtering
			if !a.shouldProcessUserEvent(msg) {
				continue
			}

			// Ingest the event
			a.ingestUserEvent(msg)

		case <-a.shutdownCh:
			return
		}
	}
}
source: func (e *Environment) Clone() *Environment {
	if e == nil {
		return &Environment{}
	}
	return proto.Clone(e).(*Environment)
}
source: func NewSetBreakpointsActiveArgs(active bool) *SetBreakpointsActiveArgs {
	args := new(SetBreakpointsActiveArgs)
	args.Active = active
	return args
}
source: func (h *LangHandler) lintPackage(ctx context.Context, bctx *build.Context, conn jsonrpc2.JSONRPC2, uri lsp.DocumentURI) error {
	filename := h.FilePath(uri)
	pkg, err := ContainingPackage(h.BuildContext(ctx), filename, h.RootFSPath)
	if err != nil {
		return err
	}

	files := make([]string, 0, len(pkg.GoFiles))
	for _, f := range pkg.GoFiles {
		files = append(files, path.Join(pkg.Dir, f))
	}
	return h.lint(ctx, bctx, conn, []string{path.Dir(filename)}, files)
}
source: func GetColorTable(target uint32, format uint32, xtype uint32, table unsafe.Pointer) {
	C.glowGetColorTable(gpGetColorTable, (C.GLenum)(target), (C.GLenum)(format), (C.GLenum)(xtype), table)
}
source: func (m *ExpirationManager) Stop() error {
	// Stop all the pending expiration timers
	m.logger.Debug("stop triggered")
	defer m.logger.Debug("finished stopping")

	// Do this before stopping pending timers to avoid potential races with
	// expiring timers
	close(m.quitCh)

	m.pendingLock.Lock()
	for _, pending := range m.pending {
		pending.timer.Stop()
	}
	m.pending = make(map[string]pendingInfo)
	m.pendingLock.Unlock()

	if m.inRestoreMode() {
		for {
			if !m.inRestoreMode() {
				break
			}
			time.Sleep(10 * time.Millisecond)
		}
	}

	return nil
}
source: func (f *Fpdf) HTMLBasicNew() (html HTMLBasicType) {
	html.pdf = f
	html.Link.ClrR, html.Link.ClrG, html.Link.ClrB = 0, 0, 128
	html.Link.Bold, html.Link.Italic, html.Link.Underscore = false, false, true
	return
}
source: func Convert_networking_IngressRule_To_v1beta1_IngressRule(in *networking.IngressRule, out *v1beta1.IngressRule, s conversion.Scope) error {
	return autoConvert_networking_IngressRule_To_v1beta1_IngressRule(in, out, s)
}
source: func (s *gceOps) waitForAttach(
	disk *compute.Disk,
	timeout time.Duration,
) (string, error) {
	devicePath, err := task.DoRetryWithTimeout(
		func() (interface{}, bool, error) {
			devicePath, err := s.DevicePath(disk.Name)
			if se, ok := err.(*storageops.StorageError); ok &&
				se.Code == storageops.ErrVolAttachedOnRemoteNode {
				return "", false, err
			} else if err != nil {
				return "", true, err
			}

			return devicePath, false, nil
		},
		storageops.ProviderOpsTimeout,
		storageops.ProviderOpsRetryInterval)
	if err != nil {
		return "", err
	}

	return devicePath.(string), nil
}
source: func (s *UsersStore) Num(ctx context.Context) (int, error) {
	err := validOrganization(ctx)
	if err != nil {
		return 0, err
	}

	// retrieve all users from the underlying UsersStore
	usrs, err := s.All(ctx)
	if err != nil {
		return 0, err
	}

	return len(usrs), nil
}
source: func mergeObjects(objA, objB ast.Object) (result ast.Object, ok bool) {
	result = ast.NewObject()
	stop := objA.Until(func(k, v *ast.Term) bool {
		if v2 := objB.Get(k); v2 == nil {
			result.Insert(k, v)
		} else {
			obj1, ok1 := v.Value.(ast.Object)
			obj2, ok2 := v2.Value.(ast.Object)

			if !ok1 || !ok2 {
				result.Insert(k, v)
				return false
			}
			obj3, ok := mergeObjects(obj1, obj2)
			if !ok {
				return true
			}
			result.Insert(k, ast.NewTerm(obj3))
		}
		return false
	})
	if stop {
		return nil, false
	}
	objB.Foreach(func(k, v *ast.Term) {
		if v2 := objA.Get(k); v2 == nil {
			result.Insert(k, v)
		}
	})
	return result, true
}
source: func NewBoolFilter() BoolFilter {
	f := BoolFilter{
		mustClauses:    make([]Filter, 0),
		shouldClauses:  make([]Filter, 0),
		mustNotClauses: make([]Filter, 0),
	}
	return f
}
source: func (b *backend) parseAndVerifyRoleTagValue(ctx context.Context, s logical.Storage, tag string) (*roleTag, error) {
	tagItems := strings.Split(tag, ":")

	// Tag must contain version, nonce, policies and HMAC
	if len(tagItems) < 4 {
		return nil, fmt.Errorf("invalid tag")
	}

	rTag := &roleTag{}

	// Cache the HMAC value. The last item in the collection.
	rTag.HMAC = tagItems[len(tagItems)-1]

	// Remove the HMAC from the list.
	tagItems = tagItems[:len(tagItems)-1]

	// Version will be the first element.
	rTag.Version = tagItems[0]
	if rTag.Version != roleTagVersion {
		return nil, fmt.Errorf("invalid role tag version")
	}

	// Nonce will be the second element.
	rTag.Nonce = tagItems[1]

	// Delete the version and nonce from the list.
	tagItems = tagItems[2:]

	for _, tagItem := range tagItems {
		var err error
		switch {
		case strings.HasPrefix(tagItem, "i="):
			rTag.InstanceID = strings.TrimPrefix(tagItem, "i=")
		case strings.HasPrefix(tagItem, "r="):
			rTag.Role = strings.TrimPrefix(tagItem, "r=")
		case strings.HasPrefix(tagItem, "p="):
			rTag.Policies = strings.Split(strings.TrimPrefix(tagItem, "p="), ",")
		case strings.HasPrefix(tagItem, "d="):
			rTag.DisallowReauthentication, err = strconv.ParseBool(strings.TrimPrefix(tagItem, "d="))
			if err != nil {
				return nil, err
			}
		case strings.HasPrefix(tagItem, "m="):
			rTag.AllowInstanceMigration, err = strconv.ParseBool(strings.TrimPrefix(tagItem, "m="))
			if err != nil {
				return nil, err
			}
		case strings.HasPrefix(tagItem, "t="):
			rTag.MaxTTL, err = time.ParseDuration(fmt.Sprintf("%ss", strings.TrimPrefix(tagItem, "t=")))
			if err != nil {
				return nil, err
			}
		default:
			return nil, fmt.Errorf("unrecognized item %q in tag", tagItem)
		}
	}

	if rTag.Role == "" {
		return nil, fmt.Errorf("missing role name")
	}

	roleEntry, err := b.lockedAWSRole(ctx, s, rTag.Role)
	if err != nil {
		return nil, err
	}
	if roleEntry == nil {
		return nil, fmt.Errorf("entry not found for %q", rTag.Role)
	}

	// Create a HMAC of the plaintext value of role tag and compare it with the given value.
	verified, err := verifyRoleTagValue(rTag, roleEntry)
	if err != nil {
		return nil, err
	}
	if !verified {
		return nil, fmt.Errorf("role tag signature verification failed")
	}

	return rTag, nil
}
source: func (k *OrderAwareKey) UnmarshalText(text []byte) error {
	i := atomic.AddUint64(&keyOrderCounter, 1)
	k.Order = i
	k.Key = string(text)
	return nil
}
source: func newReceiver(ls linkSettings) *receiver {
	r := &receiver{link: link{linkSettings: ls}}
	r.endpoint.init(r.link.pLink.String())
	if r.capacity < 1 {
		r.capacity = 1
	}
	r.buffer = make(chan ReceivedMessage, r.capacity)
	r.handler().addLink(r.pLink, r)
	r.link.pLink.Open()
	if r.prefetch {
		r.flow(r.maxFlow())
	}
	return r
}
source: func ReconnectHandler(cb ConnHandler) Option {
	return func(o *Options) error {
		o.ReconnectedCB = cb
		return nil
	}
}
source: func (in *WorkflowStatus) DeepCopy() *WorkflowStatus {
	if in == nil {
		return nil
	}
	out := new(WorkflowStatus)
	in.DeepCopyInto(out)
	return out
}
source: func (_ *AttachISO) CheckChanges(a, e, changes *AttachISO) error {
	glog.Info("AttachISO.CheckChanges invoked!")
	return nil
}
source: func updateAllTxnsValidMainchain(db *sql.DB) (rowsUpdated int64, err error) {
	rowsUpdated, err = sqlExec(db, internal.UpdateRegularTxnsValidAll,
		"failed to update regular transactions' validity status")
	if err != nil {
		return
	}
	return sqlExec(db, internal.UpdateTxnsMainchainAll,
		"failed to update all transactions' mainchain status")
}
source: func (s *JobProcessDetails) SetNumberOfInProgressThings(v int64) *JobProcessDetails {
	s.NumberOfInProgressThings = &v
	return s
}
source: func GetTriplesecMaybePrompt(m MetaContext) (tsec Triplesec, ppgen PassphraseGeneration, err error) {
	defer m.Trace("GetTriplesecMaybePrompt", func() error { return err })()

	// 1. try cached
	m.Debug("| trying cached triplesec")
	if tsec, ppgen = m.TriplesecAndGeneration(); tsec != nil && !ppgen.IsNil() {
		m.Debug("| cached trieplsec stream ok, using it")
		return tsec, ppgen, nil
	}

	// 2. login and get it
	m.Debug("| using full GetPassphraseStreamViaPrompt")
	var pps *PassphraseStream
	pps, tsec, err = GetPassphraseStreamViaPrompt(m)
	if err != nil {
		return nil, ppgen, err
	}
	if pps == nil {
		m.Debug("| Got back empty passphrase stream; returning nil")
		return nil, ppgen, NewNoTriplesecError()
	}
	if tsec == nil {
		m.Debug("| Got back empty triplesec")
		return nil, ppgen, NewNoTriplesecError()
	}
	ppgen = pps.Generation()
	if ppgen.IsNil() {
		m.Debug("| Got back a non-nill Triplesec but an invalid ppgen; returning nil")
		return nil, ppgen, NewNoTriplesecError()
	}
	m.Debug("| got non-nil Triplesec back from prompt")
	return tsec, ppgen, err
}
source: func GtLit(column, literal string) Cmp {
	return Cmp{
		op:     gt,
		column: column,
		value:  lit(literal),
	}
}
source: func NewSignerFromFile(caFile, caKeyFile string, policy *config.Signing) (*Signer, error) {
	log.Debug("Loading CA: ", caFile)
	ca, err := helpers.ReadBytes(caFile)
	if err != nil {
		return nil, err
	}
	log.Debug("Loading CA key: ", caKeyFile)
	cakey, err := helpers.ReadBytes(caKeyFile)
	if err != nil {
		return nil, cferr.Wrap(cferr.CertificateError, cferr.ReadFailed, err)
	}

	parsedCa, err := helpers.ParseCertificatePEM(ca)
	if err != nil {
		return nil, err
	}

	strPassword := os.Getenv("CFSSL_CA_PK_PASSWORD")
	password := []byte(strPassword)
	if strPassword == "" {
		password = nil
	}

	priv, err := helpers.ParsePrivateKeyPEMWithPassword(cakey, password)
	if err != nil {
		log.Debug("Malformed private key %v", err)
		return nil, err
	}

	return NewSigner(priv, parsedCa, signer.DefaultSigAlgo(priv), policy)
} 63%|██████▎   | 3131/5000 [00:03<00:03, 589.59it/s]
source: func (actionSet ActionSet) ToSlice() []Action {
	actions := []Action{}
	for action := range actionSet {
		actions = append(actions, action)
	}

	return actions
}
source: func StrInt8(v []byte, err error) (int8, error) {
	if err != nil {
		return 0, err
	} else if v == nil {
		return 0, nil
	} else {
		res, err := strconv.ParseInt(hack.String(v), 10, 8)
		return int8(res), err
	}
}
source: func makeCertificate(certPEMBlock, keyPEMBlock []byte) (Certificate, error) {
	var cert Certificate

	// Convert to a tls.Certificate
	tlsCert, err := tls.X509KeyPair(certPEMBlock, keyPEMBlock)
	if err != nil {
		return cert, err
	}
	if len(tlsCert.Certificate) == 0 {
		return cert, errors.New("certificate is empty")
	}
	cert.Certificate = tlsCert

	// Parse leaf certificate, extract relevant metadata, and staple OCSP
	leaf, err := x509.ParseCertificate(tlsCert.Certificate[0])
	if err != nil {
		return cert, err
	}
	err = fillCertFromLeaf(&cert, leaf)
	if err != nil {
		return cert, err
	}
	err = stapleOCSP(&cert, certPEMBlock)
	if err != nil {
		log.Printf("[WARNING] Stapling OCSP: %v", err)
	}

	return cert, nil
}
source: func (s *Swarm) StreamsWithGroup(g Group) []*Stream {
	return StreamsWithGroup(g, s.Streams())
}
source: func (sf *StackFrame) SourceContext(beforeCount int, afterCount int) (linesBefore [][]byte, line []byte, linesAfter [][]byte) {

	if beforeCount >= sf.Line {
		beforeCount = sf.Line - 1
	}
	firstLine := sf.Line - beforeCount
	lastLine := sf.Line + afterCount

	lines := [][]byte{}

	file, err := os.Open(sf.File)
	if err != nil {
		return nil, nil, nil
	}

	scanner := bufio.NewScanner(file)
	for i := 1; scanner.Scan(); i++ {
		if i > lastLine {
			break
		}
		if i < firstLine {
			continue
		}
		lines = append(lines, scanner.Bytes())
	}
	file.Close()

	if len(lines) < beforeCount+1 {
		// something went wrong. We didn't read the whole source
		return nil, nil, nil
	}

	linesBefore = lines[:beforeCount]
	line = lines[beforeCount]
	linesAfter = lines[beforeCount+1:]

	return linesBefore, line, linesAfter
}
source: func (s *UpdateThingGroupsForThingInput) SetThingGroupsToAdd(v []*string) *UpdateThingGroupsForThingInput {
	s.ThingGroupsToAdd = v
	return s
}
source: func (m MiddlewareFunc) AgentMatches(tests ...regexp.Regexp) MiddlewareFunc {
	return func(h HandlerFunc) HandlerFunc {
		return func(c *Context) error {
			for _, test := range tests {
				if test.MatchString(c.Request().UserAgent()) {
					return m(h)(c)
				}
			}
			return h(c)
		}
	}
}
source: func (b *Broker) DescribeGroups(request *DescribeGroupsRequest) (*DescribeGroupsResponse, error) {
	response := new(DescribeGroupsResponse)

	err := b.sendAndReceive(request, response)
	if err != nil {
		return nil, err
	}

	return response, nil
}
source: func (f *FSM) ErrorMissingFSMState(decisionTask *swf.PollForDecisionTaskOutput, outcome Outcome) {
	f.log("action=tick workflow=%s workflow-id=%s at=missing-fsm-state error=marked-state-not-in-fsm state=%s", s.LS(decisionTask.WorkflowType.Name), s.LS(decisionTask.WorkflowExecution.WorkflowId), outcome.State)
}
source: func NewConfigurationManager(dispatcher core.Dispatcher) core.ConfigMgr {
	configMgr := new(ConfigurationManager)
	configMgr.dispatcher = dispatcher
	configMgr.Sources = make(map[string]core.ConfigSource)
	configMgr.ConfigurationMap = make(map[string]string)
	//configMgr.logger = cLogger

	return configMgr
}
source: func (c *Client) UpdateIpAddress(p *UpdateIpAddressParameter) (*PublicIpAddress, error) {
	obj, err := c.Request("updateIpAddress", convertParamToMap(p))
	if err != nil {
		return nil, err
	}
	return obj.(*PublicIpAddress), err
}
source: func (k *KBPKIClient) VerifyMerkleRoot(
	ctx context.Context, root keybase1.MerkleRootV2,
	kbfsRoot keybase1.KBFSRoot) error {
	return k.serviceOwner.KeybaseService().VerifyMerkleRoot(
		ctx, root, kbfsRoot)
}
source: func (s *Selection) Prev() *Selection {
	return pushStack(s, getSiblingNodes(s.Nodes, siblingPrev, nil, nil))
}
source: func (s *Block) HasWord(address rune, command float64) (res bool) {
	for _, m := range s.Nodes {
		if word, ok := m.(*Word); ok {
			if word.Address == address && word.Command == command {
				return true
			}
		}
	}
	return false
}
source: func (cAppender *consoleAppender) Append(event *Event) (ok bool) {
	ok = false
	defer gorivets.EndQuietly()
	msg := ToLogMessage(event, cAppender.layoutTemplate)
	if cAppender.async {
		caFactory.msgChannel <- msg
	} else {
		caFactory.write(msg)
	}
	ok = caFactory.msgChannel != nil
	return ok
}
source: func (v *View) ExpandByClass(r text.Region, classes int) text.Region {
	// Sublime doesn't consider the points the region starts on.
	// If not already on edge of buffer, expand by 1 in both directions.
	a := r.A
	if a > 0 {
		a -= 1
	} else if a < 0 {
		a = 0
	}

	b := r.B
	size := v.Size()
	if b < size {
		b += 1
	} else if b > size {
		b = size
	}

	for ; a > 0 && (v.Classify(a)&classes == 0); a -= 1 {
	}
	for ; b < size && (v.Classify(b)&classes == 0); b += 1 {
	}
	return text.Region{a, b}
}
source: func (d *DNS) GetDomains(domainId interface{}) ([]*Domain, error) {
	params := linode.Parameters{}
	if domainId != nil {
		id, ok := domainId.(int)
		if ok {
			params.Set("DomainID", strconv.Itoa(id))
		}
	}

	var list []*Domain
	_, err := d.linode.Request("domain.list", params, &list)
	if err != nil {
		return nil, err
	}
	return list, nil
}
source: func (t *Torrent) byteRegionPieces(off, size int64) (begin, end pieceIndex) {
	if off >= *t.length {
		return
	}
	if off < 0 {
		size += off
		off = 0
	}
	if size <= 0 {
		return
	}
	begin = pieceIndex(off / t.info.PieceLength)
	end = pieceIndex((off + size + t.info.PieceLength - 1) / t.info.PieceLength)
	if end > pieceIndex(t.info.NumPieces()) {
		end = pieceIndex(t.info.NumPieces())
	}
	return
}
source: func (mr *MockProviderClientMockRecorder) ValidateDataSourceConfig(arg0, arg1 interface{}, arg2 ...interface{}) *gomock.Call {
	mr.mock.ctrl.T.Helper()
	varargs := append([]interface{}{arg0, arg1}, arg2...)
	return mr.mock.ctrl.RecordCallWithMethodType(mr.mock, "ValidateDataSourceConfig", reflect.TypeOf((*MockProviderClient)(nil).ValidateDataSourceConfig), varargs...)
}
source: func (m *MountPoint) Path() string {
	if m.Volume != nil {
		return m.Volume.Path()
	}
	return m.Source
}
source: func GetPossibilities(adjectiveAmount int, nounAmount int, randomNumberPlaces int) (float64) {
  return math.Pow(float64(len(adjectives)), float64(adjectiveAmount)) *
       math.Pow(float64(len(nouns)), float64(nounAmount)) *
       math.Pow(10, float64(randomNumberPlaces))
}
source: func (r *bufferingReaderAt) grabBuf() []byte {
	if len(r.pool) != 0 {
		b := r.pool[len(r.pool)-1]
		r.pool = r.pool[:len(r.pool)-1]
		return b
	}
	return make([]byte, r.blockSize)
}
source: func Fatalf(format string, args ...interface{}) {
	logger.Crit(fmt.Sprintf(format, args...))
}
source: func WatchWithRetry(ctx context.Context, getWatch func() (watch.Interface, error)) chan struct {
	*watch.Event
	Error error
} {
	ch := make(chan struct {
		*watch.Event
		Error error
	})
	execute := func() (bool, error) {
		w, err := getWatch()
		if err != nil {
			return false, err
		}
		defer w.Stop()

		for {
			select {
			case event, ok := <-w.ResultChan():
				if ok {
					ch <- struct {
						*watch.Event
						Error error
					}{Event: &event, Error: nil}
				} else {
					return true, nil
				}
			case <-ctx.Done():
				return false, nil
			}
		}
	}
	go func() {
		defer close(ch)
		for {
			retry, err := execute()
			if err != nil {
				ch <- struct {
					*watch.Event
					Error error
				}{Error: err}
			}
			if !retry {
				return
			}
			time.Sleep(time.Second)
		}
	}()
	return ch
}
source: func (this *Weixinmp) ReplyVoiceMsg(rw http.ResponseWriter, mediaId string) error {
	var msg voiceMsg
	msg.MsgType = "voice"
	msg.Voice.MediaId = mediaId
	return this.replyMsg(rw, &msg)
}
source: func (w *Worktree) Status() (Status, error) {
	var hash plumbing.Hash

	ref, err := w.r.Head()
	if err != nil && err != plumbing.ErrReferenceNotFound {
		return nil, err
	}

	if err == nil {
		hash = ref.Hash()
	}

	return w.status(hash)
}
source: func (s *SpheroDriver) SetBackLED(level uint8) {
	s.packetChannel <- s.craftPacket([]uint8{level}, 0x02, 0x21)
}
source: func (c *Config) LogDebug(format string, v ...interface{}) {
	c.doLog(LogDebug, format, v...)
}
source: func VerifyAPIServerBindAddress(address string) error {
	ip := net.ParseIP(address)
	if ip == nil {
		return errors.Errorf("cannot parse IP address: %s", address)
	}
	if !ip.IsGlobalUnicast() {
		return errors.Errorf("cannot use %q as the bind address for the API Server", address)
	}
	return nil
}
source: func source(lines [][]byte, n int) []byte {
	n-- // in stack trace, lines are 1-indexed but our array is 0-indexed
	if n < 0 || n >= len(lines) {
		return dunno
	}
	return bytes.TrimSpace(lines[n])
}
source: func (m *Machine) WatchPrincipalUnits() StringsWatcher {
	m = &Machine{st: m.st, doc: m.doc}
	coll := machinesC
	getUnits := func() ([]string, error) {
		if err := m.Refresh(); err != nil {
			return nil, err
		}
		return m.doc.Principals, nil
	}
	return newUnitsWatcher(m.st, m.Tag(), getUnits, coll, m.doc.DocID)
}
source: func (c *meteredConn) Close() error {
	err := c.Conn.Close()
	c.lock.RLock()
	if c.id == (enode.ID{}) {
		// If the peer disconnects before the handshake.
		c.lock.RUnlock()
		meteredPeerFeed.Send(MeteredPeerEvent{
			Type:    PeerHandshakeFailed,
			IP:      c.ip,
			Elapsed: time.Since(c.connected),
		})
		return err
	}
	id := c.id
	if !c.trafficMetered {
		// If the peer isn't registered in the traffic registries.
		c.lock.RUnlock()
		meteredPeerFeed.Send(MeteredPeerEvent{
			Type: PeerDisconnected,
			IP:   c.ip,
			ID:   id,
		})
		return err
	}
	ingress, egress := uint64(c.ingressMeter.Count()), uint64(c.egressMeter.Count())
	c.lock.RUnlock()

	// Decrement the metered peer count
	atomic.AddInt32(&meteredPeerCount, -1)

	// Unregister the peer from the traffic registries
	key := fmt.Sprintf("%s/%s", c.ip, id)
	PeerIngressRegistry.Unregister(key)
	PeerEgressRegistry.Unregister(key)

	meteredPeerFeed.Send(MeteredPeerEvent{
		Type:    PeerDisconnected,
		IP:      c.ip,
		ID:      id,
		Ingress: ingress,
		Egress:  egress,
	})
	return err
}
source: func NewMockConn(localPk, remotePk *btcec.PublicKey,
	localAddr, remoteAddr net.Addr,
	bufferSize int) (*MockPeer, *MockPeer) {

	localPeer := &MockPeer{
		remotePub:    remotePk,
		remoteAddr:   remoteAddr,
		localPub:     localPk,
		localAddr:    localAddr,
		IncomingMsgs: make(chan []byte, bufferSize),
		OutgoingMsgs: make(chan []byte, bufferSize),
		Quit:         make(chan struct{}),
	}

	remotePeer := &MockPeer{
		remotePub:    localPk,
		remoteAddr:   localAddr,
		localPub:     remotePk,
		localAddr:    remoteAddr,
		IncomingMsgs: localPeer.OutgoingMsgs,
		OutgoingMsgs: localPeer.IncomingMsgs,
		Quit:         make(chan struct{}),
	}

	localPeer.RemoteQuit = remotePeer.Quit
	remotePeer.RemoteQuit = localPeer.Quit

	return localPeer, remotePeer
}
source: func (r *REST) Create(ctx context.Context, obj runtime.Object, _ rest.ValidateObjectFunc, options *metav1.CreateOptions) (runtime.Object, error) {
	localRAR, ok := obj.(*authorizationapi.LocalResourceAccessReview)
	if !ok {
		return nil, kapierrors.NewBadRequest(fmt.Sprintf("not a localResourceAccessReview: %#v", obj))
	}
	if errs := authorizationvalidation.ValidateLocalResourceAccessReview(localRAR); len(errs) > 0 {
		return nil, kapierrors.NewInvalid(authorization.Kind(localRAR.Kind), "", errs)
	}
	if namespace := apirequest.NamespaceValue(ctx); len(namespace) == 0 {
		return nil, kapierrors.NewBadRequest(fmt.Sprintf("namespace is required on this type: %v", namespace))
	} else if (len(localRAR.Action.Namespace) > 0) && (namespace != localRAR.Action.Namespace) {
		return nil, field.Invalid(field.NewPath("namespace"), localRAR.Action.Namespace, fmt.Sprintf("namespace must be: %v", namespace))
	}

	// transform this into a ResourceAccessReview
	clusterRAR := &authorizationapi.ResourceAccessReview{
		Action: localRAR.Action,
	}
	clusterRAR.Action.Namespace = apirequest.NamespaceValue(ctx)

	return r.clusterRARRegistry.CreateResourceAccessReview(apirequest.WithNamespace(ctx, ""), clusterRAR)
}
source: func (ki *KeyspaceInfo) UpdateServedFromMap(tabletType topodatapb.TabletType, cells []string, keyspace string, remove bool, allCells []string) error {
	// check parameters to be sure
	if err := ki.CheckServedFromMigration(tabletType, cells, keyspace, remove); err != nil {
		return err
	}

	ksf := ki.GetServedFrom(tabletType)
	if ksf == nil {
		// the record doesn't exist
		if remove {
			if len(ki.ServedFroms) == 0 {
				ki.ServedFroms = nil
			}
			log.Warningf("Trying to remove KeyspaceServedFrom for missing type %v in keyspace %v", tabletType, ki.keyspace)
		} else {
			ki.ServedFroms = append(ki.ServedFroms, &topodatapb.Keyspace_ServedFrom{
				TabletType: tabletType,
				Cells:      cells,
				Keyspace:   keyspace,
			})
		}
		return nil
	}

	if remove {
		result, emptyList := removeCells(ksf.Cells, cells, allCells)
		if emptyList {
			// we don't have any cell left, we need to clear this record
			var newServedFroms []*topodatapb.Keyspace_ServedFrom
			for _, k := range ki.ServedFroms {
				if k != ksf {
					newServedFroms = append(newServedFroms, k)
				}
			}
			ki.ServedFroms = newServedFroms
		} else {
			ksf.Cells = result
		}
	} else {
		if ksf.Keyspace != keyspace {
			return vterrors.Errorf(vtrpc.Code_FAILED_PRECONDITION, "cannot UpdateServedFromMap on existing record for keyspace %v, different keyspace: %v != %v", ki.keyspace, ksf.Keyspace, keyspace)
		}
		ksf.Cells = addCells(ksf.Cells, cells)
	}
	return nil
}
source: func (c *Client) NewRawPutRequest(urlStr string, body string) (*http.Request, error) {
	// Build URL for request
	u, err := c.buildURLForRequest(urlStr)
	if err != nil {
		return nil, err
	}

	buf := bytes.NewBuffer([]byte(body))
	req, err := http.NewRequest("PUT", u, buf)
	if err != nil {
		return nil, err
	}

	// Apply Authentication
	if err := c.addAuthentication(req); err != nil {
		return nil, err
	}

	// Request compact JSON
	// See https://gerrit-review.googlesource.com/Documentation/rest-api.html#output
	req.Header.Add("Accept", "application/json")
	req.Header.Add("Content-Type", "application/x-www-form-urlencoded")

	// TODO: Add gzip encoding
	// Accept-Encoding request header is set to gzip
	// See https://gerrit-review.googlesource.com/Documentation/rest-api.html#output

	return req, nil
}
source: func (f *asyncFlusher) start(numParallel int) {
	f.chunks = make(chan chunk)
	for i := 0; i < numParallel; i++ {
		f.wg.Add(1)
		go func() {
			defer f.wg.Done()
			f.uploaderLoop()
		}()
	}
}
source: func (l *intLogger) IsTrace() bool {
	return Level(atomic.LoadInt32(l.level)) == Trace
}
source: func (kl *Kubelet) rejectPod(pod *v1.Pod, reason, message string) {
	kl.recorder.Eventf(pod, v1.EventTypeWarning, reason, message)
	kl.statusManager.SetPodStatus(pod, v1.PodStatus{
		Phase:   v1.PodFailed,
		Reason:  reason,
		Message: "Pod " + message})
}
source: func infoComponent(st model.Status, label, text string) *ui.BuildComponent {
	return &ui.BuildComponent{
		Type:   ui.Summary,
		Label:  ui.NewEmptyLink(label),
		Text:   []string{text},
		Status: st,
	}
}
source: func (c *Client) GetExportRootClients(
	ctx context.Context, name string) ([]string, error) {

	ex, err := c.GetExportByName(ctx, name)
	if err != nil {
		return nil, err
	}
	if ex == nil {
		return nil, nil
	}
	if ex.RootClients == nil {
		return nil, nil
	}
	return *ex.RootClients, nil
}
source: func (r *router) MethodsFor(path string) []string {
	methods := []string{}
	for _, route := range r.getRoutes() {
		matches := route.regex.FindStringSubmatch(path)
		if len(matches) > 0 && matches[0] == path && !hasMethod(methods, route.method) {
			methods = append(methods, route.method)
		}
	}
	return methods
}
source: func (cd *ConnectionDetails) Finalize() error {
	cd.Dialect = normalizeSynonyms(cd.Dialect)

	if cd.Options == nil { // for safety
		cd.Options = make(map[string]string)
	}

	// Process the database connection string, if provided.
	if cd.URL != "" {
		if err := cd.withURL(); err != nil {
			return err
		}
	}

	if fin, ok := finalizer[cd.Dialect]; ok {
		fin(cd)
	}

	if DialectSupported(cd.Dialect) {
		if cd.Database != "" || cd.URL != "" {
			return nil
		}
		return errors.New("no database or URL specified")
	}
	return errors.Errorf("unsupported dialect '%v'", cd.Dialect)
}
source: func (env *environ) buildInstanceSpec(args environs.StartInstanceParams) (*instances.InstanceSpec, error) {
	arches := args.Tools.Arches()
	series := args.Tools.OneSeries()
	spec, err := findInstanceSpec(
		env, &instances.InstanceConstraint{
			Region:      env.cloud.Region,
			Series:      series,
			Arches:      arches,
			Constraints: args.Constraints,
		},
		args.ImageMetadata,
	)
	return spec, errors.Trace(err)
}
source: func (g *TaskGroup) AddSpread(s *Spread) *TaskGroup {
	g.Spreads = append(g.Spreads, s)
	return g
}
source: func (r *FastHttpResponse) Get(key int) (value interface{}, err error) {
	switch key {
	case revel.HTTP_SERVER_HEADER:
		value = r.Header()
	case revel.HTTP_STREAM_WRITER:
		value = r
	case revel.HTTP_WRITER:
		value = r.Writer
	default:
		err = revel.ENGINE_UNKNOWN_GET
	}
	return
}
source: func (c *clusterClient) SchedPolicyDelete(name string) error {
	req := c.c.Delete().Resource(clusterPath + SchedPath).Instance(name)
	res := req.Do()

	if res.Error() != nil {
		return res.FormatError()
	}

	return nil
}
source: func elfVariableSubstitutions(ep endpoint) map[string]uint32 {
	result := make(map[string]uint32)

	if ipv6 := ep.IPv6Address(); ipv6 != nil {
		// Corresponds to DEFINE_IPV6() in bpf/lib/utils.h
		result["LXC_IP_1"] = sliceToBe32(ipv6[0:4])
		result["LXC_IP_2"] = sliceToBe32(ipv6[4:8])
		result["LXC_IP_3"] = sliceToBe32(ipv6[8:12])
		result["LXC_IP_4"] = sliceToBe32(ipv6[12:16])
	}
	if ipv4 := ep.IPv4Address(); ipv4 != nil {
		result["LXC_IPV4"] = byteorder.HostSliceToNetwork(ipv4, reflect.Uint32).(uint32)
	}

	mac := ep.GetNodeMAC()
	result["NODE_MAC_1"] = sliceToBe32(mac[0:4])
	result["NODE_MAC_2"] = uint32(sliceToBe16(mac[4:6]))
	result["LXC_ID"] = uint32(ep.GetID())
	identity := ep.GetIdentity().Uint32()
	result["SECLABEL"] = identity
	result["SECLABEL_NB"] = byteorder.HostToNetwork(identity).(uint32)

	return result

}
source: func NewMsgCFCheckpt(filterType FilterType, stopHash *chainhash.Hash,
	headersCount int) *MsgCFCheckpt {
	return &MsgCFCheckpt{
		FilterType:    filterType,
		StopHash:      *stopHash,
		FilterHeaders: make([]*chainhash.Hash, 0, headersCount),
	}
}
source: func fetchRawCreditAmount(v []byte) (btcutil.Amount, error) {
	if len(v) < 9 {
		str := fmt.Sprintf("%s: short read (expected %d bytes, read %d)",
			bucketCredits, 9, len(v))
		return 0, storeError(ErrData, str, nil)
	}
	return btcutil.Amount(byteOrder.Uint64(v)), nil
}
source: func DecryptBytes(data, key []byte) ([]byte, error) {
	block, err := aes.NewCipher(key)
	if err != nil {
		return nil, err
	}
	gcm, err := cipher.NewGCM(block)
	if err != nil {
		return nil, err
	}
	nonceSize := gcm.NonceSize()
	if len(data) < nonceSize {
		return nil, errors.New("size of data is less than the nonce")
	}

	nonce, out := data[:nonceSize], data[nonceSize:]
	out, err = gcm.Open(nil, nonce, out, nil)
	if err != nil {
		return nil, err
	}
	return out, nil
}
source: func (s *GetTrailStatusOutput) SetTimeLoggingStopped(v string) *GetTrailStatusOutput {
	s.TimeLoggingStopped = &v
	return s
}
source: func NewPlot(data table.Grouping) *Plot {
	p := &Plot{
		env: &plotEnv{
			data: data,
		},
		scales:         make(map[string]scalerTree),
		scaledData:     make(map[scaledDataKey]*scaledData),
		scaleSet:       make(map[scaleKey]bool),
		axisLabels:     make(map[string]string),
		autoAxisLabels: make(map[string][]string),
	}
	return p
}
source: func (c *Client) GetSnapshots() (Refs, error) {
	initiators, err := c.api.GetSnapshots()
	if err != nil {
		return nil, err
	}
	return initiators.Snapshots, nil
}
source: func (f *FakeDocker) RunContainer(opts RunContainerOptions) error {
	f.RunContainerOpts = opts
	if f.RunContainerErrorBeforeStart {
		return f.RunContainerError
	}
	if opts.Stdout != nil {
		opts.Stdout.Close()
	}
	if opts.Stderr != nil {
		opts.Stderr.Close()
	}
	if opts.OnStart != nil {
		if err := opts.OnStart(""); err != nil {
			return err
		}
	}
	if opts.Stdin != nil {
		_, err := io.Copy(ioutil.Discard, opts.Stdin)
		if err != nil {
			return err
		}
	}
	if opts.PostExec != nil {
		opts.PostExec.PostExecute(f.RunContainerContainerID, string(opts.Command))
	}
	return f.RunContainerError
}
source: func (s *Store) GitInit(ctx context.Context, un, ue string) error {
	rcs, err := backend.InitRCS(ctx, backend.GetRCSBackend(ctx), s.url.Path, un, ue)
	if err != nil {
		return err
	}
	s.rcs = rcs
	return nil
}
source: func (a *attributeStatement) String() string {
	buff := new(bytes.Buffer)
	for i, attr := range a.Attributes {
		if i != 0 {
			buff.WriteString(", ")
		}
		buff.WriteString(attr.String())
	}
	return buff.String()
}
source: func (c *FakeReplicationControllers) GetScale(replicationControllerName string, options v1.GetOptions) (result *autoscalingv1.Scale, err error) {
	obj, err := c.Fake.
		Invokes(testing.NewGetSubresourceAction(replicationcontrollersResource, c.ns, "scale", replicationControllerName), &autoscalingv1.Scale{})

	if obj == nil {
		return nil, err
	}
	return obj.(*autoscalingv1.Scale), err
}
source: func (shardSwap *shardSchemaSwap) isSwapApplied(tablet *topodatapb.Tablet) (bool, error) {
	swapIDResult, err := shardSwap.executeAdminQuery(
		tablet,
		fmt.Sprintf("SELECT value FROM _vt.local_metadata WHERE db_name = '%s' AND name = '%s'", topoproto.TabletDbName(tablet), lastAppliedMetadataName),
		1 /* maxRows */)
	if err != nil {
		return false, err
	}
	if len(swapIDResult.Rows) == 0 {
		// No such row means we need to apply the swap.
		return false, nil
	}
	swapID, err := sqltypes.ToUint64(swapIDResult.Rows[0][0])
	if err != nil {
		return false, err
	}
	return swapID == shardSwap.parent.swapID, nil
}
source: func (r *RegistrationDB) RemoveRegistration(k Registration) {
	r.Lock()
	defer r.Unlock()
	delete(r.registrationMap, k)
}
source: func ReadTokenFile(fpath string) (*oauth2.Token, error) {
	f, err := os.Open(fpath)
	if err != nil {
		return nil, err
	}
	tok := &oauth2.Token{}
	err = json.NewDecoder(f).Decode(tok)
	defer f.Close()
	return tok, err
}
source: func getAddressParts(a string) (string, string, error) {
	parts := strings.SplitN(a, "://", 2)
	if len(parts) != 2 {
		return "", "", fmt.Errorf("missing protocol within address '%s'", a)
	}

	u, _ := url.Parse(a)
	switch u.Scheme {
	case "unix", "unixpacket", "unixgram":
		return parts[0], parts[1], nil
	}

	var host string
	if u.Hostname() != "" {
		host = u.Hostname()
	}
	host += ":"
	if u.Port() == "" {
		host += "6514"
	} else {
		host += u.Port()
	}

	return u.Scheme, host, nil
}
source: func Skip(message string, callerSkip ...int) {
	skip := 0
	if len(callerSkip) > 0 {
		skip = callerSkip[0]
	}

	globalFailer.Skip(message, codelocation.New(skip+1))
	panic(GINKGO_PANIC)
}
source: func (q *DisjunctionQuery) Or(queries ...FtsQuery) *DisjunctionQuery {
	q.options["disjuncts"] = append(q.options["disjuncts"].([]FtsQuery), queries...)
	return q
}
source: func (db *WiredDB) RewindStakeDB(ctx context.Context, toHeight int64, quiet ...bool) (stakeDBHeight int64, err error) {
	// Target height must be non-negative. It is not possible to disconnect the
	// genesis block.
	if toHeight < 0 {
		toHeight = 0
	}

	// Periodically log progress unless quiet[0]==true
	showProgress := true
	if len(quiet) > 0 {
		showProgress = !quiet[0]
	}

	// Disconnect blocks until the stake database reaches the target height.
	stakeDBHeight = int64(db.sDB.Height())
	startHeight := stakeDBHeight
	pStep := int64(1000)
	for stakeDBHeight > toHeight {
		// Log rewind progress at regular intervals.
		if stakeDBHeight == startHeight || stakeDBHeight%pStep == 0 {
			endSegment := pStep * ((stakeDBHeight - 1) / pStep)
			if endSegment < toHeight {
				endSegment = toHeight
			}
			if showProgress {
				log.Infof("Rewinding from %d to %d", stakeDBHeight, endSegment)
			}
		}

		// Check for quit signal.
		select {
		case <-ctx.Done():
			log.Infof("Rewind cancelled at height %d.", stakeDBHeight)
			return
		default:
		}

		// Disconect the best block.
		if err = db.sDB.DisconnectBlock(false); err != nil {
			return
		}
		stakeDBHeight = int64(db.sDB.Height())
		log.Tracef("Stake db now at height %d.", stakeDBHeight)
	}
	return
}
source: func (s *Set) Add(value interface{}) bool {
	// Check existence
	found := s.Has(value)

	// Lock set for write
	s.mutex.Lock()
	defer s.mutex.Unlock()

	// Add value to set
	s.m[value] = struct{}{}

	// Return inverse, so true if element already existed
	return !found
}
source: func (ds *DataSource) skylinePruning(prop *property.PhysicalProperty) []*candidatePath {
	candidates := make([]*candidatePath, 0, 4)
	for _, path := range ds.possibleAccessPaths {
		// if we already know the range of the scan is empty, just return a TableDual
		if len(path.ranges) == 0 && !ds.ctx.GetSessionVars().StmtCtx.UseCache {
			return []*candidatePath{{path: path}}
		}
		var currentCandidate *candidatePath
		if path.isTablePath {
			currentCandidate = ds.getTableCandidate(path, prop)
		} else if len(path.accessConds) > 0 || !prop.IsEmpty() || path.forced {
			// We will use index to generate physical plan if:
			// this path's access cond is not nil or
			// we have prop to match or
			// this index is forced to choose.
			currentCandidate = ds.getIndexCandidate(path, prop)
		} else {
			continue
		}
		pruned := false
		for i := len(candidates) - 1; i >= 0; i-- {
			result := compareCandidates(candidates[i], currentCandidate)
			if result == 1 {
				pruned = true
				// We can break here because the current candidate cannot prune others anymore.
				break
			} else if result == -1 {
				candidates = append(candidates[:i], candidates[i+1:]...)
			}
		}
		if !pruned {
			candidates = append(candidates, currentCandidate)
		}
	}
	return candidates
}
source: func (p *Pattern) geoPlaid() {
	height := 0
	width := 0

	i := 1
	j := 0
	for i <= 18 {

		space := utils.HexVal(p.Hash, j, 1)
		height = height + int(space) + 5

		val := utils.HexVal(p.Hash, j+1, 1)
		opacity := utils.Opacity(val)
		fill := utils.FillColor(val)
		stripeHeight := val + 5

		styles := make(map[string]interface{})
		styles["opacity"] = opacity
		styles["fill"] = fill

		p.Svg.Rect(0, height, "100%", stripeHeight, styles)

		height = height + int(stripeHeight)
		j = j + 2

		i = i + 1
	}

	i = 1
	j = 0
	for i <= 18 {

		space := utils.HexVal(p.Hash, j, 1)
		width = width + int(space) + 5

		val := utils.HexVal(p.Hash, j+1, 1)
		opacity := utils.Opacity(val)
		fill := utils.FillColor(val)
		stripeWidth := val + 5

		styles := make(map[string]interface{})
		styles["opacity"] = opacity
		styles["fill"] = fill

		p.Svg.Rect(width, 0, stripeWidth, "100%", styles)

		width = width + int(stripeWidth)
		j = j + 2

		i = i + 1
	}

	p.Svg.SetHeight(int(height))
	p.Svg.SetWidth(int(width))
}
source: func (f *FileStats) StatLine(previous *FileStats, span time.Duration) string {
	var bytesDownloaded uint64
	if previous != nil {
		bytesDownloaded = f.BytesCompleted - previous.BytesCompleted
	}

	return fmt.Sprintf("Files (%d/%d) - %s / %s - %0.1f%% - %s/s",
		f.CountCompleted, f.CountScheduled,
		humanize.Bytes(f.BytesCompleted), humanize.Bytes(f.BytesScheduled),
		100*float64(f.BytesCompleted)/float64(f.BytesScheduled),
		humanize.Bytes(uint64(float64(bytesDownloaded)/span.Seconds())),
	)
}
source: func (tms *TrustMetricStore) OnStop() {
	tms.BaseService.OnStop()

	tms.mtx.Lock()
	defer tms.mtx.Unlock()

	// Stop all trust metric go-routines
	for _, tm := range tms.peerMetrics {
		tm.Stop()
	}

	// Make the final trust history data save
	tms.saveToDB()
}
source: func (ve *SignerValidatorEndpoint) acceptConnection() (net.Conn, error) {
	conn, err := ve.listener.Accept()
	if err != nil {
		if !ve.IsRunning() {
			return nil, nil // Ignore error from listener closing.
		}
		return nil, err
	}
	return conn, nil
}
source: func Logger(ctx context.Context) *zap.Logger {
	if ctxlogger, ok := ctx.Value(ctxLogKey).(*zap.Logger); ok {
		return ctxlogger
	}
	return zaplog.L()
}
source: func (s *Service) SpaceDelete(ctx context.Context, spaceIdentity string) (*Space, error) {
	var space Space
	return &space, s.Delete(ctx, &space, fmt.Sprintf("/spaces/%v", spaceIdentity))
}
source: func (n *Node) setState(s seesaw.HAState) {
	n.statusLock.Lock()
	defer n.statusLock.Unlock()
	if n.haStatus.State != s {
		n.haStatus.State = s
		n.haStatus.Since = time.Now()
		n.haStatus.Transitions++
	}
}
source: func NewOrderedValues(vals [][]string) OrderedValues {
	if len(vals) == 0 {
		return nil
	}
	var nov OrderedValues
	for i := range vals {
		var a [][]byte
		for j := range vals[i] {
			a = append(a, []byte(vals[i][j]))
		}
		nov = append(nov, a)
	}
	return nov
}
source: func (p *Etcd) Open(logger log.Logger) (storage.Storage, error) {
	return p.open(logger)
}
source: func (o *CSNATPool) CTranslationMaps(info *bambou.FetchingInfo) (CTranslationMapsList, *bambou.Error) {

	var list CTranslationMapsList
	err := bambou.CurrentSession().FetchChildren(o, CTranslationMapIdentity, &list, info)
	return list, err
}
source: func (n *NodeConfig) MarshalJSON() ([]byte, error) {
	confJSON := nodeConfigJSON{
		ID:              n.ID.String(),
		Name:            n.Name,
		Services:        n.Services,
		Port:            n.Port,
		EnableMsgEvents: n.EnableMsgEvents,
	}
	if n.PrivateKey != nil {
		confJSON.PrivateKey = hex.EncodeToString(crypto.FromECDSA(n.PrivateKey))
	}
	return json.Marshal(confJSON)
}
source: func (s *CirconusSink) SetGauge(key []string, val float32) {
	flatKey := s.flattenKey(key)
	s.metrics.SetGauge(flatKey, int64(val))
}
source: func NewProtoWrapper(db keyval.CoreBrokerWatcher, serializer ...keyval.Serializer) *ProtoWrapper {
	if len(serializer) > 0 {
		return &ProtoWrapper{db, serializer[0]}
	}
	return &ProtoWrapper{db, &keyval.SerializerProto{}}
}
source: func ListPointers(data []byte) ([]string, error) {
	if len(data) == 0 {
		return nil, fmt.Errorf("Invalid JSON")
	}
	rv := []string{""}

	scan := &json.Scanner{}
	scan.Reset()

	offset := 0
	beganLiteral := 0
	var current []string
	for {
		if offset >= len(data) {
			return rv, nil
		}
		newOp := scan.Step(scan, int(data[offset]))
		offset++

		switch newOp {
		case json.ScanBeginArray:
			current = append(current, "0")
		case json.ScanObjectKey:
			current[len(current)-1] = grokLiteral(data[beganLiteral-1 : offset-1])
		case json.ScanBeginLiteral:
			beganLiteral = offset
		case json.ScanArrayValue:
			n := mustParseInt(current[len(current)-1])
			current[len(current)-1] = strconv.Itoa(n + 1)
		case json.ScanEndArray, json.ScanEndObject:
			current = sliceToEnd(current)
		case json.ScanBeginObject:
			current = append(current, "")
		case json.ScanError:
			return nil, fmt.Errorf("Error reading JSON object at offset %v", offset)
		}

		if newOp == json.ScanBeginArray || newOp == json.ScanArrayValue ||
			newOp == json.ScanObjectKey {
			rv = append(rv, encodePointer(current))
		}
	}
}
source: func Pair(g1 *G1, g2 *G2) *GT {
	return &GT{optimalAte(g2.p, g1.p, new(bnPool))}
}
source: func (cache *policyCache) delete(identity *identityPkg.Identity) bool {
	cache.Lock()
	defer cache.Unlock()
	_, ok := cache.policies[identity.ID]
	if ok {
		delete(cache.policies, identity.ID)
	}
	return ok
}
source: func (r *DateRule) Max(max time.Time) *DateRule {
	r.max = max
	return r
}
source: func (c *Client) GetAPIInfo(ctx context.Context) (*APIInfo, error) {
	var apiInfo APIInfo

	req, err := c.NewRequest("GET", infoPath, nil, nil)
	if err != nil {
		return nil, err
	}

	if err := c.Do(ctx, req, &apiInfo); err != nil {
		return nil, err
	}

	return &apiInfo, nil
}
source: func RedisStore(client *redis.Client) TokenStore {
	if client == nil {
		panic("RedisStore: redis client is nil")
	}
	return &redisStore{
		client: client,
	}
}
source: func (st *State) MetricBatch(id string) (*MetricBatch, error) {
	c, closer := st.db().GetCollection(metricsC)
	defer closer()
	doc := metricBatchDoc{}
	err := c.Find(bson.M{"_id": id}).One(&doc)
	if err == mgo.ErrNotFound {
		return nil, errors.NotFoundf("metric %v", id)
	}
	if err != nil {
		return nil, err
	}
	return &MetricBatch{st: st, doc: doc}, nil
}
source: func (volume *VolumeToAttach) GenerateError(prefixMsg string, err error) (simpleErr, detailedErr error) {
	simpleMsg, detailedMsg := volume.GenerateMsg(prefixMsg, errSuffix(err))
	return fmt.Errorf(simpleMsg), fmt.Errorf(detailedMsg)
}
source: func (n *collElgNotifier) elgEnabled(ledgerID string, existingPolicy, postCommitPolicy *common.CollectionPolicyConfig) (bool, error) {
	existingMember, err := n.membershipInfoProvider.AmMemberOf(ledgerID, existingPolicy)
	if err != nil || existingMember {
		return false, err
	}
	return n.membershipInfoProvider.AmMemberOf(ledgerID, postCommitPolicy)
}
source: func (ctl *taskController) PrepareTopic(ctx context.Context, publisher string) (topic string, token string, err error) {
	return ctl.eng.prepareTopic(ctx, &topicParams{
		jobID:     ctl.JobID(),
		invID:     ctl.InvocationID(),
		manager:   ctl.manager,
		publisher: publisher,
	})
}
source: func (inputSet StringSet) ToList() []string {
	returnList := make([]string, 0, len(inputSet))
	for key, _ := range inputSet {
		returnList = append(returnList, key)
	}
	return returnList
}
source: func WriteJson(path string, dat *string) {
	_, err0 := os.Stat(path)
	if err0 != nil || !os.IsExist(err0) {
		os.Create(path)
	}
	err := ioutil.WriteFile(path, []byte(*dat), 0644)
	if err != nil {
		panic("Create json file failed")
	}
}
source: func (s *AttributeValue) SetNS(v []*string) *AttributeValue {
	s.NS = v
	return s
}
source: func (*Service) DeleteHost(c context.Context, req *crimson.DeleteHostRequest) (*empty.Empty, error) {
	if err := deleteHost(c, req.Name); err != nil {
		return nil, err
	}
	return &empty.Empty{}, nil
}
source: func (l *Limiter) WrapHandle(h http.Handler) {
	l.rateLimiter.Wrap(h)
	l.ConnLimiter.Wrap(l.rateLimiter)
}
source: func ExtractRestrictIndices(opts ...interface{}) *opt.RestrictIndicesOption {
	for _, o := range opts {
		if v, ok := o.(*opt.RestrictIndicesOption); ok {
			return v
		}
	}
	return nil
}
source: func (bitmap *bitmap) set(index int, bit int) {
	if index >= bitmap.Size {
		panic("index out of range")
	}

	div, mod := index>>3, index&0x07
	shift := byte(1 << uint(7-mod))

	bitmap.data[div] &= ^shift
	if bit > 0 {
		bitmap.data[div] |= shift
	}
}
source: func Exists(table Table, chain string, rule ...string) bool {
	return exists(false, table, chain, rule...)
}
source: func NewNamedValueInt(TIME_BOOT_MS uint32, VALUE int32, NAME [10]uint8) *NamedValueInt {
	m := NamedValueInt{}
	m.TIME_BOOT_MS = TIME_BOOT_MS
	m.VALUE = VALUE
	m.NAME = NAME
	return &m
}
source: func (eh userSettingsUpdateEventHandler) Handle(s *Session, i interface{}) {
	if t, ok := i.(*UserSettingsUpdate); ok {
		eh(s, t)
	}
}
source: func (lt *LifeTime) ExpireNow() {
	lt.Time = CookieExpireDelete
	if lt.timer != nil {
		lt.timer.Stop()
	}
}
source: func (t *Timestamp) UnmarshalJSON(data []byte) error {
	strValue := string(data)
	strValue = strings.Replace(strValue, `"`, ``, -1)
	if strings.Contains(strValue, ".") {
		components := strings.Split(strValue, ".")
		if integerValue, integerErr := strconv.ParseInt(components[0], 10, 64); integerErr == nil {
			t.time = time.Unix(integerValue, 0)
			t.uuid = components[1]
		}
	}

	if integerValue, integerErr := strconv.ParseInt(strValue, 10, 64); integerErr == nil {
		t.time = time.Unix(integerValue, 0)
	}

	return nil
}
source: func SetRawValues(data []byte, values []types.Datum) error {
	for i := 0; i < len(values); i++ {
		l, err := peek(data)
		if err != nil {
			return errors.Trace(err)
		}
		values[i].SetRaw(data[:l:l])
		data = data[l:]
	}
	return nil
}
source: func PNGCompressionLevel(level png.CompressionLevel) EncodeOption {
	return func(c *encodeConfig) {
		c.pngCompressionLevel = level
	}
}
source: func (d *stiDocker) Version() (dockertypes.Version, error) {
	ctx, cancel := getDefaultContext()
	defer cancel()
	return d.client.ServerVersion(ctx)
}
source: func Dial(address string) (*Conn, error) {
	tr, err := getTransport(address)
	if err != nil {
		return nil, err
	}
	return newConn(tr)
}
source: func dumpRespBody(resp *http.Response) ([]byte, error) {
	if resp.Body == nil {
		return nil, nil
	}
	var b bytes.Buffer
	savecl := resp.ContentLength
	var save io.ReadCloser
	var err error
	save, resp.Body, err = drainBody(resp.Body)
	if err != nil {
		return nil, err
	}
	_, err = io.Copy(&b, resp.Body)
	if err != nil {
		return nil, err
	}
	resp.Body = save
	resp.ContentLength = savecl
	if err != nil {
		return nil, err
	}
	return b.Bytes(), nil
}
source: func (c *Tracing) StartWithParams(v *TracingStartParams) (*gcdmessage.ChromeResponse, error) {
	return gcdmessage.SendDefaultRequest(c.target, c.target.GetSendCh(), &gcdmessage.ParamRequest{Id: c.target.GetId(), Method: "Tracing.start", Params: v})
}
source: func (c *FakeJobs) List(opts v1.ListOptions) (result *batchv1.JobList, err error) {
	obj, err := c.Fake.
		Invokes(testing.NewListAction(jobsResource, jobsKind, c.ns, opts), &batchv1.JobList{})

	if obj == nil {
		return nil, err
	}

	label, _, _ := testing.ExtractFromListOptions(opts)
	if label == nil {
		label = labels.Everything()
	}
	list := &batchv1.JobList{ListMeta: obj.(*batchv1.JobList).ListMeta}
	for _, item := range obj.(*batchv1.JobList).Items {
		if label.Matches(labels.Set(item.Labels)) {
			list.Items = append(list.Items, item)
		}
	}
	return list, err
}
source: func (s *StructInjector) setState() {
	// note for zero length of struct's fields:
	// if struct doesn't contain any field
	// so both of the below variables will be 0,
	// so it's a singleton.
	// At the other hand the `s.HasFields` maybe false
	// but the struct may contain UNEXPORTED fields or non-bindable fields (request-scoped on both cases)
	// so a new controller/struct at the caller side should be initialized on each request,
	// we should not depend on the `HasFields` for singleton or no, this is the reason I
	// added the `.State` now.

	staticBindingsFieldsLength := s.countBindType(Static)
	allStructFieldsLength := NumFields(s.elemType, false)
	// check if unexported(and exported) fields are set-ed manually or via binding (at this time we have all fields set-ed inside the "initRef")
	// i.e &Controller{unexportedField: "my value"}
	// or dependencies values = "my value" and Controller struct {Field string}
	// if so then set the temp staticBindingsFieldsLength to that number, so for example:
	// if static binding length is 0
	// but an unexported field is set-ed then act that as singleton.
	if allStructFieldsLength > staticBindingsFieldsLength {
		structFieldsUnexportedNonZero := LookupNonZeroFieldsValues(s.initRef, false)
		staticBindingsFieldsLength = len(structFieldsUnexportedNonZero)
	}

	// println("staticBindingsFieldsLength: ", staticBindingsFieldsLength)
	// println("allStructFieldsLength: ", allStructFieldsLength)

	// if the number of static values binded is equal to the
	// total struct's fields(including unexported fields this time) then set as singleton.
	if staticBindingsFieldsLength == allStructFieldsLength {
		s.Scope = Singleton
		// the default is `Stateless`, which means that a new instance should be created
		//  on each inject action by the caller.
		return
	}

	s.CanInject = s.Scope == Stateless && s.Has
}
source: func (sp *SAMLServiceProvider) validateResponseAttributes(response *types.Response) error {
	if response.Destination != "" && response.Destination != sp.AssertionConsumerServiceURL {
		return ErrInvalidValue{
			Key:      DestinationAttr,
			Expected: sp.AssertionConsumerServiceURL,
			Actual:   response.Destination,
		}
	}

	if response.Version != "2.0" {
		return ErrInvalidValue{
			Reason:   ReasonUnsupported,
			Key:      "SAML version",
			Expected: "2.0",
			Actual:   response.Version,
		}
	}

	return nil
}
source: func (f *FilterOp) Exists(field string) *FilterOp {
	f.ExistsProp = &propertyPathMarker{Field: field}
	return f
}
source: func NewChannelDisabled(flags uint16, update ChannelUpdate) *FailChannelDisabled {
	return &FailChannelDisabled{
		Flags:  flags,
		Update: update,
	}
}
source: func (q *queue) Idle() bool {
	q.lock.Lock()
	defer q.lock.Unlock()

	queued := q.blockTaskQueue.Size() + q.receiptTaskQueue.Size()
	pending := len(q.blockPendPool) + len(q.receiptPendPool)
	cached := len(q.blockDonePool) + len(q.receiptDonePool)

	return (queued + pending + cached) == 0
}
source: func (ui *CommandlineUI) readString() string {
	for {
		fmt.Printf("> ")
		text, err := ui.in.ReadString('\n')
		if err != nil {
			log.Crit("Failed to read user input", "err", err)
		}
		if text = strings.TrimSpace(text); text != "" {
			return text
		}
	}
}
source: func (c *ModelBuilderContext) EnsureTask(task Task) error {
	task = c.setLifecycleOverride(task)
	key := buildTaskKey(task)

	existing, found := c.Tasks[key]
	if found {
		if reflect.DeepEqual(task, existing) {
			glog.V(8).Infof("EnsureTask ignoring identical ")
			return nil
		} else {
			glog.Warningf("EnsureTask found task mismatch for %q", key)
			glog.Warningf("\tExisting: %v", existing)
			glog.Warningf("\tNew: %v", task)

			return fmt.Errorf("cannot add different task with same key %q", key)
		}
	}
	c.Tasks[key] = task
	return nil
}
source: func Debug(format string, v ...interface{}) {
	log.Debug(fmt.Sprintf(format, v...))
}
source: func (ap *AccountPermissions) Clone() AccountPermissions {
	// clone base permissions
	basePermissionsClone := ap.Base
	var rolesClone []string
	// It helps if we normalise empty roles to []string(nil) rather than []string{}
	if len(ap.Roles) > 0 {
		// clone roles []string
		rolesClone = make([]string, len(ap.Roles))
		// strings are immutable so copy suffices
		copy(rolesClone, ap.Roles)
	}

	return AccountPermissions{
		Base:  basePermissionsClone,
		Roles: rolesClone,
	}
}
source: func (e *Ethtool) Change(intf string, config map[string]bool) error {
	names, err := e.FeatureNames(intf)
	if err != nil {
		return err
	}

	length := uint32(len(names))

	features := ethtoolSfeatures{
		cmd:  ETHTOOL_SFEATURES,
		size: (length + 32 - 1) / 32,
	}

	for key, value := range config {
		if index, ok := names[key]; ok {
			setFeatureBit(&features.blocks, index, value)
		} else {
			return fmt.Errorf("unsupported feature %q", key)
		}
	}

	return e.ioctl(intf, uintptr(unsafe.Pointer(&features)))
}
source: func (c *Client) HealthService() grpc_health_v1.HealthClient {
	c.connMu.Lock()
	defer c.connMu.Unlock()
	return grpc_health_v1.NewHealthClient(c.conn)
}
source: func (s *GetInsightResultsOutput) SetInsightResults(v *InsightResults) *GetInsightResultsOutput {
	s.InsightResults = v
	return s
}
source: func Fibonacci(factor time.Duration) Algorithm {
	return func(attempt uint) time.Duration {
		return (factor * time.Duration(fibonacciNumber(attempt)))
	}
}
source: func Marshal(message proto.Message) (string, error) {
	data, err := proto.Marshal(message)
	if err != nil {
		return "", err
	}
	return base64.RawURLEncoding.EncodeToString(data), nil
}
source: func (logger *Logger) Log(priority Priority, v ...interface{}) {
	fields := logger.fieldValues()
	fields["priority"] = priority
	fields["message"] = fmt.Sprint(v...)
	for _, sink := range logger.sinks {
		sink.Log(fields)
	}
}
source: func (c *Storage) TrackCacheStorageForOriginWithParams(v *StorageTrackCacheStorageForOriginParams) (*gcdmessage.ChromeResponse, error) {
	return gcdmessage.SendDefaultRequest(c.target, c.target.GetSendCh(), &gcdmessage.ParamRequest{Id: c.target.GetId(), Method: "Storage.trackCacheStorageForOrigin", Params: v})
}
source: func (sk *Sketch) maybeToNormal() {
	if uint32(len(sk.tmpSet))*100 > sk.m {
		sk.mergeSparse()
		if uint32(sk.sparseList.Len()) > sk.m {
			sk.toNormal()
		}
	}
}
source: func OptionIngress() SandboxOption {
	return func(sb *sandbox) {
		sb.ingress = true
		sb.oslTypes = append(sb.oslTypes, osl.SandboxTypeIngress)
	}
}
source: func (s *Subscription) PendingLimits() (int, int, error) {
	if s == nil {
		return -1, -1, ErrBadSubscription
	}
	s.mu.Lock()
	defer s.mu.Unlock()
	if s.conn == nil {
		return -1, -1, ErrBadSubscription
	}
	if s.typ == ChanSubscription {
		return -1, -1, ErrTypeSubscription
	}
	return s.pMsgsLimit, s.pBytesLimit, nil
}
source: func (c *imageResolutionCache) ResolveObjectReference(ref *kapi.ObjectReference, defaultNamespace string, forceResolveLocalNames bool) (*rules.ImagePolicyAttributes, error) {
	switch ref.Kind {
	case "ImageStreamTag":
		ns := ref.Namespace
		if len(ns) == 0 {
			ns = defaultNamespace
		}
		name, tag, ok := imageapi.SplitImageStreamTag(ref.Name)
		if !ok {
			return &rules.ImagePolicyAttributes{IntegratedRegistry: true}, fmt.Errorf("references of kind ImageStreamTag must be of the form NAME:TAG")
		}
		return c.resolveImageStreamTag(ns, name, tag, false, false)

	case "ImageStreamImage":
		ns := ref.Namespace
		if len(ns) == 0 {
			ns = defaultNamespace
		}
		name, id, ok := imageapi.SplitImageStreamImage(ref.Name)
		if !ok {
			return &rules.ImagePolicyAttributes{IntegratedRegistry: true}, fmt.Errorf("references of kind ImageStreamImage must be of the form NAME@DIGEST")
		}
		return c.resolveImageStreamImage(ns, name, id)

	case "DockerImage":
		ref, err := imageapi.ParseDockerImageReference(ref.Name)
		if err != nil {
			return nil, err
		}
		return c.resolveImageReference(ref, defaultNamespace, forceResolveLocalNames)

	default:
		return nil, fmt.Errorf("image policy does not allow image references of kind %q", ref.Kind)
	}
}
source: func (m *MonitorFormatter) traceEvents(prefix string, data []byte) {
	tn := monitor.TraceNotify{}

	if err := binary.Read(bytes.NewReader(data), byteorder.Native, &tn); err != nil {
		fmt.Printf("Error while parsing trace notification message: %s\n", err)
	}
	if m.match(monitorAPI.MessageTypeTrace, tn.Source, tn.DstID) {
		switch m.Verbosity {
		case INFO:
			tn.DumpInfo(data)
		case JSON:
			tn.DumpJSON(data, prefix)
		default:
			fmt.Println(msgSeparator)
			tn.DumpVerbose(!m.Hex, data, prefix)
		}
	}
}
source: func (o *UplinkConnection) CreateCustomProperty(child *CustomProperty) *bambou.Error {

	return bambou.CurrentSession().CreateChild(o, child)
}
source: func (s *Segmenter) Err() error {
	if s.err == io.EOF {
		return nil
	}
	return s.err
}
source: func (mp MultiPolygon) Bound() Bound {
	if len(mp) == 0 {
		return emptyBound
	}
	bound := mp[0].Bound()
	for i := 1; i < len(mp); i++ {
		bound = bound.Union(mp[i].Bound())
	}

	return bound
}
source: func (be *BuiltinBackupEngine) ExecuteRestore(
	ctx context.Context,
	cnf *Mycnf,
	mysqld MysqlDaemon,
	logger logutil.Logger,
	dir string,
	bhs []backupstorage.BackupHandle,
	restoreConcurrency int,
	hookExtraEnv map[string]string) (mysql.Position, error) {

	var bh backupstorage.BackupHandle
	var bm builtinBackupManifest
	var toRestore int

	for toRestore = len(bhs) - 1; toRestore >= 0; toRestore-- {
		bh = bhs[toRestore]
		rc, err := bh.ReadFile(ctx, backupManifest)
		if err != nil {
			log.Warningf("Possibly incomplete backup %v in directory %v on BackupStorage: can't read MANIFEST: %v)", bh.Name(), dir, err)
			continue
		}

		err = json.NewDecoder(rc).Decode(&bm)
		rc.Close()
		if err != nil {
			log.Warningf("Possibly incomplete backup %v in directory %v on BackupStorage (cannot JSON decode MANIFEST: %v)", bh.Name(), dir, err)
			continue
		}

		logger.Infof("Restore: found backup %v %v to restore with %v files", bh.Directory(), bh.Name(), len(bm.FileEntries))
		break
	}
	if toRestore < 0 {
		// There is at least one attempted backup, but none could be read.
		// This implies there is data we ought to have, so it's not safe to start
		// up empty.
		return mysql.Position{}, errors.New("backup(s) found but none could be read, unsafe to start up empty, restart to retry restore")
	}

	// Starting from here we won't be able to recover if we get stopped by a cancelled
	// context. Thus we use the background context to get through to the finish.

	logger.Infof("Restore: shutdown mysqld")
	err := mysqld.Shutdown(context.Background(), cnf, true)
	if err != nil {
		return mysql.Position{}, err
	}

	logger.Infof("Restore: deleting existing files")
	if err := removeExistingFiles(cnf); err != nil {
		return mysql.Position{}, err
	}

	logger.Infof("Restore: reinit config file")
	err = mysqld.ReinitConfig(context.Background(), cnf)
	if err != nil {
		return mysql.Position{}, err
	}

	logger.Infof("Restore: copying all files")
	if err := be.restoreFiles(context.Background(), cnf, bh, bm.FileEntries, bm.TransformHook, !bm.SkipCompress, restoreConcurrency, hookExtraEnv); err != nil {
		return mysql.Position{}, err
	}

	return bm.Position, nil
}
source: func (c *Config) ProxySSH() bool {
	value, _ := c.defined["proxy-ssh"].(bool)
	return value
}
source: func NewSetWebLifecycleStateArgs(state string) *SetWebLifecycleStateArgs {
	args := new(SetWebLifecycleStateArgs)
	args.State = state
	return args
}
source: func Convert_v1_BuildStatusOutput_To_build_BuildStatusOutput(in *v1.BuildStatusOutput, out *build.BuildStatusOutput, s conversion.Scope) error {
	return autoConvert_v1_BuildStatusOutput_To_build_BuildStatusOutput(in, out, s)
}
source: func (i *instanceManager) AllStats() []*device.DeviceGroupStats {
	i.deviceStatsLock.RLock()
	defer i.deviceStatsLock.RUnlock()
	return i.deviceStats
}
source: func (h *stiGit) Checkout(repo, ref string) error {
	opts := cmd.CommandOpts{
		Stdout: os.Stdout,
		Stderr: os.Stderr,
		Dir:    repo,
	}
	if log.V(1) {
		return h.RunWithOptions(opts, "git", "checkout", ref)
	}
	return h.RunWithOptions(opts, "git", "checkout", "--quiet", ref)
}
source: func (e *Enforcer) RunPolicyLoader(ctx context.Context) error {
	cm, err := e.clientset.CoreV1().ConfigMaps(e.namespace).Get(e.configmap, metav1.GetOptions{})
	if err != nil {
		if !apierr.IsNotFound(err) {
			return err
		}
	} else {
		err = e.syncUpdate(cm)
		if err != nil {
			return err
		}
	}
	e.runInformer(ctx)
	return nil
}
source: func (a *SetVirtualTimePolicyArgs) SetBudget(budget float64) *SetVirtualTimePolicyArgs {
	a.Budget = &budget
	return a
}
source: func FixConfig(cfg *Config) {
	if cfg == nil {
		return
	}
	if cfg.Endpoint == "" {
		cfg.Endpoint = DefaultEndpoint
	}
}
source: func (gp *EpgPolicy) Delete() error {
	// delete from the DB
	delete(epgPolicyDb, gp.EpgPolicyKey)

	return gp.Clear()
}
source: func (b *AdapterBase) Informers() (informers.SharedInformerFactory, error) {
	if b.informers == nil {
		clientConfig, err := b.ClientConfig()
		if err != nil {
			return nil, err
		}
		kubeClient, err := kubernetes.NewForConfig(clientConfig)
		if err != nil {
			return nil, err
		}
		b.informers = informers.NewSharedInformerFactory(kubeClient, 0)
	}

	return b.informers, nil
}
source: func extractFieldsFromRegex(re *regexp.Regexp, input string) map[string]string {
	submatches := re.FindStringSubmatch(input)
	results := make(map[string]string)
	subexpNames := re.SubexpNames()
	if len(subexpNames) > len(submatches) {
		log.Printf("D! No matches found in '%s'", input)
		return results
	}
	for i, name := range subexpNames {
		if name != input && name != "" && input != "" {
			results[name] = trim(submatches[i])
		}
	}
	return results
}
source: func IPCount(subnet net.IPNet) float64 {
	maskSize, _ := subnet.Mask.Size()

	if subnet.IP.To4() != nil {
		return math.Pow(2, float64(32-maskSize))
	} else {
		return math.Pow(2, float64(128-maskSize))
	}

}
source: func (daemon *Daemon) reloadClusterDiscovery(conf *config.Config, attributes map[string]string) (err error) {
	defer func() {
		// prepare reload event attributes with updatable configurations
		attributes["cluster-store"] = conf.ClusterStore
		attributes["cluster-advertise"] = conf.ClusterAdvertise

		attributes["cluster-store-opts"] = "{}"
		if daemon.configStore.ClusterOpts != nil {
			opts, err2 := json.Marshal(conf.ClusterOpts)
			if err != nil {
				err = err2
			}
			attributes["cluster-store-opts"] = string(opts)
		}
	}()

	newAdvertise := conf.ClusterAdvertise
	newClusterStore := daemon.configStore.ClusterStore
	if conf.IsValueSet("cluster-advertise") {
		if conf.IsValueSet("cluster-store") {
			newClusterStore = conf.ClusterStore
		}
		newAdvertise, err = config.ParseClusterAdvertiseSettings(newClusterStore, conf.ClusterAdvertise)
		if err != nil && err != discovery.ErrDiscoveryDisabled {
			return err
		}
	}

	if daemon.clusterProvider != nil {
		if err := conf.IsSwarmCompatible(); err != nil {
			return err
		}
	}

	// check discovery modifications
	if !config.ModifiedDiscoverySettings(daemon.configStore, newClusterStore, newAdvertise, conf.ClusterOpts) {
		return nil
	}

	// enable discovery for the first time if it was not previously enabled
	if daemon.discoveryWatcher == nil {
		discoveryWatcher, err := discovery.Init(newClusterStore, newAdvertise, conf.ClusterOpts)
		if err != nil {
			return fmt.Errorf("failed to initialize discovery: %v", err)
		}
		daemon.discoveryWatcher = discoveryWatcher
	} else if err == discovery.ErrDiscoveryDisabled {
		// disable discovery if it was previously enabled and it's disabled now
		daemon.discoveryWatcher.Stop()
	} else if err = daemon.discoveryWatcher.Reload(conf.ClusterStore, newAdvertise, conf.ClusterOpts); err != nil {
		// reload discovery
		return err
	}

	daemon.configStore.ClusterStore = newClusterStore
	daemon.configStore.ClusterOpts = conf.ClusterOpts
	daemon.configStore.ClusterAdvertise = newAdvertise

	if daemon.netController == nil {
		return nil
	}
	netOptions, err := daemon.networkOptions(daemon.configStore, daemon.PluginStore, nil)
	if err != nil {
		logrus.WithError(err).Warn("failed to get options with network controller")
		return nil
	}
	err = daemon.netController.ReloadConfiguration(netOptions...)
	if err != nil {
		logrus.Warnf("Failed to reload configuration with network controller: %v", err)
	}
	return nil
}
source: func (s *RPCServer) GetThread(arg GetThreadIn, out *GetThreadOut) error {
	t, err := s.debugger.FindThread(arg.Id)
	if err != nil {
		return err
	}
	if t == nil {
		return fmt.Errorf("no thread with id %d", arg.Id)
	}
	out.Thread = t
	return nil
}
source: func (c *Manager) FilterLibraryItem(ctx context.Context, libraryItemID string, filter FilterRequest) (FilterResponse, error) {
	url := internal.URL(c, internal.VCenterOVFLibraryItem).WithID(libraryItemID).WithAction("filter")
	var res FilterResponse
	return res, c.Do(ctx, url.Request(http.MethodPost, filter), &res)
}
source: func parseTrustedNodes(trustedNodes []string) map[enode.ID]*enode.Node {
	nodes := make(map[enode.ID]*enode.Node)

	for _, node := range trustedNodes {
		node, err := enode.ParseV4(node)
		if err != nil {
			log.Warn("Trusted node URL invalid", "enode", node, "err", err)
			continue
		}
		nodes[node.ID()] = node
	}
	return nodes
}
source: func NewSchemaOrSchemaArrayWithSchema(s *Schema) *SchemaOrSchemaArray {
	result := &SchemaOrSchemaArray{}
	result.Schema = s
	return result
}
source: func getRootDirInfo(rootDir string) (int64, int64, error) {
	cmd := exec.Command("df", "-k", "--output=size,used", rootDir)
	output, err := cmd.Output()
	if err != nil {
		return 0, 0, err
	}
	return parseInfo(string(output))
}
source: func (api *PublicWhisperAPI) GetPublicKey(ctx context.Context, id string) (hexutil.Bytes, error) {
	key, err := api.w.GetPrivateKey(id)
	if err != nil {
		return hexutil.Bytes{}, err
	}
	return crypto.FromECDSAPub(&key.PublicKey), nil
}
source: func Init(c Config) {
	if c.LoggerLevel != "" {
		config.LoggerLevel = c.LoggerLevel
	}

	if c.LoggerFile != "" {
		config.LoggerFile = c.LoggerFile
		config.Writers = append(config.Writers, "file")
	}

	if c.EnableRsyslog {
		config.EnableRsyslog = c.EnableRsyslog
	}

	if c.RsyslogNetwork != "" {
		config.RsyslogNetwork = c.RsyslogNetwork
	}

	if c.RsyslogAddr != "" {
		config.RsyslogAddr = c.RsyslogAddr
	}
	if len(c.Writers) == 0 {
		config.Writers = append(config.Writers, "stdout")

	} else {
		config.Writers = c.Writers
	}
	config.LogFormatText = c.LogFormatText
	RegisterWriter("stdout", os.Stdout)
	var file io.Writer
	var err error
	if config.LoggerFile != "" {
		file, err = os.OpenFile(config.LoggerFile, os.O_APPEND|os.O_CREATE|os.O_WRONLY, 0666)
		if err != nil {
			panic(err)
		}

	}
	for _, sink := range config.Writers {
		if sink == "file" {
			if file == nil {
				log.Panic("Must set file path")
			}
			RegisterWriter("file", file)
		}
	}
}
source: func ExitError(ctx context.Context, exitCode int, err error, format string, args ...interface{}) error {
	if err != nil {
		out.Debug(ctx, "Stacktrace: %+v", err)
	}
	return cli.NewExitError(fmt.Sprintf(format, args...), exitCode)
}
source: func Generate(w http.ResponseWriter, r *http.Request, opts ...GenerateOption) {
	o := &GenerateOptions{
		name:   XSRFCookieName,
		path:   "/",
		domain: "",
		maxAge: 0,
	}
	for _, opt := range opts {
		opt(o)
	}
	if !hasCookie(r, o.name) || o.force {
		http.SetCookie(w, &http.Cookie{
			Name:   o.name,
			Value:  newKey(),
			Path:   o.path,
			Domain: o.domain,
			Secure: r.TLS != nil,
			MaxAge: o.maxAge,
		})
	}
}
source: func (s *Store) Exists(ctx context.Context, name string) bool {
	out.Debug(ctx, "consul.Exists(%s)", name)
	v, err := s.Get(ctx, name)
	if err == nil && v != nil {
		return true
	}
	return false
}
source: func (b *UpdateService) Routing(routing string) *UpdateService {
	b.routing = routing
	return b
}
source: func (db *DB) DeleteBlocksAboveHeight(height int64) (NSummaryRows, NStakeInfoRows int64, err error) {
	// Attempt to purge the block data.
	NSummaryRows, NStakeInfoRows, err = db.deleteBlocksAboveHeight(height)
	if err != nil {
		return
	}

	err = db.updateHeights()
	return
}
source: func WriteServerBinary(w io.Writer, p []byte) error {
	return WriteServerMessage(w, ws.OpBinary, p)
}
source: func (c *Controller) Query(ctx context.Context, req *query.Request) (flux.Query, error) {
	// Set the request on the context so platform specific Flux operations can retrieve it later.
	ctx = query.ContextWithRequest(ctx, req)
	// Set the org label value for controller metrics
	ctx = context.WithValue(ctx, orgLabel, req.OrganizationID.String())
	q, err := c.c.Query(ctx, req.Compiler)
	if err != nil {
		// If the controller reports an error, it's usually because of a syntax error
		// or other problem that the client must fix.
		return q, &platform.Error{
			Code: platform.EInvalid,
			Msg:  err.Error(),
		}
	}

	return q, nil
} 66%|██████▌   | 3278/5000 [00:04<00:02, 736.11it/s]
source: func (s *DescribeAccountModificationsOutput) SetAccountModifications(v []*AccountModification) *DescribeAccountModificationsOutput {
	s.AccountModifications = v
	return s
}
source: func (m TerrainMap) Slice(bounds coord.Bounds) TerrainMap {
	bounds, err := m.Bounds.Intersection(bounds)
	if err != nil {
		panic("invalid terrain map slicing operation: " + err.Error())
	}

	x := bounds.TopL.X - m.Bounds.TopL.X
	y := -(bounds.TopL.Y - m.Bounds.TopL.Y)
	w, h := bounds.Width(), bounds.Height()
	rows := make([][]TerrainType, h)

	for i, row := range m.TerrainTypes[y : y+h] {
		rows[i] = row[x : x+w]
	}

	return TerrainMap{
		bounds,
		rows,
	}
}
source: func GetEntry(hash string) (*Entry, error) {
	params := hashRequest{Hash: hash}
	req := NewJSON2Request("entry", APICounter(), params)
	resp, err := factomdRequest(req)
	if err != nil {
		return nil, err
	}
	if resp.Error != nil {
		return nil, resp.Error
	}

	e := new(Entry)
	if err := json.Unmarshal(resp.JSONResult(), e); err != nil {
		return nil, err
	}

	return e, nil
}
source: func (m Match) Match(position int) (string, error) {
	matches := m.Command.Expression().FindAllStringSubmatch(m.Request, -1)

	if len(matches) != 1 {
		return "", errors.New("Unable to parse request")
	}

	if position >= len(matches[0]) {
		return "", fmt.Errorf("No parameter at position %d", position)
	}

	return matches[0][position+1], nil
}
source: func (r *Route) LogFields() logrus.Fields {
	return logrus.Fields{
		"prefix":            r.Prefix,
		"nexthop":           r.Nexthop,
		"local":             r.Local,
		logfields.Interface: r.Device,
	}
}
source: func CheckCertificateSigningRequest(d Depot, name string) bool {
	return d.Check(CsrTag(name))
}
source: func (m *MockMachine) SetModificationStatus(arg0 status.StatusInfo) error {
	ret := m.ctrl.Call(m, "SetModificationStatus", arg0)
	ret0, _ := ret[0].(error)
	return ret0
}
source: func Record(cl *Client, span *ssf.SSFSpan, done chan<- error) error {
	if cl == nil {
		return ErrNoClient
	}

	op := &recordOp{span: span, result: done}
	select {
	case cl.spans <- span:
		atomic.AddInt64(&cl.successfulRecords, 1)
		if done != nil {
			go func() { done <- nil }()
		}
		return nil
	case cl.records <- op:
		atomic.AddInt64(&cl.successfulRecords, 1)
		return nil
	default:
	}
	atomic.AddInt64(&cl.failedRecords, 1)
	return ErrWouldBlock
}
source: func (s *ChainService) BanPeer(sp *ServerPeer) {
	select {
	case s.banPeers <- sp:
	case <-s.quit:
		return
	}
}
source: func (s *sender) retransmitTimerExpired() bool {
	// Check if the timer actually expired or if it's a spurious wake due
	// to a previously orphaned runtime timer.
	if !s.resendTimer.checkExpiration() {
		return true
	}

	s.ep.stack.Stats().TCP.Timeouts.Increment()

	// Give up if we've waited more than a minute since the last resend.
	if s.rto >= 60*time.Second {
		return false
	}

	// Set new timeout. The timer will be restarted by the call to sendData
	// below.
	s.rto *= 2

	if s.fr.active {
		// We were attempting fast recovery but were not successful.
		// Leave the state. We don't need to update ssthresh because it
		// has already been updated when entered fast-recovery.
		s.leaveFastRecovery()
	}

	// See: https://tools.ietf.org/html/rfc6582#section-3.2 Step 4.
	// We store the highest sequence number transmitted in cases where
	// we were not in fast recovery.
	s.fr.last = s.sndNxt - 1

	s.cc.HandleRTOExpired()

	// Mark the next segment to be sent as the first unacknowledged one and
	// start sending again. Set the number of outstanding packets to 0 so
	// that we'll be able to retransmit.
	//
	// We'll keep on transmitting (or retransmitting) as we get acks for
	// the data we transmit.
	s.outstanding = 0

	// Expunge all SACK information as per https://tools.ietf.org/html/rfc6675#section-5.1
	//
	//  In order to avoid memory deadlocks, the TCP receiver is allowed to
	//  discard data that has already been selectively acknowledged. As a
	//  result, [RFC2018] suggests that a TCP sender SHOULD expunge the SACK
	//  information gathered from a receiver upon a retransmission timeout
	//  (RTO) "since the timeout might indicate that the data receiver has
	//  reneged." Additionally, a TCP sender MUST "ignore prior SACK
	//  information in determining which data to retransmit."
	//
	// NOTE: We take the stricter interpretation and just expunge all
	// information as we lack more rigorous checks to validate if the SACK
	// information is usable after an RTO.
	s.ep.scoreboard.Reset()
	s.writeNext = s.writeList.Front()
	s.sendData()

	return true
}
source: func fromNetworkHostsPorts(netHostsPorts [][]network.HostPort) [][]hostPort {
	hsps := make([][]hostPort, len(netHostsPorts))
	for i, netHostPorts := range netHostsPorts {
		hsps[i] = make([]hostPort, len(netHostPorts))
		for j, netHostPort := range netHostPorts {
			hsps[i][j] = fromNetworkHostPort(netHostPort)
		}
	}
	return hsps
}
source: func ParseFont(fontReader io.Reader) (*truetype.Font, error) {
	fontBytes, err := ioutil.ReadAll(fontReader)
	if err != nil {
		return nil, err
	}

	font, err := freetype.ParseFont(fontBytes)
	if err != nil {
		return nil, err
	}

	return font, nil
}
source: func Uint64n(n uint64) uint64 {
	if n == 0 {
		panic("fastrand: argument to Uint64n is 0")
	}
	// To eliminate modulo bias, keep selecting at random until we fall within
	// a range that is evenly divisible by n.
	// NOTE: since n is at most math.MaxUint64, max is minimized when:
	//    n = math.MaxUint64/2 + 1 -> max = math.MaxUint64 - math.MaxUint64/2
	// This gives an expected 2 tries before choosing a value < max.
	max := math.MaxUint64 - math.MaxUint64%n
	b := Bytes(8)
	r := *(*uint64)(unsafe.Pointer(&b[0]))
	for r >= max {
		Read(b)
		r = *(*uint64)(unsafe.Pointer(&b[0]))
	}
	return r % n
}
source: func Password(url string) string {
	auth := strings.SplitN(credentials(url), ":", 2)
	if len(auth) < 2 {
		return ""
	}
	return auth[1]
}
source: func (a *Agent) ListKeys(token string, relayFactor uint8) (*structs.KeyringResponses, error) {
	args := structs.KeyringRequest{Operation: structs.KeyringList}
	parseKeyringRequest(&args, token, relayFactor)
	return a.keyringProcess(&args)
}
source: func ProfileGet(name string) func(context.Context) ([]byte, time.Time, error) {
	p := pprof.Lookup(name)
	if p == nil {
		return nil
	}

	// See https://golang.org/pkg/runtime/pprof/#Profile.WriteTo
	// for the meaning of debug.
	debug := 1
	if name == "goroutine" {
		debug = 2
	}
	return profileRead(p, debug)
}
source: func (r *Store) GitPull(ctx context.Context, name, origin, remote string) error {
	ctx, store, _ := r.getStore(ctx, name)
	return store.RCS().Pull(ctx, origin, remote)
}
source: func (o *os) setup() {
	for i := 0; i < 10; i++ {
		// wait till there's a valid address from the server
		if p := strings.Split(o.address(), ":"); len(p) < 2 {
			time.Sleep(GossipEvent / 100.0)
			continue
		}
		// have a valid address, setup, now
		o.subscriber(context.Background(), &Announcement{
			Namespace: o.opts.Namespace,
			Address:   o.address(),
			Timestamp: time.Now().Unix(),
		})
		return
	}
}
source: func NewMemberChangeNameType(Description string) *MemberChangeNameType {
	s := new(MemberChangeNameType)
	s.Description = Description
	return s
}
source: func FamiliarString(ref Reference) string {
	if nn, ok := ref.(normalizedNamed); ok {
		return nn.Familiar().String()
	}
	return ref.String()
}
source: func (c *Conversation) End() (toSend []ValidMessage, err error) {
	previousMsgState := c.msgState
	if c.msgState == encrypted {
		c.smp.wipe()
		// Error can only happen when Rand reader is broken
		toSend, _, err = c.createSerializedDataMessage(nil, messageFlagIgnoreUnreadable, []tlv{tlv{tlvType: tlvTypeDisconnected}})
	}
	c.lastMessageStateChange = time.Time{}
	c.ake = nil
	c.msgState = plainText
	defer c.signalSecurityEventIf(previousMsgState == encrypted, GoneInsecure)

	c.keys.ourCurrentDHKeys.wipe()
	c.keys.ourPreviousDHKeys.wipe()
	wipeBigInt(c.keys.theirCurrentDHPubKey)
	return
}
source: func NewSpaceTemplateController(service *goa.Service, db application.DB, config SpaceTemplateControllerConfiguration) *SpaceTemplateController {
	return &SpaceTemplateController{Controller: service.NewController("SpaceTemplateController"), db: db, config: config}
}
source: func decorateAndWriteInfo(
	store jujuclient.ClientStore,
	details prepareDetails,
	controllerName, modelName string,
) error {
	qualifiedModelName := jujuclient.JoinOwnerModelName(
		names.NewUserTag(details.AccountDetails.User),
		modelName,
	)
	if err := store.AddController(controllerName, details.ControllerDetails); err != nil {
		return errors.Trace(err)
	}
	if err := store.UpdateBootstrapConfig(controllerName, details.BootstrapConfig); err != nil {
		return errors.Trace(err)
	}
	if err := store.UpdateAccount(controllerName, details.AccountDetails); err != nil {
		return errors.Trace(err)
	}
	if err := store.UpdateModel(controllerName, qualifiedModelName, details.ModelDetails); err != nil {
		return errors.Trace(err)
	}
	if err := store.SetCurrentModel(controllerName, qualifiedModelName); err != nil {
		return errors.Trace(err)
	}
	return nil
}
source: func (t *Template) Execute(w io.Writer, data interface{}) error {
	return t.tmpl.Execute(w, data)
}
source: func (a *Account) removeServiceImport(subject string) {
	a.mu.Lock()
	si, ok := a.imports.services[subject]
	if ok && si != nil && si.ae {
		a.nae--
	}
	delete(a.imports.services, subject)
	a.mu.Unlock()
	if a.srv != nil && a.srv.gateway.enabled {
		a.srv.gatewayHandleServiceImport(a, []byte(subject), nil, -1)
	}
}
source: func validateRoleMappings(roleMappings []interface{}) []error {
	errors := make([]error, 0)

	for _, r := range roleMappings {
		rm := r.(map[string]interface{})

		// If Type equals "Token" or "Rules", ambiguous_role_resolution must be defined.
		// This should be removed as soon as we can have a ValidateFuncAgainst callable on the schema.
		if err := validateCognitoRoleMappingsAmbiguousRoleResolutionAgainstType(rm); len(err) > 0 {
			errors = append(errors, fmt.Errorf("Role Mapping %q: %v", rm["identity_provider"].(string), err))
		}

		// Validating that Rules Configuration is defined when Type equals Rules
		// but not defined when Type equals Token.
		if err := validateCognitoRoleMappingsRulesConfiguration(rm); len(err) > 0 {
			errors = append(errors, fmt.Errorf("Role Mapping %q: %v", rm["identity_provider"].(string), err))
		}
	}

	return errors
}
source: func Deserialize(p []byte) (*stats.CPUStats, error) {
	st := &stats.CPUStats{}
	err := json.Unmarshal(p, st)
	if err != nil {
		return nil, err
	}
	return st, nil
}
source: func (h *BrandsHandler) GetBrand(w http.ResponseWriter, r *http.Request) {
	uuidMatcher := regexp.MustCompile(validUUID)
	vars := mux.Vars(r)
	UUID := vars["uuid"]
	transID := transactionidutils.GetTransactionIDFromRequest(r)
	w.Header().Set("Content-Type", "application/json")
	w.Header().Set("Cache-Control", CacheControlHeader)

	if UUID == "" || !uuidMatcher.MatchString(UUID) {
		msg := fmt.Sprintf(`uuid '%s' is either missing or invalid`, UUID)
		logger.WithTransactionID(transID).WithUUID(UUID).Error(msg)
		w.WriteHeader(http.StatusBadRequest)
		w.Write([]byte(`{"message": "` + msg + `"}`))
		return
	}

	brand, canonicalUUID, found, err := h.getBrandViaConceptsAPI(UUID, transID)
	if err != nil {
		w.WriteHeader(http.StatusInternalServerError)
		w.Write([]byte(`{"message": "failed to return brand"}`))
		return
	}

	if found && canonicalUUID != "" && canonicalUUID != UUID {
		redirectURL := strings.Replace(r.RequestURI, UUID, canonicalUUID, 1)
		logger.WithTransactionID(transID).WithUUID(UUID).Debug("serving redirect")
		w.Header().Set("Location", redirectURL)
		w.WriteHeader(http.StatusMovedPermanently)
		return
	}
	if !found {
		msg := fmt.Sprint("brand not found")
		w.WriteHeader(http.StatusNotFound)
		logger.WithTransactionID(transID).WithUUID(UUID).Info(msg)
		w.Write([]byte(`{"message": "` + msg + `"}`))
		return
	}

	logger.Debugf("Brand (uuid): %s\n", brand.ID)

	w.WriteHeader(http.StatusOK)
	err = json.NewEncoder(w).Encode(brand)
	if err != nil {
		msg := fmt.Sprintf("brand: %v could not be marshaled", brand)
		logger.WithError(err).WithTransactionID(transID).WithUUID(UUID).Error(msg)
		w.WriteHeader(http.StatusInternalServerError)
		w.Write([]byte(`{"message": "` + msg + `"}`))
	}
}
source: func (b *Buffer) PeekBack() float64 {
	if b.size == 0 {
		return 0
	}
	if b.tail == 0 {
		return b.array[len(b.array)-1]
	}
	return b.array[b.tail-1]
}
source: func (s *SendBounceInput) SetBounceSender(v string) *SendBounceInput {
	s.BounceSender = &v
	return s
}
source: func (bu *Binutils) String() string {
	r := bu.get()
	var llvmSymbolizer, addr2line, nm, objdump string
	if r.llvmSymbolizerFound {
		llvmSymbolizer = r.llvmSymbolizer
	}
	if r.addr2lineFound {
		addr2line = r.addr2line
	}
	if r.nmFound {
		nm = r.nm
	}
	if r.objdumpFound {
		objdump = r.objdump
	}
	return fmt.Sprintf("llvm-symbolizer=%q addr2line=%q nm=%q objdump=%q fast=%t",
		llvmSymbolizer, addr2line, nm, objdump, r.fast)
}
source: func (s *RadiusSettings) SetUseSameUsername(v bool) *RadiusSettings {
	s.UseSameUsername = &v
	return s
}
source: func parseLen(p []byte) (int, error) {
	if len(p) == 0 {
		return -1, protocolError("malformed length")
	}

	if p[0] == '-' && len(p) == 2 && p[1] == '1' {
		// handle $-1 and $-1 null replies.
		return -1, nil
	}

	var n int
	for _, b := range p {
		n *= 10
		if b < '0' || b > '9' {
			return -1, protocolError("illegal bytes in length")
		}
		n += int(b - '0')
	}

	return n, nil
}
source: func (fbo *folderBranchOps) getMostRecentFullyMergedMD(ctx context.Context) (
	ImmutableRootMetadata, error) {
	mergedRev, err := fbo.getJournalPredecessorRevision(ctx)
	if err != nil {
		return ImmutableRootMetadata{}, err
	}

	if mergedRev == kbfsmd.RevisionUninitialized {
		// No unflushed journal entries, so use the local head.
		lState := makeFBOLockState()
		return fbo.getMDForReadHelper(ctx, lState, mdReadNoIdentify)
	}

	// Otherwise, use the specified revision.
	rmd, err := getSingleMD(ctx, fbo.config, fbo.id(), kbfsmd.NullBranchID,
		mergedRev, kbfsmd.Merged, nil)
	if err != nil {
		return ImmutableRootMetadata{}, err
	}

	fbo.vlog.CLogf(
		ctx, libkb.VLog1, "Most recent fully merged revision is %d", mergedRev)
	return rmd, nil
}
source: func MakeHandler(bs Service, logger kitlog.Logger) http.Handler {
	opts := []kithttp.ServerOption{
		kithttp.ServerErrorHandler(transport.NewLogErrorHandler(logger)),
		kithttp.ServerErrorEncoder(encodeError),
	}

	bookCargoHandler := kithttp.NewServer(
		makeBookCargoEndpoint(bs),
		decodeBookCargoRequest,
		encodeResponse,
		opts...,
	)
	loadCargoHandler := kithttp.NewServer(
		makeLoadCargoEndpoint(bs),
		decodeLoadCargoRequest,
		encodeResponse,
		opts...,
	)
	requestRoutesHandler := kithttp.NewServer(
		makeRequestRoutesEndpoint(bs),
		decodeRequestRoutesRequest,
		encodeResponse,
		opts...,
	)
	assignToRouteHandler := kithttp.NewServer(
		makeAssignToRouteEndpoint(bs),
		decodeAssignToRouteRequest,
		encodeResponse,
		opts...,
	)
	changeDestinationHandler := kithttp.NewServer(
		makeChangeDestinationEndpoint(bs),
		decodeChangeDestinationRequest,
		encodeResponse,
		opts...,
	)
	listCargosHandler := kithttp.NewServer(
		makeListCargosEndpoint(bs),
		decodeListCargosRequest,
		encodeResponse,
		opts...,
	)
	listLocationsHandler := kithttp.NewServer(
		makeListLocationsEndpoint(bs),
		decodeListLocationsRequest,
		encodeResponse,
		opts...,
	)

	r := mux.NewRouter()

	r.Handle("/booking/v1/cargos", bookCargoHandler).Methods("POST")
	r.Handle("/booking/v1/cargos", listCargosHandler).Methods("GET")
	r.Handle("/booking/v1/cargos/{id}", loadCargoHandler).Methods("GET")
	r.Handle("/booking/v1/cargos/{id}/request_routes", requestRoutesHandler).Methods("GET")
	r.Handle("/booking/v1/cargos/{id}/assign_to_route", assignToRouteHandler).Methods("POST")
	r.Handle("/booking/v1/cargos/{id}/change_destination", changeDestinationHandler).Methods("POST")
	r.Handle("/booking/v1/locations", listLocationsHandler).Methods("GET")

	return r
}
source: func (s *InternalLBService) NewListInternalLoadBalancerVMsParams() *ListInternalLoadBalancerVMsParams {
	p := &ListInternalLoadBalancerVMsParams{}
	p.p = make(map[string]interface{})
	return p
}
source: func (e Encoder) AppendDurations(dst []byte, vals []time.Duration, unit time.Duration, useInt bool) []byte {
	if len(vals) == 0 {
		return append(dst, '[', ']')
	}
	dst = append(dst, '[')
	dst = e.AppendDuration(dst, vals[0], unit, useInt)
	if len(vals) > 1 {
		for _, d := range vals[1:] {
			dst = e.AppendDuration(append(dst, ','), d, unit, useInt)
		}
	}
	dst = append(dst, ']')
	return dst
}
source: func (db *DB) PropertyValue(propName string) string {
	if db.closed {
		panic(ErrDBClosed)
	}

	cname := C.CString(propName)
	value := C.GoString(C.leveldb_property_value(db.Ldb, cname))
	C.free(unsafe.Pointer(cname))
	return value
}
source: func (r *HealthRecord) IgnoredErrorString() string {
	if r.IgnoredError == nil {
		return ""
	}
	return r.IgnoredError.Error()
}
source: func (cache *DiskBlockCacheLocal) Shutdown(ctx context.Context) {
	// Wait for the cache to either finish starting or error.
	select {
	case <-cache.startedCh:
	case <-cache.startErrCh:
		return
	}
	cache.lock.Lock()
	defer cache.lock.Unlock()
	// shutdownCh has to be checked under lock, otherwise we can race.
	select {
	case <-cache.shutdownCh:
		cache.log.CWarningf(ctx, "Shutdown called more than once")
	default:
	}
	close(cache.shutdownCh)
	if cache.blockDb == nil {
		return
	}
	cache.closer()
	cache.blockDb = nil
	cache.metaDb = nil
	cache.tlfDb = nil
	if cache.useLimiter() {
		cache.config.DiskLimiter().onSimpleByteTrackerDisable(ctx,
			cache.cacheType, int64(cache.getCurrBytes()))
	}
	cache.hitMeter.Shutdown()
	cache.missMeter.Shutdown()
	cache.putMeter.Shutdown()
	cache.updateMeter.Shutdown()
	cache.evictCountMeter.Shutdown()
	cache.evictSizeMeter.Shutdown()
	cache.deleteCountMeter.Shutdown()
	cache.deleteSizeMeter.Shutdown()
}
source: func (this *NamespaceBasedEnricher) addNamespaceInfo(metricSet *core.MetricSet) {
	metricSetType, found := metricSet.Labels[core.LabelMetricSetType.Key]
	if !found {
		return
	}
	if metricSetType != core.MetricSetTypePodContainer &&
		metricSetType != core.MetricSetTypePod &&
		metricSetType != core.MetricSetTypeNamespace {
		return
	}

	namespaceName, found := metricSet.Labels[core.LabelNamespaceName.Key]
	if !found {
		return
	}

	nsObj, exists, err := this.store.GetByKey(namespaceName)
	if exists && err == nil {
		namespace, ok := nsObj.(*kube_api.Namespace)
		if ok {
			metricSet.Labels[core.LabelPodNamespaceUID.Key] = string(namespace.UID)
		} else {
			glog.Errorf("Wrong namespace store content")
		}
	} else if err != nil {
		glog.Warningf("Failed to get namespace %s: %v", namespaceName, err)
	} else if !exists {
		glog.Warningf("Namespace doesn't exist: %s", namespaceName)
	}
}
source: func (c *Client) GetReceivedByAccount(account string) (btcutil.Amount, error) {
	return c.GetReceivedByAccountAsync(account).Receive()
}
source: func (m VirtualDiskManager) ShrinkVirtualDisk(ctx context.Context, name string, dc *Datacenter, copy *bool) (*Task, error) {
	req := types.ShrinkVirtualDisk_Task{
		This: m.Reference(),
		Name: name,
		Copy: copy,
	}

	if dc != nil {
		ref := dc.Reference()
		req.Datacenter = &ref
	}

	res, err := methods.ShrinkVirtualDisk_Task(ctx, m.c, &req)
	if err != nil {
		return nil, err
	}

	return NewTask(m.c, res.Returnval), nil
}
source: func (s *NotificationConfigurationDeprecated) SetTopicConfiguration(v *TopicConfigurationDeprecated) *NotificationConfigurationDeprecated {
	s.TopicConfiguration = v
	return s
}
source: func splitDecl(obj *ast.Object, id *ast.Ident) (expr, typ ast.Node) {
	switch decl := obj.Decl.(type) {
	case nil:
		return nil, nil
	case *ast.ValueSpec:
		return splitVarDecl(obj.Name, decl.Names, decl.Values, decl.Type)

	case *ast.TypeSpec:
		return nil, decl.Type

	case *ast.FuncDecl:
		if decl.Recv != nil {
			return decl, decl.Type
		}
		return decl.Body, decl.Type

	case *ast.Field:
		return nil, decl.Type

	case *ast.LabeledStmt:
		return decl, nil

	case *ast.ImportSpec:
		return nil, decl

	case *ast.AssignStmt:
		return splitVarDecl(obj.Name, exprsToIdents(decl.Lhs), decl.Rhs, nil)

	case *ast.GenDecl:
		if decl.Tok == token.CONST {
			return splitConstDecl(obj.Name, decl)
		}
	case *ast.TypeSwitchStmt:
		expr := decl.Assign.(*ast.AssignStmt).Rhs[0].(*ast.TypeAssertExpr).X
		for _, stmt := range decl.Body.List {
			tcase := stmt.(*ast.CaseClause)
			for _, stmt := range tcase.Body {
				if containsNode(stmt, id) {
					if len(tcase.List) == 1 {
						return expr, tcase.List[0]
					}
					return expr, nil
				}
			}
		}
		return expr, nil
	}
	debugp("unknown decl type %T %v", obj.Decl, obj.Decl)
	return nil, nil
}
source: func CreateTable(db *sql.DB, tableName string) error {
	createCommand, tableNameFound := createTableStatements[tableName]
	if !tableNameFound {
		return fmt.Errorf("table name %s unknown", tableName)
	}

	return createTable(db, tableName, createCommand)
}
source: func (db *DB) GetPropertyCF(propName string, cf *ColumnFamilyHandle) string {
	cProp := C.CString(propName)
	defer C.free(unsafe.Pointer(cProp))
	cValue := C.rocksdb_property_value_cf(db.c, cf.c, cProp)
	defer C.free(unsafe.Pointer(cValue))
	return C.GoString(cValue)
}
source: func (stack *ErrorStack) Push(err error) bool {
	if err != nil {
		stack.errors = append(stack.errors, err)
		return true
	}
	return false
}
source: func (treeNode *TreeNode) Search(patternNode PatternNode) []*TreeNode {
	results := []*TreeNode{}

	// Current node
	if treeNode.compare(patternNode) {
		results = append(results, treeNode)
	}

	// Current node's children
	for _, child := range treeNode.Children {
		for _, subResult := range child.Search(patternNode) {
			results = append(results, subResult)
		}
	}

	return results
}
source: func (p *LogsPump) Route(route *Route, logstream chan *Message) {
	p.mu.Lock()
	for _, pump := range p.pumps {
		if route.MatchContainer(
			normalID(pump.container.ID),
			normalName(pump.container.Name),
			pump.container.Config.Labels) {

			pump.add(logstream, route)
			defer pump.remove(logstream)
		}
	}
	updates := make(chan *update)
	p.routes[updates] = struct{}{}
	p.mu.Unlock()
	defer func() {
		p.mu.Lock()
		delete(p.routes, updates)
		p.mu.Unlock()
		route.closed = true
	}()
	for {
		select {
		case event := <-updates:
			switch event.Status {
			case "start", "restart":
				if route.MatchContainer(
					normalID(event.pump.container.ID),
					normalName(event.pump.container.Name),
					event.pump.container.Config.Labels) {

					event.pump.add(logstream, route)
					defer event.pump.remove(logstream)
				}
			case "die":
				if strings.HasPrefix(route.FilterID, event.ID) {
					// If the route is just about a single container,
					// we can stop routing when it dies.
					return
				}
			}
		case <-route.Closer():
			return
		}
	}
}
source: func (f *Form) AddClass(class string) *Form {
	f.class = append(f.class, class)
	return f
}
source: func (c *Client) NodeFree(id int32) error {
	return c.oscConn.Send(osc.Message{
		Address:   nodeFreeAddress,
		Arguments: osc.Arguments{osc.Int(id)},
	})
}
source: func (st *BuildStruct) Name() string {
	// FooBar -> fooBar
	// IIS -> iis
	// AEData -> aeData

	name := st.SimpleName()

	if !st.Private {
		return name
	}
	if len(name) <= 1 {
		return strings.ToLower(name)
	}
	if name == strings.ToUpper(name) {
		return strings.ToLower(name)
	}

	runeNames := []rune(name)
	if unicode.IsLower(runeNames[0]) {
		return name
	} else if unicode.IsLower(runeNames[1]) {
		return string(unicode.ToLower(runeNames[0])) + string(runeNames[1:])
	}

	var idx int
	for idx = 0; idx < len(runeNames); idx++ {
		r := runeNames[idx]
		if unicode.IsLower(r) {
			break
		}
	}

	return strings.ToLower(string(runeNames[0:idx-1])) + string(runeNames[idx-1:])
}
source: func (p *Point) PointDistance(p2 Point) float32 {
	return math.Sqrt(p.PointDistanceSquared(p2))
}
source: func (t *tree) parsePlural(tok item) ast.Node {
	const ctx = "plural"
	if !t.inmsg {
		t.unexpected(tok, "not in msg")
	}

	// plural and switch nodes have the same structure.
	// BUG: the location quoted the erorr messages will not be correct.
	var sw = t.parseSwitch(tok, itemPluralEnd).(*ast.SwitchNode)
	var defaultNode ast.ParentNode
	var cases []*ast.MsgPluralCaseNode
	for _, node := range sw.Cases {
		if len(node.Values) == 0 {
			defaultNode = node.Body.(ast.ParentNode)
		} else {
			var intNode, ok = node.Values[0].(*ast.IntNode)
			if !ok || len(node.Values) > 1 {
				t.errorf("plural case must be a single integer, got %v", node.Values)
			}
			cases = append(cases, &ast.MsgPluralCaseNode{node.Pos, int(intNode.Value), node.Body.(ast.ParentNode)})
		}
	}
	if defaultNode == nil {
		t.errorf("{default} case required")
	}
	return &ast.MsgPluralNode{sw.Pos, "", sw.Value, cases, defaultNode}
}
source: func NewOpenPGPDecrypter(secRingPath string, passphrase string) (*OpenPGPDecrypter, error) {
	var dk *openpgp.EntityList
	var od *OpenPGPDecrypter
	var err error

	dk, err = ReadSecRing(secRingPath)
	if err != nil {
		return nil, err
	}

	od = &OpenPGPDecrypter{
		Keys:       dk,
		passphrase: passphrase,
	}

	return od, err
}
source: func KeysEqual(ak, bk ssh.PublicKey) bool {
	a := ssh.Marshal(ak)
	b := ssh.Marshal(bk)
	return (len(a) == len(b) && subtle.ConstantTimeCompare(a, b) == 1)
}
source: func (c *Client) UseError(fn context.HandlerFunc) *Client {
	c.Middleware.UseError(fn)
	return c
}
source: func SerialDeps(fns ...interface{}) {
	types := checkFns(fns)
	ctx := context.Background()
	for i := range fns {
		runDeps(ctx, types[i:i+1], fns[i:i+1])
	}
}
source: func (s *Stack) RemoveAddress(id tcpip.NICID, addr tcpip.Address) *tcpip.Error {
	s.mu.RLock()
	defer s.mu.RUnlock()

	if nic, ok := s.nics[id]; ok {
		return nic.RemoveAddress(addr)
	}

	return tcpip.ErrUnknownNICID
}
source: func (p *TextMapPropagator) Inject(
	sc SpanContext,
	abstractCarrier interface{},
) error {
	textMapWriter, ok := abstractCarrier.(opentracing.TextMapWriter)
	if !ok {
		return opentracing.ErrInvalidCarrier
	}

	// Do not encode the string with trace context to avoid accidental double-encoding
	// if people are using opentracing < 0.10.0. Our colon-separated representation
	// of the trace context is already safe for HTTP headers.
	textMapWriter.Set(p.headerKeys.TraceContextHeaderName, sc.String())
	for k, v := range sc.baggage {
		safeKey := p.addBaggageKeyPrefix(k)
		safeVal := p.encodeValue(v)
		textMapWriter.Set(safeKey, safeVal)
	}
	return nil
}
source: func (w *Window) GetNSGLContext() uintptr {
	ret := uintptr(C.workaround_glfwGetNSGLContext(w.data))
	panicError()
	return ret
}
source: func HashProvider(f func() hash.Hash) HashProviderFunc {
	if f == nil {
		return nil
	}
	return func(s string) (uint64, error) {
		hasher := f()
		_, err := hasher.Write([]byte(s))
		if err != nil {
			return 0, err
		}
		hash := hasher.Sum(nil)
		if x := len(hash); x > 8 {
			hash = hash[:8]
		}
		y, z := binary.Uvarint(hash)
		if z < 0 {
			// should never happen since we cap the length of the buffer before decoding
			return 0, errHashOverflow
		}
		return y, nil
	}
}
source: func (m *Money) Round() *Money {
	return &Money{amount: mutate.calc.round(m.amount, m.currency.Fraction), currency: m.currency}
}
source: func (u *utxoNursery) reloadClasses(bestHeight uint32) error {
	// Loading all active heights up to and including the current block.
	activeHeights, err := u.cfg.Store.HeightsBelowOrEqual(
		uint32(bestHeight))
	if err != nil {
		return err
	}

	// Return early if nothing to sweep.
	if len(activeHeights) == 0 {
		return nil
	}

	utxnLog.Infof("(Re)-sweeping %d heights below height=%d",
		len(activeHeights), bestHeight)

	// Attempt to re-register notifications for any outputs still at these
	// heights.
	for _, classHeight := range activeHeights {
		utxnLog.Debugf("Attempting to sweep outputs at height=%v",
			classHeight)

		if err = u.graduateClass(classHeight); err != nil {
			utxnLog.Errorf("Failed to sweep outputs at "+
				"height=%v: %v", classHeight, err)
			return err
		}
	}

	utxnLog.Infof("UTXO Nursery is now fully synced")

	return nil
}
source: func (a *Attributes) Value(name string) (string, bool, error) {
	attr, ok := a.Attrs[name]
	return attr, ok, nil
}
source: func (a *IPRangeAllocator) findNextAvailbleIndex(idx int64) int64 {
	// walk up from the index
	for i := idx; i < a.size; i++ {
		if !a.reserved[i] {
			return i
		}
	}

	// nothing above that one... lets try to walk down to find something
	for i := idx - 1; i >= 0; i-- {
		if !a.reserved[i] {
			return i
		}
	}

	// ok, everything is probably taken
	return -1
}
source: func (tr *Transaction) Discard() {
	tr.lk.Lock()
	if !tr.closed {
		tr.discard()
		tr.setDone()
	}
	tr.lk.Unlock()
}
source: func (cm ConsumerMessage) Ack(multiple bool) error {
	return cm.delivery.Ack(multiple)
}
source: func (u *Unit) SetAgentPresence() (*presence.Pinger, error) {
	presenceCollection := u.st.getPresenceCollection()
	recorder := u.st.getPingBatcher()
	m, err := u.st.Model()
	if err != nil {
		return nil, errors.Trace(err)
	}
	p := presence.NewPinger(presenceCollection, m.ModelTag(), u.globalAgentKey(),
		func() presence.PingRecorder { return u.st.getPingBatcher() })
	err = p.Start()
	if err != nil {
		return nil, err
	}
	// Make sure this Agent status is written to the database before returning.
	recorder.Sync()
	return p, nil
}
source: func MakePublishInfo(networks map[string]string, ports []string) map[string][]string {
	result := map[string][]string{}
	for networkName, ip := range networks {
		data := []string{}
		for _, port := range ports {
			data = append(data, fmt.Sprintf("%s:%s", ip, port))
		}
		if len(data) > 0 {
			result[networkName] = data
		}
	}
	return result
}
source: func (w *Weavebox) Put(route string, h Handler) {
	w.add("PUT", route, h)
}
source: func (nc *Conn) readOp(c *control) error {
	br := bufio.NewReaderSize(nc.conn, defaultBufSize)
	line, err := br.ReadString('\n')
	if err != nil {
		return err
	}
	parseControl(line, c)
	return nil
}
source: func DecodeDeploymentConfig(controller metav1.ObjectMetaAccessor) (*appsv1.DeploymentConfig, error) {
	encodedConfig, exists := controller.GetObjectMeta().GetAnnotations()[appsv1.DeploymentEncodedConfigAnnotation]
	if !exists {
		return nil, fmt.Errorf("object %s does not have encoded deployment config annotation", controller.GetObjectMeta().GetName())
	}
	config, err := runtime.Decode(annotationDecoder, []byte(encodedConfig))
	if err != nil {
		return nil, err
	}
	externalConfig, ok := config.(*appsv1.DeploymentConfig)
	if !ok {
		return nil, fmt.Errorf("object %+v is not v1.DeploymentConfig", config)
	}
	return externalConfig, nil
}
source: func (s *BulkProcessorService) RetryItemStatusCodes(retryItemStatusCodes ...int) *BulkProcessorService {
	s.retryItemStatusCodes = retryItemStatusCodes
	return s
}
source: func (c *UpdateFee) Decode(r io.Reader, pver uint32) error {
	return ReadElements(r,
		&c.ChanID,
		&c.FeePerKw,
	)
}
source: func (ps *pulloutSubquery) setUnderlying(underlying builder) {
	ps.underlying = underlying
	ps.underlying.Reorder(ps.subquery.Order())
	ps.order = ps.underlying.Order() + 1
}
source: func (o *LDAPQueryOnAttribute) NewSearchRequest(attributeValue string, attributes []string) (*ldap.SearchRequest, error) {
	if strings.EqualFold(o.QueryAttribute, "dn") {
		dn, err := ldap.ParseDN(attributeValue)
		if err != nil {
			return nil, fmt.Errorf("could not search by dn, invalid dn value: %v", err)
		}
		baseDN, err := ldap.ParseDN(o.BaseDN)
		if err != nil {
			return nil, fmt.Errorf("could not search by dn, invalid dn value: %v", err)
		}
		if !baseDN.AncestorOf(dn) && !baseDN.Equal(dn) {
			return nil, NewQueryOutOfBoundsError(attributeValue, o.BaseDN)
		}
		return o.buildDNQuery(attributeValue, attributes), nil

	} else {
		return o.buildAttributeQuery(attributeValue, attributes), nil
	}
}
source: func ToLowerAbridge(str string) (s string) {
	l := len(str)
	if l == 0 {
		return ""
	}

	arbi := []byte{unibyte.ToLower(str[0])}
	for i := 1; i < l; i++ {
		b := str[i]
		if unibyte.IsUpper(b) {
			arbi = append(arbi, unibyte.ToLower(b))
		}
	}

	return string(arbi)
}
source: func NewDuration(duration string) (d *Duration, err error) {
	dur, err := readDuration(duration)
	tmp := Duration(dur)
	return &tmp, err
}
source: func (s *Service) Kill(ctx context.Context, signal string) error {
	return s.collectContainersAndDo(ctx, func(c *container.Container) error {
		return c.Kill(ctx, signal)
	})
}
source: func (a *attributes) GetName() string {
	if a.event.ObjectRef == nil {
		return ""
	}
	return a.event.ObjectRef.Name
}
source: func (db *database) EntityWithName(name string) (e Entity, err error) {
	return db.entityForKey(toEntityKey(name))
}
source: func (v *vcsCmd) runOutput(dir string, cmd string, keyval ...string) ([]byte, error) {
	return v.run1(dir, cmd, keyval, true)
}
source: func AppendFile(dst string, src string) error {
	appendFile, err := os.OpenFile(dst, os.O_WRONLY|os.O_APPEND|os.O_CREATE, 0644)
	if err != nil {
		return err
	}
	defer appendFile.Close()

	srcFile, err := os.Open(src)
	if err != nil {
		return err
	}
	defer srcFile.Close()
	// Allocate staging buffer.
	var buf = make([]byte, defaultAppendBufferSize)
	_, err = io.CopyBuffer(appendFile, srcFile, buf)
	return err
}
source: func (c *Connector) CreateScope(ctx context.Context, md *dosa.ScopeMetadata) error {
	bytes, err := json.Marshal(*md)
	if err != nil {
		return errors.Wrap(err, "could not encode metadata into JSON")
	}
	mds := string(bytes)

	request := &dosarpc.CreateScopeRequest{
		Name:      &(md.Name),
		Requester: &(md.Creator),
		Metadata:  &mds,
	}

	if err = c.client.CreateScope(ctx, request, getHeaders(c.headers)...); err != nil {
		if !dosarpc.Dosa_CreateScope_Helper.IsException(err) {
			return errors.Wrap(err, "failed to CreateScope due to network issue")
		}

		return errors.Wrap(err, "failed to CreateScope")
	}

	return nil
}
source: func (c *MouseRotator) Update(float32) {
	if engo.Input.Mouse.Button == engo.MouseButtonMiddle && engo.Input.Mouse.Action == engo.Press {
		c.pressed = true
	}

	if engo.Input.Mouse.Action == engo.Release {
		c.pressed = false
	}

	if c.pressed {
		engo.Mailbox.Dispatch(CameraMessage{Axis: Angle, Value: (c.oldX - engo.Input.Mouse.X) * -c.RotationSpeed, Incremental: true})
	}

	c.oldX = engo.Input.Mouse.X
}
source: func (d DecrypterProto) IsEncrypted(object interface{}) bool {
	_, ok := object.(proto.Message)
	if !ok {
		return false
	}
	_, ok = d.mapping[reflect.TypeOf(object)]
	return ok
}
source: func (s *scanner) Remaining() string {
	return string(s.bytes[s.position:len(s.bytes)])
}
source: func (c *Client) ListIPv6ReverseDNS(id string) (list []ReverseDNSIPv6, err error) {
	var ipMap map[string][]ReverseDNSIPv6
	if err := c.get(`server/reverse_list_ipv6?SUBID=`+id, &ipMap); err != nil {
		return nil, err
	}

	for _, iplist := range ipMap {
		for _, ip := range iplist {
			list = append(list, ip)
		}
	}
	sort.Sort(reverseDNSIPv6s(list))
	return list, nil
}
source: func (s *ListBackupsOutput) SetBackupSummaries(v []*BackupSummary) *ListBackupsOutput {
	s.BackupSummaries = v
	return s
}
source: func (in *ResourceAccessReview) DeepCopy() *ResourceAccessReview {
	if in == nil {
		return nil
	}
	out := new(ResourceAccessReview)
	in.DeepCopyInto(out)
	return out
}
source: func (c *protectedContext) context() context.Context {
	c.mu.RLock()
	defer c.mu.RUnlock()
	return c.ctx
}
source: func (e *engineImpl) getJob(c context.Context, jobID string) (*Job, error) {
	job := &Job{JobID: jobID}
	switch err := ds.Get(c, job); {
	case err == nil:
		return job, nil
	case err == ds.ErrNoSuchEntity:
		return nil, nil
	default:
		return nil, transient.Tag.Apply(err)
	}
}
source: func KeyRangeIncludes(big, small *topodatapb.KeyRange) bool {
	if big == nil {
		// The outside one covers everything, we're good.
		return true
	}
	if small == nil {
		// The smaller one covers everything, better have the
		// bigger one also cover everything.
		return len(big.Start) == 0 && len(big.End) == 0
	}
	// Now we check small.Start >= big.Start, and small.End <= big.End
	if len(big.Start) != 0 && bytes.Compare(small.Start, big.Start) < 0 {
		return false
	}
	if len(big.End) != 0 && (len(small.End) == 0 || bytes.Compare(small.End, big.End) > 0) {
		return false
	}
	return true
}
source: func New(dir string) *Client {
	socket := filepath.Join(dir, ".gopass-agent.sock")
	return &Client{
		http: &http.Client{
			Transport: &http.Transport{
				DialContext: func(context.Context, string, string) (net.Conn, error) {
					return net.Dial("unix", socket)
				},
			},
			Timeout: 10 * time.Minute,
		},
	}
}
source: func (b *Bootstrapper) Configure(cs ...Configurator) {
	for _, c := range cs {
		c(b)
	}
}
source: func Filter(key, value string) RequestOptions {
	return func(req *http.Request) {
		q := req.URL.Query()
		q.Add(key, value)
		req.URL.RawQuery = strings.Replace(q.Encode(), "%2B", "+", 1)
	}
}
source: func (in *KubeProxyIPTablesConfiguration) DeepCopy() *KubeProxyIPTablesConfiguration {
	if in == nil {
		return nil
	}
	out := new(KubeProxyIPTablesConfiguration)
	in.DeepCopyInto(out)
	return out
}
source: func ListRemoveRangeFromOp(binName string, index int) *Operation {
	return &Operation{opType: _CDT_MODIFY, binName: binName, binValue: ListValue{_CDT_LIST_REMOVE_RANGE, IntegerValue(index)}, encoder: listGenericOpEncoder}
}
source: func (r Location_Group_Pricing) GetPrices() (resp []datatypes.Product_Item_Price, err error) {
	err = r.Session.DoRequest("SoftLayer_Location_Group_Pricing", "getPrices", nil, &r.Options, &resp)
	return
}
source: func (_class HostClass) SetMultipathing(sessionID SessionRef, host HostRef, value bool) (_err error) {
	_method := "host.set_multipathing"
	_sessionIDArg, _err := convertSessionRefToXen(fmt.Sprintf("%s(%s)", _method, "session_id"), sessionID)
	if _err != nil {
		return
	}
	_hostArg, _err := convertHostRefToXen(fmt.Sprintf("%s(%s)", _method, "host"), host)
	if _err != nil {
		return
	}
	_valueArg, _err := convertBoolToXen(fmt.Sprintf("%s(%s)", _method, "value"), value)
	if _err != nil {
		return
	}
	_, _err =  _class.client.APICall(_method, _sessionIDArg, _hostArg, _valueArg)
	return
}
source: func (lk *localKeys) allocate(key string, val idpool.ID) (idpool.ID, error) {
	lk.Lock()
	defer lk.Unlock()

	if k, ok := lk.keys[key]; ok {
		if val != k.val {
			return idpool.NoID, fmt.Errorf("local key already allocated with different value (%s != %s)", val, k.val)
		}

		k.refcnt++
		kvstore.Trace("Incremented local key refcnt", nil, logrus.Fields{fieldKey: key, fieldID: val, fieldRefCnt: k.refcnt})
		return k.val, nil
	}

	k := &localKey{key: key, val: val, refcnt: 1}
	lk.keys[key] = k
	lk.ids[val] = k
	kvstore.Trace("New local key", nil, logrus.Fields{fieldKey: key, fieldID: val, fieldRefCnt: 1})
	return val, nil
}
source: func SetContext(err error, key string, value interface{}) {
	if e, ok := err.(withContext); ok {
		e.Set(key, value)
	}
}
source: func (b *HogeJSONBuilder) AddByJSONNames(names ...string) *HogeJSONBuilder {
	for _, name := range names {
		info := b._jsonPropertyMap[name]
		if info == nil {
			continue
		}
		b._properties[info.fieldName] = info
	}
	return b
}
source: func NewRequestFailure(err Error, statusCode int, reqID string) RequestFailure {
	return newRequestError(err, statusCode, reqID)
}
source: func NewLocalPositionNed(TIME_BOOT_MS uint32, X float32, Y float32, Z float32, VX float32, VY float32, VZ float32) *LocalPositionNed {
	m := LocalPositionNed{}
	m.TIME_BOOT_MS = TIME_BOOT_MS
	m.X = X
	m.Y = Y
	m.Z = Z
	m.VX = VX
	m.VY = VY
	m.VZ = VZ
	return &m
}
source: func (s *Action) SetCloudwatchMetric(v *CloudwatchMetricAction) *Action {
	s.CloudwatchMetric = v
	return s
}
source: func (q QueueProps) WriteTo(w io.Writer) (int64, error) {
	var buf bytes.Buffer

	for _, prop := range q {
		_, err := prop.WriteTo(&buf)
		if err != nil {
			return 0, err
		}
	}

	return encoding.WriteTo(w, buf.Bytes())
}
source: func TrimTrailingSpaces(p []byte) []byte {
	for i := len(p) - 1; i >= 0; i-- {
		if p[i] != 0x20 && p[i] != '\n' && p[i] != '\t' {
			return p[:i+1]
		}
	}
	// it was all spaces
	return p[:0]
}
source: func ParseProxyID(proxyID string) (endpointID uint16, ingress bool, protocol string, port uint16, err error) {
	comps := strings.Split(proxyID, ":")
	if len(comps) != 4 {
		err = fmt.Errorf("invalid proxy ID structure: %s", proxyID)
		return
	}
	epID, err := strconv.ParseUint(comps[0], 10, 16)
	if err != nil {
		return
	}
	endpointID = uint16(epID)
	ingress = comps[1] == "ingress"
	protocol = comps[2]
	l4port, err := strconv.ParseUint(comps[3], 10, 16)
	if err != nil {
		return
	}
	port = uint16(l4port)
	return
}
source: func JSONContext(buffer Buffer, event *cue.Event) {
	fields := event.Context.Fields()
	marshaled, _ := json.Marshal(fields)
	buffer.Append(marshaled)
}
source: func (r *Request) SetStringBody(s string) {
	r.SetReaderBody(strings.NewReader(s))
}
source: func NewMockCommandRunner(ctrl *gomock.Controller) *MockCommandRunner {
	mock := &MockCommandRunner{ctrl: ctrl}
	mock.recorder = &MockCommandRunnerMockRecorder{mock}
	return mock
}
source: func EncodeBig(dst []byte, src *big.Int) []byte {
	start := len(dst)
	n := new(big.Int)
	n.Set(src)
	radix := big.NewInt(58)
	zero := big.NewInt(0)

	for n.Cmp(zero) > 0 {
		mod := new(big.Int)
		n.DivMod(n, radix, mod)
		dst = append(dst, alphabet[mod.Int64()])
	}

	for i, j := start, len(dst)-1; i < j; i, j = i+1, j-1 {
		dst[i], dst[j] = dst[j], dst[i]
	}
	return dst
}
source: func (r Rule) HandleF(h events.HandlerFunc) Rule {
	return r.Handle(events.Handler(h))
}
source: func (l *Result) Store() (storage.Store, error) {
	return inmem.NewFromObject(l.Documents), nil
}
source: func (d *Datapath) netSynAckRetrieveState(p *packet.Packet) (*connection.TCPConnection, error) {

	conn, err := d.sourcePortConnectionCache.GetReset(p.SourcePortHash(packet.PacketTypeNetwork), 0)
	if err != nil {
		return nil, errNonPUTraffic
	}

	return conn.(*connection.TCPConnection), nil
}
source: func (s *XPackWatcherDeleteWatchService) Id(id string) *XPackWatcherDeleteWatchService {
	s.id = id
	return s
}
source: func decryptWriterV10(dst io.Writer, config *Config) (*decWriterV10, error) {
	ad, err := newAuthDecV10(config)
	if err != nil {
		return nil, err
	}
	return &decWriterV10{
		authDecV10: ad,
		dst:        dst,
		buffer:     make(packageV10, maxPackageSize),
	}, nil
}
source: func (h *history) Load() {
	in := bufio.NewReader(h.file)

	for {
		line, err := in.ReadString('\n')
		if err == io.EOF {
			break
		}

		h.li.PushBack(strings.TrimRight(line, "\n"))
	}

	h.mark = h.li.Back() // Point to an element.
}
source: func DefaultConfig() *Config {
	hostname, err := os.Hostname()
	if err != nil {
		panic(err)
	}

	return &Config{
		NodeName:                     hostname,
		BroadcastTimeout:             5 * time.Second,
		LeavePropagateDelay:          1 * time.Second,
		EventBuffer:                  512,
		QueryBuffer:                  512,
		LogOutput:                    os.Stderr,
		ProtocolVersion:              4,
		ReapInterval:                 15 * time.Second,
		RecentIntentTimeout:          5 * time.Minute,
		ReconnectInterval:            30 * time.Second,
		ReconnectTimeout:             24 * time.Hour,
		QueueCheckInterval:           30 * time.Second,
		QueueDepthWarning:            128,
		MaxQueueDepth:                4096,
		TombstoneTimeout:             24 * time.Hour,
		FlapTimeout:                  60 * time.Second,
		MemberlistConfig:             memberlist.DefaultLANConfig(),
		QueryTimeoutMult:             16,
		QueryResponseSizeLimit:       1024,
		QuerySizeLimit:               1024,
		EnableNameConflictResolution: true,
		DisableCoordinates:           false,
		UserEventSizeLimit:           512,
	}
}
source: func newStorageAPI(endpoint Endpoint) (storage StorageAPI, err error) {
	if endpoint.IsLocal {
		return newPosix(endpoint.Path)
	}

	return newStorageRESTClient(endpoint)
}
source: func IsServiceNotProvided(err error) bool {
	_, ok := err.(*disco.ErrServiceNotProvided)
	return ok
}
source: func (p CassandraPlugin) Restore(endpoint plugin.ShieldEndpoint) error {
	cassandra, err := cassandraInfo(endpoint)
	if err != nil {
		return err
	}

	plugin.DEBUG("Creating directory '%s' with 0755 permissions", "/var/vcap/store/shield/cassandra")
	err = os.MkdirAll("/var/vcap/store/shield/cassandra", 0755)
	if err != nil {
		fmt.Fprintf(os.Stderr, "@R{\u2717 Create base temporary directory}\n")
		return err
	}
	fmt.Fprintf(os.Stderr, "@G{\u2713 Create base temporary directory}\n")

	keyspaceDirPath := filepath.Join("/var/vcap/store/shield/cassandra", cassandra.Keyspace)

	// Recursively remove /var/vcap/store/shield/cassandra/{cassandra.Keyspace}, if any
	cmd := fmt.Sprintf("rm -rf \"%s\"", keyspaceDirPath)
	plugin.DEBUG("Executing `%s`", cmd)
	err = plugin.Exec(cmd, plugin.STDOUT)
	if err != nil {
		fmt.Fprintf(os.Stderr, "@R{\u2717 Clear base temporary directory}\n")
		return err
	}
	fmt.Fprintf(os.Stderr, "@G{\u2713 Clear base temporary directory}\n")

	defer func() {
		// plugin.DEBUG("Skipping recursive deletion of directory '%s'", keyspaceDirPath)

		// Recursively remove /var/vcap/store/shield/cassandra/{cassandra.Keyspace}, if any
		cmd := fmt.Sprintf("rm -rf \"%s\"", keyspaceDirPath)
		plugin.DEBUG("Executing `%s`", cmd)
		err := plugin.Exec(cmd, plugin.STDOUT)
		if err != nil {
			fmt.Fprintf(os.Stderr, "@R{\u2717 Clean base temporary directory}\n")
			return
		}
		fmt.Fprintf(os.Stderr, "@G{\u2713 Clean base temporary directory}\n")
	}()

	cmd = fmt.Sprintf("tar -x -C /var/vcap/store/shield/cassandra -f -")
	plugin.DEBUG("Executing `%s`", cmd)
	err = plugin.Exec(cmd, plugin.STDIN)
	if err != nil {
		fmt.Fprintf(os.Stderr, "@R{\u2717 Extract tar to temporary directory}\n")
		return err
	}
	fmt.Fprintf(os.Stderr, "@G{\u2713 Extract tar to temporary directory}\n")

	// Iterate through all table directories /var/vcap/store/shield/cassandra/{cassandra.Keyspace}/{tablename}
	dir, err := os.Open(keyspaceDirPath)
	if err != nil {
		fmt.Fprintf(os.Stderr, "@R{\u2717 Load all tables data}\n")
		return err
	}
	defer dir.Close()

	entries, err := dir.Readdir(-1)
	if err != nil {
		fmt.Fprintf(os.Stderr, "@R{\u2717 Load all tables data}\n")
		return err
	}
	for _, tableDirInfo := range entries {
		if !tableDirInfo.IsDir() {
			continue
		}
		// Run sstableloader on each sub-directory found, assuming it is a table backup
		tableDirPath := filepath.Join(keyspaceDirPath, tableDirInfo.Name())
		cmd := fmt.Sprintf("sstableloader -u \"%s\" -pw \"%s\" -d \"%s\" \"%s\"", cassandra.User, cassandra.Password, cassandra.Host, tableDirPath)
		plugin.DEBUG("Executing: `%s`", cmd)
		err = plugin.Exec(cmd, plugin.STDIN)
		if err != nil {
			fmt.Fprintf(os.Stderr, "@R{\u2717 Load all tables data}\n")
			return err
		}
	}
	fmt.Fprintf(os.Stderr, "@G{\u2713 Load all tables data}\n")

	return nil
}
source: func (b *blockManager) NotificationsSinceHeight(
	height uint32) ([]blockntfns.BlockNtfn, uint32, error) {

	b.newFilterHeadersMtx.RLock()
	defer b.newFilterHeadersMtx.RUnlock()

	bestHeight := b.filterHeaderTip

	// If a height of 0 is provided by the caller, then a backlog of
	// notifications is not needed.
	if height == 0 {
		return nil, bestHeight, nil
	}

	// If the best height matches the filter header tip, then we're done and
	// don't need to proceed any further.
	if bestHeight == height {
		return nil, bestHeight, nil
	}

	// If the request has a height later than a height we've yet to come
	// across in the chain, we'll return an error to indicate so to the
	// caller.
	if height > bestHeight {
		return nil, 0, fmt.Errorf("request with height %d is greater "+
			"than best height known %d", height, bestHeight)
	}

	// Otherwise, we need to read block headers from disk to deliver a
	// backlog to the caller before we proceed.
	blocks := make([]blockntfns.BlockNtfn, 0, bestHeight-height)
	for i := height + 1; i <= bestHeight; i++ {
		header, err := b.server.BlockHeaders.FetchHeaderByHeight(i)
		if err != nil {
			return nil, 0, err
		}

		blocks = append(blocks, blockntfns.NewBlockConnected(*header, i))
	}

	return blocks, bestHeight, nil
}
source: func (c *Client) CreateSnapshot(id, description string) (Snapshot, error) {
	values := url.Values{
		"SUBID":       {id},
		"description": {description},
	}

	var snapshot Snapshot
	if err := c.post(`snapshot/create`, values, &snapshot); err != nil {
		return Snapshot{}, err
	}
	snapshot.Description = description

	return snapshot, nil
}
source: func (s *storage) meta(br blob.Ref) (m blobMeta, err error) {
	ms, err := s.index.Get(br.String())
	if err != nil {
		if err == sorted.ErrNotFound {
			err = os.ErrNotExist
		}
		return
	}
	m, ok := parseBlobMeta(ms)
	if !ok {
		err = fmt.Errorf("diskpacked: bad blob metadata: %q", ms)
	}
	return
}
source: func NewScanner(r io.Reader) *Scanner {
	_, ok := r.(io.ReadSeeker)

	crc := crc32.NewIEEE()
	return &Scanner{
		r:          newScannerReader(r, crc),
		crc:        crc,
		IsSeekable: ok,
	}
}
source: func (a *SetInspectModeArgs) SetHighlightConfig(highlightConfig HighlightConfig) *SetInspectModeArgs {
	a.HighlightConfig = &highlightConfig
	return a
}
source: func Mux(pattern string, mux *http.ServeMux) InboundOption {
	return func(i *Inbound) {
		i.mux = mux
		i.muxPattern = pattern
	}
}
source: func (s *sentinel) ObservablesDo(f func(o Observable) error) error {
	s.mux.Lock()
	defer s.mux.Unlock()
	var errs []error
	for observable := range s.observables {
		if err := f(observable); err != nil {
			errs = append(errs, err)
		}
	}
	if len(errs) > 0 {
		return errors.Collect(errs...)
	}
	return nil
}
source: func (c *UserStore) Delete(ctx context.Context, u *chronograf.User) error {
	return c.Ctrl.DeleteUser(ctx, u.Name)
} 68%|██████▊   | 3415/5000 [00:04<00:01, 857.20it/s]
source: func (cal crActionList) collapse() crActionList {
	// Order of precedence for a given fromName:
	// 1) renameUnmergedAction
	// 2) copyUnmergedEntryAction
	// 3) copyUnmergedAttrAction
	infoMap := make(map[string]collapseActionInfo) // fromName -> info
	indicesToRemove := make(map[int]bool)
	for i, untypedAction := range cal {
		switch action := untypedAction.(type) {

		// Unmerged actions:
		case *renameUnmergedAction:
			setTopAction(action, action.fromName, i, infoMap, indicesToRemove)
		case *copyUnmergedEntryAction:
			untypedTopAction := infoMap[action.fromName].topAction
			switch untypedTopAction.(type) {
			case *renameUnmergedAction:
				indicesToRemove[i] = true
			default:
				setTopAction(action, action.fromName, i, infoMap,
					indicesToRemove)
			}
		case *copyUnmergedAttrAction:
			untypedTopAction := infoMap[action.fromName].topAction
			switch topAction := untypedTopAction.(type) {
			case *renameUnmergedAction:
				indicesToRemove[i] = true
			case *copyUnmergedEntryAction:
				indicesToRemove[i] = true
			case *copyUnmergedAttrAction:
				// Add attributes to the current top action, if not
				// already there.
				for _, a := range action.attr {
					found := false
					for _, topA := range topAction.attr {
						if a == topA {
							found = true
							break
						}
					}
					if !found {
						topAction.attr = append(topAction.attr, a)
					}
				}
				indicesToRemove[i] = true
			default:
				setTopAction(action, action.fromName, i, infoMap,
					indicesToRemove)
			}

		// Merged actions
		case *renameMergedAction:
			// Prefix merged actions with a reserved prefix to keep
			// them separate from the unmerged actions.
			setTopAction(action, ".kbfs_merged_"+action.fromName, i, infoMap,
				indicesToRemove)
		}
	}

	if len(indicesToRemove) == 0 {
		return cal
	}

	newList := make(crActionList, 0, len(cal)-len(indicesToRemove))
	for i, action := range cal {
		if indicesToRemove[i] {
			continue
		}
		newList = append(newList, action)
	}

	return newList
}
source: func (c *Client) execute(req *http.Request, result interface{}, needsStatus ...int) error {
	for {
		resp, err := c.http.Do(req)
		if err != nil {
			return err
		}
		defer resp.Body.Close()

		if c.AutoRetry && shouldRetry(resp.StatusCode) {
			time.Sleep(retryDuration(resp))
			continue
		}
		if resp.StatusCode != http.StatusOK && isFailure(resp.StatusCode, needsStatus) {
			return c.decodeError(resp)
		}

		if result != nil {
			if err := json.NewDecoder(resp.Body).Decode(result); err != nil {
				return err
			}
		}
		break
	}
	return nil
}
source: func (s *PortManager) IsPortAvailable(networks []tcpip.NetworkProtocolNumber, transport tcpip.TransportProtocolNumber, addr tcpip.Address, port uint16, reuse bool) bool {
	s.mu.Lock()
	defer s.mu.Unlock()
	return s.isPortAvailableLocked(networks, transport, addr, port, reuse)
}
source: func (c *ExtensionManagerClient) Extensions() (osquery.InternalExtensionList, error) {
	return c.Client.Extensions(context.Background())
}
source: func (t *ConsoleLogFormatter) Format(entry *logrus.Entry) (data []byte, err error) {
	buffer := bytes.Buffer{}
	addspaceflag := false

	if t.Flag == 0 {
		t.Flag = LstdFlags
	}

	if t.TimestampFormat == "" {
		t.TimestampFormat = time.RFC3339
	}

	if t.Flag&Ltime != 0 {
		timetext := entry.Time.Format(t.TimestampFormat)
		timetext, addspaceflag = addspace(timetext, addspaceflag)
		if _, err = buffer.WriteString(timetext); err != nil {
			err = errutil.New("write timestamp to buffer failed", err)
			return
		}
	}

	if t.Flag&(Lshortfile|Llongfile) != 0 {
		var filelinetext string
		filters := append([]runtimecaller.Filter{filterLogrusRuntimeCaller}, t.RuntimeCallerFilters...)
		if callinfo, ok := errutil.RuntimeCaller(1+t.CallerOffset, filters...); ok {
			if t.Flag&Lshortfile != 0 {
				filelinetext = fmt.Sprintf("%s:%d", callinfo.FileName(), callinfo.Line())
			} else {
				filelinetext = fmt.Sprintf("%s/%s:%d", callinfo.PackageName(), callinfo.FileName(), callinfo.Line())
			}

			filelinetext, addspaceflag = addspace(filelinetext, addspaceflag)
		}

		if _, err = buffer.WriteString(filelinetext); err != nil {
			err = errutil.New("write fileline to buffer failed", err)
			return
		}
	}

	if t.Flag&Llevel != 0 {
		leveltext := fmt.Sprintf("[%s]", entry.Level.String())
		leveltext, addspaceflag = addspace(leveltext, addspaceflag)
		if _, err = buffer.WriteString(leveltext); err != nil {
			err = errutil.New("write level to buffer failed", err)
			return
		}
	}

	message := entry.Message
	message, _ = addspace(message, addspaceflag)
	if _, err = buffer.WriteString(message); err != nil {
		err = errutil.New("write message to buffer failed", err)
		return
	}

	if err = buffer.WriteByte('\n'); err != nil {
		err = errutil.New("write newline to buffer failed", err)
		return
	}

	data = buffer.Bytes()
	return
}
source: func writeStatus(requestedTag string, out progress.Output, layersDownloaded bool) {
	if layersDownloaded {
		progress.Message(out, "", "Status: Downloaded newer image for "+requestedTag)
	} else {
		progress.Message(out, "", "Status: Image is up to date for "+requestedTag)
	}
}
source: func (e *Error) Error() string {
	line, column, context := e.Position()
	return fmt.Sprintf("parse error:%d:%d: %s\n%s", line, column, e.Message, context)
}
source: func NewKeySet(keys ...Key) KeySet {
	set := make(KeySet)
	for _, key := range keys {
		set.Add(key)
	}

	return set
}
source: func (o CustomResourceDefinitionsServerOptions) AddFlags(fs *pflag.FlagSet) {
	o.RecommendedOptions.AddFlags(fs)
	o.APIEnablement.AddFlags(fs)
}
source: func ReadConfig(filename, clusterName string) (*Notification, error) {
	p := &pb.Cluster{}
	b, err := ioutil.ReadFile(filename)
	if err != nil {
		return nil, err
	}
	if err = proto.UnmarshalText(string(b), p); err != nil {
		return nil, err
	}

	c, err := protoToCluster(p, clusterName)
	if err != nil {
		return nil, err
	}
	return &Notification{c, false, p, SourceDisk, filename, time.Now()}, nil
}
source: func (ls LabelArray) DeepCopy() LabelArray {
	if ls == nil {
		return nil
	}

	o := make(LabelArray, len(ls), len(ls))
	copy(o, ls)
	return o
}
source: func (c *RPCClient) Start() error {
	err := c.Connect(c.reconnectAttempts)
	if err != nil {
		return err
	}

	// Verify that the server is running on the expected network.
	net, err := c.GetCurrentNet()
	if err != nil {
		c.Disconnect()
		return err
	}
	if net != c.chainParams.Net {
		c.Disconnect()
		return errors.New("mismatched networks")
	}

	c.quitMtx.Lock()
	c.started = true
	c.quitMtx.Unlock()

	c.wg.Add(1)
	go c.handler()
	return nil
}
source: func attachVolumes(ctx *context, ops map[params.MachineStorageId]*attachVolumeOp) error {
	volumeAttachmentParams := make([]storage.VolumeAttachmentParams, 0, len(ops))
	for _, op := range ops {
		volumeAttachmentParams = append(volumeAttachmentParams, op.args)
	}
	paramsBySource, volumeSources, err := volumeAttachmentParamsBySource(
		ctx.config.StorageDir, volumeAttachmentParams, ctx.config.Registry,
	)
	if err != nil {
		return errors.Trace(err)
	}
	var reschedule []scheduleOp
	var volumeAttachments []storage.VolumeAttachment
	var statuses []params.EntityStatusArgs
	for sourceName, volumeAttachmentParams := range paramsBySource {
		logger.Debugf("attaching volumes: %+v", volumeAttachmentParams)
		volumeSource := volumeSources[sourceName]
		if volumeSource == nil {
			// The storage provider does not support dynamic
			// storage, there's nothing for the provisioner
			// to do here.
			continue
		}
		results, err := volumeSource.AttachVolumes(ctx.config.CloudCallContext, volumeAttachmentParams)
		if err != nil {
			return errors.Annotatef(err, "attaching volumes from source %q", sourceName)
		}

		for i, result := range results {
			p := volumeAttachmentParams[i]
			statuses = append(statuses, params.EntityStatusArgs{
				Tag:    p.Volume.String(),
				Status: status.Attached.String(),
			})
			entityStatus := &statuses[len(statuses)-1]
			if result.Error != nil {
				// Reschedule the volume attachment.
				id := params.MachineStorageId{
					MachineTag:    p.Machine.String(),
					AttachmentTag: p.Volume.String(),
				}
				reschedule = append(reschedule, ops[id])

				// Note: we keep the status as "attaching" to
				// indicate that we will retry. When we distinguish
				// between transient and permanent errors, we will
				// set the status to "error" for permanent errors.
				entityStatus.Status = status.Attaching.String()
				entityStatus.Info = result.Error.Error()
				logger.Debugf(
					"failed to attach %s to %s: %v",
					names.ReadableString(p.Volume),
					names.ReadableString(p.Machine),
					result.Error,
				)
				continue
			}
			volumeAttachments = append(volumeAttachments, *result.VolumeAttachment)
		}
	}
	scheduleOperations(ctx, reschedule...)
	setStatus(ctx, statuses)
	if err := createVolumeAttachmentPlans(ctx, volumeAttachments); err != nil {
		return errors.Trace(err)
	}
	if err := setVolumeAttachmentInfo(ctx, volumeAttachments); err != nil {
		return errors.Trace(err)
	}

	return nil
}
source: func (value Value) IsFunction() bool {
	if value.kind != valueObject {
		return false
	}
	return value.value.(*_object).class == "Function"
}
source: func (p PHYPayload) MarshalJSON() ([]byte, error) {
	type phyAlias PHYPayload
	return json.Marshal(phyAlias(p))
}
source: func (s Settings) Stream(file string) ([]byte, error) {
	_, err := os.Stat(file)
	if err != nil {
		return nil, err
	}
	content, err := ioutil.ReadFile(file)
	s.Fatal(err)
	return content, err
}
source: func NewRegexpList(initialValues ...string) (result *RegexpList) {
	sort.Slice(initialValues, func(i, j int) bool {
		return len(initialValues[i]) < len(initialValues[j])
	})

	tmp := RegexpList(initialValues)
	return &tmp
}
source: func normalizeHelper(number string,
	normalizationReplacements map[rune]rune,
	removeNonMatches bool) string {

	var normalizedNumber = builder.NewBuilder(nil)
	for _, character := range number {
		newDigit, ok := normalizationReplacements[unicode.ToUpper(character)]
		if ok {
			normalizedNumber.WriteRune(newDigit)
		} else if !removeNonMatches {
			normalizedNumber.WriteRune(character)
		}
		// If neither of the above are true, we remove this character.
	}
	return normalizedNumber.String()
}
source: func Empty(xu *xgbutil.XUtil) bool {
	xu.EvqueueLck.RLock()
	defer xu.EvqueueLck.RUnlock()

	return len(xu.Evqueue) == 0
}
source: func (tx *Tx) Commit() error {
	err := tx.Tx.Commit()
	if err != nil {
		return tx.EventErr("dbr.commit.error", err)
	}
	tx.Event("dbr.commit")
	return nil
}
source: func NewFileReader(ctx context.Context, fetcher blob.Fetcher, fileBlobRef blob.Ref) (*FileReader, error) {
	// TODO(bradfitz): rename this into bytes reader? but for now it's still
	//                 named FileReader, but can also read a "bytes" schema.
	if !fileBlobRef.Valid() {
		return nil, errors.New("schema/filereader: NewFileReader blobref invalid")
	}
	rc, _, err := fetcher.Fetch(ctx, fileBlobRef)
	if err != nil {
		return nil, fmt.Errorf("schema/filereader: fetching file schema blob: %v", err)
	}
	defer rc.Close()
	ss, err := parseSuperset(rc)
	if err != nil {
		return nil, fmt.Errorf("schema/filereader: decoding file schema blob: %v", err)
	}
	ss.BlobRef = fileBlobRef
	if ss.Type != "file" && ss.Type != "bytes" {
		return nil, fmt.Errorf("schema/filereader: expected \"file\" or \"bytes\" schema blob, got %q", ss.Type)
	}
	fr, err := ss.NewFileReader(fetcher)
	if err != nil {
		return nil, fmt.Errorf("schema/filereader: creating FileReader for %s: %v", fileBlobRef, err)
	}
	return fr, nil
}
source: func ReadInt64(file string) (int64, error) {
	f, err := os.Open(file)
	if err != nil {
		return 0, err
	}
	defer f.Close()

	buf := make([]byte, 19)
	n, err := f.Read(buf)
	if err != nil {
		return 0, err
	}

	p := strings.Split(string(buf[0:n]), "\n")
	v, err := strconv.ParseInt(p[0], 10, 64)
	if err != nil {
		return 0, err
	}

	return v, nil
}
source: func (so *SpanObserver) OnFinish(options opentracing.FinishOptions) {
	so.mux.Lock()
	defer so.mux.Unlock()

	if so.operationName == "" || so.kind != Inbound {
		return
	}

	mets := so.metricsByEndpoint.get(so.operationName)
	latency := options.FinishTime.Sub(so.startTime)
	if so.err {
		mets.RequestCountFailures.Inc(1)
		mets.RequestLatencyFailures.Record(latency)
	} else {
		mets.RequestCountSuccess.Inc(1)
		mets.RequestLatencySuccess.Record(latency)
	}
	mets.recordHTTPStatusCode(so.httpStatusCode)
}
source: func NewRulerWithJson(jsonstr []byte) (*Ruler, error) {
	var rules []*Rule

	err := json.Unmarshal(jsonstr, &rules)
	if err != nil {
		return nil, err
	}

	return NewRuler(rules), nil
}
source: func copyIPMask(src net.IPMask) net.IPMask {
	return net.IPMask(copyBytes(src))
}
source: func joinDeque(s *lane.Deque) string {
	var (
		buffer bytes.Buffer
		bDeque *lane.Deque
	)
	bDeque = lane.NewDeque()
	for e := s.Shift(); e != nil; e = s.Shift() {
		subpath := fmt.Sprintf("%v", e)
		if !(subpath == "" && s.Empty()) {
			buffer.WriteString("/")
			buffer.WriteString(subpath)
		}
		bDeque.Append(e)
	}
	for e := bDeque.Shift(); e != nil; e = bDeque.Shift() {
		s.Append(e)
	}
	return buffer.String()
}
source: func CommandFor(basename string) *cobra.Command {
	var cmd *cobra.Command

	// Make case-insensitive and strip executable suffix if present
	if runtime.GOOS == "windows" {
		basename = strings.ToLower(basename)
		basename = strings.TrimSuffix(basename, ".exe")
	}

	switch basename {
	default:
		cmd = NewCommandOpenShift("openshift")
	}

	if cmd.UsageFunc() == nil {
		templates.ActsAsRootCommand(cmd, []string{"options"})
	}
	flagtypes.GLog(cmd.PersistentFlags())

	return cmd
}
source: func sendEvents(evtChan chan *dt.ScheduledEvent, interval time.Duration) {
	t := time.NewTicker(time.Minute)
	select {
	case now := <-t.C:
		sendEventsTick(evtChan, now)
		sendEvents(evtChan, interval)
	}
}
source: func (server *ResilientServer) GetSrvKeyspaceNames(ctx context.Context, cell string) ([]string, error) {
	server.counts.Add(queryCategory, 1)

	// find the entry in the cache, add it if not there
	key := cell
	server.mutex.Lock()
	entry, ok := server.srvKeyspaceNamesCache[key]
	if !ok {
		entry = &srvKeyspaceNamesEntry{
			cell: cell,
		}
		server.srvKeyspaceNamesCache[key] = entry
	}
	server.mutex.Unlock()

	// Lock the entry, and do everything holding the lock except
	// querying the underlying topo server.
	//
	// This means that even if the topo server is very slow, two concurrent
	// requests will only issue one underlying query.
	entry.mutex.Lock()
	defer entry.mutex.Unlock()

	cacheValid := entry.value != nil && time.Since(entry.insertionTime) < server.cacheTTL
	shouldRefresh := time.Since(entry.lastQueryTime) > server.cacheRefresh

	// If it is not time to check again, then return either the cached
	// value or the cached error but don't ask consul again.
	if !shouldRefresh {
		if cacheValid {
			return entry.value, nil
		}
		return nil, entry.lastError
	}

	// Refresh the state in a background goroutine if no refresh is already
	// in progress none is already running. This way queries are not blocked
	// while the cache is still valid but past the refresh time, and avoids
	// calling out to the topo service while the lock is held.
	if entry.refreshingChan == nil {
		entry.refreshingChan = make(chan struct{})
		entry.lastQueryTime = time.Now()
		go func() {
			result, err := server.topoServer.GetSrvKeyspaceNames(ctx, cell)

			entry.mutex.Lock()
			defer func() {
				close(entry.refreshingChan)
				entry.refreshingChan = nil
				entry.mutex.Unlock()
			}()

			if err == nil {
				// save the value we got and the current time in the cache
				entry.insertionTime = time.Now()
				entry.value = result
			} else {
				server.counts.Add(errorCategory, 1)
				if entry.insertionTime.IsZero() {
					log.Errorf("GetSrvKeyspaceNames(%v, %v) failed: %v (no cached value, caching and returning error)", ctx, cell, err)

				} else if entry.value != nil && time.Since(entry.insertionTime) < server.cacheTTL {
					server.counts.Add(cachedCategory, 1)
					log.Warningf("GetSrvKeyspaceNames(%v, %v) failed: %v (keeping cached value: %v)", ctx, cell, err, entry.value)
				} else {
					log.Errorf("GetSrvKeyspaceNames(%v, %v) failed: %v (cached value expired)", ctx, cell, err)
					entry.insertionTime = time.Time{}
					entry.value = nil
				}
			}

			entry.lastError = err
			entry.lastErrorCtx = ctx
		}()
	}

	// If the cached entry is still valid then use it, otherwise wait
	// for the refresh attempt to complete to get a more up to date
	// response.
	//
	// In the event that the topo service is slow or unresponsive either
	// on the initial fetch or if the cache TTL expires, then several
	// requests could be blocked on refreshingCond waiting for the response
	// to come back.
	if cacheValid {
		return entry.value, nil
	}

	refreshingChan := entry.refreshingChan
	entry.mutex.Unlock()
	select {
	case <-refreshingChan:
	case <-ctx.Done():
		entry.mutex.Lock()
		return nil, fmt.Errorf("timed out waiting for keyspace names")
	}
	entry.mutex.Lock()

	if entry.value != nil {
		return entry.value, nil
	}

	return nil, entry.lastError
}
source: func (s *StartOutboundVoiceContactInput) SetSourcePhoneNumber(v string) *StartOutboundVoiceContactInput {
	s.SourcePhoneNumber = &v
	return s
}
source: func NewWebsocketHub() *WebsocketHub {
	return &WebsocketHub{
		clients:          make(map[*hubSpoke]*client),
		Register:         make(chan *clientHubSpoke),
		Unregister:       make(chan *hubSpoke),
		HubRelay:         make(chan pstypes.HubMessage),
		bufferTickerChan: make(chan int, clientSignalSize),
		quitWSHandler:    make(chan struct{}),
		requestLimit:     MaxPayloadBytes, // 1 MB
	}
}
source: func DecodeBody(resp *http.Response, out interface{}) error {
	return json.NewDecoder(resp.Body).Decode(out)
}
source: func New(ctx context.Context, next http.Handler, confCircuitBreaker config.CircuitBreaker, name string) (http.Handler, error) {
	expression := confCircuitBreaker.Expression

	logger := middlewares.GetLogger(ctx, name, typeName)
	logger.Debug("Creating middleware")
	logger.Debug("Setting up with expression: %s", expression)

	oxyCircuitBreaker, err := cbreaker.New(next, expression, createCircuitBreakerOptions(expression))
	if err != nil {
		return nil, err
	}
	return &circuitBreaker{
		circuitBreaker: oxyCircuitBreaker,
		name:           name,
	}, nil
}
source: func (c *Client) PlanList(addonServiceIdentity string, lr *ListRange) ([]Plan, error) {
	req, err := c.NewRequest("GET", "/addon-services/"+addonServiceIdentity+"/plans", nil, nil)
	if err != nil {
		return nil, err
	}

	if lr != nil {
		lr.SetHeader(req)
	}

	var plansRes []Plan
	return plansRes, c.DoReq(req, &plansRes)
}
source: func (te *TxEngine) close(immediate bool) {
	// Shut down functions are idempotent.
	// No need to check if 2pc is enabled.
	te.stopWatchdog()

	poolEmpty := make(chan bool)
	rollbackDone := make(chan bool)
	// This goroutine decides if transactions have to be
	// forced to rollback, and if so, when. Once done,
	// the function closes rollbackDone, which can be
	// verified to make sure it won't kick in later.
	go func() {
		defer func() {
			tabletenv.LogError()
			close(rollbackDone)
		}()
		if immediate {
			// Immediately rollback everything and return.
			log.Info("Immediate shutdown: rolling back now.")
			te.rollbackTransactions()
			return
		}
		if te.shutdownGracePeriod <= 0 {
			// No grace period was specified. Never rollback.
			te.rollbackPrepared()
			log.Info("No grace period specified: performing normal wait.")
			return
		}
		tmr := time.NewTimer(te.shutdownGracePeriod)
		defer tmr.Stop()
		select {
		case <-tmr.C:
			log.Info("Grace period exceeded: rolling back now.")
			te.rollbackTransactions()
		case <-poolEmpty:
			// The pool cleared before the timer kicked in. Just return.
			log.Info("Transactions completed before grace period: shutting down.")
		}
	}()
	te.txPool.WaitForEmpty()
	// If the goroutine is still running, signal that it can exit.
	close(poolEmpty)
	// Make sure the goroutine has returned.
	<-rollbackDone

	te.txPool.Close()
	te.twoPC.Close()
}
source: func Int64Slice(v []int64) []*int64 {
	out := make([]*int64, len(v))
	for i := range v {
		out[i] = &v[i]
	}
	return out
}
source: func GetScreenSize() (int, int) {
	size := C.get_screen_size()
	// fmt.Println("...", size, size.width)
	return int(size.width), int(size.height)
}
source: func BuildURL(baseUrl string, queryValues url.Values) string {
	qryString := queryValues.Encode()
	if len(qryString) > 0 {
		return baseUrl + "?" + qryString
	}
	return baseUrl
}
source: func gcsToObjectError(err error, params ...string) error {
	if err == nil {
		return nil
	}

	bucket := ""
	object := ""
	uploadID := ""
	if len(params) >= 1 {
		bucket = params[0]
	}
	if len(params) == 2 {
		object = params[1]
	}
	if len(params) == 3 {
		uploadID = params[2]
	}

	// in some cases just a plain error is being returned
	switch err.Error() {
	case "storage: bucket doesn't exist":
		err = minio.BucketNotFound{
			Bucket: bucket,
		}
		return err
	case "storage: object doesn't exist":
		if uploadID != "" {
			err = minio.InvalidUploadID{
				UploadID: uploadID,
			}
		} else {
			err = minio.ObjectNotFound{
				Bucket: bucket,
				Object: object,
			}
		}
		return err
	}

	googleAPIErr, ok := err.(*googleapi.Error)
	if !ok {
		// We don't interpret non MinIO errors. As minio errors will
		// have StatusCode to help to convert to object errors.
		return err
	}

	if len(googleAPIErr.Errors) == 0 {
		return err
	}

	reason := googleAPIErr.Errors[0].Reason
	message := googleAPIErr.Errors[0].Message

	switch reason {
	case "required":
		// Anonymous users does not have storage.xyz access to project 123.
		fallthrough
	case "keyInvalid":
		fallthrough
	case "forbidden":
		err = minio.PrefixAccessDenied{
			Bucket: bucket,
			Object: object,
		}
	case "invalid":
		err = minio.BucketNameInvalid{
			Bucket: bucket,
		}
	case "notFound":
		if object != "" {
			err = minio.ObjectNotFound{
				Bucket: bucket,
				Object: object,
			}
			break
		}
		err = minio.BucketNotFound{Bucket: bucket}
	case "conflict":
		if message == "You already own this bucket. Please select another name." {
			err = minio.BucketAlreadyOwnedByYou{Bucket: bucket}
			break
		}
		if message == "Sorry, that name is not available. Please try a different one." {
			err = minio.BucketAlreadyExists{Bucket: bucket}
			break
		}
		err = minio.BucketNotEmpty{Bucket: bucket}
	}

	return err
}
source: func (n NodeList) NodeSet() *NodeSet {
	db := NewNodeSet()
	n.Store(db)
	return db
}
source: func (f HandlerFunc) ServeHTTP(w http.ResponseWriter, req *http.Request) {
	ww := NewResponseWriter(w)
	if err := f(ww, req); err != nil {
		DefaultServeMux.HandleError(ww, req, err)
		return
	}
}
source: func (i *Index) openFields() error {
	f, err := os.Open(i.path)
	if err != nil {
		return errors.Wrap(err, "opening directory")
	}
	defer f.Close()

	fis, err := f.Readdir(0)
	if err != nil {
		return errors.Wrap(err, "reading directory")
	}

	for _, fi := range fis {
		if !fi.IsDir() {
			continue
		}

		i.logger.Debugf("open field: %s", fi.Name())
		fld, err := i.newField(i.fieldPath(filepath.Base(fi.Name())), filepath.Base(fi.Name()))
		if err != nil {
			return errors.Wrapf(ErrName, "'%s'", fi.Name())
		}
		if err := fld.Open(); err != nil {
			return fmt.Errorf("open field: name=%s, err=%s", fld.Name(), err)
		}
		i.logger.Debugf("add field to index.fields: %s", fi.Name())
		i.fields[fld.Name()] = fld
	}
	return nil
}
source: func (sel *selector) names() string {
	bf := new(bytes.Buffer)

	switch parent := sel.parent.(type) {
	case nil, *atRule:
		for _, name := range strings.Split(sel.name, comma) {
			if bf.Len() > 0 {
				bf.WriteString(comma)
			}

			bf.WriteString(strings.TrimSpace(name))
		}
	case *selector:
		for _, parentS := range strings.Split(parent.names(), comma) {
			for _, s := range strings.Split(sel.name, comma) {
				if bf.Len() > 0 {
					bf.WriteString(comma)
				}

				s = strings.TrimSpace(s)

				if strings.Index(s, ampersand) != -1 {
					bf.WriteString(strings.Replace(s, ampersand, parentS, -1))
				} else {
					bf.WriteString(parentS)
					bf.WriteString(space)
					bf.WriteString(s)
				}
			}
		}
	}

	return bf.String()
}
source: func (s *OptionGroupOption) SetSupportsOptionVersionDowngrade(v bool) *OptionGroupOption {
	s.SupportsOptionVersionDowngrade = &v
	return s
}
source: func (r *reader) read3BitNormal() []float32 {
	ret := []float32{0.0, 0.0, 0.0}

	hasX := r.readBoolean()
	haxY := r.readBoolean()

	if hasX {
		ret[0] = r.readNormal()
	}

	if haxY {
		ret[1] = r.readNormal()
	}

	negZ := r.readBoolean()
	prodsum := ret[0]*ret[0] + ret[1]*ret[1]

	if prodsum < 1.0 {
		ret[2] = float32(math.Sqrt(float64(1.0 - prodsum)))
	} else {
		ret[2] = 0.0
	}

	if negZ {
		ret[2] = -ret[2]
	}

	return ret
}
source: func (q *Query) SelectOrInsert(values ...interface{}) (inserted bool, _ error) {
	if q.stickyErr != nil {
		return false, q.stickyErr
	}

	var insertq *Query
	var insertErr error
	for i := 0; i < 5; i++ {
		if i >= 2 {
			time.Sleep(internal.RetryBackoff(i-2, 250*time.Millisecond, 5*time.Second))
		}

		err := q.Select(values...)
		if err == nil {
			return false, nil
		}
		if err != internal.ErrNoRows {
			return false, err
		}

		if insertq == nil {
			insertq = q
			if len(insertq.columns) > 0 {
				insertq = insertq.Copy()
				insertq.columns = nil
			}
		}

		res, err := insertq.Insert(values...)
		if err != nil {
			insertErr = err
			if err == internal.ErrNoRows {
				continue
			}
			if pgErr, ok := err.(internal.PGError); ok {
				if pgErr.IntegrityViolation() {
					continue
				}
				if pgErr.Field('C') == "55000" {
					// Retry on "#55000 attempted to delete invisible tuple".
					continue
				}
			}
			return false, err
		}
		if res.RowsAffected() == 1 {
			return true, nil
		}
	}

	err := fmt.Errorf(
		"pg: SelectOrInsert: select returns no rows (insert fails with err=%q)",
		insertErr)
	return false, err
}
source: func (s *VLANService) NewDedicateGuestVlanRangeParams(physicalnetworkid string, vlanrange string) *DedicateGuestVlanRangeParams {
	p := &DedicateGuestVlanRangeParams{}
	p.p = make(map[string]interface{})
	p.p["physicalnetworkid"] = physicalnetworkid
	p.p["vlanrange"] = vlanrange
	return p
}
source: func (s *GetMetricDataInput) SetHistoricalMetrics(v []*HistoricalMetric) *GetMetricDataInput {
	s.HistoricalMetrics = v
	return s
}
source: func (a *attributes) GetResource() string {
	if a.event.ObjectRef == nil {
		return ""
	}
	return a.event.ObjectRef.Resource
}
source: func Equal(l, r Value) (bool, error) {

	if l == nil && r == nil {
		return true, nil
	}

	if r == nil {
		switch l.(type) {
		case NilValue:
			return true, nil
		}
		return false, nil
	}
	if _, isNil := r.(NilValue); isNil {
		switch l.(type) {
		case nil:
			return true, nil
		case NilValue:
			return true, nil
		}
		return false, nil
	}

	switch lt := l.(type) {
	case nil, NilValue:
		return false, nil
	case StringValue:
		if lt.Val() == r.ToString() {
			return true, nil
		}
		return false, nil
	case IntValue:
		rhv, _ := ValueToInt64(r)
		return lt.Val() == rhv, nil
	case NumberValue:
		rhv, _ := ValueToFloat64(r)
		return lt.Val() == rhv, nil
	case BoolValue:
		rhv, _ := ValueToBool(r)
		return lt.Val() == rhv, nil
	case TimeValue:
		rhv, _ := ValueToTime(r)
		return lt.Val() == rhv, nil
	case Slice:
		if rhv, ok := r.(Slice); ok {
			if lt.Len() != rhv.Len() {
				return false, nil
			}
			rhslice := rhv.SliceValue()
			for i, lhval := range lt.SliceValue() {
				if eq, err := Equal(lhval, rhslice[i]); !eq || err != nil {
					return false, nil
				}
			}
			return true, nil
		}
	}
	return false, fmt.Errorf("Could not evaluate equals for %v = %v", l.Value(), r.Value())
}
source: func TryProtocolsWithRegistryURL(registry string, allowInsecure bool, action func(registryURL url.URL) error) (*url.URL, error) {
	var errs []error

	if !strings.Contains(registry, "://") {
		registry = "unset://" + registry
	}
	url, err := url.Parse(registry)
	if err != nil {
		return nil, err
	}
	var protos []string
	switch {
	case len(url.Scheme) > 0 && url.Scheme != "unset":
		protos = []string{url.Scheme}
	case allowInsecure || netutils.IsPrivateAddress(registry):
		protos = []string{"https", "http"}
	default:
		protos = []string{"https"}
	}
	registry = url.Host

	for _, proto := range protos {
		klog.V(4).Infof("Trying protocol %s for the registry URL %s", proto, registry)
		url.Scheme = proto
		err := action(*url)
		if err == nil {
			return url, nil
		}

		if err != nil {
			klog.V(4).Infof("Error with %s for %s: %v", proto, registry, err)
		}

		if _, ok := err.(*errcode.Errors); ok {
			// we got a response back from the registry, so return it
			return url, err
		}
		errs = append(errs, err)
		if proto == "https" && strings.Contains(err.Error(), "server gave HTTP response to HTTPS client") && !allowInsecure {
			errs = append(errs, fmt.Errorf("\n* Append --force-insecure if you really want to prune the registry using insecure connection."))
		} else if proto == "http" && strings.Contains(err.Error(), "malformed HTTP response") {
			errs = append(errs, fmt.Errorf("\n* Are you trying to connect to a TLS-enabled registry without TLS?"))
		}
	}

	return nil, kerrors.NewAggregate(errs)
}
source: func (q *TagQuery) getInitialByEqual(expr kv, idCh chan schema.MKey, stopCh chan struct{}) {
	defer q.wg.Done()

KEYS:
	for k := range q.index[expr.key][expr.value] {
		select {
		case <-stopCh:
			break KEYS
		case idCh <- k:
		}
	}

	close(idCh)
}
source: func ClearDownloads(bundlesDir string) error {
	downloadDir := downloadsPath(bundlesDir)
	err := os.RemoveAll(downloadDir)
	return errors.Annotate(err, "unable to clear bundle downloads")
}
source: func SearchUser(r *http.Request, searchString string) (*user.User, error) {
	userMgr := user.NewManager(r)
	usr, err := userMgr.GetByName(searchString)
	if err == nil {
		return usr, err
	}
	if !db.IsNotFound(err) {
		return nil, err
	}
	valMgr := validationdb.NewManager(r)
	validatedPhonenumber, err := valMgr.GetByPhoneNumber(searchString)
	if err != nil && !db.IsNotFound(err) {
		return nil, err
	}
	if !db.IsNotFound(err) {
		return userMgr.GetByName(validatedPhonenumber.Username)
	}
	validatedEmailAddress, err := valMgr.GetByEmailAddress(searchString)
	if err != nil && !db.IsNotFound(err) {
		return nil, err
	}
	if !db.IsNotFound(err) {
		return userMgr.GetByName(validatedEmailAddress.Username)
	}
	idMgr := iyoid.NewManager(r)
	clientID, _ := context.Get(r, "client_id").(string)
	idObj, err := idMgr.GetByIDAndAZP(searchString, clientID)
	if err != nil {
		return nil, err
	}
	return userMgr.GetByName(idObj.Username)
}
source: func (ow *outerWorker) buildTask(ctx context.Context) (*lookUpJoinTask, error) {
	ow.executor.newFirstChunk()

	task := &lookUpJoinTask{
		doneCh:            make(chan error, 1),
		outerResult:       ow.executor.newFirstChunk(),
		encodedLookUpKeys: chunk.NewChunkWithCapacity([]*types.FieldType{types.NewFieldType(mysql.TypeBlob)}, ow.ctx.GetSessionVars().MaxChunkSize),
		lookupMap:         mvmap.NewMVMap(),
	}
	task.memTracker = memory.NewTracker(stringutil.MemoizeStr(func() string { return fmt.Sprintf("lookup join task %p", task) }), -1)
	task.memTracker.AttachTo(ow.parentMemTracker)

	ow.increaseBatchSize()
	if ow.lookup.isOuterJoin { // if is outerJoin, push the requiredRows down
		requiredRows := int(atomic.LoadInt64(&ow.lookup.requiredRows))
		task.outerResult.SetRequiredRows(requiredRows, ow.maxBatchSize)
	} else {
		task.outerResult.SetRequiredRows(ow.batchSize, ow.maxBatchSize)
	}

	task.memTracker.Consume(task.outerResult.MemoryUsage())
	for !task.outerResult.IsFull() {
		err := ow.executor.Next(ctx, chunk.NewRecordBatch(ow.executorChk))
		if err != nil {
			return task, err
		}
		if ow.executorChk.NumRows() == 0 {
			break
		}

		oldMemUsage := task.outerResult.MemoryUsage()
		task.outerResult.Append(ow.executorChk, 0, ow.executorChk.NumRows())
		newMemUsage := task.outerResult.MemoryUsage()
		task.memTracker.Consume(newMemUsage - oldMemUsage)
	}
	if task.outerResult.NumRows() == 0 {
		return nil, nil
	}

	if ow.filter != nil {
		outerMatch := make([]bool, 0, task.outerResult.NumRows())
		var err error
		task.outerMatch, err = expression.VectorizedFilter(ow.ctx, ow.filter, chunk.NewIterator4Chunk(task.outerResult), outerMatch)
		if err != nil {
			return task, err
		}
		task.memTracker.Consume(int64(cap(task.outerMatch)))
	}
	return task, nil
}
source: func (sb *StatsdBuffer) FGauge(stat string, value float64) error {
	sb.eventChannel <- &event.FGauge{Name: stat, Value: value}
	return nil
}
source: func (holder *itrHolder) moveToNext() (exhausted bool, err error) {
	var res statedb.QueryResult
	if res, err = holder.itr.Next(); err != nil {
		return false, err
	}
	if res != nil {
		holder.kv = res.(*statedb.VersionedKV)
	}
	return res == nil, nil
}
source: func (b *Benchmark) Run(ctx context.Context) error {
	fmt.Printf("Listening for incoming connections at %s:%d\n", b.cfg.IP, b.cfg.Port)
	if err := b.collector.Listen(b.cfg.Port); err != nil {
		return err
	}
	j, err := b.launch(ctx)
	if err != nil {
		return err
	}
	fmt.Printf("Service %s launched (%d instances)\n", j.ID, b.cfg.Count)

	// Periodically print stats.
	doneCh := make(chan struct{})
	go func() {
		for {
			select {
			case <-time.After(5 * time.Second):
				fmt.Printf("\n%s: Progression report\n", time.Now())
				b.collector.Stats(os.Stdout, time.Second)
			case <-doneCh:
				return
			}
		}
	}()

	fmt.Println("Collecting metrics...")
	b.collector.Collect(ctx, b.cfg.Count)
	doneCh <- struct{}{}

	fmt.Printf("\n%s: Benchmark completed\n", time.Now())
	b.collector.Stats(os.Stdout, time.Second)

	return nil
}
source: func (s *ContextStoreWithDefault) ResetTLSMaterial(name string, data *store.ContextTLSData) error {
	if name == DefaultContextName {
		return errors.New("The default context store does not support ResetTLSMaterial")
	}
	return s.Store.ResetTLSMaterial(name, data)
}
source: func (c *LoginController) Authorize(ctx *app.AuthorizeLoginContext) error {
	return redirectWithParams(ctx, c.configuration, ctx.ResponseData.Header(), ctx.Params, authservice.LoginLoginPath())
}
source: func (c ClientBuildClient) Update(namespace string, build *buildv1.Build) error {
	_, e := c.Client.BuildV1().Builds(namespace).Update(build)
	return e
}
source: func IsKeyword(s string) bool {
	for _, x := range Keywords {
		if x == s {
			return true
		}
	}
	return false
}
source: func (n *NetStore) getFetcher(ref Address) *fetcher {
	key := hex.EncodeToString(ref)
	f, ok := n.fetchers.Get(key)
	if ok {
		return f.(*fetcher)
	}
	return nil
}
source: func DiscoverService(name string, conf common.Conf) (Service, error) {
	hostSeries := series.MustHostSeries()
	initName, err := discoverInitSystem(hostSeries)
	if err != nil {
		return nil, errors.Trace(err)
	}

	service, err := newService(name, conf, initName, hostSeries)
	if err != nil {
		return nil, errors.Trace(err)
	}

	return service, nil
}
source: func (f *File) Read(p []byte) (n int, err error) {
	return f.Data.Read(p)
}
source: func (m *MockInterface) CoordinationV1beta1() v1beta15.CoordinationV1beta1Interface {
	ret := m.ctrl.Call(m, "CoordinationV1beta1")
	ret0, _ := ret[0].(v1beta15.CoordinationV1beta1Interface)
	return ret0
}
source: func (rb *Bitmap) FromBase64(str string) (int64, error) {
	data, err := base64.StdEncoding.DecodeString(str)
	if err != nil {
		return 0, err
	}
	buf := bytes.NewBuffer(data)

	return rb.ReadFrom(buf)
}
source: func (s *Service) Log(ctx context.Context, follow bool) error {
	return s.collectContainersAndDo(ctx, func(c *container.Container) error {
		containerNumber, err := c.Number()
		if err != nil {
			return err
		}
		name := fmt.Sprintf("%s_%d", s.name, containerNumber)
		if s.Config().ContainerName != "" {
			name = s.Config().ContainerName
		}
		l := s.context.LoggerFactory.CreateContainerLogger(name)
		return c.Log(ctx, l, follow)
	})
}
source: func RankingEqual(o1, o2 *RankingOption) bool {
	if o1 != nil {
		return o1.Equal(o2)
	}
	if o2 != nil {
		return o2.Equal(o1)
	}
	return true
}
source: func (robot *Robot) Handle(handlers ...interface{}) {
	for _, h := range handlers {
		nh, err := NewHandler(h)
		if err != nil {
			Logger.Fatal(err)
			panic(err)
		}

		robot.handlers = append(robot.handlers, nh)
	}
}
source: func LoadMasterKeysFromPEM(public, private []byte) error {
	pub, priv, err := LoadRSAKeyPair(public, private)
	if err != nil {
		return err
	}

	mKeyLock.Lock()
	defer mKeyLock.Unlock()
	masterKeys = MasterKeys{pub, priv}
	return nil
}
source: func (wb *WriteBatch) DeleteCF(cf *ColumnFamilyHandle, key []byte) {
	cKey := byteToChar(key)
	C.rocksdb_writebatch_delete_cf(wb.c, cf.c, cKey, C.size_t(len(key)))
}
source: func (s *HTTPServer) parse(resp http.ResponseWriter, req *http.Request, dc *string, b *structs.QueryOptions) bool {
	return s.parseInternal(resp, req, dc, b, true)
}
source: func (s *scanner) shouldClose(resp *pb.ScanResponse, region hrpc.RegionInfo) bool {
	if resp.MoreResults != nil && !*resp.MoreResults {
		// the filter for the whole scan has been exhausted, close the scanner
		return true
	}

	if s.scannerID != noScannerID {
		// not done with this region yet
		return false
	}

	// Check to see if this region is the last we should scan because:
	// (1) it's the last region
	if len(region.StopKey()) == 0 && !s.rpc.Reversed() {
		return true
	}
	if s.rpc.Reversed() && len(region.StartKey()) == 0 {
		return true
	}
	// (3) because its stop_key is greater than or equal to the stop_key of this scanner,
	// provided that (2) we're not trying to scan until the end of the table.
	if !s.rpc.Reversed() {
		return len(s.rpc.StopRow()) != 0 && // (2)
			bytes.Compare(s.rpc.StopRow(), region.StopKey()) <= 0 // (3)
	}

	//  Reversed Scanner
	return len(s.rpc.StopRow()) != 0 && // (2)
		bytes.Compare(s.rpc.StopRow(), region.StartKey()) >= 0 // (3)
}
source: func (h *Health) AddCheck(cfg *Config) error {
	if h.active.val() {
		return ErrNoAddCfgWhenActive
	}

	h.configs = append(h.configs, cfg)
	return nil
}
source: func NewSource(ctx *Context, stmt *rel.SqlSource, isFinal bool) (*Source, error) {
	s := &Source{Stmt: stmt, ctx: ctx, SourcePb: &SourcePb{Final: isFinal}, PlanBase: NewPlanBase(false)}
	err := s.load()
	if err != nil {
		return nil, err
	}
	return s, nil
}
source: func (b *FastLogStore) GetLog(idx uint64, log *raft.Log) error {
	b.mu.RLock()
	defer b.mu.RUnlock()
	if b.closed {
		return ErrClosed
	}
	vlog := b.lvm[idx]
	if vlog == nil {
		return raft.ErrLogNotFound
	}
	*log = *vlog
	return nil
}
source: func (s *volumeAttachmentLister) Get(name string) (*v1.VolumeAttachment, error) {
	obj, exists, err := s.indexer.GetByKey(name)
	if err != nil {
		return nil, err
	}
	if !exists {
		return nil, errors.NewNotFound(v1.Resource("volumeattachment"), name)
	}
	return obj.(*v1.VolumeAttachment), nil
}
source: func (d *DB) makeRoomForWrite(force bool) error {
	allowDelay := !force
	for {
		// TODO: check any previous sticky error, if the paranoid option is set.

		if allowDelay && len(d.versions.currentVersion().files[0]) > l0SlowdownWritesTrigger {
			// We are getting close to hitting a hard limit on the number of
			// L0 files. Rather than delaying a single write by several
			// seconds when we hit the hard limit, start delaying each
			// individual write by 1ms to reduce latency variance.
			d.mu.Unlock()
			time.Sleep(1 * time.Millisecond)
			d.mu.Lock()
			allowDelay = false
			// TODO: how do we ensure we are still 'at the front of the writer queue'?
			continue
		}

		if !force && d.mem.ApproximateMemoryUsage() <= d.opts.GetWriteBufferSize() {
			// There is room in the current memtable.
			break
		}

		if d.imm != nil {
			// We have filled up the current memtable, but the previous
			// one is still being compacted, so we wait.
			d.compactionCond.Wait()
			continue
		}

		if len(d.versions.currentVersion().files[0]) > l0StopWritesTrigger {
			// There are too many level-0 files.
			d.compactionCond.Wait()
			continue
		}

		// Attempt to switch to a new memtable and trigger compaction of old
		// TODO: drop and re-acquire d.mu around the I/O.
		newLogNumber := d.versions.nextFileNum()
		newLogFile, err := d.opts.GetFileSystem().Create(dbFilename(d.dirname, fileTypeLog, newLogNumber))
		if err != nil {
			return err
		}
		newLog := record.NewWriter(newLogFile)
		if err := d.log.Close(); err != nil {
			newLogFile.Close()
			return err
		}
		if err := d.logFile.Close(); err != nil {
			newLog.Close()
			newLogFile.Close()
			return err
		}
		d.logNumber, d.logFile, d.log = newLogNumber, newLogFile, newLog
		d.imm, d.mem = d.mem, memdb.New(&d.icmpOpts)
		force = false
		d.maybeScheduleCompaction()
	}
	return nil
}
source: func LoadJSON(path string, marshal json.Unmarshaler) error {
	j := NewJSON(path, marshal)
	watch(j)
	j.Load()
	return j.err
}
source: func (whisper *Whisper) AddKeyPair(key *ecdsa.PrivateKey) (string, error) {
	id, err := GenerateRandomID()
	if err != nil {
		return "", fmt.Errorf("failed to generate ID: %s", err)
	}

	whisper.keyMu.Lock()
	whisper.privateKeys[id] = key
	whisper.keyMu.Unlock()

	return id, nil
}
source: func (c *Consumer) SubscribeTopics(topics []string, rebalanceCb RebalanceCb) (err error) {
	ctopics := C.rd_kafka_topic_partition_list_new(C.int(len(topics)))
	defer C.rd_kafka_topic_partition_list_destroy(ctopics)

	for _, topic := range topics {
		ctopic := C.CString(topic)
		defer C.free(unsafe.Pointer(ctopic))
		C.rd_kafka_topic_partition_list_add(ctopics, ctopic, C.RD_KAFKA_PARTITION_UA)
	}

	e := C.rd_kafka_subscribe(c.handle.rk, ctopics)
	if e != C.RD_KAFKA_RESP_ERR_NO_ERROR {
		return newError(e)
	}

	c.rebalanceCb = rebalanceCb
	c.handle.currAppRebalanceEnable = c.rebalanceCb != nil || c.appRebalanceEnable

	return nil
}
source: func NewDearmor62DecryptStream(versionValidator VersionValidator, ciphertext io.Reader, kr Keyring) (*MessageKeyInfo, io.Reader, string, error) {
	dearmored, frame, err := NewArmor62DecoderStream(ciphertext, armor62EncryptionHeaderChecker, armor62EncryptionFrameChecker)
	if err != nil {
		return nil, nil, "", err
	}
	brand, err := frame.GetBrand()
	if err != nil {
		return nil, nil, "", err
	}
	mki, r, err := NewDecryptStream(versionValidator, dearmored, kr)
	if err != nil {
		return mki, nil, "", err
	}
	return mki, r, brand, nil
}
source: func (e ErrorNode) Temporary() bool {
	type temporary interface {
		Temporary() bool
	}

	for err := e.cause; err != nil; {
		if t, ok := err.(temporary); ok {
			return t.Temporary()
		}

		if cause, ok := err.(causer); ok {
			err = cause.Cause()
		} else {
			err = nil
		}
	}
	return false
}
source: func TLSConfig(cert *x509.Certificate, serverName string, config fab.EndpointConfig) (*tls.Config, error) {

	if cert != nil {
		config.TLSCACertPool().Add(cert)
	}

	certPool, err := config.TLSCACertPool().Get()
	if err != nil {
		return nil, err
	}
	return &tls.Config{RootCAs: certPool, Certificates: config.TLSClientCerts(), ServerName: serverName}, nil
}
source: func (r Notification_User_Subscriber_Preference) GetDefaultPreference() (resp datatypes.Notification_Preference, err error) {
	err = r.Session.DoRequest("SoftLayer_Notification_User_Subscriber_Preference", "getDefaultPreference", nil, &r.Options, &resp)
	return
}
source: func DeleteIsiVolume(
	ctx context.Context,
	client api.Client,
	name string) (resp *getIsiVolumesResp, err error) {

	err = client.Delete(
		ctx,
		realNamespacePath(client),
		name,
		recursiveTrueQS,
		nil,
		&resp)
	return resp, err
}
source: func removeCarriageReturns(b bytes.Buffer) bytes.Buffer {
	if runtime.GOOS == "windows" {
		var buf bytes.Buffer
		for {
			byt, er := b.ReadBytes(0x0D)
			end := len(byt)
			if nil == er {
				end -= 1
			}
			if nil != byt {
				buf.Write(byt[:end])
			} else {
				break
			}
			if nil != er {
				break
			}
		}
		b = buf
	}
	return b

}
source: func GetLicenseSummary(ctx context.Context, license model.IssuedLicense) (string, error) {
	lclient, err := getClient()
	if err != nil {
		return "", err
	}

	cr, err := lclient.VerifyLicense(ctx, license)
	if err != nil {
		return "", err
	}
	return lclient.SummarizeLicense(cr, license.KeyID).String(), nil
}
source: func (t *TSMReader) Delete(keys [][]byte) error {
	if !t.index.Delete(keys) {
		return nil
	}
	if err := t.tombstoner.Add(keys); err != nil {
		return err
	}
	if err := t.tombstoner.Flush(); err != nil {
		return err
	}
	return nil
}
source: func NewWithLog(logger Logger, handlers ...Handler) *Tango {
	tan := &Tango{
		Router:     newRouter(),
		logger:     logger,
		handlers:   make([]Handler, 0),
		ErrHandler: Errors(),
	}

	tan.ctxPool.New = func() interface{} {
		return &Context{
			tan:    tan,
			Logger: tan.logger,
		}
	}

	tan.respPool.New = func() interface{} {
		return &responseWriter{}
	}

	tan.Use(handlers...)

	return tan
}
source: func computeAppResources(isolators types.Isolators) (appResources, error) {
	res := appResources{}
	var err error

	withIsolator := func(name string, f func() error) error {
		ok, err := cgroup.IsIsolatorSupported(name)
		if err != nil {
			return errwrap.Wrapf("could not check for isolator "+name, err)
		}

		if !ok {
			fmt.Fprintf(os.Stderr, "warning: resource/%s isolator set but support disabled in the kernel, skipping\n", name)
			return nil
		}

		return f()
	}

	for _, isolator := range isolators {
		if err != nil {
			return res, err
		}

		switch v := isolator.Value().(type) {
		case *types.ResourceMemory:
			err = withIsolator("memory", func() error {
				if v.Limit() == nil {
					return nil
				}

				val := uint64(v.Limit().Value())
				res.MemoryLimit = &val
				return nil
			})
		case *types.ResourceCPU:
			err = withIsolator("cpu", func() error {
				if v.Limit() == nil {
					return nil
				}
				if v.Limit().Value() > MaxMilliValue {
					return fmt.Errorf("cpu limit exceeds the maximum millivalue: %v", v.Limit().String())
				}

				val := uint64(v.Limit().MilliValue() / 10)
				res.CPUQuota = &val
				return nil
			})
		case *types.LinuxCPUShares:
			err = withIsolator("cpu", func() error {
				val := uint64(*v)
				res.LinuxCPUShares = &val
				return nil
			})
		case *types.LinuxOOMScoreAdj:
			val := int(*v)
			res.LinuxOOMScoreAdjust = &val
		}
	}

	return res, err
}
source: func (d *dir) mkfile(p string) (*file, error) {
	n := d.find(p)
	if n.path() == p {
		if n.isdir() {
			return nil, errIsDir
		}

		return n.(*file), nil
	}

	dirpath, filename := path.Split(p)
	// Make any non-existent directories
	n, err := d.mkdirs(dirpath)
	if err != nil {
		return nil, err
	}

	dd := n.(*dir)
	n = &file{
		common: common{
			p:   path.Join(dd.path(), filename),
			mod: time.Now(),
		},
	}

	dd.add(n)
	return n.(*file), nil
}
source: func (b *Backend) Rehash() uint64 {
	// If we have no backend, the value is zero
	if b == nil {
		return 0
	}

	// Use hashstructure to hash only our type with the config.
	code, err := hashstructure.Hash(map[string]interface{}{
		"type":   b.Type,
		"config": b.RawConfig.Raw,
	}, nil)

	// This should never happen since we have just some basic primitives
	// so panic if there is an error.
	if err != nil {
		panic(err)
	}

	return code
}
source: func (idx *TxIndex) ConnectBlock(dbTx database.Tx, block *btcutil.Block,
	stxos []blockchain.SpentTxOut) error {

	// Increment the internal block ID to use for the block being connected
	// and add all of the transactions in the block to the index.
	newBlockID := idx.curBlockID + 1
	if err := dbAddTxIndexEntries(dbTx, block, newBlockID); err != nil {
		return err
	}

	// Add the new block ID index entry for the block being connected and
	// update the current internal block ID accordingly.
	err := dbPutBlockIDIndexEntry(dbTx, block.Hash(), newBlockID)
	if err != nil {
		return err
	}
	idx.curBlockID = newBlockID
	return nil
}
source: func NewPetList(ctx *middleware.Context, handler PetListHandler) *PetList {
	return &PetList{Context: ctx, Handler: handler}
}
source: func (v *Xception2) Equals(rhs *Xception2) bool {
	if v == nil {
		return rhs == nil
	} else if rhs == nil {
		return false
	}
	if !_I32_EqualsPtr(v.ErrorCode, rhs.ErrorCode) {
		return false
	}
	if !((v.StructThing == nil && rhs.StructThing == nil) || (v.StructThing != nil && rhs.StructThing != nil && v.StructThing.Equals(rhs.StructThing))) {
		return false
	}

	return true
}
source: func newCommand(name string, data []byte) (Command, error) {
	// Find the registered command.
	command := commandTypes[name]
	if command == nil {
		return nil, fmt.Errorf("raft.Command: Unregistered command type: %s", name)
	}

	// Make a copy of the command.
	v := reflect.New(reflect.Indirect(reflect.ValueOf(command)).Type()).Interface()
	copy, ok := v.(Command)
	if !ok {
		panic(fmt.Sprintf("raft: Unable to copy command: %s (%v)", command.CommandName(), reflect.ValueOf(v).Kind().String()))
	}

	// If data for the command was passed in the decode it.
	if data != nil {
		if encoder, ok := copy.(CommandEncoder); ok {
			if err := encoder.Decode(bytes.NewReader(data)); err != nil {
				return nil, err
			}
		} else {
			if err := json.NewDecoder(bytes.NewReader(data)).Decode(copy); err != nil {
				return nil, err
			}
		}
	}

	return copy, nil
}
source: func getFileLine(calldepth int) (string, int) {

	var file string
	var line int

	var ok bool
	_, file, line, ok = runtime.Caller(calldepth)
	if !ok {
		file = "???"
		line = 0
	}

	return file, line
}
source: func (s *DescribeInventoryDeletionsOutput) SetInventoryDeletions(v []*InventoryDeletionStatusItem) *DescribeInventoryDeletionsOutput {
	s.InventoryDeletions = v
	return s
}
source: func (sh SignedHeader) StringIndented(indent string) string {
	return fmt.Sprintf(`SignedHeader{
%s  %v
%s  %v
%s}`,
		indent, sh.Header.StringIndented(indent+"  "),
		indent, sh.Commit.StringIndented(indent+"  "),
		indent)
}
source: func (i *Int64Value) Set(s string) error {
	v, err := strconv.ParseInt(s, 0, 64)
	*i = Int64Value(v)
	return err
}
source: func Convert_v1beta1_AdmissionRequest_To_admission_AdmissionRequest(in *v1beta1.AdmissionRequest, out *admission.AdmissionRequest, s conversion.Scope) error {
	return autoConvert_v1beta1_AdmissionRequest_To_admission_AdmissionRequest(in, out, s)
}
source: func (o *Link) CreateCSNATPool(child *CSNATPool) *bambou.Error {

	return bambou.CurrentSession().CreateChild(o, child)
}
source: func New(appName, tableName string, opts ...Option) (*Checkpoint, error) {
	client := dynamodb.New(session.New(aws.NewConfig()))

	ck := &Checkpoint{
		tableName:   tableName,
		appName:     appName,
		client:      client,
		maxInterval: time.Duration(1 * time.Minute),
		done:        make(chan struct{}),
		mu:          &sync.Mutex{},
		checkpoints: map[key]string{},
		retryer:     &DefaultRetryer{},
	}

	for _, opt := range opts {
		opt(ck)
	}

	go ck.loop()

	return ck, nil
}
source: func (r *Resource) do(method string) (*Resource, error) {
	url := *r.Api.BaseUrl
	if len(url.Path) > 0 {
		url.Path += "/" + r.Url
	} else {
		url.Path = r.Url
	}
	if r.Api.PathSuffix != "" {
		url.Path += r.Api.PathSuffix
	}

	url.RawQuery = r.QueryValues.Encode()
	req, err := http.NewRequest(method, url.String(), r.Payload)
	if err != nil {
		return r, err
	}

	if r.Api.BasicAuth != nil {
		req.SetBasicAuth(r.Api.BasicAuth.Username, r.Api.BasicAuth.Password)
	}

	if r.Headers != nil {
		for k, _ := range r.Headers {
			req.Header.Set(k, r.Headers.Get(k))
		}
	}

	resp, err := r.Api.Client.Do(req)
	if err != nil {
		return r, err
	}

	r.Raw = resp

	if resp.StatusCode >= 400 {
		return r, nil
	}

	for k, _ := range r.Raw.Header {
		r.SetHeader(k, r.Raw.Header.Get(k));
	}

	defer resp.Body.Close()

	err = json.NewDecoder(resp.Body).Decode(r.Response)
	if err != nil {
		return r, err
	}

	return r, nil
}
source: func (d *BuildConfigDescriber) DescribeTriggers(bc *buildv1.BuildConfig, out *tabwriter.Writer) {
	describeBuildTriggers(bc.Spec.Triggers, bc.Name, bc.Namespace, out, d)
}
source: func (u Uint16) MarshalBinary() ([]byte, error) {
	b := uio.NewBigEndianBuffer(nil)
	b.Write16(uint16(u))
	return b.Data(), nil
}
source: func (context *BaseContext) SetInt64(key string, value int64) {
	context.userData[key] = value
}
source: func (hc *HealthCheck) Ping(cancel <-chan struct{}, key HealthStatusKey, report func(HealthStatus)) {
	timer := time.NewTimer(0)
	defer timer.Stop()
	for {
		select {
		case <-timer.C:
			stat := hc.Run(key)
			stat.KillFlag = hc.KillCountLimit > 0 && hc.KillCounter >= hc.KillCountLimit
			timer.Reset(hc.Interval)
			report(stat)
		case <-cancel:
			return
		}
	}
}
source: func (s *Action) GitCredentialStore(ctx context.Context, c *cli.Context) error {
	cred, err := parseGitCredentials(termio.Stdin)
	if err != nil {
		return ExitError(ctx, ExitUnsupported, err, "Error: %v while parsing git-credential", err)
	}
	path := "git/" + fsutil.CleanFilename(cred.Host) + "/" + fsutil.CleanFilename(cred.Username)
	// This should never really be an issue because git automatically removes invalid credentials first
	if s.Store.Exists(ctx, path) {
		fmt.Fprintf(os.Stderr, ""+
			"gopass: did not store \"%s\" because it already exists. "+
			"If you want to overwrite it, delete it first by doing: "+
			"\"gopass rm %s\"\n",
			path, path,
		)
		return nil
	}
	secret := secret.New(cred.Password, "")
	if cred.Username != "" {
		_ = secret.SetValue("login", cred.Username)
	}
	err = s.Store.Set(ctx, path, secret)
	if err != nil {
		fmt.Fprintf(os.Stderr, "gopass error: error while writing to store: %v\n", err)
	}
	return nil
}
source: func newUploadTracker(checker Checker, uploader Uploader, isol *isolated.Isolated) *UploadTracker {
	isol.Files = make(map[string]isolated.File)
	return &UploadTracker{
		checker:       checker,
		uploader:      uploader,
		isol:          isol,
		fileHashCache: make(map[string]hashResult),
		lOS:           standardOS{},
	}
}
source: func GetSignableRoles(repo client.Repository, target *client.Target) ([]data.RoleName, error) {
	var signableRoles []data.RoleName

	// translate the full key names, which includes the GUN, into just the key IDs
	allCanonicalKeyIDs := make(map[string]struct{})
	for fullKeyID := range repo.GetCryptoService().ListAllKeys() {
		allCanonicalKeyIDs[path.Base(fullKeyID)] = struct{}{}
	}

	allDelegationRoles, err := repo.GetDelegationRoles()
	if err != nil {
		return signableRoles, err
	}

	// if there are no delegation roles, then just try to sign it into the targets role
	if len(allDelegationRoles) == 0 {
		signableRoles = append(signableRoles, data.CanonicalTargetsRole)
		return signableRoles, nil
	}

	// there are delegation roles, find every delegation role we have a key for, and
	// attempt to sign into into all those roles.
	for _, delegationRole := range allDelegationRoles {
		// We do not support signing any delegation role that isn't a direct child of the targets role.
		// Also don't bother checking the keys if we can't add the target
		// to this role due to path restrictions
		if path.Dir(delegationRole.Name.String()) != data.CanonicalTargetsRole.String() || !delegationRole.CheckPaths(target.Name) {
			continue
		}

		for _, canonicalKeyID := range delegationRole.KeyIDs {
			if _, ok := allCanonicalKeyIDs[canonicalKeyID]; ok {
				signableRoles = append(signableRoles, delegationRole.Name)
				break
			}
		}
	}

	if len(signableRoles) == 0 {
		return signableRoles, errors.Errorf("no valid signing keys for delegation roles")
	}

	return signableRoles, nil

}
source: func (pdb *BrokerWatcher) ListValues(key string) (keyval.BytesKeyValIterator, error) {
	keyValues := pdb.db.GetDataForPrefix(pdb.prefixKey(key))
	data := make([]*decoder.FileDataEntry, 0, len(keyValues))
	for _, entry := range keyValues {
		data = append(data, &decoder.FileDataEntry{
			Key:   strings.TrimPrefix(entry.Key, pdb.prefix),
			Value: entry.Value,
		})
	}
	return &bytesKeyValIterator{len: len(data), data: data}, nil
}
source: func (s *Server) UpdateSpec(ctx context.Context, q *ApplicationUpdateSpecRequest) (*appv1.ApplicationSpec, error) {
	s.projectLock.Lock(q.Spec.Project)
	defer s.projectLock.Unlock(q.Spec.Project)

	a, err := s.appclientset.ArgoprojV1alpha1().Applications(s.ns).Get(*q.Name, metav1.GetOptions{})
	if err != nil {
		return nil, err
	}
	if err := s.enf.EnforceErr(ctx.Value("claims"), rbacpolicy.ResourceApplications, rbacpolicy.ActionUpdate, appRBACName(*a)); err != nil {
		return nil, err
	}
	a.Spec = q.Spec
	err = s.validateAndNormalizeApp(ctx, a)
	if err != nil {
		return nil, err
	}
	normalizedSpec := a.Spec.DeepCopy()

	for i := 0; i < 10; i++ {
		a.Spec = *normalizedSpec
		_, err = s.appclientset.ArgoprojV1alpha1().Applications(s.ns).Update(a)
		if err == nil {
			s.logEvent(a, ctx, argo.EventReasonResourceUpdated, "updated application spec")
			return normalizedSpec, nil
		}
		if !apierr.IsConflict(err) {
			return nil, err
		}
		a, err = s.appclientset.ArgoprojV1alpha1().Applications(s.ns).Get(*q.Name, metav1.GetOptions{})
		if err != nil {
			return nil, err
		}
	}
	return nil, status.Errorf(codes.Internal, "Failed to update application spec. Too many conflicts")
}
source: func (pgb *ChainDB) PowerlessTickets() (*apitypes.PowerlessTickets, error) {
	ctx, cancel := context.WithTimeout(pgb.ctx, pgb.queryTimeout)
	defer cancel()
	return retrievePowerlessTickets(ctx, pgb.db)
}
source: func baseName(name string) string {
	// First, find the last element
	if i := strings.LastIndex(name, "/"); i >= 0 {
		name = name[i+1:]
	}
	// Now drop the suffix
	if i := strings.LastIndex(name, "."); i >= 0 {
		name = name[0:i]
	}
	return name
}
source: func (t *Tags) Merge(tags *Tags) error {
	a := *tags
	for _, tag := range a {
		err := t.Add(tag)
		if err != nil && !e.Equal(err, ErrTagExist) {
			return e.Forward(err)
		}
	}
	return nil
}
source: func (p *prober) markIPsLocked() {
	for ip, node := range p.nodes {
		node.deletionMark = true
		p.nodes[ip] = node
	}
}
source: func TransactionIoIndexCtx(next http.Handler) http.Handler {
	return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		inout := chi.URLParam(r, "inout")
		inoutid := chi.URLParam(r, "inoutid")
		ctx := context.WithValue(r.Context(), ctxTxInOut, inout)
		ctx = context.WithValue(ctx, ctxTxInOutId, inoutid)
		next.ServeHTTP(w, r.WithContext(ctx))
	})
}
source: func NewGithubStatusMessageWithRepo(p level.Priority, status GithubStatus) Composer {
	s := MakeGithubStatusMessageWithRepo(status)
	_ = s.SetPriority(p)

	return s
}
source: func (seq *Sequence) Next() (KSUID, error) {
	id := seq.Seed // copy
	count := seq.count
	if count > math.MaxUint16 {
		return Nil, errors.New("too many IDs were generated")
	}
	seq.count++
	return withSequenceNumber(id, uint16(count)), nil
}
source: func isDestRelative(base, dest string) bool {
	fullPath := dest
	if !filepath.IsAbs(dest) {
		fullPath = filepath.Join(base, dest)
	}
	relative, err := filepath.Rel(base, fullPath)
	if err != nil {
		return false
	}
	return relative == "." || relative == stripPathShortcuts(relative)
}
source: func (b binding) HasQueryParam() bool {
	if b.Body != nil && len(b.Body.FieldPath) == 0 {
		return false
	}
	fields := make(map[string]bool)
	for _, f := range b.Method.RequestType.Fields {
		fields[f.GetName()] = true
	}
	if b.Body != nil {
		delete(fields, b.Body.FieldPath.String())
	}
	for _, p := range b.PathParams {
		delete(fields, p.FieldPath.String())
	}
	return len(fields) > 0
} 71%|███████   | 3536/5000 [00:04<00:01, 930.44it/s]
source: func (s *Webhook) SetLastModifiedSecret(v time.Time) *Webhook {
	s.LastModifiedSecret = &v
	return s
}
source: func (b *BackDep) Edge() *FwdEdge {
	ret := &FwdEdge{From: &b.Depender, To: &dm.Attempt_ID{}}
	if err := ret.To.SetDMEncoded(b.DependeeGroup.StringID()); err != nil {
		panic(err)
	}
	return ret
}
source: func (is *Is) False(b bool) {
	is.TB.Helper()
	if b {
		fail(is, "expected boolean to be false")
	}
}
source: func (l *littleWire) i2cUpdateDelay(duration uint) error {
	C.i2c_updateDelay(l.lwHandle, C.uint(duration))
	return l.error()
}
source: func (s *Sentinel) Close() {
	s.mutex.Lock()
	defer s.mutex.Unlock()
	s.close()
}
source: func apps(db *gorm.DB, scope scope) ([]*App, error) {
	var apps []*App
	// Default to ordering by name.
	scope = composedScope{order("name"), scope}
	return apps, find(db, scope, &apps)
}
source: func (e *ErrorClass) Contains(err error, opts ...EquivalenceOption) bool {
	if err == nil {
		return false
	}
	cast, ok := err.(*Error)
	if !ok {
		return findSystemErrorClass(err).Is(e)
	}
	if cast.class.Is(e) {
		return true
	}
	if combineEquivOpts(opts)&IncludeWrapped == 0 {
		return false
	}
	return e.Contains(cast.err, opts...)
}
source: func (c *Credentials) isValid() (bool, error) {
	if len(c.ServerURL) == 0 {
		return false, NewErrCredentialsMissingServerURL()
	}

	if len(c.Username) == 0 {
		return false, NewErrCredentialsMissingUsername()
	}

	return true, nil
}
source: func buildNumber(build *buildv1.Build) (int64, error) {
	annotations := build.GetAnnotations()
	if stringNumber, ok := annotations[buildutil.BuildNumberAnnotation]; ok {
		return strconv.ParseInt(stringNumber, 10, 64)
	}
	return 0, fmt.Errorf("build %s/%s does not have %s annotation", build.Namespace, build.Name, buildutil.BuildNumberAnnotation)
}
source: func (q *BytesQueue) Peek() ([]byte, error) {
	data, _, err := q.peek(q.head)
	return data, err
}
source: func FloatEquals(a float64, b float64) bool {
	return math.Abs(a-b) < MinFloatDelta
}
source: func (hook *GraylogHook) SetWriter(w *Writer) error {
	if w == nil {
		return errors.New("writer can't be nil")
	}
	hook.gelfLogger = w
	return nil
}
source: func (p *ConnectionPool) Close() chan bool {
	done := make(chan bool)
	go func() {
		for len(p.pool) > 0 {
			c := <-p.pool
			c.returnOnClose = false
			c.Close()
		}
		done <- true
	}()
	return done
}
source: func new_package_file_cache_forever(name, defalias string) *package_file_cache {
	m := new(package_file_cache)
	m.name = name
	m.mtime = -1
	m.defalias = defalias
	return m
}
source: func goType(pkg string, f *descriptor.FieldDescriptorProto) string {
	if pkg != "" {
		pkg = pkg + "."
	}
	switch *f.Type {
	case descriptor.FieldDescriptorProto_TYPE_DOUBLE:
		if *f.Label == descriptor.FieldDescriptorProto_LABEL_REPEATED {
			return "[]float64"
		}
		return "float64"
	case descriptor.FieldDescriptorProto_TYPE_FLOAT:
		if *f.Label == descriptor.FieldDescriptorProto_LABEL_REPEATED {
			return "[]float32"
		}
		return "float32"
	case descriptor.FieldDescriptorProto_TYPE_INT64:
		if *f.Label == descriptor.FieldDescriptorProto_LABEL_REPEATED {
			return "[]int64"
		}
		return "int64"
	case descriptor.FieldDescriptorProto_TYPE_UINT64:
		if *f.Label == descriptor.FieldDescriptorProto_LABEL_REPEATED {
			return "[]uint64"
		}
		return "uint64"
	case descriptor.FieldDescriptorProto_TYPE_INT32:
		if *f.Label == descriptor.FieldDescriptorProto_LABEL_REPEATED {
			return "[]int32"
		}
		return "int32"
	case descriptor.FieldDescriptorProto_TYPE_UINT32:
		if *f.Label == descriptor.FieldDescriptorProto_LABEL_REPEATED {
			return "[]uint32"
		}
		return "uint32"
	case descriptor.FieldDescriptorProto_TYPE_BOOL:
		if *f.Label == descriptor.FieldDescriptorProto_LABEL_REPEATED {
			return "[]bool"
		}
		return "bool"
	case descriptor.FieldDescriptorProto_TYPE_STRING:
		if *f.Label == descriptor.FieldDescriptorProto_LABEL_REPEATED {
			return "[]string"
		}
		return "string"
	case descriptor.FieldDescriptorProto_TYPE_MESSAGE:
		if *f.Label == descriptor.FieldDescriptorProto_LABEL_REPEATED {
			return fmt.Sprintf("[]*%s%s", pkg, shortType(*f.TypeName))
		}
		return fmt.Sprintf("*%s%s", pkg, shortType(*f.TypeName))
	case descriptor.FieldDescriptorProto_TYPE_BYTES:
		if *f.Label == descriptor.FieldDescriptorProto_LABEL_REPEATED {
			return "[]byte"
		}
		return "byte"
	case descriptor.FieldDescriptorProto_TYPE_ENUM:
		return fmt.Sprintf("*%s%s", pkg, shortType(*f.TypeName))
	default:
		return "interface{}"
	}
}
source: func (c *ApiController) GetWorkersAll() {
	log.Info("Get all workers")

	workers := models.GetAllWorkers()

	c.Data["json"] = workers
	c.ServeJson()
}
source: func (s *LambdaResource) SetEventTriggers(v []*EventTriggerDefinition) *LambdaResource {
	s.EventTriggers = v
	return s
}
source: func (p *BulkProcessor) Start(ctx context.Context) error {
	p.startedMu.Lock()
	defer p.startedMu.Unlock()

	if p.started {
		return nil
	}

	// We must have at least one worker.
	if p.numWorkers < 1 {
		p.numWorkers = 1
	}

	p.requestsC = make(chan BulkableRequest)
	p.executionId = 0
	p.stats = newBulkProcessorStats(p.numWorkers)
	p.stopReconnC = make(chan struct{})

	// Create and start up workers.
	p.workers = make([]*bulkWorker, p.numWorkers)
	for i := 0; i < p.numWorkers; i++ {
		p.workerWg.Add(1)
		p.workers[i] = newBulkWorker(p, i)
		go p.workers[i].work(ctx)
	}

	// Start the ticker for flush (if enabled)
	if int64(p.flushInterval) > 0 {
		p.flusherStopC = make(chan struct{})
		go p.flusher(p.flushInterval)
	}

	p.started = true

	return nil
}
source: func (m Map) MustJSON() string {
	result, err := m.JSON()
	if err != nil {
		panic(err.Error())
	}
	return result
}
source: func (s *Shape) Rename(newName string) {
	if s.AliasedShapeName {
		panic(fmt.Sprintf("attempted to rename %s, but flagged as aliased",
			s.ShapeName))
	}

	for _, r := range s.refs {
		r.OrigShapeName = r.ShapeName
		r.ShapeName = newName
	}

	delete(s.API.Shapes, s.ShapeName)
	s.OrigShapeName = s.ShapeName
	s.API.Shapes[newName] = s
	s.ShapeName = newName
}
source: func fsNew(path string) (Client, *probe.Error) {
	if strings.TrimSpace(path) == "" {
		return nil, probe.NewError(EmptyPath{})
	}
	return &fsClient{
		PathURL: newClientURL(normalizePath(path)),
	}, nil
}
source: func bigIntToIP(v *big.Int) net.IP {
	return net.IP(v.Bytes())
}
source: func sslCertificateAuthority(tlsConf *tls.Config, o values) {
	if sslrootcert := o.Get("sslrootcert"); sslrootcert != "" {
		tlsConf.RootCAs = x509.NewCertPool()

		cert, err := ioutil.ReadFile(sslrootcert)
		if err != nil {
			panic(err)
		}

		ok := tlsConf.RootCAs.AppendCertsFromPEM(cert)
		if !ok {
			errorf("couldn't parse pem in sslrootcert")
		}
	}
}
source: func (scope *Scope) Set(name string, value interface{}) *Scope {
	scope.db.InstantSet(name, value)
	return scope
}
source: func (s EnvSettings) HelmKeyPassphrase() string {
	if d, ok := os.LookupEnv("HELM_KEY_PASSPHRASE"); ok {
		return d
	}
	return ""
}
source: func (writer *ConsoleWriter) SetRotateSize(rotateSize int64) {
	writer.lock.Lock()
	defer writer.lock.Unlock()

	return
}
source: func Unregister(endpoint string) {
	if inst, exist := connectionPool[endpoint]; exist {
		inst.connection.Close()
	}
	delete(connectionPool, endpoint)
}
source: func Finalize(bundle Bundle) (Bundle, error) {
	var valueTrits = make([]Trits, len(bundle))
	var timestampTrits = make([]Trits, len(bundle))
	var currentIndexTrits = make([]Trits, len(bundle))
	var obsoleteTagTrits = make([]Trits, len(bundle))
	var lastIndexTrits = PadTrits(IntToTrits(int64(bundle[0].LastIndex)), 27)

	for i := range bundle {
		valueTrits[i] = PadTrits(IntToTrits(bundle[i].Value), 81)
		timestampTrits[i] = PadTrits(IntToTrits(int64(bundle[i].Timestamp)), 27)
		currentIndexTrits[i] = PadTrits(IntToTrits(int64(bundle[i].CurrentIndex)), 27)
		obsoleteTagTrits[i] = PadTrits(MustTrytesToTrits(bundle[i].ObsoleteTag), 81)
	}

	var bundleHash Hash
	for {
		k := kerl.NewKerl()

		for i := 0; i < len(bundle); i++ {
			relevantTritsForBundleHash := MustTrytesToTrits(
				bundle[i].Address +
					MustTritsToTrytes(valueTrits[i]) +
					MustTritsToTrytes(obsoleteTagTrits[i]) +
					MustTritsToTrytes(timestampTrits[i]) +
					MustTritsToTrytes(currentIndexTrits[i]) +
					MustTritsToTrytes(lastIndexTrits),
			)
			k.Absorb(relevantTritsForBundleHash)
		}

		bundleHashTrits, err := k.Squeeze(HashTrinarySize)
		if err != nil {
			return nil, err
		}
		bundleHash = MustTritsToTrytes(bundleHashTrits)

		// check whether normalized bundle hash can be computed
		normalizedBundleHash := signing.NormalizedBundleHash(bundleHash)
		ok := true
		for i := range normalizedBundleHash {
			if normalizedBundleHash[i] == 13 {
				ok = false
				break
			}
		}
		if ok {
			break
		}
		obsoleteTagTrits[0] = AddTrits(obsoleteTagTrits[0], Trits{1})
	}

	// set the computed bundle hash on each tx in the bundle
	for i := range bundle {
		tx := &bundle[i]
		if i == 0 {
			tx.ObsoleteTag = MustTritsToTrytes(obsoleteTagTrits[0])
		}
		tx.Bundle = bundleHash
	}

	return bundle, nil
}
source: func isIDTranslated(translations map[string]map[string]translation.Translation, lang, id string) bool {
	_, contains := translations[lang][id]
	return contains
}
source: func isEqCrossStructField(fl FieldLevel) bool {

	field := fl.Field()
	kind := field.Kind()

	topField, topKind, ok := fl.GetStructFieldOK()
	if !ok || topKind != kind {
		return false
	}

	switch kind {

	case reflect.Int, reflect.Int8, reflect.Int16, reflect.Int32, reflect.Int64:
		return topField.Int() == field.Int()

	case reflect.Uint, reflect.Uint8, reflect.Uint16, reflect.Uint32, reflect.Uint64, reflect.Uintptr:
		return topField.Uint() == field.Uint()

	case reflect.Float32, reflect.Float64:
		return topField.Float() == field.Float()

	case reflect.Slice, reflect.Map, reflect.Array:
		return int64(topField.Len()) == int64(field.Len())

	case reflect.Struct:

		fieldType := field.Type()

		// Not Same underlying type i.e. struct and time
		if fieldType != topField.Type() {
			return false
		}

		if fieldType == timeType {

			t := field.Interface().(time.Time)
			fieldTime := topField.Interface().(time.Time)

			return fieldTime.Equal(t)
		}
	}

	// default reflect.String:
	return topField.String() == field.String()
}
source: func toStatus(err error) error {
	switch {
	case err == mapper.ErrNoSuchJob:
		return status.Errorf(codes.NotFound, "no such mapping job")
	case transient.Tag.In(err):
		return status.Errorf(codes.Internal, err.Error())
	case err != nil:
		return status.Errorf(codes.InvalidArgument, err.Error())
	default:
		return nil
	}
}
source: func uuid() string {
	f, _ := os.Open(randomSource)
	defer f.Close()
	b := make([]byte, 16)
	f.Read(b)
	return fmt.Sprintf("%x-%x-%x-%x-%x", b[0:4], b[4:6], b[6:8], b[8:10], b[10:])
}
source: func formatArgs(args ...interface{}) []string {
	formatted := make([]string, 0, len(args))
	for _, a := range args {
		s := colorize(pretty.Sprint(a), cyan)
		formatted = append(formatted, s)
	}
	return formatted
}
source: func (s *SyncedSet) Del(datas ...interface{}) {
	s.Lock()
	defer s.Unlock()
	for _, data := range datas {
		delete(s.set, data)
	}
}
source: func OAuth2ClientCredentials(clientID, clientSecret, tokenURL string) registry.Option {
	return func(o *registry.Options) {
		c := clientcredentials.Config{
			ClientID:     clientID,
			ClientSecret: clientSecret,
			TokenURL:     tokenURL,
		}

		o.Context = context.WithValue(o.Context, contextHttpClient{}, newOAuthClient(c))
	}
}
source: func (p *Parser) parseString() (string, error) {
	tok, pos, lit := p.ScanIgnoreWhitespace()
	if tok != STRING {
		return "", newParseError(tokstr(tok, lit), []string{"string"}, pos)
	}
	return lit, nil
}
source: func (r *Router) FilterParam(param string, filter http.HandlerFunc) {
	r.Filter(func(w http.ResponseWriter, req *http.Request) {
		c := NewContext(req)
		if len(c.Params.Get(param)) > 0 { filter(w, req) }
	})
}
source: func (s *backupBlobStorage) RemoveFile(id string) error {
	return s.storeImpl.RemoveForBucket(s.modelUUID, s.path(id))
}
source: func NewConsumerGroup(addrs []string, groupID string, config *Config) (ConsumerGroup, error) {
	client, err := NewClient(addrs, config)
	if err != nil {
		return nil, err
	}

	c, err := newConsumerGroup(groupID, client)
	if err != nil {
		_ = client.Close()
	}
	return c, err
}
source: func (r *Reader) ReadByte() (byte, error) {
	for r.buffered() < 1 && r.state == nil {
		r.more()
	}
	if r.buffered() < 1 {
		return 0, r.err()
	}
	b := r.data[r.n]
	r.n++
	return b, nil
}
source: func (m *MockIndex) ForeignThree(arg0 imp3.Imp3) {
	m.ctrl.T.Helper()
	m.ctrl.Call(m, "ForeignThree", arg0)
}
source: func inCollectionOp(key string, ids ...string) bson.D {
	ret := bson.D{}
	switch len(ids) {
	case 0:
	case 1:
		ret = append(ret, bson.DocElem{key, ids[0]})
	default:
		ret = append(ret, bson.DocElem{key, bson.D{{"$in", ids}}})
	}
	return ret
}
source: func (c *counters) ResetAll() {
	c.mu.Lock()
	defer c.mu.Unlock()
	c.counts = make(map[string]*int64)
}
source: func (n *NameProvider) GetJSONNames(subject interface{}) []string {
	n.lock.Lock()
	defer n.lock.Unlock()
	tpe := reflect.Indirect(reflect.ValueOf(subject)).Type()
	names, ok := n.index[tpe]
	if !ok {
		names = n.makeNameIndex(tpe)
	}

	res := make([]string, 0, len(names.jsonNames))
	for k := range names.jsonNames {
		res = append(res, k)
	}
	return res
}
source: func StringVar(flagVar *string, short string, long string, value string, usage string) *string {
	flag.StringVar(flagVar, short, value, usage)
	flag.StringVar(flagVar, long, value, usage)
	addKeyDescription(short, long, value, usage)
	return flagVar
}
source: func NewSecrets(s PublicSecrets) (Secrets, error) {
	switch s.SecretsType() {
	case PKICompactType:
		t := s.(*CompactPKIPublicSecrets)
		return NewCompactPKIWithTokenCA(t.Key, t.Certificate, t.CA, t.TokenCAs, t.Token, t.Compressed)
	default:
		return nil, fmt.Errorf("Unsupported type")
	}
}
source: func (c Client) GetObjectWithContext(ctx context.Context, bucketName, objectName string, opts GetObjectOptions) (*Object, error) {
	return c.getObjectWithContext(ctx, bucketName, objectName, opts)
}
source: func NewDiscoverer(config *common.RuntimeConfig, cleanupTracker *deleter.CleanupStatusTracker) (*Discoverer, error) {
	sharedInformer := config.InformerFactory.Storage().V1().StorageClasses()
	sharedInformer.Informer().AddEventHandler(cache.ResourceEventHandlerFuncs{
		// We don't need an actual event handler for StorageClasses,
		// but we must pass a non-nil one to cache.NewInformer()
		AddFunc:    nil,
		UpdateFunc: nil,
		DeleteFunc: nil,
	})

	labelMap := make(map[string]string)
	for _, labelName := range config.NodeLabelsForPV {
		labelVal, ok := config.Node.Labels[labelName]
		if ok {
			labelMap[labelName] = labelVal
		}
	}

	if config.UseAlphaAPI {
		nodeAffinity, err := generateNodeAffinity(config.Node)
		if err != nil {
			return nil, fmt.Errorf("Failed to generate node affinity: %v", err)
		}
		tmpAnnotations := map[string]string{}
		err = StorageNodeAffinityToAlphaAnnotation(tmpAnnotations, nodeAffinity)
		if err != nil {
			return nil, fmt.Errorf("Failed to convert node affinity to alpha annotation: %v", err)
		}
		return &Discoverer{
			RuntimeConfig:   config,
			Labels:          labelMap,
			CleanupTracker:  cleanupTracker,
			classLister:     sharedInformer.Lister(),
			nodeAffinityAnn: tmpAnnotations[common.AlphaStorageNodeAffinityAnnotation]}, nil
	}

	volumeNodeAffinity, err := generateVolumeNodeAffinity(config.Node)
	if err != nil {
		return nil, fmt.Errorf("Failed to generate volume node affinity: %v", err)
	}

	return &Discoverer{
		RuntimeConfig:  config,
		Labels:         labelMap,
		CleanupTracker: cleanupTracker,
		classLister:    sharedInformer.Lister(),
		nodeAffinity:   volumeNodeAffinity}, nil
}
source: func (c *StatsdClient) FGaugeWithSampling(stat string, value float64, sampleRate float32) error {
	if err := checkSampleRate(sampleRate); err != nil {
		return err
	}

	if !shouldFire(sampleRate) {
		return nil
	}

	if value < 0 {
		err := c.send(stat, "%d|g", 0, 1)
		if nil != err {
			return err
		}
	}

	return c.send(stat, "%g|g", value, sampleRate)
}
source: func SubStepsToUI(c context.Context, ub URLBuilder, substeps []*miloProto.Step_Substep) ([]*ui.BuildComponent, []*ui.PropertyGroup) {
	components := make([]*ui.BuildComponent, 0, len(substeps))
	propGroups := make([]*ui.PropertyGroup, 0, len(substeps)+1) // This is the max number or property groups.
	for _, substepContainer := range substeps {
		anno := substepContainer.GetStep()
		if anno == nil {
			// TODO: We ignore non-embedded substeps for now.
			continue
		}

		bs := miloBuildStep(c, ub, anno, true)
		components = append(components, &bs)
		addPropGroups(&propGroups, &bs, anno)
	}

	return components, propGroups
}
source: func (mat *T) AssignOrthogonalProjection(left, right, bottom, top, znear, zfar float32) *T {
	ooRightLeft := 1 / (right - left)
	ooTopBottom := 1 / (top - bottom)
	ooFarNear := 1 / (zfar - znear)

	mat[0][0] = 2 * ooRightLeft
	mat[1][0] = 0
	mat[2][0] = 0
	mat[3][0] = -(right + left) * ooRightLeft

	mat[0][1] = 0
	mat[1][1] = 2 * ooTopBottom
	mat[2][1] = 0
	mat[3][1] = -(top + bottom) * ooTopBottom

	mat[0][2] = 0
	mat[1][2] = 0
	mat[2][2] = -2 * ooFarNear
	mat[3][2] = -(zfar + znear) * ooFarNear

	mat[0][3] = 0
	mat[1][3] = 0
	mat[2][3] = 0
	mat[3][3] = 1

	return mat
}
source: func (a *DetachFromTargetArgs) SetSessionID(sessionID SessionID) *DetachFromTargetArgs {
	a.SessionID = &sessionID
	return a
}
source: func TempoEvent(bpmF float64) *Event {
	ms := uint32(60000000 / bpmF)

	// bpm is expressed in in microseconds per MIDI quarter-note
	// This event indicates a tempo change.  Another way of putting
	// "microseconds per quarter-note" is "24ths of a microsecond per MIDI
	// clock".  Representing tempos as time per beat instead of beat per time
	// allows absolutely exact dword-term synchronization with a time-based sync
	// protocol such as SMPTE time code or MIDI time code.  This amount of
	// accuracy provided by this tempo resolution allows a four-minute piece at
	// 120 beats per minute to be accurate within 500 usec at the end of the
	// piece.  Ideally, these events should only occur where MIDI clocks would
	// be located Q this convention is intended to guarantee, or at least
	// increase the likelihood, of compatibility with other synchronization
	// devices so that a time signature/tempo map stored in this format may
	// easily be transferred to another device.
	return &Event{
		MsgType:        uint8(EventByteMap["Meta"]),
		Cmd:            uint8(MetaByteMap["Tempo"]),
		MsPerQuartNote: ms,
	}
}
source: func (cs Set) Ref() string {
	domain, _, ref := cs.Split()
	if domain == "projects" {
		return ref
	}
	return ""
}
source: func (s *KinesisFirehoseDestination) SetIAMRoleARN(v string) *KinesisFirehoseDestination {
	s.IAMRoleARN = &v
	return s
}
source: func AddFlashObj(overseer Overseer, w http.ResponseWriter, r *http.Request, key string, value interface{}) error {
	mv, err := json.Marshal(value)
	if err != nil {
		return errors.Wrap(err, "unable to marshal flash value")
	}

	return AddFlash(overseer, w, r, key, string(mv))
}
source: func JoystickGetDeviceProduct(index int) int {
	return int(C.SDL_JoystickGetDeviceProduct(C.int(index)))
}
source: func (s *StreamFramer) Destroy() {
	s.l.Lock()

	wasShutdown := s.shutdown
	s.shutdown = true

	if !wasShutdown {
		close(s.shutdownCh)
	}

	s.heartbeat.Stop()
	s.flusher.Stop()
	running := s.running
	s.l.Unlock()

	// Ensure things were flushed
	if running {
		<-s.exitCh
	}

	// Close out chan only after exitCh has exited
	if !wasShutdown {
		close(s.out)
	}
}
source: func (p *Ping) Decode(r io.Reader, pver uint32) error {
	return ReadElements(r,
		&p.NumPongBytes,
		&p.PaddingBytes)
}
source: func MustParseSupportedVersions(s string) SupportedVersions {
	versions, err := ParseSupportedVersions(s)
	if err != nil {
		panic(err)
	}
	return versions
}
source: func (hook *GraylogHook) Fire(entry *logrus.Entry) error {
	hook.mu.RLock() // Claim the mutex as a RLock - allowing multiple go routines to log simultaneously
	defer hook.mu.RUnlock()

	var file string
	var line int

	if entry.Caller != nil {
		file = entry.Caller.File
		line = entry.Caller.Line
	}

	newData := make(map[string]interface{})
	for k, v := range entry.Data {
		newData[k] = v
	}

	newEntry := &logrus.Entry{
		Logger:  entry.Logger,
		Data:    newData,
		Time:    entry.Time,
		Level:   entry.Level,
		Caller:  entry.Caller,
		Message: entry.Message,
	}
	gEntry := graylogEntry{newEntry, file, line}

	if hook.synchronous {
		hook.sendEntry(gEntry)
	} else {
		hook.wg.Add(1)
		hook.buf <- gEntry
	}

	return nil
}
source: func (s *DomainName) SetDistributionDomainName(v string) *DomainName {
	s.DistributionDomainName = &v
	return s
}
source: func (pk *PublicKey) CanSign() bool {
	return pk.PubKeyAlgo != PubKeyAlgoRSAEncryptOnly && pk.PubKeyAlgo != PubKeyAlgoElGamal
}
source: func StringShrinker(v interface{}) gopter.Shrink {
	return runeSliceShrinker([]rune(v.(string))).Map(runesToString)
}
source: func (b *batchChecker) getOldRow(ctx sessionctx.Context, t table.Table, handle int64) ([]types.Datum, error) {
	oldValue, ok := b.dupOldRowValues[string(t.RecordKey(handle))]
	if !ok {
		return nil, errors.NotFoundf("can not be duplicated row, due to old row not found. handle %d", handle)
	}
	cols := t.WritableCols()
	oldRow, oldRowMap, err := tables.DecodeRawRowData(ctx, t.Meta(), handle, cols, oldValue)
	if err != nil {
		return nil, err
	}
	// Fill write-only and write-reorg columns with originDefaultValue if not found in oldValue.
	for _, col := range cols {
		if col.State != model.StatePublic && oldRow[col.Offset].IsNull() {
			_, found := oldRowMap[col.ID]
			if !found {
				oldRow[col.Offset], err = table.GetColOriginDefaultValue(ctx, col.ToInfo())
				if err != nil {
					return nil, err
				}
			}
		}
	}
	return oldRow, nil
}
source: func (c Cap) IsValid() bool {
	return c.center.Vector.IsUnit() && c.radius <= s1.StraightChordAngle
}
source: func (t *Tree) String() string {
	t.mutex.RLock()
	defer t.mutex.RUnlock()

	return fmt.Sprintf("topic.Tree:%s", t.root.string(0))
}
source: func NewOCFBDecrypter(block cipher.Block, prefix []byte, resync OCFBResyncOption) cipher.Stream {
	blockSize := block.BlockSize()
	if len(prefix) != blockSize+2 {
		return nil
	}

	x := &ocfbDecrypter{
		b:       block,
		fre:     make([]byte, blockSize),
		outUsed: 0,
	}
	prefixCopy := make([]byte, len(prefix))
	copy(prefixCopy, prefix)

	block.Encrypt(x.fre, x.fre)
	for i := 0; i < blockSize; i++ {
		prefixCopy[i] ^= x.fre[i]
	}

	block.Encrypt(x.fre, prefix[:blockSize])
	prefixCopy[blockSize] ^= x.fre[0]
	prefixCopy[blockSize+1] ^= x.fre[1]

	if prefixCopy[blockSize-2] != prefixCopy[blockSize] ||
		prefixCopy[blockSize-1] != prefixCopy[blockSize+1] {
		return nil
	}

	if resync {
		block.Encrypt(x.fre, prefix[2:])
	} else {
		x.fre[0] = prefix[blockSize]
		x.fre[1] = prefix[blockSize+1]
		x.outUsed = 2
	}
	copy(prefix, prefixCopy)
	return x
}
source: func FromBase64(v []byte) (Buffer, error) {
	b := Buffer{}
	if err := b.Base64Decode(v); err != nil {
		return Buffer(nil), errors.Wrap(err, "failed to decode from base64")
	}

	return b, nil
}
source: func (c *Client) AddCloud(cloud jujucloud.Cloud) error {
	bestVer := c.BestAPIVersion()
	if bestVer < 2 {
		return errors.NotImplementedf("AddCloud() (need v2+, have v%d)", bestVer)
	}
	if (len(cloud.Config) > 0 || len(cloud.RegionConfig) > 0) && bestVer < 5 {
		return errors.New("adding a cloud with config parameters is not supported by this version of Juju")
	}
	args := params.AddCloudArgs{Name: cloud.Name, Cloud: common.CloudToParams(cloud)}
	err := c.facade.FacadeCall("AddCloud", args, nil)
	if err != nil {
		return errors.Trace(err)
	}
	return nil
}
source: func AddChecksums(inputs []Trytes, isAddress bool, checksumLength uint64) ([]Trytes, error) {
	withChecksums := make([]Trytes, len(inputs))
	for i, s := range inputs {
		t, err := AddChecksum(s, isAddress, checksumLength)
		if err != nil {
			return nil, err
		}
		withChecksums[i] = t
	}
	return withChecksums, nil
}
source: func (s *precheckShim) IsMigrationActive(modelUUID string) (bool, error) {
	return state.IsMigrationActive(s.State, modelUUID)
}
source: func Unquote(str string) string {
	if len(str) < 2 {
		return str
	}
	for _, quote := range []string{`'`, `"`} {
		if str[0:1] == quote && str[len(str)-1:] == quote {
			return strings.Trim(str, quote)
		}
	}
	return str
}
source: func (o *Organizations) Get(ctx context.Context, query chronograf.OrganizationQuery) (*chronograf.Organization, error) {
	org, _, err := o.findOrg(query)
	return org, err
}
source: func (b BlockServerMeasured) IsUnflushed(ctx context.Context, tlfID tlf.ID,
	id kbfsblock.ID) (isUnflushed bool, err error) {
	b.isUnflushedTimer.Time(func() {
		isUnflushed, err = b.delegate.IsUnflushed(ctx, tlfID, id)
	})
	return isUnflushed, err

}
source: func (f *File) adjustColDimensions(xlsx *xlsxWorksheet, col, offset int) {
	for rowIdx := range xlsx.SheetData.Row {
		for colIdx, v := range xlsx.SheetData.Row[rowIdx].C {
			cellCol, cellRow, _ := CellNameToCoordinates(v.R)
			if col <= cellCol {
				if newCol := cellCol + offset; newCol > 0 {
					xlsx.SheetData.Row[rowIdx].C[colIdx].R, _ = CoordinatesToCellName(newCol, cellRow)
				}
			}
		}
	}
}
source: func (t ListType) SetDefaultValue(v interface{}) (FieldType, error) {
	if v == nil {
		t.DefaultValue = nil
		return t, nil
	}
	defVal, err := t.ComponentType.ConvertToModel(v)
	if err != nil {
		return nil, errs.Wrapf(err, "failed to set default value of list type to %+v (%[1]T)", v)
	}
	t.DefaultValue = defVal
	return t, nil
}
source: func Convert_v1beta2_DeploymentStatus_To_apps_DeploymentStatus(in *v1beta2.DeploymentStatus, out *apps.DeploymentStatus, s conversion.Scope) error {
	return autoConvert_v1beta2_DeploymentStatus_To_apps_DeploymentStatus(in, out, s)
}
source: func (s *Service) SetEdges(v []*Edge) *Service {
	s.Edges = v
	return s
}
source: func (c *Context) Report(err error, data Data) error {
	if rErr, ok := err.(reportableError); ok {
		if rErr.Reportable() == false {
			return nil
		}
	}

	dataMaps := make([]Data, 1, 3)
	dataMaps[0] = c.Data()
	if gErr, ok := err.(grohlError); ok {
		if errData := gErr.Data(); errData != nil {
			dataMaps = append(dataMaps, errData)
		}
	}

	if data != nil {
		dataMaps = append(dataMaps, data)
	}

	merged := dupeMaps(dataMaps...)
	errorToMap(err, merged)

	if c.ErrorReporter != nil {
		return c.ErrorReporter.Report(err, merged)
	} else {
		var logErr error
		logErr = c.log(merged)
		if logErr != nil {
			return logErr
		}

		for _, line := range ErrorBacktraceLines(err) {
			lineData := dupeMaps(merged)
			lineData["site"] = line
			logErr = c.log(lineData)
			if logErr != nil {
				return logErr
			}
		}
		return nil
	}
}
source: func IsChaincodeDeployed(chainid, ccName, ccVersion string, ccHash []byte, sccp sysccprovider.SystemChaincodeProvider) (bool, error) {
	qe, err := sccp.GetQueryExecutorForLedger(chainid)
	if err != nil {
		return false, fmt.Errorf("Could not retrieve QueryExecutor for channel %s, error %s", chainid, err)
	}
	defer qe.Done()

	// XXX We are leaking details of the LSCC table structure to other parts of the code, and this is terrible
	chaincodeDataBytes, err := qe.GetState("lscc", ccName)
	if err != nil {
		return false, fmt.Errorf("Could not retrieve state for chaincode %s on channel %s, error %s", ccName, chainid, err)
	}

	if chaincodeDataBytes == nil {
		return false, nil
	}

	chaincodeData := &ChaincodeData{}
	err = proto.Unmarshal(chaincodeDataBytes, chaincodeData)
	if err != nil {
		return false, fmt.Errorf("Unmarshalling ChaincodeQueryResponse failed, error %s", err)
	}
	return chaincodeData.CCVersion() == ccVersion && bytes.Equal(chaincodeData.Hash(), ccHash), nil
}
source: func (w *QWriter) U(s string) {
	bb, ok := w.w.(*ByteBuffer)
	if ok {
		bb.B = appendURLEncode(bb.B, s)
	} else {
		w.b = appendURLEncode(w.b[:0], s)
		w.Write(w.b)
	}
}
source: func NewDefaultClientWithTimeout(timeout time.Duration) (*Client, error) {
	timeoutAfter := time.After(timeout)
	var c *Client
	var err error
	for {
		select {
		case <-timeoutAfter:
			return nil, fmt.Errorf("failed to create cilium agent client after %f seconds timeout: %s", timeout.Seconds(), err)
		default:
		}

		c, err = NewDefaultClient()
		if err != nil {
			time.Sleep(500 * time.Millisecond)
			continue
		}

		for {
			select {
			case <-timeoutAfter:
				return nil, fmt.Errorf("failed to create cilium agent client after %f seconds timeout: %s", timeout.Seconds(), err)
			default:
			}
			// This is an API call that we do to the cilium-agent to check
			// if it is up and running.
			_, err = c.Daemon.GetConfig(nil)
			if err != nil {
				time.Sleep(500 * time.Millisecond)
				continue
			}
			return c, nil
		}
	}
}
source: func (uuid UUID) Variant() Variant {
	if len(uuid) != 16 {
		return Invalid
	}
	switch {
	case (uuid[8] & 0xc0) == 0x80:
		return RFC4122
	case (uuid[8] & 0xe0) == 0xc0:
		return Microsoft
	case (uuid[8] & 0xe0) == 0xe0:
		return Future
	default:
		return Reserved
	}
}
source: func (r Response) StatusCode() int {
	if 0 == r.statusCode {
		// no status code has been written yet; assume OK
		return http.StatusOK
	}
	return r.statusCode
}
source: func underlyingPtrType(val interface{}) (interface{}, bool) {
	refVal := reflect.ValueOf(val)

	switch refVal.Kind() {
	case reflect.Ptr:
		if refVal.IsNil() {
			return nil, false
		}
		convVal := refVal.Elem().Interface()
		return convVal, true
	}

	return nil, false
}
source: func (vm *Engine) disasm(scriptIdx int, scriptOff int) string {
	return fmt.Sprintf("%02x:%04x: %s", scriptIdx, scriptOff,
		vm.scripts[scriptIdx][scriptOff].print(false))
}
source: func (state *UserState) ConfirmationCode(username string) (string, error) {
	return state.users.Get(username, "confirmationCode")
}
source: func InitRedisConn(conn goetty.IOSession) {
	conn.SetAttr(lenScratch, make([]byte, 32, 32))
	conn.SetAttr(numScratch, make([]byte, 40, 40))
}
source: func addAll(dir, rootDir string, includeCurrentFolder bool, writerFunc ArchiveWriteFunc) error {
	// Get a list of all entries in the directory, as []os.FileInfo
	fileInfos, err := ioutil.ReadDir(dir)
	if err != nil {
		return err
	}

	// Loop through all entries
	for _, info := range fileInfos {
		full := filepath.Join(dir, info.Name())

		// If the entry is a file, get an io.Reader for it
		var file *os.File
		var reader io.Reader
		if !info.IsDir() {
			file, err = os.Open(full)
			if err != nil {
				return err
			}
			reader = file
		}

		// Write the entry into the archive
		subDir := getSubDir(dir, rootDir, includeCurrentFolder)
		entryName := path.Join(subDir, info.Name())
		if err := writerFunc(info, reader, entryName); err != nil {
			if file != nil {
				file.Close()
			}
			return err
		}

		if file != nil {
			if err := file.Close(); err != nil {
				return err
			}
		}

		// If the entry is a directory, recurse into it
		if info.IsDir() {
			addAll(full, rootDir, includeCurrentFolder, writerFunc)
		}
	}
	return nil
}
source: func (c *Callbacks) OnCDemoConsoleCmd(fn func(*dota.CDemoConsoleCmd) error) {
	c.onCDemoConsoleCmd = append(c.onCDemoConsoleCmd, fn)
}
source: func NewOvsSwitch(bridgeName, netType, localIP, fwdMode string,
	vlanIntf []string, hostPvtNW int, vxlanUDPPort int) (*OvsSwitch, error) {
	var err error
	var datapath string
	var ofnetPort, ctrlrPort uint16
	log.Infof("Received request to create new ovs switch bridge:%s, localIP:%s, fwdMode:%s", bridgeName, localIP, fwdMode)
	sw := new(OvsSwitch)
	sw.bridgeName = bridgeName
	sw.netType = netType
	sw.uplinkDb = cmap.New()
	sw.hostPvtNW = hostPvtNW
	sw.vxlanEncapMtu, err = netutils.GetHostLowestLinkMtu()
	if err != nil {
		log.Fatalf("Failed to get Host Node MTU. Err: %v", err)
	}

	// Create OVS db driver
	sw.ovsdbDriver, err = NewOvsdbDriver(bridgeName, "secure", vxlanUDPPort)
	if err != nil {
		log.Fatalf("Error creating ovsdb driver. Err: %v", err)
	}

	sw.ovsdbDriver.ovsSwitch = sw

	if netType == "vxlan" {
		ofnetPort = vxlanOfnetPort
		ctrlrPort = vxlanCtrlerPort
		switch fwdMode {
		case "bridge":
			datapath = "vxlan"
		case "routing":
			datapath = "vrouter"
		default:
			log.Errorf("Invalid datapath mode")
			return nil, errors.New("invalid forwarding mode. Expects 'bridge' or 'routing'")
		}
		// Create an ofnet agent
		sw.ofnetAgent, err = ofnet.NewOfnetAgent(bridgeName, datapath, net.ParseIP(localIP),
			ofnetPort, ctrlrPort, vlanIntf)

		if err != nil {
			log.Fatalf("Error initializing ofnet")
			return nil, err
		}

	} else if netType == "vlan" {
		ofnetPort = vlanOfnetPort
		ctrlrPort = vlanCtrlerPort
		switch fwdMode {
		case "bridge":
			datapath = "vlan"
		case "routing":
			datapath = "vlrouter"
		default:
			log.Errorf("Invalid datapath mode")
			return nil, errors.New("invalid forwarding mode. Expects 'bridge' or 'routing'")
		}
		// Create an ofnet agent
		sw.ofnetAgent, err = ofnet.NewOfnetAgent(bridgeName, datapath, net.ParseIP(localIP),
			ofnetPort, ctrlrPort, vlanIntf)

		if err != nil {
			log.Fatalf("Error initializing ofnet")
			return nil, err
		}

	} else if netType == "host" {
		err = fmt.Errorf("Explicit host-net not supported")
		return nil, err
	}

	// Add controller to the OVS
	ctrlerIP := "127.0.0.1"
	target := fmt.Sprintf("tcp:%s:%d", ctrlerIP, ctrlrPort)
	if !sw.ovsdbDriver.IsControllerPresent(target) {
		err = sw.ovsdbDriver.AddController(ctrlerIP, ctrlrPort)
		if err != nil {
			log.Errorf("Error adding controller to switch: %s. Err: %v", bridgeName, err)
			return nil, err
		}
	}

	log.Infof("Waiting for OVS switch(%s) to connect..", netType)

	// Wait for a while for OVS switch to connect to agent
	if sw.ofnetAgent != nil {
		sw.ofnetAgent.WaitForSwitchConnection()
	}

	log.Infof("Switch (%s) connected.", netType)

	return sw, nil
}
source: func NewBlockMeta(block *Block, blockParts *PartSet) *BlockMeta {
	return &BlockMeta{
		BlockID: BlockID{block.Hash(), blockParts.Header()},
		Header:  block.Header,
	}
}
source: func (vm *Machine) Info() (minx, miny, minz, maxx, maxy, maxz float64, feedrates []float64) {
	for _, pos := range vm.Positions {
		if pos.X < minx {
			minx = pos.X
		} else if pos.X > maxx {
			maxx = pos.X
		}

		if pos.Y < miny {
			miny = pos.Y
		} else if pos.Y > maxy {
			maxy = pos.Y
		}

		if pos.Z < minz {
			minz = pos.Z
		} else if pos.Z > maxz {
			maxz = pos.Z
		}

		feedrateFound := false
		for _, feed := range feedrates {
			if feed == pos.State.Feedrate {
				feedrateFound = true
				break
			}
		}
		if !feedrateFound {
			feedrates = append(feedrates, pos.State.Feedrate)
		}
	}
	return
}
source: func (c *Client) RevokeCloud(user, access string, clouds ...string) error {
	if bestVer := c.BestAPIVersion(); bestVer < 3 {
		return errors.NotImplementedf("RevokeCloud() (need v3+, have v%d)", bestVer)
	}
	return c.modifyCloudUser(params.RevokeCloudAccess, user, access, clouds)
}
source: func (r *Request) ErrorMessage(rcode int) *dns.Msg {
	m := new(dns.Msg)
	m.SetRcode(r.Req, rcode)
	return m
}
source: func OpenTowerDB(dbPath string) (*TowerDB, error) {
	path := filepath.Join(dbPath, dbName)

	// If the database file doesn't exist, this indicates we much initialize
	// a fresh database with the latest version.
	firstInit := !fileExists(path)
	if firstInit {
		// Ensure all parent directories are initialized.
		err := os.MkdirAll(dbPath, 0700)
		if err != nil {
			return nil, err
		}
	}

	bdb, err := bbolt.Open(path, dbFilePermission, nil)
	if err != nil {
		return nil, err
	}

	// If the file existed previously, we'll now check to see that the
	// metadata bucket is properly initialized. It could be the case that
	// the database was created, but we failed to actually populate any
	// metadata. If the metadata bucket does not actually exist, we'll
	// set firstInit to true so that we can treat is initialize the bucket.
	if !firstInit {
		var metadataExists bool
		err = bdb.View(func(tx *bbolt.Tx) error {
			metadataExists = tx.Bucket(metadataBkt) != nil
			return nil
		})
		if err != nil {
			return nil, err
		}

		if !metadataExists {
			firstInit = true
		}
	}

	towerDB := &TowerDB{
		db:     bdb,
		dbPath: dbPath,
	}

	if firstInit {
		// If the database has not yet been created, we'll initialize
		// the database version with the latest known version.
		err = towerDB.db.Update(func(tx *bbolt.Tx) error {
			return initDBVersion(tx, getLatestDBVersion(dbVersions))
		})
		if err != nil {
			bdb.Close()
			return nil, err
		}
	} else {
		// Otherwise, ensure that any migrations are applied to ensure
		// the data is in the format expected by the latest version.
		err = towerDB.syncVersions(dbVersions)
		if err != nil {
			bdb.Close()
			return nil, err
		}
	}

	// Now that the database version fully consistent with our latest known
	// version, ensure that all top-level buckets known to this version are
	// initialized. This allows us to assume their presence throughout all
	// operations. If an known top-level bucket is expected to exist but is
	// missing, this will trigger a ErrUninitializedDB error.
	err = towerDB.db.Update(initTowerDBBuckets)
	if err != nil {
		bdb.Close()
		return nil, err
	}

	return towerDB, nil
}
source: func NewBucket() *Bucket {
	bkt := new(Bucket)

	bkt.Weight = 0
	bkt.pad = make([]byte, 4)
	bkt.Actions = make([]Action, 0)
	bkt.WatchPort = P_ANY
	bkt.WatchGroup = OFPG_ANY
	bkt.Length = bkt.Len()

	return bkt
}
source: func (t Text) Render(w io.Writer, v interface{}) error {
	if hw, ok := w.(http.ResponseWriter); ok {
		c := hw.Header().Get(ContentType)
		if c != "" {
			t.Head.ContentType = c
		}
		t.Head.Write(hw)
	}

	w.Write([]byte(v.(string)))
	return nil
}
source: func ServeConn(block BlockCrypt, dataShards, parityShards int, conn net.PacketConn) (*Listener, error) {
	l := new(Listener)
	l.conn = conn
	l.sessions = make(map[string]*UDPSession)
	l.chAccepts = make(chan *UDPSession, acceptBacklog)
	l.chSessionClosed = make(chan net.Addr)
	l.die = make(chan struct{})
	l.dataShards = dataShards
	l.parityShards = parityShards
	l.block = block
	l.fecDecoder = newFECDecoder(rxFECMulti*(dataShards+parityShards), dataShards, parityShards)

	// calculate header size
	if l.block != nil {
		l.headerSize += cryptHeaderSize
	}
	if l.fecDecoder != nil {
		l.headerSize += fecHeaderSizePlus2
	}

	go l.monitor()
	return l, nil
}
source: func (s *Store) LeaderCh() <-chan bool {
	if s.raft == nil {
		ch := make(chan bool, 1)
		ch <- true
		return ch
	}
	return s.leaderCh
}
source: func WithGitInit(ctx context.Context, bv bool) context.Context {
	return context.WithValue(ctx, ctxKeyGitInit, bv)
}
source: func CharmArchiveEntry(charmPath, entryPath string, wantIcon bool) ([]byte, error) {
	// TODO(fwereade) 2014-01-27 bug #1285685
	// This doesn't handle symlinks helpfully, and should be talking in
	// terms of bundles rather than zip readers; but this demands thought
	// and design and is not amenable to a quick fix.
	zipReader, err := zip.OpenReader(charmPath)
	if err != nil {
		return nil, errors.Annotatef(err, "unable to read charm")
	}
	defer zipReader.Close()
	for _, file := range zipReader.File {
		if path.Clean(file.Name) != entryPath {
			continue
		}
		fileInfo := file.FileInfo()
		if fileInfo.IsDir() {
			return nil, &params.Error{
				Message: "directory listing not allowed",
				Code:    params.CodeForbidden,
			}
		}
		contents, err := file.Open()
		if err != nil {
			return nil, errors.Annotatef(err, "unable to read file %q", entryPath)
		}
		defer contents.Close()
		return ioutil.ReadAll(contents)
	}
	if wantIcon {
		// An icon was requested but none was found in the archive so
		// return the default icon instead.
		return []byte(DefaultCharmIcon), nil
	}
	return nil, errors.NotFoundf("charm file")
}
source: func (s *LoadBalancerService) RemoveFromGlobalLoadBalancerRule(p *RemoveFromGlobalLoadBalancerRuleParams) (*RemoveFromGlobalLoadBalancerRuleResponse, error) {
	resp, err := s.cs.newRequest("removeFromGlobalLoadBalancerRule", p.toURLValues())
	if err != nil {
		return nil, err
	}

	var r RemoveFromGlobalLoadBalancerRuleResponse
	if err := json.Unmarshal(resp, &r); err != nil {
		return nil, err
	}

	// If we have a async client, we need to wait for the async result
	if s.cs.async {
		b, err := s.cs.GetAsyncJobResult(r.JobID, s.cs.timeout)
		if err != nil {
			if err == AsyncTimeoutErr {
				return &r, err
			}
			return nil, err
		}

		if err := json.Unmarshal(b, &r); err != nil {
			return nil, err
		}
	}

	return &r, nil
}
source: func GetPlayerByID(ID uint) (*Player, error) {
	player := &Player{}

	if err := db.DB.First(player, ID).Error; err != nil {
		return nil, err
	}

	return player, nil
}
source: func QuotaPredictor(factory ApiClientFactory) complete.Predictor {
	return complete.PredictFunc(func(a complete.Args) []string {
		client, err := factory()
		if err != nil {
			return nil
		}

		resp, _, err := client.Search().PrefixSearch(a.Last, contexts.Quotas, nil)
		if err != nil {
			return []string{}
		}
		return resp.Matches[contexts.Quotas]
	})
}
source: func (o *AcceptLogoutRequestParams) WithHTTPClient(client *http.Client) *AcceptLogoutRequestParams {
	o.SetHTTPClient(client)
	return o
}
source: func NewEnvClient() (storageops.Ops, error) {
	region, err := storageops.GetEnvValueStrict("AWS_REGION")
	if err != nil {
		return nil, err
	}

	instance, err := storageops.GetEnvValueStrict("AWS_INSTANCE_NAME")
	if err != nil {
		return nil, err
	}

	instanceType, err := storageops.GetEnvValueStrict("AWS_INSTANCE_TYPE")
	if err != nil {
		return nil, err
	}

	if _, err := credentials.NewEnvCredentials().Get(); err != nil {
		return nil, ErrAWSEnvNotAvailable
	}

	ec2 := ec2.New(
		session.New(
			&aws.Config{
				Region:      &region,
				Credentials: credentials.NewEnvCredentials(),
			},
		),
	)

	return NewEc2Storage(instance, instanceType, ec2), nil
}
source: func (s *DownloadDBLogFilePortionInput) SetNumberOfLines(v int64) *DownloadDBLogFilePortionInput {
	s.NumberOfLines = &v
	return s
}
source: func (_class SecretClass) Destroy(sessionID SessionRef, self SecretRef) (_err error) {
	_method := "secret.destroy"
	_sessionIDArg, _err := convertSessionRefToXen(fmt.Sprintf("%s(%s)", _method, "session_id"), sessionID)
	if _err != nil {
		return
	}
	_selfArg, _err := convertSecretRefToXen(fmt.Sprintf("%s(%s)", _method, "self"), self)
	if _err != nil {
		return
	}
	_, _err =  _class.client.APICall(_method, _sessionIDArg, _selfArg)
	return
}
source: func (heap *FloatingFibonacciHeap) Min() (*Entry, error) {
	if heap.IsEmpty() {
		return nil, EmptyHeapError("Trying to get minimum element of empty heap")
	}
	return heap.min, nil
}
source: func Serve(l net.PacketConn, handler Handler) error {
	srv := Server{
		Handler:         handler,
		MaxMessageBytes: DefaultMaxMessageBytes,
	}
	return srv.Serve(l)
}
source: func RestartBee(bee *BeeInterface) {
	(*bee).Stop()

	(*bee).SetSigChan(make(chan bool))
	(*bee).Start()
	go func(mod *BeeInterface) {
		startBee(mod, 0)
	}(bee)
}
source: func (r RepoLogger) SetRepoLogLevel(l LogLevel) {
	logger.Lock()
	defer logger.Unlock()
	r.setRepoLogLevelInternal(l)
}
source: func (c oauthClient) Reminder(reminderID uint) (wl.Reminder, error) {
	url := fmt.Sprintf(
		"%s/reminders/%d",
		c.apiURL,
		reminderID,
	)

	req, err := c.newGetRequest(url)
	if err != nil {
		return wl.Reminder{}, err
	}

	resp, err := c.do(req)
	if err != nil {
		return wl.Reminder{}, err
	}

	if resp.StatusCode != http.StatusOK {
		return wl.Reminder{}, fmt.Errorf("Unexpected response code %d - expected %d", resp.StatusCode, http.StatusOK)
	}

	reminder := wl.Reminder{}
	err = json.NewDecoder(resp.Body).Decode(&reminder)
	if err != nil {
		return wl.Reminder{}, err
	}
	return reminder, nil
}
source: func CheckEnvironmentTargetedCorrectly(targetedOrganizationRequired bool, targetedSpaceRequired bool, testOrg string, command ...string) {
	LoginCF()

	if targetedOrganizationRequired {
		By("errors if org is not targeted")
		session := CF(command...)
		Eventually(session).Should(Say("FAILED"))
		Eventually(session.Err).Should(Say("No org targeted, use 'cf target -o ORG' to target an org\\."))
		Eventually(session).Should(Exit(1))

		if targetedSpaceRequired {
			By("errors if space is not targeted")
			TargetOrg(testOrg)
			session := CF(command...)
			Eventually(session).Should(Say("FAILED"))
			Eventually(session.Err).Should(Say("No space targeted, use 'cf target -s SPACE' to target a space\\."))
			Eventually(session).Should(Exit(1))
		}
	}

	By("errors if user not logged in")
	LogoutCF()
	session := CF(command...)
	Eventually(session).Should(Say("FAILED"))
	Eventually(session.Err).Should(Say("Not logged in\\. Use 'cf login' to log in\\."))
	Eventually(session).Should(Exit(1))

	By("errors if cli not targeted")
	UnsetAPI()
	session = CF(command...)
	Eventually(session).Should(Say("FAILED"))
	Eventually(session.Err).Should(Say("No API endpoint set\\. Use 'cf login' or 'cf api' to target an endpoint\\."))
	Eventually(session).Should(Exit(1))
}
source: func (info *ImageInfoType) GobEncode() (buf []byte, err error) {
	fields := []interface{}{info.data, info.smask, info.n, info.w, info.h, info.cs,
		info.pal, info.bpc, info.f, info.dp, info.trns, info.scale, info.dpi}
	w := new(bytes.Buffer)
	encoder := gob.NewEncoder(w)
	for j := 0; j < len(fields) && err == nil; j++ {
		err = encoder.Encode(fields[j])
	}
	if err == nil {
		buf = w.Bytes()
	}
	return
}
source: func (t *TSMReader) ReadAt(entry *IndexEntry, vals []Value) ([]Value, error) {
	t.mu.RLock()
	v, err := t.accessor.readBlock(entry, vals)
	t.mu.RUnlock()
	return v, err
}
source: func (pc *PCCloud) DeleteDisk(pdID string) error {
	photonClient, err := getPhotonClient(pc)
	if err != nil {
		klog.Errorf("Photon Cloud Provider: Failed to get photon client for DeleteDisk, error: [%v]", err)
		return err
	}

	task, err := photonClient.Disks.Delete(pdID)
	if err != nil {
		klog.Errorf("Photon Cloud Provider: Failed to DeleteDisk. Error[%v]", err)
		return err
	}

	_, err = photonClient.Tasks.Wait(task.ID)
	if err != nil {
		klog.Errorf("Photon Cloud Provider: Failed to wait for task to DeleteDisk. Error[%v]", err)
		return err
	}

	return nil
}
source: func (gce *Connection) Instance(id, zone string) (Instance, error) {
	var result Instance
	raw, err := gce.raw.GetInstance(gce.projectID, zone, id)
	if err != nil {
		return result, errors.Trace(err)
	}
	result = *newInstance(raw, nil)
	return result, nil
}
source: func (e *Empire) DomainsFind(q DomainsQuery) (*Domain, error) {
	return domainsFind(e.db, q)
}
source: func extractBtcdRPCParams(btcdConfigPath string) (string, string, error) {
	// First, we'll open up the btcd configuration file found at the target
	// destination.
	btcdConfigFile, err := os.Open(btcdConfigPath)
	if err != nil {
		return "", "", err
	}
	defer btcdConfigFile.Close()

	// With the file open extract the contents of the configuration file so
	// we can attempt to locate the RPC credentials.
	configContents, err := ioutil.ReadAll(btcdConfigFile)
	if err != nil {
		return "", "", err
	}

	// Attempt to locate the RPC user using a regular expression. If we
	// don't have a match for our regular expression then we'll exit with
	// an error.
	rpcUserRegexp, err := regexp.Compile(`(?m)^\s*rpcuser\s*=\s*([^\s]+)`)
	if err != nil {
		return "", "", err
	}
	userSubmatches := rpcUserRegexp.FindSubmatch(configContents)
	if userSubmatches == nil {
		return "", "", fmt.Errorf("unable to find rpcuser in config")
	}

	// Similarly, we'll use another regular expression to find the set
	// rpcpass (if any). If we can't find the pass, then we'll exit with an
	// error.
	rpcPassRegexp, err := regexp.Compile(`(?m)^\s*rpcpass\s*=\s*([^\s]+)`)
	if err != nil {
		return "", "", err
	}
	passSubmatches := rpcPassRegexp.FindSubmatch(configContents)
	if passSubmatches == nil {
		return "", "", fmt.Errorf("unable to find rpcuser in config")
	}

	return string(userSubmatches[1]), string(passSubmatches[1]), nil
}
source: func GetAsset(name string) *gob.Decoder {
	b, err := Asset("internal/model/" + name)
	util.CheckError(err)
	return gob.NewDecoder(bytes.NewReader(b))
}
source: func (b *Bitmap) container(key uint64) *Container {
	return b.Containers.Get(key)
}
source: func (lnng LognormalGenerator) Lognormal(mean, stddev float64) float64 {
	return math.Exp(mean + stddev*lnng.gauss.StdGaussian())
}
source: func (s *Store) fixupTokenRoleLinks(tx *memdb.Txn, original *structs.ACLToken) (*structs.ACLToken, error) {
	owned := false
	token := original

	cloneToken := func(t *structs.ACLToken, copyNumLinks int) *structs.ACLToken {
		clone := *t
		clone.Roles = make([]structs.ACLTokenRoleLink, copyNumLinks)
		copy(clone.Roles, t.Roles[:copyNumLinks])
		return &clone
	}

	for linkIndex, link := range original.Roles {
		if link.ID == "" {
			return nil, fmt.Errorf("Detected corrupted token within the state store - missing role link ID")
		}

		role, err := s.getRoleWithTxn(tx, nil, link.ID, "id")

		if err != nil {
			return nil, err
		}

		if role == nil {
			if !owned {
				// clone the token as we cannot touch the original
				token = cloneToken(original, linkIndex)
				owned = true
			}
			// if already owned then we just don't append it.
		} else if role.Name != link.Name {
			if !owned {
				token = cloneToken(original, linkIndex)
				owned = true
			}

			// append the corrected policy
			token.Roles = append(token.Roles, structs.ACLTokenRoleLink{ID: link.ID, Name: role.Name})

		} else if owned {
			token.Roles = append(token.Roles, link)
		}
	}

	return token, nil
}
source: func (r *resourceRecordChangeset) IsEmpty() bool {
	if len(r.additions) == 0 && len(r.removals) == 0 && len(r.upserts) == 0 {
		return true
	}

	return false
}
source: func (p *Project) Stop(containerID string) error {
	return p.StopWithTimeout(containerID, DefaultStopTimeout)
}
source: func (m *Machine) SetProviderAddresses(addresses ...network.Address) error {
	err := m.setAddresses(nil, &addresses)
	return errors.Annotatef(err, "cannot set addresses of machine %v", m)
}
source: func (o *Enterprise) CreateRoutingPolicy(child *RoutingPolicy) *bambou.Error {

	return bambou.CurrentSession().CreateChild(o, child)
}
source: func (o *ListTasksUnprocessableEntity) WithPayload(payload *models.ValidationError) *ListTasksUnprocessableEntity {
	o.Payload = payload
	return o
}
source: func (p *Provider) Provide(configurationChan chan<- config.Message, pool *safe.Pool) error {
	pool.GoCtx(func(routineCtx context.Context) {
		ctxLog := log.With(routineCtx, log.Str(log.ProviderName, "rancher"))
		logger := log.FromContext(ctxLog)

		operation := func() error {
			client, err := p.createClient(ctxLog)
			if err != nil {
				logger.Errorf("Failed to create the metadata client metadata service: %v", err)
				return err
			}

			updateConfiguration := func(_ string) {
				stacks, err := client.GetStacks()
				if err != nil {
					logger.Errorf("Failed to query Rancher metadata service: %v", err)
					return
				}

				rancherData := p.parseMetadataSourcedRancherData(ctxLog, stacks)

				logger.Printf("Received Rancher data %+v", rancherData)

				configuration := p.buildConfiguration(ctxLog, rancherData)
				configurationChan <- config.Message{
					ProviderName:  "rancher",
					Configuration: configuration,
				}
			}
			updateConfiguration("init")

			if p.Watch {
				if p.IntervalPoll {
					p.intervalPoll(ctxLog, client, updateConfiguration)
				} else {
					// Long polling should be favored for the most accurate configuration updates.
					// Holds the connection until there is either a change in the metadata repository or `p.RefreshSeconds` has elapsed.
					client.OnChangeCtx(ctxLog, p.RefreshSeconds, updateConfiguration)
				}
			}

			return nil
		}

		notify := func(err error, time time.Duration) {
			logger.Errorf("Provider connection error %+v, retrying in %s", err, time)
		}
		err := backoff.RetryNotify(safe.OperationWithRecover(operation), backoff.WithContext(job.NewBackOff(backoff.NewExponentialBackOff()), ctxLog), notify)
		if err != nil {
			logger.Errorf("Cannot connect to Provider server: %+v", err)
		}
	})

	return nil
} 73%|███████▎  | 3659/5000 [00:04<00:01, 1000.53it/s]
source: func (d *FaxBase) DateCreatedAsTime() (time.Time, error) {
	return time.Parse(time.RFC1123Z, d.DateCreated)
}
source: func (s *fseState) init(br *bitReader, tableLog uint8, dt []decSymbol) {
	s.dt = dt
	br.fill()
	s.state = dt[br.getBits(tableLog)]
}
source: func (tc *TabletStatsCache) WaitForAnyTablet(ctx context.Context, cell, keyspace, shard string, tabletTypes []topodatapb.TabletType) error {
	return tc.waitForAnyTablet(ctx, keyspace, shard, tabletTypes)
}
source: func (enc *Encoder) AddObjectKey(key string, v MarshalerJSONObject) {
	enc.ObjectKey(key, v)
}
source: func NewCommand() *Command {
	return &Command{
		Stderr:      os.Stderr,
		Stdout:      os.Stdout,
		Logger:      zap.NewNop(),
		batchSize:   defaultBatchSize,
		concurrency: runtime.GOMAXPROCS(0),
	}
}
source: func (q Queue) PeekN(n int) (msgs []*Message, err error) {
	msgs, err = q.PeekNWithTimeout(n, 0)

	return
}
source: func updateAgentsCommand() *cli.Command {
	return &cli.Command{
		Name:     UpdateAgentsCommandName,
		Usage:    UpdateAgentsCommandUsage,
		Action:   ActionWrapper(updateAgentsAction),
		Category: agentCategory,
		Flags: []cli.Flag{
			cli.StringSliceFlag{Name: "uuid", Usage: "GoCD Agent UUIDs"},
			cli.StringFlag{Name: "state", Usage: "Whether agents are enabled or disabled. Allowed values 'Enabled','Disabled'."},
			cli.StringFlag{Name: "operations", Usage: "JSON encoded config for bulk operation updates."},
		},
	}
}
source: func Sort(tx *wire.MsgTx) *wire.MsgTx {
	txCopy := tx.Copy()
	sort.Sort(sortableInputSlice(txCopy.TxIn))
	sort.Sort(sortableOutputSlice(txCopy.TxOut))
	return txCopy
}
source: func (c *Cargo) DeriveDeliveryProgress(history HandlingHistory) {
	c.Delivery = DeriveDeliveryFrom(c.RouteSpecification, c.Itinerary, history)
}
source: func (s *HlsIngest) SetIngestEndpoints(v []*IngestEndpoint) *HlsIngest {
	s.IngestEndpoints = v
	return s
}
source: func (s *WorkspaceBundle) SetRootStorage(v *RootStorage) *WorkspaceBundle {
	s.RootStorage = v
	return s
}
source: func (db *database) Run(transactions jujutxn.TransactionSource) error {
	runner, closer := db.TransactionRunner()
	defer closer()
	return runner.Run(transactions)
}
source: func (m *MockLXDProfileInstanceBroker) StartInstance(arg0 context.ProviderCallContext, arg1 environs.StartInstanceParams) (*environs.StartInstanceResult, error) {
	ret := m.ctrl.Call(m, "StartInstance", arg0, arg1)
	ret0, _ := ret[0].(*environs.StartInstanceResult)
	ret1, _ := ret[1].(error)
	return ret0, ret1
}
source: func (b *basicAuth) simpleBasicAuthFunc(user, pass string, r *http.Request) bool {
	// Equalize lengths of supplied and required credentials
	// by hashing them
	givenUser := sha256.Sum256([]byte(user))
	givenPass := sha256.Sum256([]byte(pass))
	requiredUser := sha256.Sum256([]byte(b.opts.User))
	requiredPass := sha256.Sum256([]byte(b.opts.Password))

	// Compare the supplied credentials to those set in our options
	if subtle.ConstantTimeCompare(givenUser[:], requiredUser[:]) == 1 &&
		subtle.ConstantTimeCompare(givenPass[:], requiredPass[:]) == 1 {
		return true
	}

	return false
}
source: func PrintResponse(resp *http.Response, includeBody bool) error {
	respBytes, err := httputil.DumpResponse(resp, includeBody)
	if err != nil {
		return err
	}
	fmt.Println(string(respBytes))
	return nil
}
source: func (b *Bittrex) BuyLimit(market string, quantity, rate decimal.Decimal) (uuid string, err error) {
	r, err := b.client.do("GET", fmt.Sprintf("market/buylimit?market=%s&quantity=%s&rate=%s", market, quantity, rate), "", true)
	if err != nil {
		return
	}
	var response jsonResponse
	if err = json.Unmarshal(r, &response); err != nil {
		return
	}
	if err = handleErr(response); err != nil {
		return
	}
	var u Uuid
	err = json.Unmarshal(response.Result, &u)
	uuid = u.Id
	return
}
source: func (buf *Buffer) End() error {
	if buf.pos >= buf.size {
		return nil
	}

	buf.pos = buf.size
	return buf.Refresh()
}
source: func (api userApi) GetWeeklyAlbumChart(args map[string]interface{}) (result UserGetWeeklyAlbumChart, err error) {
	defer func() { appendCaller(err, "lastfm.User.GetWeeklyAlbumChart") }()
	err = callGet("user.getweeklyalbumchart", api.params, args, &result, P{
		"plain": []string{"user", "from", "to"},
	})
	return
}
source: func Post(url string, r io.Reader) error {
	status, _, rc, err := DefaultClient.Post(url, nil, r)
	if err != nil {
		return err
	}
	defer rc.Close()
	if !status.IsSuccess() {
		return &StatusError{status}
	}
	return nil
}
source: func (oauther *OAuther) Transport() *oauth.Transport {
	oauther.config = &oauth.Config{
		AccessType:   "offline",
		ClientId:     oauther.ClientId,
		ClientSecret: oauther.ClientSecret,
		RedirectURL:  fmt.Sprintf("http://localhost:%s/", oauther.Port),
		Scope:        oauther.Scope,
		AuthURL:      oauther.AuthURL,
		TokenURL:     oauther.TokenURL,
	}

	transport := &oauth.Transport{Config: oauther.config}
	transport.Token = oauther.Token
	return transport
}
source: func (s *Store) DeleteMatching(dataType interface{}, query *Query) error {
	return s.Bolt().Update(func(tx *bolt.Tx) error {
		return s.TxDeleteMatching(tx, dataType, query)
	})
}
source: func SetGlobalVariable(endpoint, key string, value interface{}) error {
	var inst *Instance
	var exists bool
	if inst, exists = connectionPool[endpoint]; !exists {
		return errNotRegistered
	}
	if !globalKeyExp.MatchString(key) {
		return errKeyInvalid
	}
	if _, err := inst.connection.Exec(fmt.Sprintf("SET GLOBAL %s=?", key), value); err != nil {
		return err
	}
	return nil
}
source: func Provider() terraform.ResourceProvider {
	return &schema.Provider{
		ResourcesMap: map[string]*schema.Resource{
			"kubernetes_kubeconfig": resourceKubeconfig(),
			"kubernetes_cluster":    resourceCluster(),
		},

		ConfigureFunc: providerConfig,
	}
}
source: func FindServices(tx ReadTx, by By) ([]*api.Service, error) {
	checkType := func(by By) error {
		switch by.(type) {
		case byName, byNamePrefix, byIDPrefix, byRuntime, byReferencedNetworkID, byReferencedSecretID, byReferencedConfigID, byCustom, byCustomPrefix, byAll:
			return nil
		default:
			return ErrInvalidFindBy
		}
	}

	serviceList := []*api.Service{}
	appendResult := func(o api.StoreObject) {
		serviceList = append(serviceList, o.(*api.Service))
	}

	err := tx.find(tableService, by, checkType, appendResult)
	return serviceList, err
}
source: func (obj *object) Copy() Object {
	cpy, _ := obj.Map(func(k, v *Term) (*Term, *Term, error) {
		return k.Copy(), v.Copy(), nil
	})
	return cpy
}
source: func (txt *Text) Draw(t pixel.Target, matrix pixel.Matrix) {
	txt.DrawColorMask(t, matrix, nil)
}
source: func RegisterPartial(name string, source string) {
	partialsMutex.Lock()
	defer partialsMutex.Unlock()

	if partials[name] != nil {
		panic(fmt.Errorf("Partial already registered: %s", name))
	}

	partials[name] = newPartial(name, source, nil)
}
source: func extractPackageName(line string) (packageName, methodName string) {
	packagePath, packageNameAndFunction := splitAtLastSlash(line)
	parts := strings.Split(packageNameAndFunction, ".")
	packageName = parts[0]
	if len(packagePath) > 0 {
		packageName = fmt.Sprintf("%s/%s", packagePath, packageName)
	}
	methodName = strings.Join(parts[1:], ".")
	return
}
source: func (c *Client) DeleteDictionary(i *DeleteDictionaryInput) error {
	if i.Service == "" {
		return ErrMissingService
	}

	if i.Version == 0 {
		return ErrMissingVersion
	}

	if i.Name == "" {
		return ErrMissingName
	}

	path := fmt.Sprintf("/service/%s/version/%d/dictionary/%s", i.Service, i.Version, i.Name)
	resp, err := c.Delete(path, nil)
	if err != nil {
		return err
	}
	defer resp.Body.Close()

	// Unlike other endpoints, the dictionary endpoint does not return a status
	// response - it just returns a 200 OK.
	return nil
}
source: func (m *MockLambdaAPI) UpdateFunctionConfigurationRequest(arg0 *lambda.UpdateFunctionConfigurationInput) (*request.Request, *lambda.FunctionConfiguration) {
	ret := m.ctrl.Call(m, "UpdateFunctionConfigurationRequest", arg0)
	ret0, _ := ret[0].(*request.Request)
	ret1, _ := ret[1].(*lambda.FunctionConfiguration)
	return ret0, ret1
}
source: func (s *NetworkService) UpdatePhysicalNetwork(p *UpdatePhysicalNetworkParams) (*UpdatePhysicalNetworkResponse, error) {
	resp, err := s.cs.newRequest("updatePhysicalNetwork", p.toURLValues())
	if err != nil {
		return nil, err
	}

	var r UpdatePhysicalNetworkResponse
	if err := json.Unmarshal(resp, &r); err != nil {
		return nil, err
	}

	// If we have a async client, we need to wait for the async result
	if s.cs.async {
		b, err := s.cs.GetAsyncJobResult(r.JobID, s.cs.timeout)
		if err != nil {
			if err == AsyncTimeoutErr {
				return &r, err
			}
			return nil, err
		}

		b, err = getRawValue(b)
		if err != nil {
			return nil, err
		}

		if err := json.Unmarshal(b, &r); err != nil {
			return nil, err
		}
	}

	return &r, nil
}
source: func (c *MConnection) sendPacketMsg() bool {
	// Choose a channel to create a PacketMsg from.
	// The chosen channel will be the one whose recentlySent/priority is the least.
	var leastRatio float32 = math.MaxFloat32
	var leastChannel *Channel
	for _, channel := range c.channels {
		// If nothing to send, skip this channel
		if !channel.isSendPending() {
			continue
		}
		// Get ratio, and keep track of lowest ratio.
		ratio := float32(channel.recentlySent) / float32(channel.desc.Priority)
		if ratio < leastRatio {
			leastRatio = ratio
			leastChannel = channel
		}
	}

	// Nothing to send?
	if leastChannel == nil {
		return true
	}
	// c.Logger.Info("Found a msgPacket to send")

	// Make & send a PacketMsg from this channel
	_n, err := leastChannel.writePacketMsgTo(c.bufConnWriter)
	if err != nil {
		c.Logger.Error("Failed to write PacketMsg", "err", err)
		c.stopForError(err)
		return true
	}
	c.sendMonitor.Update(int(_n))
	c.flushTimer.Set()
	return false
}
source: func fastAppendEncodeBase62(dst []byte, src []byte) []byte {
	dst = reserve(dst, stringEncodedLength)
	n := len(dst)
	fastEncodeBase62(dst[n:n+stringEncodedLength], src)
	return dst[:n+stringEncodedLength]
}
source: func (c *Runtime) ReleaseObject(objectId string) (*gcdmessage.ChromeResponse, error) {
	var v RuntimeReleaseObjectParams
	v.ObjectId = objectId
	return c.ReleaseObjectWithParams(&v)
}
source: func New(caller base.APICaller) *Client {
	return &Client{base.NewFacadeCaller(caller, Facade)}
}
source: func (b *Driver) SetRGB(r uint8, g uint8, bl uint8) {
	b.packetChannel <- b.craftPacket([]uint8{r, g, bl, 0x01}, 0x02, 0x20)
}
source: func loadExcludeFilename(filename, workDir string, excludePaths []filepathfilter.Pattern) ([]filepathfilter.Pattern, error) {
	f, err := os.OpenFile(filename, os.O_RDONLY, 0644)
	if err != nil {
		if os.IsNotExist(err) {
			return excludePaths, nil
		}
		return excludePaths, err
	}
	defer f.Close()

	retPaths := excludePaths
	modified := false

	scanner := bufio.NewScanner(f)
	for scanner.Scan() {
		line := strings.TrimSpace(scanner.Text())
		// Skip blanks, comments and negations (not supported right now)
		if len(line) == 0 || strings.HasPrefix(line, "#") || strings.HasPrefix(line, "!") {
			continue
		}

		if !modified {
			// copy on write
			retPaths = make([]filepathfilter.Pattern, len(excludePaths))
			copy(retPaths, excludePaths)
			modified = true
		}

		path := line
		// Add pattern in context if exclude has separator, or no wildcard
		// Allow for both styles of separator at this point
		if strings.ContainsAny(path, "/\\") ||
			!strings.Contains(path, "*") {
			path = join(workDir, line)
		}
		retPaths = append(retPaths, filepathfilter.NewPattern(path))
	}

	return retPaths, nil
}
source: func (nt *NodeTree) removeZone(zone string) {
	delete(nt.tree, zone)
	for i, z := range nt.zones {
		if z == zone {
			nt.zones = append(nt.zones[:i], nt.zones[i+1:]...)
			return
		}
	}
}
source: func (s *Slice) WriteItoa(i int64, base int) (size int, err error) {
	l := len(*s)
	*s = strconv.AppendInt([]byte(*s), i, base)
	return len(*s) - l, nil
}
source: func (exe *executor) Commit(header *abciTypes.Header) (stateHash []byte, err error) {
	// The write lock to the executor is controlled by the caller (e.g. abci.App) so we do not acquire it here to avoid
	// deadlock
	defer func() {
		if r := recover(); r != nil {
			err = fmt.Errorf("recovered from panic in executor.Commit(): %v\n%s", r, debug.Stack())
		}
	}()
	// Capture height
	height := exe.block.Height
	exe.logger.InfoMsg("Executor committing", "height", exe.block.Height)
	// Form BlockExecution for this block from TxExecutions and Tendermint block header
	blockExecution, err := exe.finaliseBlockExecution(header)
	if err != nil {
		return nil, err
	}
	// First commit the app state, this app hash will not get checkpointed until the next block when we are sure
	// that nothing in the downstream commit process could have failed. At worst we go back one block.
	hash, version, err := exe.state.Update(func(ws state.Updatable) error {
		// flush the caches
		err := exe.stateCache.Flush(ws, exe.state)
		if err != nil {
			return err
		}
		err = exe.nameRegCache.Flush(ws, exe.state)
		if err != nil {
			return err
		}
		err = exe.proposalRegCache.Flush(ws, exe.state)
		if err != nil {
			return err
		}
		err = exe.validatorCache.Flush(ws, exe.state)
		if err != nil {
			return err
		}
		err = ws.AddBlock(blockExecution)
		if err != nil {
			return err
		}
		return nil
	})
	if err != nil {
		return nil, err
	}
	expectedHeight := HeightAtVersion(version)
	if expectedHeight != height {
		return nil, fmt.Errorf("expected height at state tree version %d is %d but actual height is %d",
			version, expectedHeight, height)
	}
	// Now state is fully committed publish events (this should be the last thing we do)
	exe.publishBlock(blockExecution)
	return hash, nil
}
source: func writeFile(fs utilfs.Filesystem, path string, data []byte) (retErr error) {
	// Create a temporary file in the base directory of `path` with a prefix.
	tmpFile, err := fs.TempFile(filepath.Dir(path), tmpPrefix)
	if err != nil {
		return err
	}

	tmpPath := tmpFile.Name()
	shouldClose := true

	defer func() {
		// Close the file.
		if shouldClose {
			if err := tmpFile.Close(); err != nil {
				if retErr == nil {
					retErr = fmt.Errorf("close error: %v", err)
				} else {
					retErr = fmt.Errorf("failed to close temp file after error %v; close error: %v", retErr, err)
				}
			}
		}

		// Clean up the temp file on error.
		if retErr != nil && tmpPath != "" {
			if err := removePath(fs, tmpPath); err != nil {
				retErr = fmt.Errorf("failed to remove the temporary file (%q) after error %v; remove error: %v", tmpPath, retErr, err)
			}
		}
	}()

	// Write data.
	if _, err := tmpFile.Write(data); err != nil {
		return err
	}

	// Sync file.
	if err := tmpFile.Sync(); err != nil {
		return err
	}

	// Closing the file before renaming.
	err = tmpFile.Close()
	shouldClose = false
	if err != nil {
		return err
	}

	return fs.Rename(tmpPath, path)
}
source: func loopbackPool(proxyAddr string) *x509.CertPool {
	if !utils.IsLoopback(proxyAddr) {
		log.Debugf("not using loopback pool for remote proxy addr: %v", proxyAddr)
		return nil
	}
	log.Debugf("attempting to use loopback pool for local proxy addr: %v", proxyAddr)
	certPool := x509.NewCertPool()

	certPath := filepath.Join(defaults.DataDir, defaults.SelfSignedCertPath)
	pemByte, err := ioutil.ReadFile(certPath)
	if err != nil {
		log.Debugf("could not open any path in: %v", certPath)
		return nil
	}

	for {
		var block *pem.Block
		block, pemByte = pem.Decode(pemByte)
		if block == nil {
			break
		}
		cert, err := x509.ParseCertificate(block.Bytes)
		if err != nil {
			log.Debugf("could not parse cert in: %v, err: %v", certPath, err)
			return nil
		}
		certPool.AddCert(cert)
	}
	log.Debugf("using local pool for loopback proxy: %v, err: %v", certPath, err)
	return certPool
}
source: func NewDB(db *bolt.DB, cs content.Store, ss map[string]snapshots.Snapshotter, opts ...DBOpt) *DB {
	m := &DB{
		db:      db,
		ss:      make(map[string]*snapshotter, len(ss)),
		dirtySS: map[string]struct{}{},
		dbopts: dbOptions{
			shared: true,
		},
	}

	for _, opt := range opts {
		opt(&m.dbopts)
	}

	// Initialize data stores
	m.cs = newContentStore(m, m.dbopts.shared, cs)
	for name, sn := range ss {
		m.ss[name] = newSnapshotter(m, name, sn)
	}

	return m
}
source: func (s *Store) removeConflict(ns walletdb.ReadWriteBucket, rec *TxRecord) error {
	// For each potential credit for this record, each spender (if any) must
	// be recursively removed as well.  Once the spenders are removed, the
	// credit is deleted.
	for i := range rec.MsgTx.TxOut {
		k := canonicalOutPoint(&rec.Hash, uint32(i))
		spenderHashes := fetchUnminedInputSpendTxHashes(ns, k)
		for _, spenderHash := range spenderHashes {
			// If the spending transaction spends multiple outputs
			// from the same transaction, we'll find duplicate
			// entries within the store, so it's possible we're
			// unable to find it if the conflicts have already been
			// removed in a previous iteration.
			spenderVal := existsRawUnmined(ns, spenderHash[:])
			if spenderVal == nil {
				continue
			}

			var spender TxRecord
			spender.Hash = spenderHash
			err := readRawTxRecord(&spender.Hash, spenderVal, &spender)
			if err != nil {
				return err
			}

			log.Debugf("Transaction %v is part of a removed conflict "+
				"chain -- removing as well", spender.Hash)
			if err := s.removeConflict(ns, &spender); err != nil {
				return err
			}
		}
		if err := deleteRawUnminedCredit(ns, k); err != nil {
			return err
		}
	}

	// If this tx spends any previous credits (either mined or unmined), set
	// each unspent.  Mined transactions are only marked spent by having the
	// output in the unmined inputs bucket.
	for _, input := range rec.MsgTx.TxIn {
		prevOut := &input.PreviousOutPoint
		k := canonicalOutPoint(&prevOut.Hash, prevOut.Index)
		err := deleteRawUnminedInput(ns, k, rec.Hash)
		if err != nil {
			return err
		}
	}

	return deleteRawUnmined(ns, rec.Hash[:])
}
source: func (c *removeCommand) SetFlags(f *gnuflag.FlagSet) {
	c.ControllerCommandBase.SetFlags(f)
	f.BoolVar(&c.ConfirmDelete, "y", false, "Confirm deletion of the user")
	f.BoolVar(&c.ConfirmDelete, "yes", false, "")
}
source: func (b *KopsModelContext) AutoscalingGroupName(ig *kops.InstanceGroup) string {
	switch ig.Spec.Role {
	case kops.InstanceGroupRoleMaster:
		// We need to keep this back-compatible, so we introduce the masters name,
		// though the IG name suffices for uniqueness, and with sensible naming masters
		// should be redundant...
		return ig.ObjectMeta.Name + ".masters." + b.ClusterName()
	case kops.InstanceGroupRoleNode, kops.InstanceGroupRoleBastion:
		return ig.ObjectMeta.Name + "." + b.ClusterName()

	default:
		glog.Fatalf("unknown InstanceGroup Role: %v", ig.Spec.Role)
		return ""
	}
}
source: func LaunchEditor(editor string) (content []byte, err error) {
	return launchEditorWithFilename(editor, randomFilename())
}
source: func FindPackage(ctxt *build.Context, path, dir string, mode build.ImportMode) (*build.Package, error) {
	if !useVendor {
		return ctxt.Import(path, dir, mode)
	}

	// First, walk up the filesystem from dir looking for vendor directories
	var vendorDir string
	for tmp := dir; vendorDir == "" && tmp != "/"; tmp = filepath.Dir(tmp) {
		dname := filepath.Join(tmp, "vendor", filepath.FromSlash(path))
		fd, err := os.Open(dname)
		if err != nil {
			continue
		}
		// Directories are only valid if they contain at least one file
		// with suffix ".go" (this also ensures that the file descriptor
		// we have is in fact a directory)
		names, err := fd.Readdirnames(-1)
		if err != nil {
			continue
		}
		for _, name := range names {
			if strings.HasSuffix(name, ".go") {
				vendorDir = filepath.ToSlash(dname)
				break
			}
		}
	}

	if vendorDir != "" {
		pkg, err := ctxt.ImportDir(vendorDir, mode)
		if err != nil {
			return nil, err
		}
		// Go tries to derive a valid import path for the package, but
		// it's wrong (it includes "/vendor/"). Overwrite it here.
		pkg.ImportPath = path
		return pkg, nil
	}

	return ctxt.Import(path, dir, mode)
}
source: func (util *ISCSIUtil) DetachBlockISCSIDisk(c iscsiDiskUnmapper, mapPath string) error {
	if pathExists, pathErr := mount.PathExists(mapPath); pathErr != nil {
		return fmt.Errorf("Error checking if path exists: %v", pathErr)
	} else if !pathExists {
		klog.Warningf("Warning: Unmap skipped because path does not exist: %v", mapPath)
		return nil
	}
	// If we arrive here, device is no longer used, see if need to logout the target
	// device: 192.168.0.10:3260-iqn.2017-05.com.example:test-lun-0
	device, _, err := extractDeviceAndPrefix(mapPath)
	if err != nil {
		return err
	}
	var bkpPortal []string
	var volName, iqn, lun, iface, initiatorName string
	found := true
	// load iscsi disk config from json file
	if err := util.loadISCSI(c.iscsiDisk, mapPath); err == nil {
		bkpPortal, iqn, lun, iface, volName = c.iscsiDisk.Portals, c.iscsiDisk.Iqn, c.iscsiDisk.Lun, c.iscsiDisk.Iface, c.iscsiDisk.VolName
		initiatorName = c.iscsiDisk.InitiatorName
	} else {
		// If the iscsi disk config is not found, fall back to the original behavior.
		// This portal/iqn/iface is no longer referenced, log out.
		// Extract the portal and iqn from device path.
		bkpPortal = make([]string, 1)
		bkpPortal[0], iqn, err = extractPortalAndIqn(device)
		if err != nil {
			return err
		}
		arr := strings.Split(device, "-lun-")
		if len(arr) < 2 {
			return fmt.Errorf("failed to retrieve lun from mapPath: %v", mapPath)
		}
		lun = arr[1]
		// Extract the iface from the mountPath and use it to log out. If the iface
		// is not found, maintain the previous behavior to facilitate kubelet upgrade.
		// Logout may fail as no session may exist for the portal/IQN on the specified interface.
		iface, found = extractIface(mapPath)
	}
	portals := removeDuplicate(bkpPortal)
	if len(portals) == 0 {
		return fmt.Errorf("iscsi detach disk: failed to detach iscsi disk. Couldn't get connected portals from configurations")
	}

	devicePath := getDevByPath(portals[0], iqn, lun)
	klog.V(5).Infof("iscsi: devicePath: %s", devicePath)
	if _, err = os.Stat(devicePath); err != nil {
		return fmt.Errorf("failed to validate devicePath: %s", devicePath)
	}
	// check if the dev is using mpio and if so mount it via the dm-XX device
	if mappedDevicePath := c.deviceUtil.FindMultipathDeviceForDevice(devicePath); mappedDevicePath != "" {
		devicePath = mappedDevicePath
	}
	// Detach a volume from kubelet node
	err = util.detachISCSIDisk(c.exec, portals, iqn, iface, volName, initiatorName, found)
	if err != nil {
		return fmt.Errorf("failed to finish detachISCSIDisk, err: %v", err)
	}
	return nil
}
source: func (o OutputFormats) Get(name string) *OutputFormat {
	for _, f := range o {
		if strings.EqualFold(f.Format.Name, name) {
			return &f
		}
	}
	return nil
}
source: func (q *TagQuery) getInitialByTagMatch(idCh chan schema.MKey, stopCh chan struct{}) {
	defer q.wg.Done()

TAGS:
	for tag, values := range q.index {
		if q.tagMatch.value.MatchString(tag) {
			for _, ids := range values {
				for id := range ids {
					select {
					case <-stopCh:
						break TAGS
					case idCh <- id:
					}
				}
			}
		}
	}

	close(idCh)
}
source: func howSimilarStrings(a, b string) int {

	// Give some weight to the word positions.
	const partitionSize = 4

	af, bf := strings.Fields(a), strings.Fields(b)
	if len(bf) > len(af) {
		af, bf = bf, af
	}

	m1 := make(map[string]bool)
	for i, x := range bf {
		partition := partition(i, partitionSize)
		key := x + "/" + strconv.Itoa(partition)
		m1[key] = true
	}

	common := 0
	for i, x := range af {
		partition := partition(i, partitionSize)
		key := x + "/" + strconv.Itoa(partition)
		if m1[key] {
			common++
		}
	}

	return int(math.Floor((float64(common) / float64(len(af)) * 100)))
}
source: func (c *Collector) Visit(URL string) error {
	if c.CheckHead {
		if check := c.scrape(URL, "HEAD", 1, nil, nil, nil, true); check != nil {
			return check
		}
	}
	return c.scrape(URL, "GET", 1, nil, nil, nil, true)
}
source: func (r *Router) GetDatacenterMaps() ([]structs.DatacenterMap, error) {
	r.RLock()
	defer r.RUnlock()

	var maps []structs.DatacenterMap
	for areaID, info := range r.areas {
		index := make(map[string]structs.Coordinates)
		for _, m := range info.cluster.Members() {
			ok, parts := metadata.IsConsulServer(m)
			if !ok {
				r.logger.Printf("[WARN]: consul: Non-server %q in server-only area %q",
					m.Name, areaID)
				continue
			}

			coord, ok := info.cluster.GetCachedCoordinate(parts.Name)
			if ok {
				entry := &structs.Coordinate{
					Node:  parts.Name,
					Coord: coord,
				}
				existing := index[parts.Datacenter]
				index[parts.Datacenter] = append(existing, entry)
			}
		}

		for dc, coords := range index {
			entry := structs.DatacenterMap{
				Datacenter:  dc,
				AreaID:      areaID,
				Coordinates: coords,
			}
			maps = append(maps, entry)
		}
	}
	return maps, nil
}
source: func CreateBackup(dir, backupsDir string, limit int) error {
	tmpBackupDir := filepath.Join(backupsDir, "tmp")
	if err := os.MkdirAll(backupsDir, 0750); err != nil {
		return err
	}
	if err := fileutil.CopyTree(dir, tmpBackupDir, user.NewBlankUidRange()); err != nil {
		return err
	}
	defer os.RemoveAll(tmpBackupDir)
	// prune backups
	if err := pruneOldBackups(backupsDir, limit-1); err != nil {
		return err
	}
	if err := shiftBackups(backupsDir, limit-2); err != nil {
		return err
	}
	if err := os.Rename(tmpBackupDir, filepath.Join(backupsDir, "0")); err != nil {
		return err
	}
	return nil
}
source: func ContactsUpdate(c web.C, w http.ResponseWriter, r *http.Request) {
	// Decode the request
	var input ContactsUpdateRequest
	err := utils.ParseRequest(r, &input)
	if err != nil {
		env.Log.WithFields(logrus.Fields{
			"error": err.Error(),
		}).Warn("Unable to decode a request")

		utils.JSONResponse(w, 400, &ContactsUpdateResponse{
			Success: false,
			Message: "Invalid input format",
		})
		return
	}

	// Get the contact from the database
	contact, err := env.Contacts.GetContact(c.URLParams["id"])
	if err != nil {
		utils.JSONResponse(w, 404, &ContactsUpdateResponse{
			Success: false,
			Message: "Contact not found",
		})
		return
	}

	// Fetch the current session from the middleware
	session := c.Env["token"].(*models.Token)

	// Check for ownership
	if contact.Owner != session.Owner {
		utils.JSONResponse(w, 404, &ContactsUpdateResponse{
			Success: false,
			Message: "Contact not found",
		})
		return
	}

	if input.Data != "" {
		contact.Data = input.Data
	}

	if input.Name != "" {
		contact.Name = input.Name
	}

	if input.Encoding != "" {
		contact.Encoding = input.Encoding
	}

	if input.VersionMajor != nil {
		contact.VersionMajor = *input.VersionMajor
	}

	if input.VersionMinor != nil {
		contact.VersionMinor = *input.VersionMinor
	}

	if input.PGPFingerprints != nil {
		contact.PGPFingerprints = input.PGPFingerprints
	}

	// Perform the update
	err = env.Contacts.UpdateID(c.URLParams["id"], contact)
	if err != nil {
		env.Log.WithFields(logrus.Fields{
			"error": err.Error(),
			"id":    c.URLParams["id"],
		}).Error("Unable to update a contact")

		utils.JSONResponse(w, 500, &ContactsUpdateResponse{
			Success: false,
			Message: "Internal error (code CO/UP/01)",
		})
		return
	}

	// Write the contact to the response
	utils.JSONResponse(w, 200, &ContactsUpdateResponse{
		Success: true,
		Contact: contact,
	})
}
source: func DefaultKubernetesUserAgent() string {
	return buildUserAgent(
		adjustCommand(os.Args[0]),
		adjustVersion(version.Get().GitVersion),
		gruntime.GOOS,
		gruntime.GOARCH,
		adjustCommit(version.Get().GitCommit))
}
source: func (proxier *Proxier) shutdown() {
	proxier.mu.Lock()
	defer proxier.mu.Unlock()

	for serviceName, info := range proxier.serviceMap {
		proxier.stopProxy(serviceName, info)
	}
	proxier.cleanupStaleStickySessions()
	close(proxier.stopChan)
}
source: func (oc *OutputChannel) Write(fields map[string]interface{}) (err error) {
	select {
	case oc.input <- fields:
		// Sent with success
	default:
		// Channel is full, message dropped
		err = ErrBufferFull
	}
	return err
}
source: func GetNewRC(deployment extensions.Deployment, c client.Interface) (*api.ReplicationController, error) {
	return GetNewRCFromList(deployment, c,
		func(namespace string, options api.ListOptions) ([]api.ReplicationController, error) {
			rcList, err := c.ReplicationControllers(namespace).List(options)
			return rcList.Items, err
		})
}
source: func NewDNSController(dnsProviders []dnsprovider.Interface, zoneRules *ZoneRules, updateInterval int) (*DNSController, error) {
	dnsCache, err := newDNSCache(dnsProviders)
	if err != nil {
		return nil, fmt.Errorf("error initializing DNS cache: %v", err)
	}

	c := &DNSController{
		scopes:         make(map[string]*DNSControllerScope),
		zoneRules:      zoneRules,
		dnsCache:       dnsCache,
		updateInterval: time.Duration(updateInterval) * time.Second,
	}

	return c, nil
}
source: func (s *mustRunAs) Generate(_ *api.Pod, _ *api.Container) (*api.SELinuxOptions, error) {
	return s.opts.SELinuxOptions, nil
}
source: func SatisfiesMetaFilters(meta map[string]string, filters map[string]string) bool {
	for key, value := range filters {
		if v, ok := meta[key]; !ok || v != value {
			return false
		}
	}
	return true
}
source: func DefaultHash(buf []byte) (Hash, error) {
	hashType, rawHash := DoRawDefaultHash(buf)
	return HashFromRaw(hashType, rawHash[:])
}
source: func (c *ConfigLocal) SetReporter(r Reporter) {
	c.lock.Lock()
	defer c.lock.Unlock()
	c.rep = r
}
source: func UnmarshalRequestBody(w http.ResponseWriter, r *http.Request, v interface{}) error {
	defer r.Body.Close()

	if r.Header.Get("Content-Length") == "0" {
		BadRequest(w, MessageResponse{
			Message: "empty request body",
		})
		return ErrEmptyRequestBody
	}
	if err := json.NewDecoder(r.Body).Decode(&v); err != nil {
		response := MessageResponse{}
		switch e := err.(type) {
		case *json.SyntaxError:
			response.Message = fmt.Sprintf("%v (offset %d)", e, e.Offset)
		case *json.UnmarshalTypeError:
			response.Message = fmt.Sprintf("expected json %s value but got %s (offset %d)", e.Type, e.Value, e.Offset)
		default:
			if err == io.EOF {
				err = ErrEmptyRequestBody
			}
			response.Message = err.Error()
		}
		BadRequest(w, response)
		return err
	}
	return nil
}
source: func (s *ReservationPurchaseRecommendationDetail) SetMinimumNumberOfInstancesUsedPerHour(v string) *ReservationPurchaseRecommendationDetail {
	s.MinimumNumberOfInstancesUsedPerHour = &v
	return s
}
source: func (q Query) String() string {
	return fmt.Sprintf("{Database: %q, Charset: %v, SQL: %q}",
		q.Database, q.Charset, q.SQL)
}
source: func (s *SQLStore) Close() error {
	s.Lock()
	if s.closed {
		s.Unlock()
		return nil
	}
	s.closed = true
	// This will cause MsgStore's and SubStore's to be closed.
	err := s.close()
	db := s.db
	wg := &s.wg
	// Signal background go-routines to quit
	if s.doneCh != nil {
		close(s.doneCh)
	}
	s.Unlock()

	// Wait for go routine(s) to finish
	wg.Wait()

	s.Lock()
	for _, ps := range s.preparedStmts {
		if lerr := ps.Close(); lerr != nil && err == nil {
			err = lerr
		}
	}
	if db != nil {
		if s.dbLock != nil {
			s.releaseDBLockIfOwner()
		}
		if lerr := db.Close(); lerr != nil && err == nil {
			err = lerr
		}
	}
	s.Unlock()
	return err
}
source: func (s *debugLogSocketImpl) sendError(err error) {
	if sendErr := s.conn.SendInitialErrorV0(err); sendErr != nil {
		logger.Errorf("closing websocket, %v", err)
		s.conn.Close()
		return
	}
}
source: func (tl *ThrottledLogger) Infof(format string, v ...interface{}) {
	tl.log(infoDepth, format, v...)
}
source: func (xc *CommonExchange) wsErrorCount() int {
	xc.wsMtx.RLock()
	defer xc.wsMtx.RUnlock()
	return xc.wsSync.errCount
}
source: func NewUserDeactivationNotificationWorker(ctx context.Context, app application.Application) UserDeactivationNotificationWorker {
	w := &userDeactivationNotificationWorker{
		worker.Worker{
			Ctx:   ctx,
			App:   app,
			Owner: worker.GetLockOwner(ctx),
			Name:  UserDeactivationNotification,
		},
	}
	w.Do = w.notifyUsers
	return w
}
source: func buildSafetyCheck(destPath string) error {

	// First, verify that it is either already empty or looks like a previous
	// build (to avoid clobbering anything)
	if utils.Exists(destPath) && !utils.Empty(destPath) && !utils.Exists(filepath.Join(destPath, "run.sh")) {
		return utils.NewBuildError("Abort: %s exists and does not look like a build directory.", "path", destPath)
	}

	if err := os.RemoveAll(destPath); err != nil && !os.IsNotExist(err) {
		return utils.NewBuildIfError(err, "Remove all error", "path", destPath)
	}

	if err := os.MkdirAll(destPath, 0777); err != nil {
		return utils.NewBuildIfError(err, "MkDir all error", "path", destPath)
	}
	return nil
}
source: func (s *rowSegment) Xor(other *rowSegment) *rowSegment {
	data := s.data.Xor(&other.data)

	return &rowSegment{
		data:  *data,
		shard: s.shard,
		n:     data.Count(),
	}
}
source: func AuthenticatedServer(token string, handler http.Handler) http.Handler {
	return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		// Allow the POST method only.
		if r.Method != "POST" {
			http.Error(w, "POST Method Expected", http.StatusMethodNotAllowed)
			return
		}

		// Make sure that the token query parameter is set correctly.
		if r.FormValue("token") != token && r.FormValue("access_token") != token {
			http.Error(w, "Unauthorized", http.StatusUnauthorized)
			return
		}

		// If everything is ok, serve the user-defined handler.
		handler.ServeHTTP(w, r)
	})
}
source: func StartServer(cfg abcconfig.ServerConfig, router http.Handler, logger *zap.Logger) error {
	var err error
	server := http.Server{
		ReadTimeout:  cfg.ReadTimeout,
		WriteTimeout: cfg.WriteTimeout,
		IdleTimeout:  cfg.IdleTimeout,
		ErrorLog:     log.New(serverErrLogger{logger}, "", 0),
		Handler:      router,
	}

	server.TLSConfig = &tls.Config{
		// Causes servers to use Go's default ciphersuite preferences,
		// which are tuned to avoid attacks. Does nothing on clients.
		PreferServerCipherSuites: true,
		// Only use curves which have assembly implementations
		CurvePreferences: []tls.CurveID{
			tls.CurveP256,
			tls.X25519, // Go 1.8 only
		},
	}

	// subscribe to SIGINT signals
	quit := make(chan os.Signal)
	signal.Notify(quit, os.Interrupt)

	// Start server graceful shutdown goroutine
	go func() {
		<-quit
		log.Println("Shutting down server...")
		if err := server.Shutdown(context.Background()); err != nil {
			log.Fatalf("could not shutdown: %v", err)
		}
	}()

	if len(cfg.TLSBind) > 0 {
		logger.Info("starting https listener", zap.String("bind", cfg.TLSBind))
		server.Addr = cfg.TLSBind

		// Redirect http requests to https
		go Redirect(cfg, logger)

		if err := server.ListenAndServeTLS(cfg.TLSCertFile, cfg.TLSKeyFile); err != nil {
			fmt.Printf("failed to ListenAndServeTLS: %v", err)
			return nil
		}
	} else {
		logger.Info("starting http listener", zap.String("bind", cfg.Bind))
		server.Addr = cfg.Bind
		if err := server.ListenAndServe(); err != nil {
			fmt.Printf("failed to ListenAndServe: %v", err)
			return nil
		}
	}

	return errors.Wrap(err, "failed to StartServer")
}
source: func (sup *supervisor) wait() {
	sup.cond.L.Lock()
	for len(sup.running) > 0 {
		sup.cond.Wait()
	}
	sup.cond.L.Unlock()
}
source: func (c *Container) AddElement(el Element) {
	c.Body = append(c.Body, el)
}
source: func (client *storageRESTClient) AppendFile(volume, path string, buffer []byte) error {
	values := make(url.Values)
	values.Set(storageRESTVolume, volume)
	values.Set(storageRESTFilePath, path)
	reader := bytes.NewBuffer(buffer)
	respBody, err := client.call(storageRESTMethodAppendFile, values, reader, -1)
	defer http.DrainBody(respBody)
	return err
}
source: func NewChequebook(address common.Address, backend bind.ContractBackend) (*Chequebook, error) {
	contract, err := bindChequebook(address, backend, backend, backend)
	if err != nil {
		return nil, err
	}
	return &Chequebook{ChequebookCaller: ChequebookCaller{contract: contract}, ChequebookTransactor: ChequebookTransactor{contract: contract}, ChequebookFilterer: ChequebookFilterer{contract: contract}}, nil
}
source: func GetLayerPath(s Store, layer ChainID) (string, error) {
	ls, ok := s.(*layerStore)
	if !ok {
		return "", errors.New("unsupported layer store")
	}
	ls.layerL.Lock()
	defer ls.layerL.Unlock()

	rl, ok := ls.layerMap[layer]
	if !ok {
		return "", ErrLayerDoesNotExist
	}

	if layerGetter, ok := ls.driver.(Getter); ok {
		return layerGetter.GetLayerPath(rl.cacheID)
	}
	path, err := ls.driver.Get(rl.cacheID, "")
	if err != nil {
		return "", err
	}

	if err := ls.driver.Put(rl.cacheID); err != nil {
		return "", err
	}

	return path.Path(), nil
}
source: func invokeCheckChanges(a, e, changes Task) error {
	rv, err := reflectutils.InvokeMethod(e, "CheckChanges", a, e, changes)
	if err != nil {
		return err
	}
	if !rv[0].IsNil() {
		err = rv[0].Interface().(error)
	}
	return err
}
source: func WSkewMeanSd(w, data Interface, wmean, wsd float64) (wskew float64) {
	var W float64
	Len := data.Len()

	for i := 0; i < Len; i++ {
		wi := w.Get(i)

		if wi > 0 {
			x := (data.Get(i) - wmean) / wsd
			W += wi
			wskew += (x*x*x - wskew) * (wi / W)
		}
	}

	return
}
source: func (c *asyncClient) Incrby(arg0 string, arg1 int64) (result FutureInt64, err Error) {
	arg0bytes := []byte(arg0)
	arg1bytes := []byte(fmt.Sprintf("%d", arg1))

	var resp *PendingResponse
	resp, err = c.conn.QueueRequest(&INCRBY, [][]byte{arg0bytes, arg1bytes})
	if err == nil {
		result = resp.future.(FutureInt64)
	}
	return result, err

}
source: func (b Box) GetLeft(defaults ...int) int {
	if !b.IsSet && b.Left == 0 {
		if len(defaults) > 0 {
			return defaults[0]
		}
		return 0
	}
	return b.Left
}
source: func (e *SelectStatement) AggregateRow(input Record) error {
	ok, err := e.isPassingWhereClause(input)
	if err != nil {
		return err
	}
	if !ok {
		return nil
	}

	for _, expr := range e.selectAST.Expression.Expressions {
		err := expr.aggregateRow(input)
		if err != nil {
			return err
		}
	}
	return nil
}
source: func (l *Listener) AcceptKCP() (*UDPSession, error) {
	var timeout <-chan time.Time
	if tdeadline, ok := l.rd.Load().(time.Time); ok && !tdeadline.IsZero() {
		timeout = time.After(tdeadline.Sub(time.Now()))
	}

	select {
	case <-timeout:
		return nil, &errTimeout{}
	case c := <-l.chAccepts:
		return c, nil
	case <-l.die:
		return nil, errors.New(errBrokenPipe)
	}
}
source: func (d *BMP085) Altitude() (float64, error) {
	if err := d.calibrate(); err != nil {
		return 0, err
	}

	select {
	case altitude := <-d.altitudes:
		return altitude, nil
	default:
		glog.V(1).Info("bcm085: no altitudes available... measuring")
		_, altitude, err := d.measurePressureAndAltitude()
		if err != nil {
			return 0, err
		}
		return altitude, nil
	}
}
source: func (c *Choice) Otherwise() *Choice {
	if c.pipe.err != nil {
		return c
	}
	c.execute = false
	if !c.executed {
		c.execute = true
	}
	return c
}
source: func runBQLFromFile(ctx context.Context, driver storage.Store, chanSize, bulkSize int, line string, w io.Writer) (string, int, error) {
	ss := strings.Split(strings.TrimSpace(line), " ")
	if len(ss) != 2 {
		return "", 0, fmt.Errorf("wrong syntax: run <file_with_bql_statements>")
	}
	path := ss[1]
	tracer.Trace(w, func() []string {
		return []string{fmt.Sprintf("Attempting to read file %q", path)}
	})
	lines, err := bio.GetStatementsFromFile(path)
	if err != nil {
		msg := fmt.Errorf("failed to read file %q; error %v", path, err)
		tracer.Trace(w, func() []string {
			return []string{msg.Error()}
		})
		return "", 0, msg
	}
	for idx, stm := range lines {
		fmt.Printf("Processing statement (%d/%d)\n", idx+1, len(lines))
		_, err := runBQL(ctx, stm, driver, chanSize, bulkSize, w)
		if err != nil {
			msg := fmt.Errorf("%q; %v", stm, err)
			tracer.Trace(w, func() []string {
				return []string{msg.Error()}
			})
			return "", 0, msg
		}
	}
	fmt.Println()
	return path, len(lines), nil
}
source: func (v *validator) Validate(cons Value) ([]string, error) {
	unsupported := v.checkUnsupported(cons)
	if err := v.checkConflicts(cons); err != nil {
		return unsupported, err
	}
	if err := v.checkValidValues(cons); err != nil {
		return unsupported, err
	}
	return unsupported, nil
}
source: func Checkf(err error, format string, args ...interface{}) {
	if err != nil {
		log.Fatalf("%+v", errors.Wrapf(err, format, args...))
	}
}
source: func NewDecoder(r io.Reader) *Decoder {
	decoder := new(Decoder)
	decoder.pendingTag = -1
	decoder.syms = make([]string, 0)
	decoder.in = bufio.NewReader(r)
	//	decoder.currentCursor = nil
	decoder.readHeader()
	return decoder
}
source: func (c *ConfigTree) GobDecode(buf []byte) error {
	r := bytes.NewBuffer(buf)
	decoder := gob.NewDecoder(r)
	if err := decoder.Decode(&c.root); err != nil {
		return err
	}
	return nil
}
source: func (s *StatusReport) SetCheckedTime(v time.Time) *StatusReport {
	s.CheckedTime = &v
	return s
}
source: func (r *RS) Update(oldData []byte, newData []byte, updateRow int, parity [][]byte) (err error) {
	// check args
	if len(parity) != r.ParityCnt {
		err = ErrMismatchParityCnt
		return
	}
	size := len(newData)
	if size <= 0 {
		err = ErrIllegalUpdateSize
		return
	}
	if size != len(oldData) {
		err = ErrIllegalUpdateSize
		return
	}
	for i := range parity {
		if len(parity[i]) != size {
			err = ErrIllegalUpdateSize
			return
		}
	}
	if updateRow >= r.DataCnt {
		err = ErrIllegalUpdateRow
		return
	}

	// step1: buf (old_data xor new_data)
	buf := make([]byte, size)
	xor.Encode(buf, [][]byte{oldData, newData})
	// step2: reEnc parity
	updateVects := make([][]byte, 1+r.ParityCnt)
	updateVects[0] = buf
	updateGenMatrix := make([]byte, r.ParityCnt)
	// make update_generator_matrix & update_vects
	for i := 0; i < r.ParityCnt; i++ {
		col := updateRow
		off := i*r.DataCnt + col
		c := r.genMatrix[off]
		updateGenMatrix[i] = c
		updateVects[i+1] = parity[i]
	}
	updateRS := &RS{DataCnt: 1, ParityCnt: r.ParityCnt, genMatrix: updateGenMatrix, cpu: r.cpu}
	updateRS.encode(updateVects, true)
	return nil
}
source: func (s *PacketStore) Save(pkt packet.Generic) {
	s.mutex.Lock()
	defer s.mutex.Unlock()

	id, ok := packet.GetID(pkt)
	if ok {
		s.packets[id] = pkt
	}
}
source: func (_class VMClass) CopyBiosStrings(sessionID SessionRef, vm VMRef, host HostRef) (_err error) {
	_method := "VM.copy_bios_strings"
	_sessionIDArg, _err := convertSessionRefToXen(fmt.Sprintf("%s(%s)", _method, "session_id"), sessionID)
	if _err != nil {
		return
	}
	_vmArg, _err := convertVMRefToXen(fmt.Sprintf("%s(%s)", _method, "vm"), vm)
	if _err != nil {
		return
	}
	_hostArg, _err := convertHostRefToXen(fmt.Sprintf("%s(%s)", _method, "host"), host)
	if _err != nil {
		return
	}
	_, _err =  _class.client.APICall(_method, _sessionIDArg, _vmArg, _hostArg)
	return
}
source: func SetLayout(uuid []byte, layout Layout) {
	switch layout {
	case LayoutNCS:
		uuid[8] = (uuid[8] | 0x00) & 0x0f // Msb0=0
	case LayoutRFC4122:
		uuid[8] = (uuid[8] | 0x80) & 0x8f // Msb0=1, Msb1=0
	case LayoutMicrosoft:
		uuid[8] = (uuid[8] | 0xc0) & 0xcf // Msb0=1, Msb1=1, Msb2=0
	case LayoutFuture:
		uuid[8] = (uuid[8] | 0xe0) & 0xef // Msb0=1, Msb1=1, Msb2=1
	default:
		panic("layout is invalid")
	}
}
source: func DoHash(buf []byte, ht HashType) (Hash, error) {
	switch ht {
	case SHA256Hash, SHA256HashV2:
	default:
		return Hash{}, errors.WithStack(UnknownHashTypeError{ht})
	}
	_, rawHash := DoRawDefaultHash(buf)
	return HashFromRaw(ht, rawHash[:])
}
source: func (s *server) initBinary() error {
	s.network.Handle("InsertTriples", s.handleInsertTriples)
	s.network.Handle("QueryRequest", s.handleQueryRequest)

	return nil
}
source: func checkDiscoveryUrl(cfg node, report *Report) {
	c := cfg.Child("coreos").Child("etcd").Child("discovery")
	if !c.IsValid() {
		return
	}

	if _, err := url.ParseRequestURI(c.String()); err != nil {
		report.Warning(c.line, "discovery URL is not valid")
	}
}
source: func printFunctionHeader(w io.Writer, name, path string, flatSum, cumSum int64, rpt *Report) {
	fmt.Fprintf(w, `<h1>%s</h1>%s
<pre onClick="pprof_toggle_asm()">
  Total:  %10s %10s (flat, cum) %s
`,
		template.HTMLEscapeString(name), template.HTMLEscapeString(path),
		rpt.formatValue(flatSum), rpt.formatValue(cumSum),
		percentage(cumSum, rpt.total))
}
source: func NewDigitalOceanProvisioner(ctx context.Context, client kubernetes.Interface, doClient *godo.Client) controller.Provisioner {
	var identity types.UID

	provisioner := &digitaloceanProvisioner{
		client:   client,
		doClient: doClient,
		ctx:      ctx,
		identity: identity,
	}

	return provisioner
}
source: func (daemon *Daemon) SystemDiskUsage(ctx context.Context) (*types.DiskUsage, error) {
	if !atomic.CompareAndSwapInt32(&daemon.diskUsageRunning, 0, 1) {
		return nil, fmt.Errorf("a disk usage operation is already running")
	}
	defer atomic.StoreInt32(&daemon.diskUsageRunning, 0)

	// Retrieve container list
	allContainers, err := daemon.Containers(&types.ContainerListOptions{
		Size: true,
		All:  true,
	})
	if err != nil {
		return nil, fmt.Errorf("failed to retrieve container list: %v", err)
	}

	// Get all top images with extra attributes
	allImages, err := daemon.imageService.Images(filters.NewArgs(), false, true)
	if err != nil {
		return nil, fmt.Errorf("failed to retrieve image list: %v", err)
	}

	localVolumes, err := daemon.volumes.LocalVolumesSize(ctx)
	if err != nil {
		return nil, err
	}

	allLayersSize, err := daemon.imageService.LayerDiskUsage(ctx)
	if err != nil {
		return nil, err
	}

	return &types.DiskUsage{
		LayersSize: allLayersSize,
		Containers: allContainers,
		Volumes:    localVolumes,
		Images:     allImages,
	}, nil
}
source: func (c *CmdListTrackers) GetUsage() libkb.Usage {
	return libkb.Usage{
		Config: true,
		API:    true,
	}
}
source: func (s *Eac3Settings) SetLtRtCenterMixLevel(v float64) *Eac3Settings {
	s.LtRtCenterMixLevel = &v
	return s
}
source: func Parse(r io.Reader, p ImportModuleProvider) (ProtoFile, error) {
	if r == nil {
		return ProtoFile{}, errors.New("Reader for protobuf content is mandatory")
	}

	pf := ProtoFile{}

	// parse the main proto file...
	if err := parse(r, &pf); err != nil {
		return pf, err
	}

	// verify via extra checks...
	if err := verify(&pf, p); err != nil {
		return pf, err
	}

	return pf, nil
}
source: func WithFuzzySearch(ctx context.Context, fuzzy bool) context.Context {
	return context.WithValue(ctx, ctxKeyFuzzySearch, fuzzy)
}
source: func (u eventRemoveMessage) JSON() string {
	u.Status = "success"
	eventRemoveMessageJSONBytes, e := json.MarshalIndent(u, "", " ")
	fatalIf(probe.NewError(e), "Unable to marshal into JSON.")
	return string(eventRemoveMessageJSONBytes)
}
source: func (x *Exif) LatLong() (lat, long float64, err error) {
	// All calls of x.Get might return an TagNotPresentError
	longTag, err := x.Get(FieldName("GPSLongitude"))
	if err != nil {
		return
	}
	ewTag, err := x.Get(FieldName("GPSLongitudeRef"))
	if err != nil {
		return
	}
	latTag, err := x.Get(FieldName("GPSLatitude"))
	if err != nil {
		return
	}
	nsTag, err := x.Get(FieldName("GPSLatitudeRef"))
	if err != nil {
		return
	}
	if long, err = tagDegrees(longTag); err != nil {
		return 0, 0, fmt.Errorf("Cannot parse longitude: %v", err)
	}
	if lat, err = tagDegrees(latTag); err != nil {
		return 0, 0, fmt.Errorf("Cannot parse latitude: %v", err)
	}
	ew, err := ewTag.StringVal()
	if err == nil && ew == "W" {
		long *= -1.0
	} else if err != nil {
		return 0, 0, fmt.Errorf("Cannot parse longitude: %v", err)
	}
	ns, err := nsTag.StringVal()
	if err == nil && ns == "S" {
		lat *= -1.0
	} else if err != nil {
		return 0, 0, fmt.Errorf("Cannot parse longitude: %v", err)
	}
	return lat, long, nil
}
source: func StronglyConnected(g *Graph) [][]Vertex {
	vs := g.Vertices()
	acct := sccAcct{
		NextIndex:   1,
		VertexIndex: make(map[Vertex]int, len(vs)),
	}
	for _, v := range vs {
		// Recurse on any non-visited nodes
		if acct.VertexIndex[v] == 0 {
			stronglyConnected(&acct, g, v)
		}
	}
	return acct.SCC
}
source: func (l *List) Supports(capability Capability) bool {
	_, ok := l.m[capability]
	return ok
}
source: func (c *TagCache) Save(ctx context.Context) error {
	c.lock.Lock()
	defer c.lock.Unlock()

	// Nothing to store? Just clean the state, so that ResolveTag can fetch the
	// up-to-date cache from disk later if needed.
	if len(c.addedTags) == 0 && len(c.addedFiles) == 0 {
		c.cache = nil
		return nil
	}

	// Sort all new entries, for consistency.
	sortedTags := make([]string, 0, len(c.addedTags))
	for k := range c.addedTags {
		sortedTags = append(sortedTags, string(k))
	}
	sort.Strings(sortedTags)
	sortedFiles := make([]string, 0, len(c.addedFiles))
	for k := range c.addedFiles {
		sortedFiles = append(sortedFiles, string(k))
	}
	sort.Strings(sortedFiles)

	// Load the most recent data to avoid overwriting it. Load ALL entries, even
	// if they belong to different service: we have one global cache file and
	// should preserve all entries there.
	recent, err := c.loadFromDisk(ctx, true)
	if err != nil {
		return err
	}

	// Copy existing entries, except the ones we are moving to the tail. Carefully
	// copy entries belonging to other services too, we must not overwrite them.
	mergedTags := make([]*messages.TagCache_Entry, 0, len(recent.Entries)+len(c.addedTags))
	for _, e := range recent.Entries {
		key := makeTagKey(e.Package, e.Tag)
		if e.Service != c.service || c.addedTags[key] == nil {
			mergedTags = append(mergedTags, e)
		}
	}

	// Add new entries to the tail.
	for _, k := range sortedTags {
		mergedTags = append(mergedTags, c.addedTags[tagKey(k)])
	}

	// Trim the end result, discard the head: it's where old items are.
	if len(mergedTags) > tagCacheMaxSize {
		mergedTags = mergedTags[len(mergedTags)-tagCacheMaxSize:]
	}

	// Do the same for file entries.
	mergedFiles := make([]*messages.TagCache_FileEntry, 0, len(recent.FileEntries)+len(c.addedFiles))
	for _, e := range recent.FileEntries {
		key := makeFileKey(e.Package, e.InstanceId, e.FileName)
		if e.Service != c.service || c.addedFiles[key] == nil {
			mergedFiles = append(mergedFiles, e)
		}
	}
	for _, k := range sortedFiles {
		mergedFiles = append(mergedFiles, c.addedFiles[fileKey(k)])
	}
	if len(mergedFiles) > tagCacheMaxExeSize {
		mergedFiles = mergedFiles[len(mergedFiles)-tagCacheMaxExeSize:]
	}

	// Serialize and write to disk. We still can accidentally replace someone
	// else's changes, but the probability should be relatively low. It can happen
	// only if two processes call 'Save' at the exact same time.
	updated := &messages.TagCache{Entries: mergedTags, FileEntries: mergedFiles}
	if err := c.dumpToDisk(ctx, updated); err != nil {
		return err
	}

	// The state is persisted now.
	c.cache = updated
	c.addedTags = nil
	c.addedFiles = nil

	return nil
}
source: func NewRelocationBatchResult(Entries []*RelocationBatchResultData) *RelocationBatchResult {
	s := new(RelocationBatchResult)
	s.Entries = Entries
	return s
}
source: func createRequest(method string, url string,
	payload interface{}, onlyFields []string,
	options ...RequestOptions) (req *http.Request, err error) {

	body, err := convertPayload(payload, onlyFields)
	if err != nil {
		return req, fmt.Errorf("creating request: %s\n", err)
	}
	req, err = http.NewRequest(method, url, bytes.NewBuffer(body))
	if err != nil {
		return req, fmt.Errorf("creating request: %s\n", err)
	}
	for _, option := range options {
		option(req)
	}
	userAgent(req)
	req.Header.Add("Accept", "application/json")
	return req, err
}
source: func (api *FlavorsAPI) Delete(flavorID string) (task *Task, err error) {
	res, err := api.client.restClient.Delete(api.client.Endpoint+flavorUrl+"/"+flavorID, api.client.options.TokenOptions)
	if err != nil {
		return
	}
	defer res.Body.Close()
	task, err = getTask(getError(res))
	return
}
source: func (b *BatchBuilder) AddWithPrefix(prefix string, builder Builder) *BatchBuilder {
	stmt, names := builder.ToCql()
	return b.AddStmtWithPrefix(prefix, stmt, names)
}
source: func (s *Transcript) SetTranscriptFileUri(v string) *Transcript {
	s.TranscriptFileUri = &v
	return s
}
source: func (c *Client) expect2XX(req *http.Request) (*http.Response, error) {
	res, err := c.doReqGated(req)
	if err == nil && (res.StatusCode < 200 || res.StatusCode > 299) {
		buf := new(bytes.Buffer)
		io.CopyN(buf, res.Body, 1<<20)
		res.Body.Close()
		return res, fmt.Errorf("client: got status code %d from URL %s; body %s", res.StatusCode, req.URL.String(), buf.String())
	}
	return res, err
} 76%|███████▌  | 3785/5000 [00:04<00:01, 1062.14it/s]
source: func (ns *Namespace) Format(layout string, v interface{}) (string, error) {
	t, err := cast.ToTimeE(v)
	if err != nil {
		return "", err
	}

	return t.Format(layout), nil
}
source: func (c *FakeComponentStatuses) Patch(name string, pt types.PatchType, data []byte, subresources ...string) (result *corev1.ComponentStatus, err error) {
	obj, err := c.Fake.
		Invokes(testing.NewRootPatchSubresourceAction(componentstatusesResource, name, pt, data, subresources...), &corev1.ComponentStatus{})
	if obj == nil {
		return nil, err
	}
	return obj.(*corev1.ComponentStatus), err
}
source: func Convert_security_AllowedFlexVolume_To_v1_AllowedFlexVolume(in *security.AllowedFlexVolume, out *v1.AllowedFlexVolume, s conversion.Scope) error {
	return autoConvert_security_AllowedFlexVolume_To_v1_AllowedFlexVolume(in, out, s)
}
source: func (ro *resourceOpener) OpenResource(name string) (o resource.Opened, err error) {
	if ro.unit == nil {
		return resource.Opened{}, errors.Errorf("missing unit")
	}
	app, err := ro.unit.Application()
	if err != nil {
		return resource.Opened{}, errors.Trace(err)
	}
	cURL, _ := ro.unit.CharmURL()
	id := csclient.CharmID{
		URL:     cURL,
		Channel: app.Channel(),
	}

	csOpener := newCharmstoreOpener(ro.st)
	client, err := csOpener.NewClient()
	if err != nil {
		return resource.Opened{}, errors.Trace(err)
	}

	cache := &charmstoreEntityCache{
		st:            ro.res,
		userID:        ro.userID,
		unit:          ro.unit,
		applicationID: ro.unit.ApplicationName(),
	}

	res, reader, err := charmstore.GetResource(charmstore.GetResourceArgs{
		Client:  client,
		Cache:   cache,
		CharmID: id,
		Name:    name,
	})
	if err != nil {
		return resource.Opened{}, errors.Trace(err)
	}

	opened := resource.Opened{
		Resource:   res,
		ReadCloser: reader,
	}
	return opened, nil
}
source: func (us *UndoStack) GlueFrom(mark int) {
	if mark >= us.position {
		return
	}
	var e Edit
	e.command = "sequence"
	type entry struct {
		name string
		args Args
	}
	e.v = us.actions[mark].v
	e.savedSel.AddAll(us.actions[mark].savedSel.Regions())

	entries := make([]entry, us.position-mark)
	for i := range entries {
		a := us.actions[i+mark]
		entries[i].name = a.command
		entries[i].args = a.args
		e.composite.Add(a)
	}
	us.position = mark
	us.actions = us.actions[:mark+1]
	e.args = make(Args)
	e.args["commands"] = entries
	us.Add(&e)
}
source: func (w *Writer) Init(target querypb.Target) error {
	if !w.enabled {
		return nil
	}
	w.mu.Lock()
	defer w.mu.Unlock()
	log.Info("Initializing heartbeat table.")
	w.dbName = sqlescape.EscapeID(w.dbconfigs.SidecarDBName.Get())
	w.keyspaceShard = fmt.Sprintf("%s:%s", target.Keyspace, target.Shard)
	err := w.initializeTables(w.dbconfigs.DbaWithDB())
	if err != nil {
		w.recordError(err)
		return err
	}

	return nil
}
source: func GetPackageRelease(pkg string) (string, error) {
	if utils.Platform == utils.Darwin {
		return "", nil
	}

	command := getCommandToGetPackageRelease(pkg)
	thecmd := exec.Command(command[0], command[1:]...)
	output, err := thecmd.CombinedOutput()
	if err != nil {
		e := fmt.Errorf("unable to retrieve release of package '%s' with command:'%s' output: %s  error: %s\n", pkg, command, output, err)
		return "", e
	}

	release := strings.TrimSuffix(string(output), "\n")
	return release, nil
}
source: func (t *TypedFuncs) DecisionFunc(decisionFunc interface{}) DecisionFunc {
	typeCheck(decisionFunc, []string{"*fsm.FSMContext", "*swf.HistoryEvent", t.typeArg()}, []string{"*swf.Decision"})
	return marshalledFunc{reflect.ValueOf(decisionFunc)}.decisionFunc
}
source: func (ps *ProviderSchema) SchemaForResourceAddr(addr addrs.Resource) (schema *configschema.Block, version uint64) {
	return ps.SchemaForResourceType(addr.Mode, addr.Type)
}
source: func (b *Builder) Union(unionTp string, unionCond *Builder) *Builder {
	var builder *Builder
	if b.optype != unionType {
		builder = &Builder{cond: NewCond()}
		builder.optype = unionType
		builder.dialect = b.dialect
		builder.selects = b.selects

		currentUnions := b.unions
		// erase sub unions (actually append to new Builder.unions)
		b.unions = nil

		for e := range currentUnions {
			currentUnions[e].builder.dialect = b.dialect
		}

		builder.unions = append(append(builder.unions, union{"", b}), currentUnions...)
	} else {
		builder = b
	}

	if unionCond != nil {
		if unionCond.dialect == "" && builder.dialect != "" {
			unionCond.dialect = builder.dialect
		}

		builder.unions = append(builder.unions, union{unionTp, unionCond})
	}

	return builder
}
source: func (o *ProvisioningTimeout) SetTimeoutAction(v *string) *ProvisioningTimeout {
	if o.TimeoutAction = v; o.TimeoutAction == nil {
		o.nullFields = append(o.nullFields, "TimeoutAction")
	}
	return o
}
source: func ReadTLSIdentityFromKeyPair(keyBytes, certBytes []byte, caCertsBytes [][]byte) (*Identity, error) {
	if len(keyBytes) == 0 {
		return nil, trace.BadParameter("missing private key")
	}

	if len(certBytes) == 0 {
		return nil, trace.BadParameter("missing certificate")
	}

	cert, err := tlsca.ParseCertificatePEM(certBytes)
	if err != nil {
		return nil, trace.Wrap(err, "failed to parse TLS certificate")
	}

	id, err := tlsca.FromSubject(cert.Subject)
	if err != nil {
		return nil, trace.Wrap(err)
	}

	if len(cert.Issuer.Organization) == 0 {
		return nil, trace.BadParameter("missing CA organization")
	}

	clusterName := cert.Issuer.Organization[0]
	if clusterName == "" {
		return nil, trace.BadParameter("misssing cluster name")
	}
	identity := &Identity{
		ID:              IdentityID{HostUUID: id.Username, Role: teleport.Role(id.Groups[0])},
		ClusterName:     clusterName,
		KeyBytes:        keyBytes,
		TLSCertBytes:    certBytes,
		TLSCACertsBytes: caCertsBytes,
		XCert:           cert,
	}
	// The passed in ciphersuites don't appear to matter here since the returned
	// *tls.Config is never actually used?
	_, err = identity.TLSConfig(utils.DefaultCipherSuites())
	if err != nil {
		return nil, trace.Wrap(err)
	}
	return identity, nil
}
source: func (r *Router) SubRouter(prefix string) *Router {
	router := newRouter()
	router.StrictSlash = r.StrictSlash
	router.path = r.path + prefix

	r.addRoute(newRoute(prefix, r.StrictSlash, true).All(router.serveHTTP))

	return router
}
source: func (e ServerError) ToStatus() (s keybase1.Status) {
	s.Code = StatusCodeServerError
	s.Name = "SERVER_ERROR"
	s.Desc = e.Error()
	return
}
source: func missingArg(o Option) *Error {
	return &Error{
		ErrorCode: MissingParameter,
		Name:      o.Name(),
		Err:       fmt.Errorf("missing parameter for %s", o.Name()),
	}
}
source: func ParseConsulCAConfig(raw map[string]interface{}) (*ConsulCAProviderConfig, error) {
	var config ConsulCAProviderConfig
	decodeConf := &mapstructure.DecoderConfig{
		DecodeHook:       mapstructure.StringToTimeDurationHookFunc(),
		Result:           &config,
		WeaklyTypedInput: true,
	}

	decoder, err := mapstructure.NewDecoder(decodeConf)
	if err != nil {
		return nil, err
	}

	if err := decoder.Decode(raw); err != nil {
		return nil, fmt.Errorf("error decoding config: %s", err)
	}

	return &config, nil
}
source: func (c *CachedStorageClassInfo) GetStorageClassInfo(className string) (*storagev1.StorageClass, error) {
	return c.Get(className)
}
source: func (i *Intervals) UnmarshalBinary(data []byte) (err error) {
	d := bytes.Split(data, []byte(";"))
	l := len(d)
	if l == 0 {
		return nil
	}
	if l >= 1 {
		i.start, err = strconv.ParseUint(string(d[0]), 36, 64)
		if err != nil {
			return err
		}
	}
	if l == 1 {
		return nil
	}

	i.ranges = make([][2]uint64, 0, l-1)
	for j := 1; j < l; j++ {
		r := bytes.SplitN(d[j], []byte(","), 2)
		if len(r) < 2 {
			return fmt.Errorf("range %d has less then 2 elements", j)
		}
		start, err := strconv.ParseUint(string(r[0]), 36, 64)
		if err != nil {
			return fmt.Errorf("parsing the first element in range %d: %v", j, err)
		}
		end, err := strconv.ParseUint(string(r[1]), 36, 64)
		if err != nil {
			return fmt.Errorf("parsing the second element in range %d: %v", j, err)
		}
		i.ranges = append(i.ranges, [2]uint64{start, end})
	}

	return nil
}
source: func extractOperationOptionFromMethodDescriptor(meth *pbdescriptor.MethodDescriptorProto) (*swagger_options.Operation, error) {
	if meth.Options == nil {
		return nil, nil
	}
	if !proto.HasExtension(meth.Options, swagger_options.E_Openapiv2Operation) {
		return nil, nil
	}
	ext, err := proto.GetExtension(meth.Options, swagger_options.E_Openapiv2Operation)
	if err != nil {
		return nil, err
	}
	opts, ok := ext.(*swagger_options.Operation)
	if !ok {
		return nil, fmt.Errorf("extension is %T; want an Operation", ext)
	}
	return opts, nil
}
source: func (s *SSD1306Driver) ShowImage(img image.Image) (err error) {
	if img.Bounds().Dx() != s.DisplayWidth || img.Bounds().Dy() != s.DisplayHeight {
		return errors.New("Image must match the display width and height")
	}

	s.Clear()
	for y, w, h := 0, img.Bounds().Dx(), img.Bounds().Dy(); y < h; y++ {
		for x := 0; x < w; x++ {
			c := img.At(x, y)
			if r, g, b, _ := c.RGBA(); r > 0 || g > 0 || b > 0 {
				s.Set(x, y, 1)
			}
		}
	}
	return s.Display()
}
source: func (forceApi *ForceApi) Query(query string, out interface{}) (err error) {
	uri := forceApi.apiResources[queryKey]

	params := url.Values{
		"q": {query},
	}

	err = forceApi.Get(uri, params, out)

	return
}
source: func PathsForCertAndKey(pkiPath, name string) (string, string) {
	return pathForCert(pkiPath, name), pathForKey(pkiPath, name)
}
source: func subClient(port int) {
	sock, err := sub.NewSocket()
	if err != nil {
		die("cannot make req socket: %v", err)
	}
	sock.AddTransport(ws.NewTransport())
	if err = sock.SetOption(mangos.OptionSubscribe, []byte{}); err != nil {
		die("cannot set subscription: %v", err)
	}
	url := fmt.Sprintf("ws://127.0.0.1:%d/sub", port)
	if err = sock.Dial(url); err != nil {
		die("cannot dial req url: %v", err)
	}
	if m, err := sock.Recv(); err != nil {
		die("Cannot recv sub: %v", err)
	} else {
		fmt.Printf("%s\n", string(m))
	}
}
source: func NewDispenserTokens(filename string, tokens []Token) Dispenser {
	return Dispenser{
		filename: filename,
		tokens:   tokens,
		cursor:   -1,
	}
}
source: func (conf *PluginConfig) Override(key string, value interface{}) {
	key = conf.registerKey(key)
	conf.Settings[key] = value
}
source: func NewNATSTarget(id string, args NATSArgs) (*NATSTarget, error) {
	var natsConn *nats.Conn
	var stanConn stan.Conn
	var clientID string
	var err error

	if args.Streaming.Enable {
		scheme := "nats"
		if args.Secure {
			scheme = "tls"
		}
		addressURL := scheme + "://" + args.Username + ":" + args.Password + "@" + args.Address.String()

		clientID, err = getNewUUID()
		if err != nil {
			return nil, err
		}

		connOpts := []stan.Option{stan.NatsURL(addressURL)}
		if args.Streaming.MaxPubAcksInflight > 0 {
			connOpts = append(connOpts, stan.MaxPubAcksInflight(args.Streaming.MaxPubAcksInflight))
		}

		stanConn, err = stan.Connect(args.Streaming.ClusterID, clientID, connOpts...)
	} else {
		options := nats.DefaultOptions
		options.Url = "nats://" + args.Address.String()
		options.User = args.Username
		options.Password = args.Password
		options.Token = args.Token
		options.Secure = args.Secure
		natsConn, err = options.Connect()
	}
	if err != nil {
		return nil, err
	}

	return &NATSTarget{
		id:       event.TargetID{ID: id, Name: "nats"},
		args:     args,
		stanConn: stanConn,
		natsConn: natsConn,
	}, nil
}
source: func convertNewlines(s []byte) []byte {
	for i, c := range s {
		if c != '\r' {
			continue
		}

		src := i + 1
		if src >= len(s) || s[src] != '\n' {
			s[i] = '\n'
			continue
		}

		dst := i
		for src < len(s) {
			if s[src] == '\r' {
				if src+1 < len(s) && s[src+1] == '\n' {
					src++
				}
				s[dst] = '\n'
			} else {
				s[dst] = s[src]
			}
			src++
			dst++
		}
		return s[:dst]
	}
	return s
}
source: func (s *Sleeper) nextWaker(block bool) *Waker {
	// Attempt to replenish the local list if it's currently empty.
	if s.localList == nil {
		for atomic.LoadPointer(&s.sharedList) == nil {
			// Fail request if caller requested that we
			// don't block.
			if !block {
				return nil
			}

			// Indicate to wakers that we're about to sleep,
			// this allows them to abort the wait by setting
			// waitingG back to zero (which we'll notice
			// before committing the sleep).
			atomic.StoreUintptr(&s.waitingG, preparingG)

			// Check if something was queued while we were
			// preparing to sleep. We need this interleaving
			// to avoid missing wake ups.
			if atomic.LoadPointer(&s.sharedList) != nil {
				atomic.StoreUintptr(&s.waitingG, 0)
				break
			}

			// Try to commit the sleep and report it to the
			// tracer as a select.
			//
			// gopark puts the caller to sleep and calls
			// commitSleep to decide whether to immediately
			// wake the caller up or to leave it sleeping.
			const traceEvGoBlockSelect = 24
			gopark(commitSleep, &s.waitingG, "sleeper", traceEvGoBlockSelect, 0)
		}

		// Pull the shared list out and reverse it in the local
		// list. Given that wakers push themselves in reverse
		// order, we fix things here.
		v := (*Waker)(atomic.SwapPointer(&s.sharedList, nil))
		for v != nil {
			cur := v
			v = v.next

			cur.next = s.localList
			s.localList = cur
		}
	}

	// Remove the waker in the front of the list.
	w := s.localList
	s.localList = w.next

	return w
}
source: func (j *JournalManager) enableLocked(
	ctx context.Context, tlfID tlf.ID, chargedTo keybase1.UserOrTeamID,
	bws TLFJournalBackgroundWorkStatus, allowEnableIfDirty bool) (
	tj *tlfJournal, err error) {
	j.log.CDebugf(ctx, "Enabling journal for %s (%s)", tlfID, bws)
	defer func() {
		if err != nil {
			j.deferLog.CDebugf(ctx,
				"Error when enabling journal for %s: %+v",
				tlfID, err)
		}
	}()

	if j.currentUID == keybase1.UID("") {
		return nil, errors.New("Current UID is empty")
	}
	if j.currentVerifyingKey == (kbfscrypto.VerifyingKey{}) {
		return nil, errors.New("Current verifying key is empty")
	}

	if tj, ok := j.tlfJournals[tlfID]; ok {
		err = tj.enable()
		if err != nil {
			return nil, err
		}
		return tj, nil
	}

	err = func() error {
		if j.dirtyOps[tlfID] > 0 {
			return errors.Errorf("Can't enable journal for %s while there "+
				"are outstanding dirty ops", tlfID)
		}
		if j.delegateDirtyBlockCache.IsAnyDirty(tlfID) {
			return errors.Errorf("Can't enable journal for %s while there "+
				"are any dirty blocks outstanding", tlfID)
		}
		return nil
	}()
	if err != nil {
		if !allowEnableIfDirty {
			return nil, err
		}

		j.log.CWarningf(ctx,
			"Got ignorable error on journal enable, and proceeding anyway: %+v",
			err)
	}

	tlfDir := j.tlfJournalPathLocked(tlfID)
	tj, err = makeTLFJournal(
		ctx, j.currentUID, j.currentVerifyingKey, tlfDir,
		tlfID, chargedTo, tlfJournalConfigAdapter{j.config},
		j.delegateBlockServer,
		bws, nil, j.onBranchChange, j.onMDFlush, j.config.DiskLimiter())
	if err != nil {
		return nil, err
	}

	return tj, nil
}
source: func (i *Handle) parseDestination(msg []byte) (*Destination, error) {
	var dst *Destination

	//Remove General header for this message
	hdr := deserializeGenlMsg(msg)
	NetLinkAttrs, err := nl.ParseRouteAttr(msg[hdr.Len():])
	if err != nil {
		return nil, err
	}
	if len(NetLinkAttrs) == 0 {
		return nil, fmt.Errorf("error no valid netlink message found while parsing destination record")
	}

	//Now Parse and get IPVS related attributes messages packed in this message.
	ipvsAttrs, err := nl.ParseRouteAttr(NetLinkAttrs[0].Value)
	if err != nil {
		return nil, err
	}

	//Assemble netlink attributes and create a Destination record
	dst, err = assembleDestination(ipvsAttrs)
	if err != nil {
		return nil, err
	}

	return dst, nil
}
source: func Convert_v1alpha1_Role_To_rbac_Role(in *v1alpha1.Role, out *rbac.Role, s conversion.Scope) error {
	return autoConvert_v1alpha1_Role_To_rbac_Role(in, out, s)
}
source: func (mw *GinJWTMiddleware) GetClaimsFromJWT(c *gin.Context) (MapClaims, error) {
	token, err := mw.ParseToken(c)

	if err != nil {
		return nil, err
	}

	if mw.SendAuthorization {
		if v, ok := c.Get("JWT_TOKEN"); ok {
			c.Header("Authorization", mw.TokenHeadName+" "+v.(string))
		}
	}

	claims := MapClaims{}
	for key, value := range token.Claims.(jwt.MapClaims) {
		claims[key] = value
	}

	return claims, nil
}
source: func getEncKeys(ctx *cli.Context) (map[string][]prefixSSEPair, *probe.Error) {
	sseServer := os.Getenv("MC_ENCRYPT")
	if prefix := ctx.String("encrypt"); prefix != "" {
		sseServer = prefix
	}

	sseKeys := os.Getenv("MC_ENCRYPT_KEY")
	if keyPrefix := ctx.String("encrypt-key"); keyPrefix != "" {
		if sseServer != "" && strings.Contains(keyPrefix, sseServer) {
			return nil, errConflictSSE(sseServer, keyPrefix).Trace(ctx.Args()...)
		}
		sseKeys = keyPrefix
	}

	encKeyDB, err := parseAndValidateEncryptionKeys(sseKeys, sseServer)
	if err != nil {
		return nil, err.Trace(sseKeys)
	}

	return encKeyDB, nil
}
source: func (s *Server) GetContainerProfiles(name string) ([]string, error) {
	container, _, err := s.GetContainer(name)
	if err != nil {
		return []string{}, errors.Trace(err)
	}
	return container.Profiles, nil
}
source: func (wc *WhisperClient) AddSymmetricKey(ctx *Context, key []byte) (string, error) {
	return wc.client.AddSymmetricKey(ctx.context, key)
}
source: func (db *DB) NewPutter(mode ModePut) *Putter {
	return &Putter{
		mode: mode,
		db:   db,
	}
}
source: func Delete(client *flickr.FlickrClient, id string) (*flickr.BasicResponse, error) {
	client.Init()
	client.EndpointUrl = flickr.API_ENDPOINT
	client.HTTPVerb = "POST"
	client.Args.Set("method", "flickr.photos.delete")
	client.Args.Set("photo_id", id)
	client.OAuthSign()

	response := &flickr.BasicResponse{}
	err := flickr.DoPost(client, response)
	return response, err
}
source: func NewCaptcha(opt Options) *Captcha {
	return &Captcha{
		SubURL:           opt.SubURL,
		URLPrefix:        opt.URLPrefix,
		FieldIdName:      opt.FieldIdName,
		FieldCaptchaName: opt.FieldCaptchaName,
		StdWidth:         opt.Width,
		StdHeight:        opt.Height,
		ChallengeNums:    opt.ChallengeNums,
		Expiration:       opt.Expiration,
		CachePrefix:      opt.CachePrefix,
		ColorPalette:     opt.ColorPalette,
	}
}
source: func newLock(action string) *Lock {
	l := &Lock{
		Action:   action,
		HostName: "unknown",
		UserName: "unknown",
		Time:     time.Now().Format(time.RFC3339),
		Status:   "Running",
	}
	if h, err := os.Hostname(); err == nil {
		l.HostName = h
	}
	if u, err := user.Current(); err == nil {
		l.UserName = u.Username
	}
	return l
}
source: func (f *flowBuf) putGoto(pos token.Pos, target string, b *block) {
	f.gotos[pos] = newFlowBlock(target, b)
}
source: func (r *Request) Body(v interface{}) *Request {
	var err error
	if r.err != nil {
		return r
	}
	r.body, err = json.Marshal(v)
	if err != nil {
		r.err = err
		return r
	}
	return r
}
source: func handleGetPass(r *Request) (interface{}, error) {
	fmt.Print(r.Args.One().MustString())
	data, err := terminal.ReadPassword(int(os.Stdin.Fd())) // stdin
	fmt.Println()
	if err != nil {
		return nil, err
	}
	return string(data), nil
}
source: func (o Oids) UniqBase() Oids {
	return o.uniq(func(a, b *Oid) bool {
		if b == nil {
			return a == nil
		} else {
			return b.Contains(a)
		}
	})
}
source: func (s *BulkEmailDestination) SetReplacementTags(v []*MessageTag) *BulkEmailDestination {
	s.ReplacementTags = v
	return s
}
source: func Rewrite(r Rewriter, node Node) Node {
	switch n := node.(type) {
	case *Query:
		n.Statements = Rewrite(r, n.Statements).(Statements)

	case Statements:
		for i, s := range n {
			n[i] = Rewrite(r, s).(Statement)
		}

	case *SelectStatement:
		n.Fields = Rewrite(r, n.Fields).(Fields)
		n.Dimensions = Rewrite(r, n.Dimensions).(Dimensions)
		n.Sources = Rewrite(r, n.Sources).(Sources)

		// Rewrite may return nil. Nil does not satisfy the Expr
		// interface. We only assert the rewritten result to be an
		// Expr if it is not nil:
		if cond := Rewrite(r, n.Condition); cond != nil {
			n.Condition = cond.(Expr)
		} else {
			n.Condition = nil
		}

	case *SubQuery:
		n.Statement = Rewrite(r, n.Statement).(*SelectStatement)

	case Fields:
		for i, f := range n {
			n[i] = Rewrite(r, f).(*Field)
		}

	case *Field:
		n.Expr = Rewrite(r, n.Expr).(Expr)

	case Dimensions:
		for i, d := range n {
			n[i] = Rewrite(r, d).(*Dimension)
		}

	case *Dimension:
		n.Expr = Rewrite(r, n.Expr).(Expr)

	case *BinaryExpr:
		n.LHS = Rewrite(r, n.LHS).(Expr)
		n.RHS = Rewrite(r, n.RHS).(Expr)

	case *ParenExpr:
		n.Expr = Rewrite(r, n.Expr).(Expr)

	case *Call:
		for i, expr := range n.Args {
			n.Args[i] = Rewrite(r, expr).(Expr)
		}
	}

	return r.Rewrite(node)
}
source: func (plugin *flexVolumePlugin) NewMounter(spec *volume.Spec, pod *api.Pod, _ volume.VolumeOptions) (volume.Mounter, error) {
	return plugin.newMounterInternal(spec, pod, plugin.host.GetMounter(plugin.GetPluginName()), plugin.runner)
}
source: func (s *CheckpointConfigurationUpdate) SetMinPauseBetweenCheckpointsUpdate(v int64) *CheckpointConfigurationUpdate {
	s.MinPauseBetweenCheckpointsUpdate = &v
	return s
}
source: func (p *SeriesPartition) FindIDTypedBySeriesKey(key []byte) SeriesIDTyped {
	p.mu.RLock()
	if p.closed {
		p.mu.RUnlock()
		return SeriesIDTyped{}
	}
	id := p.index.FindIDBySeriesKey(p.segments, key)
	p.mu.RUnlock()
	return id
}
source: func (sim *simra) AddSprite(s Spriter) {
	sp := s.(*sprite)
	err := sim.spritecontainer.AddSprite(&sp.Sprite, nil, nil)
	if err != nil {
		simlog.Errorf("failed to add sprite. err: %s", err.Error())
	}
}
source: func Version() *go_version.Version {
	cached.mutex.RLock()
	c := cached.version
	cached.mutex.RUnlock()
	return c
}
source: func writeTo(w io.Writer, s string) {
	w.Write([]byte(s + "\n"))
}
source: func (ln *LocalNode) UDPEndpointStatement(fromaddr, endpoint *net.UDPAddr) {
	ln.mu.Lock()
	defer ln.mu.Unlock()

	ln.udpTrack.AddStatement(fromaddr.String(), endpoint.String())
	ln.updateEndpoints()
}
source: func (c *syncClient) Move(arg0 string, arg1 int64) (result bool, err Error) {
	arg0bytes := []byte(arg0)
	arg1bytes := []byte(fmt.Sprintf("%d", arg1))

	var resp Response
	resp, err = c.conn.ServiceRequest(&MOVE, [][]byte{arg0bytes, arg1bytes})
	if err == nil {
		result = resp.GetBooleanValue()
	}
	return result, err

}
source: func (c *Container) IsRunning() bool {
	cc, err := c.Inspect()
	if err != nil {
		return false
	}

	return cc.State.Running
}
source: func (g *Generator) Render(templ string) ([]byte, error) {
	if g.loader == nil {
		g.loader = &symbols.Loader{Source: g.Starlark}
		g.links = map[string]*symbol{}
	}

	t, err := template.New("main").Funcs(g.funcMap()).Parse(templ)
	if err != nil {
		return nil, err
	}

	buf := bytes.Buffer{}
	if err := t.Execute(&buf, nil); err != nil {
		return nil, err
	}
	return buf.Bytes(), nil
}
source: func NewPushCommand(dockerCli command.Cli) *cobra.Command {
	var opts pushOptions

	cmd := &cobra.Command{
		Use:   "push [OPTIONS] NAME[:TAG]",
		Short: "Push an image or a repository to a registry",
		Args:  cli.ExactArgs(1),
		RunE: func(cmd *cobra.Command, args []string) error {
			opts.remote = args[0]
			return RunPush(dockerCli, opts)
		},
	}

	flags := cmd.Flags()

	command.AddTrustSigningFlags(flags, &opts.untrusted, dockerCli.ContentTrustEnabled())

	return cmd
}
source: func (daemon *Daemon) load(id string) (*container.Container, error) {
	container := daemon.newBaseContainer(id)

	if err := container.FromDisk(); err != nil {
		return nil, err
	}
	if err := label.ReserveLabel(container.ProcessLabel); err != nil {
		return nil, err
	}

	if container.ID != id {
		return container, fmt.Errorf("Container %s is stored at %s", container.ID, id)
	}

	return container, nil
}
source: func NewCmdStatus(name, baseCLIName, fullName string, f kcmdutil.Factory, streams genericclioptions.IOStreams) *cobra.Command {
	o := NewStatusOptions(streams)
	cmd := &cobra.Command{
		Use:     fmt.Sprintf("%s [-o dot | --suggest ]", StatusRecommendedName),
		Short:   "Show an overview of the current project",
		Long:    fmt.Sprintf(statusLong, baseCLIName),
		Example: fmt.Sprintf(statusExample, fullName),
		Run: func(cmd *cobra.Command, args []string) {
			kcmdutil.CheckErr(o.Complete(f, cmd, baseCLIName, args))
			kcmdutil.CheckErr(o.Validate())
			kcmdutil.CheckErr(o.RunStatus())
		},
	}
	cmd.Flags().StringVarP(&o.outputFormat, "output", "o", o.outputFormat, "Output format. One of: dot.")
	// TODO: remove verbose in 3.12
	// this is done to trick pflag into allowing the duplicate registration.  The local value here wins
	cmd.Flags().BoolVarP(&o.suggest, "v", "v", o.suggest, "See details for resolving issues.")
	cmd.Flags().MarkShorthandDeprecated("v", "Use --suggest instead.  Will be dropped in a future release")
	cmd.Flags().BoolVar(&o.suggest, "verbose", o.suggest, "See details for resolving issues.")
	cmd.Flags().MarkDeprecated("verbose", "Use --suggest instead.")
	cmd.Flags().MarkHidden("verbose")
	cmd.Flags().BoolVar(&o.suggest, "suggest", o.suggest, "See details for resolving issues.")
	cmd.Flags().BoolVarP(&o.allNamespaces, "all-namespaces", "A", o.allNamespaces, "If true, display status for all namespaces (must have cluster admin)")

	return cmd
}
source: func IsNotFoundError(err error) bool {
	es := err.Error()
	for _, str := range iptablesNotFoundStrings {
		if strings.Contains(es, str) {
			return true
		}
	}
	return false
}
source: func (o *OracleEnviron) DeleteMachineVnicSet(machineId string) error {
	if err := o.RemoveACLAndRules(machineId); err != nil {
		// A method not allowed error denotes that this feature
		// is not enabled. Probably a trial account, so not really an error
		if !oci.IsMethodNotAllowed(err) {
			return errors.Trace(err)
		}
	}
	name := o.client.ComposeName(o.namespace.Value(machineId))
	if err := o.client.DeleteVnicSet(name); err != nil {
		if !oci.IsNotFound(err) && !oci.IsMethodNotAllowed(err) {
			return err
		}
	}
	return nil
}
source: func RecommendedDefaultDeploymentControllerConfiguration(obj *kubectrlmgrconfigv1alpha1.DeploymentControllerConfiguration) {
	zero := metav1.Duration{}
	if obj.ConcurrentDeploymentSyncs == 0 {
		obj.ConcurrentDeploymentSyncs = 5
	}
	if obj.DeploymentControllerSyncPeriod == zero {
		obj.DeploymentControllerSyncPeriod = metav1.Duration{Duration: 30 * time.Second}
	}
}
source: func NewUnicodeLooseMD5(name string, _ map[string]string) (Vindex, error) {
	return &UnicodeLooseMD5{name: name}, nil
}
source: func (f *Flag) Get() bool {
	f.Lock()
	defer f.Unlock()
	return f.state
}
source: func (d *Datastore) DiskUsage() (uint64, error) {
	var du uint64
	err := filepath.Walk(d.path, func(p string, f os.FileInfo, err error) error {
		if err != nil {
			log.Println(err)
			return err
		}
		if f != nil {
			du += uint64(f.Size())
		}
		return nil
	})
	return du, err
}
source: func (s *Store) GetRecipients(context.Context, string) ([]string, error) {
	return nil, fmt.Errorf("not supported")
}
source: func (g Graph) OutboundEdges(node graph.Node, edgeKinds ...string) []graph.Edge {
	ret := []graph.Edge{}

	for _, n := range g.From(node) {
		edge := g.Edge(node, n)
		if edge == nil {
			continue
		}

		if len(edgeKinds) == 0 || g.EdgeKinds(edge).HasAny(edgeKinds...) {
			ret = append(ret, edge)
		}
	}

	return ret
}
source: func (fc *FeatureCollection) Append(feature *Feature) *FeatureCollection {
	fc.Features = append(fc.Features, feature)
	return fc
}
source: func (as AtomicWebSocketSet) Get(userID uint64) *websocket.Conn {
	var conn *websocket.Conn
	as.mutex.Lock()
	conn = as.sockets[userID]
	as.mutex.Unlock()
	runtime.Gosched()
	return conn
}
source: func Iterate(val Value, it Iteratee) (int, error) {
	if val == nil {
		return 0, nil
	}
	r := reflect.Indirect(reflect.ValueOf(val))
	switch r.Kind() {
	case reflect.Slice, reflect.Array:
		ln := r.Len()
		l := Loop{ln == 1, 1, 0}
		for i := 0; i < ln; i++ {
			v := r.Index(i)
			brk, err := it(i, v.Interface(), l)
			if brk || err != nil {
				return i + 1, err
			}

			l.Index++
			l.Index0++
			l.Last = ln == l.Index
		}
		return ln, nil
	case reflect.Map:
		keys := r.MapKeys()
		ln := r.Len()
		l := Loop{ln == 1, 1, 0}
		for i, k := range keys {
			v := r.MapIndex(k)
			brk, err := it(k.Interface(), v.Interface(), l)
			if brk || err != nil {
				return i + 1, err
			}

			l.Index++
			l.Index0++
			l.Last = ln == l.Index
		}
		return ln, nil
	default:
		return 0, fmt.Errorf(`stick: unable to iterate over %s "%v"`, r.Kind(), val)
	}
}
source: func ExtractUserToken(opts ...interface{}) *opt.UserTokenOption {
	for _, o := range opts {
		if v, ok := o.(*opt.UserTokenOption); ok {
			return v
		}
	}
	return nil
}
source: func (m *Machine) WatchUpgradeSeriesNotifications() (NotifyWatcher, error) {
	watch := newEntityWatcher(m.st, machineUpgradeSeriesLocksC, m.doc.DocID)
	if _, ok := <-watch.Changes(); ok {
		return watch, nil
	}

	return nil, watcher.EnsureErr(watch)
}
source: func Check(g Iterator) Stats {
	if g, ok := g.(*Immutable); ok {
		return g.stats
	}
	_, mutable := g.(*Mutable)

	n := g.Order()
	degree := make([]int, n)
	type edge struct{ v, w int }
	edges := make(map[edge]bool)
	var stats Stats
	for v := 0; v < n; v++ {
		g.Visit(v, func(w int, c int64) (skip bool) {
			if w < 0 || w >= n {
				panic("vertex out of range: " + strconv.Itoa(w))
			}
			if v == w {
				stats.Loops++
			}
			if c != 0 {
				stats.Weighted++
			}
			degree[v]++
			if mutable { // A Mutable is never a multigraph.
				stats.Size++
				return
			}
			if edges[edge{v, w}] {
				stats.Multi++
			} else {
				stats.Size++
			}
			edges[edge{v, w}] = true
			return
		})
	}
	for _, deg := range degree {
		if deg == 0 {
			stats.Isolated++
		}
	}
	return stats
}
source: func (s *testSuiteStack) Push(data *api.TestSuite) {
	newNode := &testSuiteNode{
		Member: data,
		Next:   s.head,
	}
	s.head = newNode
}
source: func (c *Client) Chmod(name string, perm os.FileMode) error {
	req := &hdfs.SetPermissionRequestProto{
		Src:        proto.String(name),
		Permission: &hdfs.FsPermissionProto{Perm: proto.Uint32(uint32(perm))},
	}
	resp := &hdfs.SetPermissionResponseProto{}

	err := c.namenode.Execute("setPermission", req, resp)
	if err != nil {
		return &os.PathError{"chmod", name, interpretException(err)}
	}

	return nil
}
source: func (o *DomainTemplate) PolicyGroupTemplates(info *bambou.FetchingInfo) (PolicyGroupTemplatesList, *bambou.Error) {

	var list PolicyGroupTemplatesList
	err := bambou.CurrentSession().FetchChildren(o, PolicyGroupTemplateIdentity, &list, info)
	return list, err
}
source: func (d DefaultRetryer) shouldThrottle(r *request.Request) bool {
	switch r.HTTPResponse.StatusCode {
	case 429:
	case 502:
	case 503:
	case 504:
	default:
		return r.IsErrorThrottle()
	}

	return true
}
source: func (r *Response) SetErrorUri(id string, description string, uri string, state string) {
	// get default error message
	if description == "" {
		description = deferror.Get(id)
	}

	// set error parameters
	r.IsError = true
	r.ErrorId = id
	r.StatusCode = r.ErrorStatusCode
	if r.StatusCode != 200 {
		r.StatusText = description
	} else {
		r.StatusText = ""
	}
	r.Output = make(ResponseData) // clear output
	r.Output["error"] = id
	r.Output["error_description"] = description
	if uri != "" {
		r.Output["error_uri"] = uri
	}
	if state != "" {
		r.Output["state"] = state
	}
}
source: func (q *Query) WithMetrics(m metrics.Metrics) *Query {
	q.metrics = m
	return q
}
source: func FoldConstant(ctx context.Context, expr Expression) Expression {
	scalarFunc, ok := expr.(*ScalarFunction)
	if !ok {
		return expr
	}
	if _, isDynamic := DynamicFuncs[scalarFunc.FuncName.L]; isDynamic {
		return expr
	}
	args := scalarFunc.GetArgs()
	canFold := true
	for i := 0; i < len(args); i++ {
		foldedArg := FoldConstant(ctx, args[i])
		scalarFunc.GetArgs()[i] = foldedArg
		if _, ok := foldedArg.(*Constant); !ok {
			canFold = false
		}
	}
	if !canFold {
		return expr
	}
	value, err := scalarFunc.Eval(nil, ctx)
	if err != nil {
		log.Printf("There may exist an error during constant folding. The function name is %s, args are %s", scalarFunc.FuncName, args)
		return expr
	}
	return &Constant{
		Value:   value,
		RetType: scalarFunc.RetType,
	}
}
source: func (c Context) Durs(key string, d []time.Duration) Context {
	c.l.context = enc.AppendDurations(enc.AppendKey(c.l.context, key), d, DurationFieldUnit, DurationFieldInteger)
	return c
}
source: func (s *VPNService) NewUpdateRemoteAccessVpnParams(id string) *UpdateRemoteAccessVpnParams {
	p := &UpdateRemoteAccessVpnParams{}
	p.p = make(map[string]interface{})
	p.p["id"] = id
	return p
}
source: func (i *AgentIPC) handleStats(client *IPCClient, seq uint64) error {
	header := responseHeader{
		Seq:   seq,
		Error: "",
	}
	resp := i.agent.Stats()
	return client.Send(&header, resp)
}
source: func (mr *MockSecretAPIClientMockRecorder) SecretCreate(ctx, secret interface{}) *gomock.Call {
	return mr.mock.ctrl.RecordCallWithMethodType(mr.mock, "SecretCreate", reflect.TypeOf((*MockSecretAPIClient)(nil).SecretCreate), ctx, secret)
}
source: func (in *LoadBalancerAccessSpec) DeepCopy() *LoadBalancerAccessSpec {
	if in == nil {
		return nil
	}
	out := new(LoadBalancerAccessSpec)
	in.DeepCopyInto(out)
	return out
}
source: func (w *KubeWaiter) WaitForStaticPodControlPlaneHashes(nodeName string) (map[string]string, error) {

	componentHash := ""
	var err error
	mirrorPodHashes := map[string]string{}
	for _, component := range constants.ControlPlaneComponents {
		err = wait.PollImmediate(constants.APICallRetryInterval, w.timeout, func() (bool, error) {
			componentHash, err = getStaticPodSingleHash(w.client, nodeName, component)
			if err != nil {
				return false, nil
			}
			return true, nil
		})
		if err != nil {
			return nil, err
		}
		mirrorPodHashes[component] = componentHash
	}

	return mirrorPodHashes, nil
}
source: func (s *DB) Count(value interface{}) *DB {
	return s.NewScope(s.Value).count(value).db
}
source: func (s *DescribeClusterSnapshotsInput) SetClusterExists(v bool) *DescribeClusterSnapshotsInput {
	s.ClusterExists = &v
	return s
}
source: func (p *PodContainer) GPUs(gpu int32) *PodContainer {
	p.Resources.Gpus = gpu
	return p
}
source: func handleLUCIBuildLegacy(c *router.Context, bucket, builder, numberOrId string) error {
	var address string
	if strings.HasPrefix(numberOrId, "b") {
		address = numberOrId[1:]
	} else {
		address = fmt.Sprintf("%s/%s/%s", bucket, builder, numberOrId)
	}

	build, err := buildbucket.GetBuildLegacy(c.Context, address, true)
	return renderBuildLegacy(c, build, true, err)
}
source: func Transform(extensions map[string]interface{}) map[string]interface{} {
	if extensions == nil {
		return nil
	}
	out := make(map[string]interface{}, len(extensions))
	for name, payload := range extensions {
		transform, ok := transformers[name]
		if !ok {
			// No transformer registered, skip.
			continue
		}
		transformedPayload := transform(payload)
		if transformedPayload == nil {
			// Transformer returned nothing, skip.
			continue
		}
		out[name] = transformedPayload
	}
	return out
}
source: func tagImportable(tagRef imagev1.TagReference) bool {
	return !(tagRef.From == nil || tagRef.From.Kind != "DockerImage" || tagRef.Reference)
}
source: func (api *APIBase) setCharmWithAgentValidation(
	params setCharmParams,
	url string,
) error {
	curl, err := charm.ParseURL(url)
	if err != nil {
		return errors.Trace(err)
	}
	newCharm, err := api.backend.Charm(curl)
	if err != nil {
		return errors.Trace(err)
	}
	if api.modelType == state.ModelTypeCAAS {
		return api.applicationSetCharm(params, newCharm)
	}

	application := params.Application
	// Check if the controller agent tools version is greater than the
	// version we support for the new LXD profiles.
	// Then check all the units, to see what their agent tools versions is
	// so that we can ensure that everyone is aligned. If the units version
	// is too low (i.e. less than the 2.6.0 epoch), then show an error
	// message that the operator should upgrade to receive the latest
	// LXD Profile changes.

	// Ensure that we only check agent versions of a charm when we have a
	// non-empty profile. So this check will only be run in the following
	// scenarios; adding a profile, upgrading a profile. Removal of a
	// profile, that had an existing charm, will check if there is currently
	// an existing charm and if so, run the check.
	// Checking that is possible, but that would require asking every unit
	// machines what profiles they currently have and matching with the
	// incoming update. This could be very costly when you have lots of
	// machines.
	currentCharm, _, err := application.Charm()
	if err != nil {
		logger.Debugf("Unable to locate current charm: %v", err)
	}
	if lxdprofile.NotEmpty(lxdCharmProfiler{Charm: currentCharm}) ||
		lxdprofile.NotEmpty(lxdCharmProfiler{Charm: newCharm}) {
		if err := validateAgentVersions(application, api.model); err != nil {
			return errors.Trace(err)
		}
	}

	return api.applicationSetCharm(params, newCharm)
}
source: func (b *SystemBackend) handleAuditedHeaderDelete(ctx context.Context, req *logical.Request, d *framework.FieldData) (*logical.Response, error) {
	header := d.Get("header").(string)
	if header == "" {
		return logical.ErrorResponse("missing header name"), nil
	}

	headerConfig := b.Core.AuditedHeadersConfig()
	err := headerConfig.remove(ctx, header)
	if err != nil {
		return nil, err
	}

	return nil, nil
}
source: func (t *stiTar) CreateTarStreamToTarWriter(dir string, includeDirInPath bool, tarWriter Writer, logger io.Writer) error {
	dir = filepath.Clean(dir) // remove relative paths and extraneous slashes
	glog.V(5).Infof("Adding %q to tar ...", dir)
	err := t.Walk(dir, func(path string, info os.FileInfo, err error) error {
		if err != nil {
			return err
		}
		// on Windows, directory symlinks report as a directory and as a symlink.
		// They should be treated as symlinks.
		if !t.shouldExclude(path) {
			// if file is a link just writing header info is enough
			if info.Mode()&os.ModeSymlink != 0 {
				if dir == path {
					return nil
				}
				if err = t.writeTarHeader(tarWriter, dir, path, info, includeDirInPath, logger); err != nil {
					glog.Errorf("Error writing header for %q: %v", info.Name(), err)
				}
				// on Windows, filepath.Walk recurses into directory symlinks when it
				// shouldn't.  https://github.com/golang/go/issues/17540
				if err == nil && info.Mode()&os.ModeDir != 0 {
					return filepath.SkipDir
				}
				return err
			}
			if info.IsDir() {
				if dir == path {
					return nil
				}
				if err = t.writeTarHeader(tarWriter, dir, path, info, includeDirInPath, logger); err != nil {
					glog.Errorf("Error writing header for %q: %v", info.Name(), err)
				}
				return err
			}

			// regular files are copied into tar, if accessible
			file, err := os.Open(path)
			if err != nil {
				glog.Errorf("Ignoring file %s: %v", path, err)
				return nil
			}
			defer file.Close()
			if err = t.writeTarHeader(tarWriter, dir, path, info, includeDirInPath, logger); err != nil {
				glog.Errorf("Error writing header for %q: %v", info.Name(), err)
				return err
			}
			if _, err = io.Copy(tarWriter, file); err != nil {
				glog.Errorf("Error copying file %q to tar: %v", path, err)
				return err
			}
		}
		return nil
	})

	if err != nil {
		glog.Errorf("Error writing tar: %v", err)
		return err
	}

	return nil
}
source: func (e *element) isEqual(e2 *element) bool {
	return (e.index == e2.index) &&
		(&e.hash).IsEqual(&e2.hash)
}
source: func (s *Transport) WaitReceiveChannel() (libchan.Receiver, error) {
	r, ok := <-s.receiverChan
	if !ok {
		return nil, io.EOF
	}

	return r, nil
}
source: func (p *ProxyWriter) Flush() {
	if f, ok := p.w.(http.Flusher); ok {
		f.Flush()
	}
}
source: func assertGetDatagram(le *logpb.LogEntry) *logpb.Datagram {
	if dg := le.GetDatagram(); dg == nil {
		panic(
			errors.Annotate(
				InvalidStreamType,
				fmt.Sprintf("got %T, expected *logpb.LogEntry_Datagram", le.Content),
			).Err(),
		)
	} else {
		return dg
	}
}
source: func (n *Node) ResolvePath(x string) string {
	return n.config.ResolvePath(x)
}
source: func attachSecret(plug *sioPlugin, namespace string, configData map[string]string) error {
	// load secret
	secretRefName := configData[confKey.secretName]
	kubeClient := plug.host.GetKubeClient()
	secretMap, err := volutil.GetSecretForPV(namespace, secretRefName, sioPluginName, kubeClient)
	if err != nil {
		klog.Error(log("failed to get secret: %v", err))
		return secretNotFoundErr
	}
	// merge secret data
	for key, val := range secretMap {
		configData[key] = val
	}

	return nil
}
source: func (k *kubernetesClient) ensureConfigMap(configMap *core.ConfigMap) error {
	configMaps := k.client().CoreV1().ConfigMaps(k.namespace)
	_, err := configMaps.Update(configMap)
	if k8serrors.IsNotFound(err) {
		_, err = configMaps.Create(configMap)
	}
	return errors.Trace(err)
}
source: func Convert_route_TLSConfig_To_v1_TLSConfig(in *route.TLSConfig, out *v1.TLSConfig, s conversion.Scope) error {
	return autoConvert_route_TLSConfig_To_v1_TLSConfig(in, out, s)
}
source: func NewServer(addr string, group []*Config) (*Server, error) {

	s := &Server{
		Addr:         addr,
		zones:        make(map[string]*Config),
		graceTimeout: 5 * time.Second,
	}

	// We have to bound our wg with one increment
	// to prevent a "race condition" that is hard-coded
	// into sync.WaitGroup.Wait() - basically, an add
	// with a positive delta must be guaranteed to
	// occur before Wait() is called on the wg.
	// In a way, this kind of acts as a safety barrier.
	s.dnsWg.Add(1)

	for _, site := range group {
		if site.Debug {
			s.debug = true
			log.D = true
		}
		// set the config per zone
		s.zones[site.Zone] = site

		// compile custom plugin for everything
		var stack plugin.Handler
		for i := len(site.Plugin) - 1; i >= 0; i-- {
			stack = site.Plugin[i](stack)

			// register the *handler* also
			site.registerHandler(stack)

			if s.trace == nil && stack.Name() == "trace" {
				// we have to stash away the plugin, not the
				// Tracer object, because the Tracer won't be initialized yet
				if t, ok := stack.(trace.Trace); ok {
					s.trace = t
				}
			}
			// Unblock CH class queries when any of these plugins are loaded.
			if _, ok := EnableChaos[stack.Name()]; ok {
				s.classChaos = true
			}
		}
		site.pluginChain = stack
	}

	return s, nil
}
source: func (v *TimeIsBeforeTime) IsValid(errors *validate.Errors) {
	if v.FirstTime.UnixNano() <= v.SecondTime.UnixNano() {
		return
	}

	if len(v.Message) > 0 {
		errors.Add(GenerateKey(v.FirstName), v.Message)
		return
	}

	errors.Add(GenerateKey(v.FirstName), fmt.Sprintf("%s must be before %s.", v.FirstName, v.SecondName))
}
source: func (a *HostAgent) addStorageTenant(tenantID string) {
	for _, tid := range a.storageTenants {
		if tid == tenantID {
			return
		}
	}
	a.storageTenants = append(a.storageTenants, tenantID)
}
source: func (o *CreateParams) WithTimeout(timeout time.Duration) *CreateParams {
	o.SetTimeout(timeout)
	return o
}
source: func CidrNetmask(prefix cty.Value) (cty.Value, error) {
	return CidrNetmaskFunc.Call([]cty.Value{prefix})
}
source: func decapitalise(input string) string {
	if len(input) == 0 {
		return input
	}

	goForm := abi.ToCamelCase(input)
	return strings.ToLower(goForm[:1]) + goForm[1:]
}
source: func (f *Registry) ListDetails() []Details {
	names := make([]string, 0, len(f.facades))
	for name := range f.facades {
		names = append(names, name)
	}
	sort.Strings(names)
	var details []Details
	for _, name := range names {
		for v, info := range f.facades[name] {
			details = append(details, Details{
				Name:    name,
				Version: v,
				Factory: info.factory,
				Type:    info.facadeType,
			})
		}
	}
	return details
}
source: func NewHandler(config HandlerConfig) (http.Handler, error) {
	if config.GetDeviceKeysByDevEUIFunc == nil {
		return nil, errors.New("backend/joinserver: GetDeviceKeysFunc must not be nil")
	}

	h := handler{
		config: config,
		log:    config.Logger,
	}

	if h.log == nil {
		h.log = &log.Logger{
			Out: ioutil.Discard,
		}
	}

	if h.config.GetKEKByLabelFunc == nil {
		h.log.Warning("backend/joinserver: get kek by label function is not set")

		h.config.GetKEKByLabelFunc = func(label string) ([]byte, error) {
			return nil, nil
		}
	}

	if h.config.GetASKEKLabelByDevEUIFunc == nil {
		h.log.Warning("backend/joinserver: get application-server kek by deveui function is not set")

		h.config.GetASKEKLabelByDevEUIFunc = func(devEUI lorawan.EUI64) (string, error) {
			return "", nil
		}
	}

	return &h, nil
}
source: func (a SizeLayerAnalyzer) Diff(image1, image2 pkgutil.Image) (util.Result, error) {
	var layerDiffs []util.SizeDiff

	maxLayer := len(image1.Layers)
	if len(image2.Layers) > maxLayer {
		maxLayer = len(image2.Layers)
	}

	for index := 0; index < maxLayer; index++ {
		var size1, size2 int64 = -1, -1
		if index < len(image1.Layers) {
			size1 = pkgutil.GetSize(image1.Layers[index].FSPath)
		}
		if index < len(image2.Layers) {
			size2 = pkgutil.GetSize(image2.Layers[index].FSPath)
		}

		if size1 != size2 {
			diff := util.SizeDiff{
				Name:  strconv.Itoa(index),
				Size1: size1,
				Size2: size2,
			}
			layerDiffs = append(layerDiffs, diff)
		}
	}

	return &util.SizeLayerDiffResult{
		Image1:   image1.Source,
		Image2:   image2.Source,
		DiffType: "SizeLayer",
		Diff:     layerDiffs,
	}, nil
}
source: func (f *FakeCustomStore) Update(obj interface{}) error {
	if f.UpdateFunc != nil {
		return f.UpdateFunc(obj)
	}
	return nil
}
source: func (c *client) sendRouteUnSubProtos(subs []*subscription, trace bool, filter func(sub *subscription) bool) bool {
	return c.sendRouteSubOrUnSubProtos(subs, false, trace, filter)
}
source: func (s *NotificationConfigurationDeprecated) SetQueueConfiguration(v *QueueConfigurationDeprecated) *NotificationConfigurationDeprecated {
	s.QueueConfiguration = v
	return s
}
source: func Resample(ls orb.LineString, df orb.DistanceFunc, totalPoints int) orb.LineString {
	if totalPoints <= 0 {
		return nil
	}

	ls, ret := resampleEdgeCases(ls, totalPoints)
	if ret {
		return ls
	}

	// precomputes the total distance and intermediate distances
	total, dists := precomputeDistances(ls, df)
	return resample(ls, dists, total, totalPoints)
}
source: func (c *Client) GetReceivedByAccountMinConf(account string, minConfirms int) (btcutil.Amount, error) {
	return c.GetReceivedByAccountMinConfAsync(account, minConfirms).Receive()
}
source: func (lc *LightningChannel) AckAddHtlcs(addRef channeldb.AddRef) error {
	return lc.channelState.AckAddHtlcs(addRef)
}
source: func (r Rect) Intersection(other Rect) Rect {
	lat := r.Lat.Intersection(other.Lat)
	lng := r.Lng.Intersection(other.Lng)

	if lat.IsEmpty() || lng.IsEmpty() {
		return EmptyRect()
	}
	return Rect{lat, lng}
}
source: func (mr *MockRemoteBindingListenerMockRecorder) OnUserBind(uid, fid interface{}) *gomock.Call {
	return mr.mock.ctrl.RecordCallWithMethodType(mr.mock, "OnUserBind", reflect.TypeOf((*MockRemoteBindingListener)(nil).OnUserBind), uid, fid)
}
source: func (s *RegionService) NewUpdateRegionParams(id int) *UpdateRegionParams {
	p := &UpdateRegionParams{}
	p.p = make(map[string]interface{})
	p.p["id"] = id
	return p
}
source: func Upgrade(client kubernetes.Interface, opts *Options) error {
	obj, err := client.ExtensionsV1beta1().Deployments(opts.Namespace).Get(deploymentName, metav1.GetOptions{})
	if err != nil {
		return err
	}
	tillerImage := obj.Spec.Template.Spec.Containers[0].Image
	if semverCompare(tillerImage) == -1 && !opts.ForceUpgrade {
		return errors.New("current Tiller version is newer, use --force-upgrade to downgrade")
	}
	obj.Spec.Template.Spec.Containers[0].Image = opts.SelectImage()
	obj.Spec.Template.Spec.Containers[0].ImagePullPolicy = opts.pullPolicy()
	obj.Spec.Template.Spec.ServiceAccountName = opts.ServiceAccount
	if _, err := client.ExtensionsV1beta1().Deployments(opts.Namespace).Update(obj); err != nil {
		return err
	}
	// If the service does not exist that would mean we are upgrading from a Tiller version
	// that didn't deploy the service, so install it.
	_, err = client.CoreV1().Services(opts.Namespace).Get(serviceName, metav1.GetOptions{})
	if apierrors.IsNotFound(err) {
		return createService(client.CoreV1(), opts.Namespace)
	}
	return err
}
source: func PackInt64(cmd BufferEx, val int64) (int, error) {
	return packAInt64(cmd, val)
}
source: func ConvertStringToKind(k string) (*Kind, error) {
	kind := Kind(k)
	switch kind {
	case KindString, KindInteger, KindFloat, KindInstant, KindURL, KindUser, KindEnum, KindList, KindIteration, KindMarkup, KindArea, KindCodebase, KindLabel, KindBoardColumn, KindBoolean, KindRemoteTracker:
		return &kind, nil
	}
	return nil, errs.Errorf("kind '%s' is not a simple type", k)
}
source: func New(dir string) *Agent {
	a := &Agent{
		socket: filepath.Join(dir, ".gopass-agent.sock"),
		cache: &cache{
			ttl:    time.Hour,
			maxTTL: 24 * time.Hour,
		},
		pinentry: func() (piner, error) {
			return pinentry.New()
		},
	}
	mux := http.NewServeMux()
	mux.HandleFunc("/ping", a.servePing)
	mux.HandleFunc("/passphrase", a.servePassphrase)
	mux.HandleFunc("/cache/remove", a.serveRemove)
	mux.HandleFunc("/cache/purge", a.servePurge)
	a.server = &http.Server{
		Handler: mux,
	}
	return a
}
source: func (m *Manager) becomeFollower() {
	// The following components are gRPC services that are
	// registered when creating the manager and will need
	// to be re-registered if they are recreated.
	// For simplicity, they are not nilled out.
	m.dispatcher.Stop()
	m.logbroker.Stop()
	m.caserver.Stop()

	if m.allocator != nil {
		m.allocator.Stop()
		m.allocator = nil
	}

	m.constraintEnforcer.Stop()
	m.constraintEnforcer = nil

	m.replicatedOrchestrator.Stop()
	m.replicatedOrchestrator = nil

	m.globalOrchestrator.Stop()
	m.globalOrchestrator = nil

	m.taskReaper.Stop()
	m.taskReaper = nil

	m.scheduler.Stop()
	m.scheduler = nil

	m.roleManager.Stop()
	m.roleManager = nil

	if m.keyManager != nil {
		m.keyManager.Stop()
		m.keyManager = nil
	}
}
source: func CreateSelectorFromLabels(aL map[string]string) labels.Selector {
	if aL == nil || len(aL) == 0 {
		return labels.Everything()
	}
	return labels.Set(aL).AsSelector()
}
source: func NewClientWithCache(caller base.APICallCloser, cache *MacaroonCache) *Client {
	frontend, backend := base.NewClientFacade(caller, "CrossModelRelations")
	return &Client{
		ClientFacade: frontend,
		facade:       backend,
		cache:        cache,
	}
}
source: func LoadTextureRW(renderer *sdl.Renderer, src *sdl.RWops, freesrc bool) (*sdl.Texture, error) {
	_renderer := (*C.SDL_Renderer)(unsafe.Pointer(renderer))
	_src := (*C.SDL_RWops)(unsafe.Pointer(src))
	_freesrc := (C.int)(sdl.Btoi(freesrc))
	_surface := C.IMG_LoadTexture_RW(_renderer, _src, _freesrc)
	if _surface == nil {
		return nil, GetError()
	}
	return (*sdl.Texture)(unsafe.Pointer(_surface)), nil
} 78%|███████▊  | 3922/5000 [00:04<00:00, 1141.96it/s]
source: func (e *endpoint) Close() {
	// Tell dispatch goroutine to stop, then write to the eventfd so that
	// it wakes up in case it's sleeping.
	atomic.StoreUint32(&e.stopRequested, 1)
	syscall.Write(e.rx.eventFD, []byte{1, 0, 0, 0, 0, 0, 0, 0})

	// Cleanup the queues inline if the worker hasn't started yet; we also
	// know it won't start from now on because stopRequested is set to 1.
	e.mu.Lock()
	workerPresent := e.workerStarted
	e.mu.Unlock()

	if !workerPresent {
		e.tx.cleanup()
		e.rx.cleanup()
	}
}
source: func (c *ChainIndexer) setSectionHead(section uint64, hash common.Hash) {
	var data [8]byte
	binary.BigEndian.PutUint64(data[:], section)

	c.indexDb.Put(append([]byte("shead"), data[:]...), hash.Bytes())
}
source: func (nc *Conn) checkDrained(sub *Subscription) {
	if nc == nil || sub == nil {
		return
	}

	// This allows us to know that whatever we have in the client pending
	// is correct and the server will not send additional information.
	nc.Flush()

	// Once we are here we just wait for Pending to reach 0 or
	// any other state to exit this go routine.
	for {
		// check connection is still valid.
		if nc.IsClosed() {
			return
		}

		// Check subscription state
		sub.mu.Lock()
		conn := sub.conn
		closed := sub.closed
		pMsgs := sub.pMsgs
		sub.mu.Unlock()

		if conn == nil || closed || pMsgs == 0 {
			nc.mu.Lock()
			nc.removeSub(sub)
			nc.mu.Unlock()
			return
		}

		time.Sleep(100 * time.Millisecond)
	}
}
source: func (s *SnapshotService) ListVMSnapshot(p *ListVMSnapshotParams) (*ListVMSnapshotResponse, error) {
	resp, err := s.cs.newRequest("listVMSnapshot", p.toURLValues())
	if err != nil {
		return nil, err
	}

	var r ListVMSnapshotResponse
	if err := json.Unmarshal(resp, &r); err != nil {
		return nil, err
	}

	return &r, nil
}
source: func (s *Snapshotter) snapshotMaxSize() int64 {
	nodes := int64(len(s.aliveNodes))
	estSize := nodes * snapshotBytesPerNode
	threshold := estSize * snapshotCompactionThreshold

	// Apply a minimum threshold to avoid frequent compaction
	if threshold < s.minCompactSize {
		threshold = s.minCompactSize
	}
	return threshold
}
source: func Convert_networking_NetworkPolicyPort_To_v1_NetworkPolicyPort(in *networking.NetworkPolicyPort, out *v1.NetworkPolicyPort, s conversion.Scope) error {
	return autoConvert_networking_NetworkPolicyPort_To_v1_NetworkPolicyPort(in, out, s)
}
source: func (c *CloudAPI) DeleteMachineMetadata(machineID string, key string) error {
	machine, err := c.GetMachine(machineID)
	if err != nil {
		return err
	}

	_, ok := machine.Metadata[key]
	if !ok {
		return fmt.Errorf(`"%s" is not a metadata key`, key)
	}

	delete(machine.Metadata, key)
	return nil
}
source: func (s *Patch) SetMsrcSeverity(v string) *Patch {
	s.MsrcSeverity = &v
	return s
}
source: func (set StringSet) Equals(sset StringSet) bool {
	// If length of set is not equal to length of given set, the
	// set is not equal to given set.
	if len(set) != len(sset) {
		return false
	}

	// As both sets are equal in length, check each elements are equal.
	for k := range set {
		if _, ok := sset[k]; !ok {
			return false
		}
	}

	return true
}
source: func (m *Manager) SavePublicKey(username string, key PublicKey) error {
	if err := m.RemovePublicKey(username, key.Label); err != nil {
		return err
	}
	return m.getUserCollection().Update(
		bson.M{"username": username},
		bson.M{"$push": bson.M{"publickeys": key}})
}
source: func getPluginMap(pluginType string, logger log.Logger) map[string]plugin.Plugin {
	pmap := map[string]plugin.Plugin{
		base.PluginTypeBase: &base.PluginBase{},
	}

	switch pluginType {
	case base.PluginTypeDevice:
		pmap[base.PluginTypeDevice] = &device.PluginDevice{}
	case base.PluginTypeDriver:
		pmap[base.PluginTypeDriver] = drivers.NewDriverPlugin(nil, logger)
	}

	return pmap
}
source: func (bra BlockRequestAction) Prefetch(block data.Block) bool {
	// When syncing, always prefetch child blocks of an indirect
	// block, since it makes no sense to sync just part of a
	// multi-block object.
	if block.IsIndirect() && bra.Sync() {
		return true
	}
	return bra.prefetch()
}
source: func ExtractBlockTransactions(msgBlock *wire.MsgBlock, txTree int8,
	chainParams *chaincfg.Params, isValid, isMainchain bool) ([]*Tx, [][]*Vout, []VinTxPropertyARRAY) {
	dbTxs, dbTxVouts, dbTxVins := processTransactions(msgBlock, txTree,
		chainParams, isValid, isMainchain)
	if txTree != wire.TxTreeRegular && txTree != wire.TxTreeStake {
		fmt.Printf("Invalid transaction tree: %v", txTree)
	}
	return dbTxs, dbTxVouts, dbTxVins
}
source: func (c *twoPhaseCommitter) doActionOnKeys(bo *Backoffer, action twoPhaseCommitAction, keys [][]byte) error {
	if len(keys) == 0 {
		return nil
	}
	groups, firstRegion, err := c.store.regionCache.GroupKeysByRegion(bo, keys)
	if err != nil {
		return errors.Trace(err)
	}

	metrics.TiKVTxnRegionsNumHistogram.WithLabelValues(action.MetricsTag()).Observe(float64(len(groups)))

	var batches []batchKeys
	var sizeFunc = c.keySize
	if action == actionPrewrite {
		sizeFunc = c.keyValueSize
		atomic.AddInt32(&c.detail.PrewriteRegionNum, int32(len(groups)))
	}
	// Make sure the group that contains primary key goes first.
	batches = appendBatchBySize(batches, firstRegion, groups[firstRegion], sizeFunc, txnCommitBatchSize)
	delete(groups, firstRegion)
	for id, g := range groups {
		batches = appendBatchBySize(batches, id, g, sizeFunc, txnCommitBatchSize)
	}

	firstIsPrimary := bytes.Equal(keys[0], c.primary())
	if firstIsPrimary && (action == actionCommit || action == actionCleanup) {
		// primary should be committed/cleanup first
		err = c.doActionOnBatches(bo, action, batches[:1])
		if err != nil {
			return errors.Trace(err)
		}
		batches = batches[1:]
	}
	if action == actionCommit {
		// Commit secondary batches in background goroutine to reduce latency.
		// The backoffer instance is created outside of the goroutine to avoid
		// potencial data race in unit test since `CommitMaxBackoff` will be updated
		// by test suites.
		secondaryBo := NewBackoffer(context.Background(), CommitMaxBackoff)
		go func() {
			e := c.doActionOnBatches(secondaryBo, action, batches)
			if e != nil {
				logutil.Logger(context.Background()).Debug("2PC async doActionOnBatches",
					zap.Uint64("conn", c.connID),
					zap.Stringer("action type", action),
					zap.Error(e))
				tikvSecondaryLockCleanupFailureCounterCommit.Inc()
			}
		}()
	} else {
		err = c.doActionOnBatches(bo, action, batches)
	}
	return errors.Trace(err)
}
source: func (b *BigIP) AddSnatPool(config *SnatPool) error {

	return b.post(config, uriLtm, uriSnatPool)
}
source: func LimitsList(appID string) error {
	c, appID, err := load(appID)

	if err != nil {
		return err
	}

	config, err := config.List(c, appID)

	fmt.Printf("=== %s Limits\n\n", appID)

	fmt.Println("--- Memory")
	if len(config.Memory) == 0 {
		fmt.Println("Unlimited")
	} else {
		memoryMap := make(map[string]string)

		for key, value := range config.Memory {
			memoryMap[key] = fmt.Sprintf("%v", value)
		}

		fmt.Print(prettyprint.PrettyTabs(memoryMap, 5))
	}

	fmt.Println("\n--- CPU")
	if len(config.CPU) == 0 {
		fmt.Println("Unlimited")
	} else {
		cpuMap := make(map[string]string)

		for key, value := range config.CPU {
			cpuMap[key] = strconv.Itoa(int(value.(float64)))
		}

		fmt.Print(prettyprint.PrettyTabs(cpuMap, 5))
	}

	return nil
}
source: func (spt *ServicePrincipalToken) RefreshWithContext(ctx context.Context) error {
	spt.refreshLock.Lock()
	defer spt.refreshLock.Unlock()
	return spt.refreshInternal(ctx, spt.inner.Resource)
}
source: func DistanceLineToLine(line1Start, line1End, line2Start, line2End geom.Coord) float64 {
	/**
	 * This calculation is susceptible to roundoff errors when
	 * passed large ordinate values.
	 * It may be possible to improve this by using {@link DD} arithmetic.
	 */
	if Equals(line1Start, line1End) {
		return DistancePointToLine(line1Start, line2Start, line2End)
	}
	if Equals(line2Start, line1End) {
		return DistancePointToLine(line2Start, line1Start, line1End)
	}

	/**
	 * Algorithm derived from http://softsurfer.com/Archive/algorithm_0106/algorithm_0106.htm
	 */
	a := VectorDot(line1Start, line1End, line1Start, line1End)
	b := VectorDot(line1Start, line1End, line2Start, line2End)
	c := VectorDot(line2Start, line2End, line2Start, line2End)
	d := VectorDot(line1Start, line1End, line2Start, line1Start)
	e := VectorDot(line2Start, line2End, line2Start, line1Start)

	denom := a*c - b*b
	if math.IsNaN(denom) {
		panic("Ordinates must not be NaN")
	}

	var s, t float64
	if denom <= 0.0 {
		/**
		 * The lines are parallel.
		 * In this case solve for the parameters s and t by assuming s is 0.
		 */
		s = 0
		// choose largest denominator for optimal numeric conditioning
		if b > c {
			t = d / b
		} else {
			t = e / c
		}
	} else {
		s = (b*e - c*d) / denom
		t = (a*e - b*d) / denom
	}
	switch {
	case s < 0:
		return DistancePointToLine(line1Start, line2Start, line2End)
	case s > 1:
		return DistancePointToLine(line1End, line2Start, line2End)
	case t < 0:
		return DistancePointToLine(line2Start, line1Start, line1End)
	case t > 1:
		return DistancePointToLine(line2End, line1Start, line1End)
	}
	/**
	 * The closest points are in interiors of segments,
	 * so compute them directly
	 */
	x1 := line1Start[0] + s*(line1End[0]-line1Start[0])
	y1 := line1Start[1] + s*(line1End[1]-line1Start[1])
	z1 := line1Start[2] + s*(line1End[2]-line1Start[2])

	x2 := line2Start[0] + t*(line2End[0]-line2Start[0])
	y2 := line2Start[1] + t*(line2End[1]-line2Start[1])
	z2 := line2Start[2] + t*(line2End[2]-line2Start[2])

	// length (p1-p2)
	return Distance(geom.Coord{x1, y1, z1}, geom.Coord{x2, y2, z2})
}
source: func (lr *ListRange) SetHeader(req *http.Request) {
	var hdrval string
	if lr.Field != "" {
		hdrval += lr.Field + " "
	}
	hdrval += lr.FirstID + ".." + lr.LastID
	params := make([]string, 0, 2)
	if lr.Max != 0 {
		params = append(params, fmt.Sprintf("max=%d", lr.Max))
	}
	if lr.Descending {
		params = append(params, "order=desc")
	}
	if len(params) > 0 {
		hdrval += fmt.Sprintf("; %s", strings.Join(params, ","))
	}
	req.Header.Set("Range", hdrval)
	return
}
source: func Convert_v1_ScaleIOPersistentVolumeSource_To_core_ScaleIOPersistentVolumeSource(in *v1.ScaleIOPersistentVolumeSource, out *core.ScaleIOPersistentVolumeSource, s conversion.Scope) error {
	return autoConvert_v1_ScaleIOPersistentVolumeSource_To_core_ScaleIOPersistentVolumeSource(in, out, s)
}
source: func (l *JSONLogger) Logm(timestamp time.Time, level gomol.LogLevel, attrs map[string]interface{}, msg string) error {
	if !l.isInitialized {
		return errors.New("JSON logger has not been initialized")
	}

	msgBytes, err := l.marshalJSON(timestamp, level, attrs, msg)
	if err != nil {
		return err
	}
	msgBytes = append(msgBytes, l.config.MessageDelimiter...)

	if !l.isConnected {
		// If we're not connected then just queue up the message and return
		// an error about not being connected
		l.queueFailure(msgBytes)
		return errors.New("Could not send message")
	}

	err = l.write(msgBytes)
	if err != nil {
		if neterr, ok := err.(net.Error); ok {
			if !neterr.Temporary() {
				// If this isn't a temporary error then queue the message
				// to the failed queue and start reconnecting
				l.queueFailure(msgBytes)
				l.performReconnect()
				return errors.New("Could not send message")
			}
		}
		return err
	}

	return nil
}
source: func (c *Client) OAuthAuthorizationCreate(scope []string, options *OAuthAuthorizationCreateOpts) (*OAuthAuthorization, error) {
	params := struct {
		Scope       []string `json:"scope"`
		Client      *string  `json:"client,omitempty"`
		Description *string  `json:"description,omitempty"`
		ExpiresIn   *int     `json:"expires_in,omitempty"`
	}{
		Scope: scope,
	}
	if options != nil {
		params.Client = options.Client
		params.Description = options.Description
		params.ExpiresIn = options.ExpiresIn
	}
	var oauthAuthorizationRes OAuthAuthorization
	return &oauthAuthorizationRes, c.Post(&oauthAuthorizationRes, "/oauth/authorizations", params)
}
source: func (vm *Engine) subScript() []parsedOpcode {
	return vm.scripts[vm.scriptIdx][vm.lastCodeSep:]
}
source: func (kw EcdhesKeyWrapEncrypt) KeyEncrypt(cek []byte) (ByteSource, error) {
	kg, err := kw.generator.KeyGenerate()
	if err != nil {
		return nil, errors.Wrap(err, "failed to create key generator")
	}

	bwpk, ok := kg.(ByteWithECPrivateKey)
	if !ok {
		return nil, errors.New("key generator generated invalid key (expected ByteWithECPrivateKey)")
	}

	block, err := aes.NewCipher(bwpk.Bytes())
	if err != nil {
		return nil, errors.Wrap(err, "failed to generate cipher from generated key")
	}

	jek, err := keywrap(block, cek)
	if err != nil {
		return nil, errors.Wrap(err, "failed to wrap data")
	}

	bwpk.ByteKey = ByteKey(jek)

	return bwpk, nil
}
source: func BackoffExponential(scalar time.Duration) BackoffFunc {
	return func(attempt uint) time.Duration {
		return scalar * time.Duration(backoffutils.ExponentBase2(attempt))
	}
}
source: func (z *Big) SetFloat(x *big.Float) *Big {
	if x.IsInf() {
		if x.Signbit() {
			z.form = ninf
		} else {
			z.form = pinf
		}
		return z
	}

	neg := x.Signbit()
	if x.Sign() == 0 {
		if neg {
			z.form |= signbit
		}
		z.compact = 0
		z.precision = 1
		return z
	}

	z.exp = 0
	x0 := new(big.Float).Copy(x).SetPrec(big.MaxPrec)
	x0.Abs(x0)
	if !x.IsInt() {
		for !x0.IsInt() {
			x0.Mul(x0, c.TenFloat)
			z.exp--
		}
	}

	if mant, acc := x0.Uint64(); acc == big.Exact {
		z.compact = mant
		z.precision = arith.Length(mant)
	} else {
		z.compact = c.Inflated
		x0.Int(&z.unscaled)
		z.precision = arith.BigLength(&z.unscaled)
	}
	z.form = finite
	if neg {
		z.form |= signbit
	}
	return z
}
source: func (c *Client) WatchActionNotifications(agent names.MachineTag) (watcher.StringsWatcher, error) {
	var results params.StringsWatchResults
	args := params.Entities{
		Entities: []params.Entity{{Tag: agent.String()}},
	}

	err := c.facade.FacadeCall("WatchActionNotifications", args, &results)
	if err != nil {
		return nil, errors.Trace(err)
	}

	if len(results.Results) != 1 {
		return nil, errors.Errorf("expected 1 result, got %d", len(results.Results))
	}

	result := results.Results[0]
	if result.Error != nil {
		return nil, errors.Trace(result.Error)
	}
	w := apiwatcher.NewStringsWatcher(c.facade.RawAPICaller(), result)
	return w, nil
}
source: func HookTasks(hookID int64, page int) ([]*HookTask, error) {
	tasks := make([]*HookTask, 0, setting.Webhook.PagingNum)
	return tasks, x.Limit(setting.Webhook.PagingNum, (page-1)*setting.Webhook.PagingNum).Where("hook_id=?", hookID).Desc("id").Find(&tasks)
}
source: func (s *PutEmailIdentityFeedbackAttributesInput) SetEmailForwardingEnabled(v bool) *PutEmailIdentityFeedbackAttributesInput {
	s.EmailForwardingEnabled = &v
	return s
}
source: func (ta *TrackAttributes) TargetDanceability(danceability float64) *TrackAttributes {
	ta.floatAttributes["target_danceability"] = danceability
	return ta
}
source: func (s *CfgEndpointState) ReadAll() ([]core.State, error) {
	return s.StateDriver.ReadAllState(endpointConfigPathPrefix, s, json.Unmarshal)
}
source: func (d *Driver) Remove(id string) error {
	dir := d.subvolumesDirID(id)
	if _, err := os.Stat(dir); err != nil {
		return err
	}
	quotasDir := d.quotasDirID(id)
	if _, err := os.Stat(quotasDir); err == nil {
		if err := os.Remove(quotasDir); err != nil {
			return err
		}
	} else if !os.IsNotExist(err) {
		return err
	}

	// Call updateQuotaStatus() to invoke status update
	d.updateQuotaStatus()

	if err := subvolDelete(d.subvolumesDir(), id, d.quotaEnabled); err != nil {
		return err
	}
	if err := system.EnsureRemoveAll(dir); err != nil {
		return err
	}
	if err := d.subvolRescanQuota(); err != nil {
		return err
	}
	return nil
}
source: func GetPublicIPv6() (net.IP, error) {
	addresses, err := net.InterfaceAddrs()
	if err != nil {
		return nil, fmt.Errorf("Failed to get interface addresses: %v", err)
	}

	return getPublicIPv6(addresses)
}
source: func (c *Client) SwitchBlockOn(blockType, msg string) error {
	args := params.BlockSwitchParams{
		Type:    blockType,
		Message: msg,
	}
	var result params.ErrorResult
	if err := c.facade.FacadeCall("SwitchBlockOn", args, &result); err != nil {
		return errors.Trace(err)
	}
	if result.Error != nil {
		// cope with typed error
		return errors.Trace(result.Error)
	}
	return nil
}
source: func (fm *FingerprintManager) setupFingerprinters(fingerprints []string) error {
	var appliedFingerprints []string

	for _, name := range fingerprints {
		f, err := fingerprint.NewFingerprint(name, fm.logger)

		if err != nil {
			fm.logger.Error("error fingerprinting", "error", err, "fingerprinter", name)
			return err
		}

		detected, err := fm.fingerprint(name, f)
		if err != nil {
			return err
		}

		// log the fingerprinters which have been applied
		if detected {
			appliedFingerprints = append(appliedFingerprints, name)
		}

		p, period := f.Periodic()
		if p {
			go fm.runFingerprint(f, period, name)
		}
	}

	fm.logger.Debug("detected fingerprints", "node_attrs", appliedFingerprints)
	return nil
}
source: func (t traceV2) Response(resp *http.Response) (err error) {
	var respTrace []byte
	// For errors we make sure to dump response body as well.
	if resp.StatusCode != http.StatusOK &&
		resp.StatusCode != http.StatusPartialContent &&
		resp.StatusCode != http.StatusNoContent {
		respTrace, err = httputil.DumpResponse(resp, true)
	} else {
		respTrace, err = httputil.DumpResponse(resp, false)
	}
	if err == nil {
		console.Debug(string(respTrace))
	}

	if globalInsecure && resp.TLS != nil {
		dumpTLSCertificates(resp.TLS)
	}

	return err
}
source: func oneTimeJobSchedule(ts time.Time) *storagetransfer.Schedule {
	date := toDate(ts)
	return &storagetransfer.Schedule{
		ScheduleEndDate:   date,
		ScheduleStartDate: date,
	}
}
source: func (tc *TeleportClient) getProxySSHPrincipal() string {
	proxyPrincipal := tc.Config.HostLogin
	if tc.DefaultPrincipal != "" {
		proxyPrincipal = tc.DefaultPrincipal
	}
	// see if we already have a signed key in the cache, we'll use that instead
	if !tc.Config.SkipLocalAuth && tc.LocalAgent() != nil {
		signers, err := tc.LocalAgent().Signers()
		if err != nil || len(signers) == 0 {
			return proxyPrincipal
		}
		cert, ok := signers[0].PublicKey().(*ssh.Certificate)
		if ok && len(cert.ValidPrincipals) > 0 {
			return cert.ValidPrincipals[0]
		}
	}
	return proxyPrincipal
}
source: func newStatsProvider(
	cadvisor cadvisor.Interface,
	podManager kubepod.Manager,
	runtimeCache kubecontainer.RuntimeCache,
	containerStatsProvider containerStatsProvider,
) *StatsProvider {
	return &StatsProvider{
		cadvisor:               cadvisor,
		podManager:             podManager,
		runtimeCache:           runtimeCache,
		containerStatsProvider: containerStatsProvider,
	}
}
source: func LoadBundle(ctx context.Context, root, id string) (*Bundle, error) {
	ns, err := namespaces.NamespaceRequired(ctx)
	if err != nil {
		return nil, err
	}
	return &Bundle{
		ID:        id,
		Path:      filepath.Join(root, ns, id),
		Namespace: ns,
	}, nil
}
source: func WithParent(context reqContext.Context) ReqContextOptions {
	return func(ctx *requestContextOpts) {
		ctx.parentContext = context
	}
}
source: func (hdr *rpmHeader) GetUint64Fallback(intTag, longTag int) ([]uint64, error) {
	if _, ok := hdr.entries[longTag]; ok {
		return hdr.GetUint64s(longTag)
	} else {
		return hdr.GetUint64s(intTag)
	}
}
source: func (p *displayPool) primary() (d *Display) {
	p.m.Lock()
	defer p.m.Unlock()
	for _, d = range p.d {
		if d.primary {
			return
		}
	}
	return
}
source: func (e *GrantExec) grantDBPriv(priv *ast.PrivElem, user *ast.UserSpec) error {
	dbName := e.Level.DBName
	if len(dbName) == 0 {
		dbName = e.ctx.GetSessionVars().CurrentDB
	}
	asgns, err := composeDBPrivUpdate(priv.Priv, "Y")
	if err != nil {
		return err
	}
	sql := fmt.Sprintf(`UPDATE %s.%s SET %s WHERE User='%s' AND Host='%s' AND DB='%s';`, mysql.SystemDB, mysql.DBTable, asgns, user.User.Username, user.User.Hostname, dbName)
	_, _, err = e.ctx.(sqlexec.RestrictedSQLExecutor).ExecRestrictedSQL(e.ctx, sql)
	return err
}
source: func (f *File) Reload() (err error) {
	for _, s := range f.dataSources {
		if err = f.reload(s); err != nil {
			// In loose mode, we create an empty default section for nonexistent files.
			if os.IsNotExist(err) && f.options.Loose {
				f.parse(bytes.NewBuffer(nil))
				continue
			}
			return err
		}
	}
	return nil
}
source: func (c *Distconf) Str(key string, defaultVal string) *Str {
	c.grabInfo(key)
	s := &strConf{
		defaultVal: defaultVal,
	}
	s.currentVal.Store(defaultVal)
	// Note: in race conditions 's' may not be the thing actually returned
	ret, okCast := c.createOrGet(key, s).(*strConf)
	if !okCast {
		c.Logger.Log(logkey.DistconfKey, key, "Registering key with multiple types!  FIX ME!!!!")
		return nil
	}
	return &ret.Str
}
source: func Endswith(expectedValue string) *endswithMatcher {
	matcher := new(endswithMatcher)
	matcher.expectedValue = expectedValue
	return matcher
}
source: func (q *Queue) Publish(item events.Event) {
	q.broadcast.Write(item)
}
source: func migrateLocalModelUsers(usermodels map[string]*ControllerModels) error {
	changes := false
	for _, modelDetails := range usermodels {
		for name, model := range modelDetails.Models {
			migratedName, changed, err := migrateModelName(name)
			if err != nil {
				return errors.Trace(err)
			}
			if !changed {
				continue
			}
			delete(modelDetails.Models, name)
			modelDetails.Models[migratedName] = model
			changes = true
		}
		migratedName, changed, err := migrateModelName(modelDetails.CurrentModel)
		if err != nil {
			return errors.Trace(err)
		}
		if !changed {
			continue
		}
		modelDetails.CurrentModel = migratedName
	}
	if changes {
		return WriteModelsFile(usermodels)
	}
	return nil
}
source: func StartLimited(inactivity, absolute time.Duration) Scene {
	s := &scene{
		id:          identifier.NewUUID(),
		props:       make(map[string]*box),
		flags:       make(map[string]bool),
		signalings:  make(map[string][]chan struct{}),
		inactivity:  inactivity,
		absolute:    absolute,
		commandChan: make(chan *envelope, 1),
	}
	s.backend = loop.Go(s.backendLoop, "scene", s.id.String())
	return s
}
source: func nodeFromBytes(t *Tr, data []byte) (*Node, error) {
	n := &Node{}
	_, err := n.UnmarshalMsg(data)
	if err != nil {
		panic(err)
		return nil, err
	}

	return n, nil
}
source: func (m *MockServiceAPIClient) TaskList(ctx context.Context, options types.TaskListOptions) ([]swarm.Task, error) {
	ret := m.ctrl.Call(m, "TaskList", ctx, options)
	ret0, _ := ret[0].([]swarm.Task)
	ret1, _ := ret[1].(error)
	return ret0, ret1
}
source: func NewAppInput(rd io.Reader) app.Input {
	return app.Input(NewInputSize(rd, defaultBufSize))
}
source: func (conn *FakeVTGateConn) GetSrvKeyspace(ctx context.Context, keyspace string) (*topodatapb.SrvKeyspace, error) {
	return nil, fmt.Errorf("NYI")
}
source: func (n *node) Count(data interface{}) (int, error) {
	return n.Select().Count(data)
}
source: func (s *String) StringOr(or string) string {
	switch {
	case s == nil:
		return or
	case !s.Valid:
		return or
	default:
		return s.Chars
	}
}
source: func (b *BigIP) ModifyRouteDomain(name string, config *RouteDomain) error {
	return b.put(config, uriNet, uriRouteDomain, name)
}
source: func (pr *PortRange) Set(value string) error {
	value = strings.TrimSpace(value)

	// TODO: Accept "80" syntax
	// TODO: Accept "80+8" syntax

	if value == "" {
		pr.Base = 0
		pr.Size = 0
		return nil
	}

	hyphenIndex := strings.Index(value, "-")
	if hyphenIndex == -1 {
		return fmt.Errorf("expected hyphen in port range")
	}

	var err error
	var low int
	var high int
	low, err = strconv.Atoi(value[:hyphenIndex])
	if err == nil {
		high, err = strconv.Atoi(value[hyphenIndex+1:])
	}
	if err != nil {
		return fmt.Errorf("unable to parse port range: %s", value)
	}

	if high < low {
		return fmt.Errorf("end port cannot be less than start port: %s", value)
	}
	pr.Base = low
	pr.Size = 1 + high - low
	return nil
}
source: func MatchesExpr(cr expr.EvalContext, node expr.Node) (bool, bool) {
	return matchesExpr(cr, node, 0)
}
source: func Run(name string) (*Motto, otto.Value, error) {
	vm := New()
	v, err := vm.Run(name)

	return vm, v, err
}
source: func (s *TrainingJobStatusCounters) SetNonRetryableError(v int64) *TrainingJobStatusCounters {
	s.NonRetryableError = &v
	return s
}
source: func (context *OpsManager) GetInstallationSettings() (settings io.Reader, err error) {
	var bytesBuffer = new(bytes.Buffer)
	url := fmt.Sprintf(OpsMgrInstallationSettingsURL, context.Hostname)
	lo.G.Debug(fmt.Sprintf("Exporting url '%s'", url))

	if err = context.saveHTTPResponse(url, bytesBuffer); err == nil {
		settings = bytesBuffer
	}
	return
}
source: func MakeAddition(key string, newVal interface{}) ItemChange {
	return ItemChange{
		Type:     added,
		Key:      key,
		NewValue: newVal,
	}
}
source: func NewImageCard(title, fimg, icon, textcontent string) ImageCard {
	card := ImageCard{}

	card.AddClass("card")

	card.image.AddClass("card-image")

	img := valente.Image{Source: fimg}
	card.image.AddElement(img)

	stitle := valente.Span{Text: title}
	stitle.AddClass("card-title")
	stitle.SetStyle("background-color", "#22222299")
	stitle.SetStyle("padding", "3px")

	card.image.AddElement(stitle)

	if len(icon) != 0 {
		aicon := valente.Link{Text: "<i class='material-icons'>" + icon + "</i>"}
		aicon.AddClass("btn-floating halfway-fab waves-effect waves-light red")
		card.image.AddElement(aicon)
	}

	card.Content.AddClass("card-content")
	card.Content.Text = "<p>" + textcontent + "</p>"

	card.AddElement(card.image)
	card.AddElement(card.Content)

	return card
}
source: func (c *Color) Sprint(a ...interface{}) string {
	return c.wrap(fmt.Sprint(a...))
}
source: func (f *Filestore) Has(c cid.Cid) (bool, error) {
	has, err := f.bs.Has(c)
	if err != nil {
		return false, err
	}

	if has {
		return true, nil
	}

	return f.fm.Has(c)
}
source: func Convert_auditregistration_Webhook_To_v1alpha1_Webhook(in *auditregistration.Webhook, out *v1alpha1.Webhook, s conversion.Scope) error {
	return autoConvert_auditregistration_Webhook_To_v1alpha1_Webhook(in, out, s)
}
source: func catURL(sourceURL string, encKeyDB map[string][]prefixSSEPair) *probe.Error {
	var reader io.ReadCloser
	size := int64(-1)
	switch sourceURL {
	case "-":
		reader = os.Stdin
	default:
		var err *probe.Error
		// Try to stat the object, the purpose is to extract the
		// size of S3 object so we can check if the size of the
		// downloaded object is equal to the original one. FS files
		// are ignored since some of them have zero size though they
		// have contents like files under /proc.
		client, content, err := url2Stat(sourceURL, false, encKeyDB)
		if err == nil && client.GetURL().Type == objectStorage {
			size = content.Size
		}
		if reader, err = getSourceStreamFromURL(sourceURL, encKeyDB); err != nil {
			return err.Trace(sourceURL)
		}
		defer reader.Close()
	}
	return catOut(reader, size).Trace(sourceURL)
}
source: func New(algo string) (*Hash, error) {
	h := &Hash{algo: algo}

	hf, ok := secureHashes[algo]
	if ok {
		h.Hash = hf()
		h.secure = true
		return h, nil
	}

	hf, ok = insecureHashes[algo]
	if ok {
		h.Hash = hf()
		h.secure = false
		return h, nil
	}

	return nil, errors.New("chash: unsupport hash algorithm " + algo)
}
source: func TableUpgradesRequired(versions map[string]TableVersion) []TableUpgrade {
	var tableUpgrades []TableUpgrade
	for t := range createLegacyTableStatements {
		var ok bool
		var req, act TableVersion
		if req, ok = requiredVersions[t]; !ok {
			log.Errorf("required version unknown for table %s", t)
			tableUpgrades = append(tableUpgrades, TableUpgrade{
				TableName:   t,
				UpgradeType: compatUnknown,
			})
			continue
		}
		if act, ok = versions[t]; !ok {
			log.Errorf("current version unknown for table %s", t)
			tableUpgrades = append(tableUpgrades, TableUpgrade{
				TableName:   t,
				UpgradeType: compatRebuild,
				RequiredVer: req,
			})
			continue
		}
		versionCompatibility := TableVersionCompatible(req, act)
		tableUpgrades = append(tableUpgrades, TableUpgrade{
			TableName:   t,
			UpgradeType: versionCompatibility,
			CurrentVer:  act,
			RequiredVer: req,
		})
	}
	return tableUpgrades
}
source: func (m *IncomingMessage) GetCommand() (string, string) {
	text := m.Text

	if !strings.HasPrefix(text, "/") {
		return "", text
	}
	r, _ := regexp.Compile("^/([a-zA-Z0-9_]+)(?:@[a-zA-Z0-9_]+)?.?(.*)?$")
	match := r.FindStringSubmatch(text)
	if len(match) == 3 {
		return match[1], match[2]
	} else if len(match) == 2 {
		return match[1], ""
	}
	return "", ""

}
source: func InitDB(b bool) DBConfiguration {
	return func(c *CyclePDB) error {
		c.initdb = b
		return nil
	}
}
source: func PackBytes(box string, name string, bb []byte) {
	b := NewBox(box)
	d := resolver.NewInMemory(map[string]file.File{})
	f, err := file.NewFile(name, bb)
	if err != nil {
		panic(err)
	}
	if err := d.Pack(name, f); err != nil {
		panic(err)
	}
	b.SetResolver(name, d)
}
source: func (p *Parser) parseSetPasswordUserStatement() (*SetPasswordUserStatement, error) {
	stmt := &SetPasswordUserStatement{}

	// Parse username
	ident, err := p.ParseIdent()

	if err != nil {
		return nil, err
	}
	stmt.Name = ident

	// Consume the required = token.
	if tok, pos, lit := p.ScanIgnoreWhitespace(); tok != EQ {
		return nil, newParseError(tokstr(tok, lit), []string{"="}, pos)
	}

	// Parse new user's password
	if ident, err = p.parseString(); err != nil {
		return nil, err
	}
	stmt.Password = ident

	return stmt, nil
}
source: func (s *Multi) AddInformer(gvk schema.GroupVersionKind, informer cache.SharedIndexInformer) error {
	s.mx.Lock()
	defer s.mx.Unlock()
	if _, ok := s.informers[gvk]; ok {
		return errors.New("informer is already registered")
	}
	f := informer.GetIndexer().GetIndexers()[ByNamespaceAndControllerUIDIndex]
	if f == nil {
		// Informer does not have this index yet i.e. this is the first/sole multistore it is added to.
		err := informer.AddIndexers(cache.Indexers{
			ByNamespaceAndControllerUIDIndex: byNamespaceAndControllerUIDIndex,
		})
		if err != nil {
			return errors.WithStack(err)
		}
	}
	s.informers[gvk] = informer
	return nil
}
source: func LookupPodName(name string) *endpoint.Endpoint {
	mutex.RLock()
	ep := lookupPodNameLocked(name)
	mutex.RUnlock()
	return ep
}
source: func (j *Job) HasUpdateStrategy() bool {
	for _, tg := range j.TaskGroups {
		if tg.Update != nil {
			return true
		}
	}

	return false
}
source: func encodeAuth(authConfig *types.AuthConfig) string {
	if authConfig.Username == "" && authConfig.Password == "" {
		return ""
	}

	authStr := authConfig.Username + ":" + authConfig.Password
	msg := []byte(authStr)
	encoded := make([]byte, base64.StdEncoding.EncodedLen(len(msg)))
	base64.StdEncoding.Encode(encoded, msg)
	return string(encoded)
}
source: func (api *CrossControllerAPI) WatchControllerInfo() (params.NotifyWatchResults, error) {
	results := params.NotifyWatchResults{
		Results: make([]params.NotifyWatchResult, 1),
	}
	w := api.watchLocalControllerInfo()
	if _, ok := <-w.Changes(); !ok {
		results.Results[0].Error = common.ServerError(watcher.EnsureErr(w))
		return results, nil
	}
	results.Results[0].NotifyWatcherId = api.resources.Register(w)
	return results, nil
}
source: func ValidateEndpointsUpdate(newEndpoints, oldEndpoints *core.Endpoints) field.ErrorList {
	allErrs := ValidateObjectMetaUpdate(&newEndpoints.ObjectMeta, &oldEndpoints.ObjectMeta, field.NewPath("metadata"))
	allErrs = append(allErrs, validateEndpointSubsets(newEndpoints.Subsets, field.NewPath("subsets"))...)
	allErrs = append(allErrs, ValidateEndpointsSpecificAnnotations(newEndpoints.Annotations, field.NewPath("annotations"))...)
	return allErrs
}
source: func getChanPointFundingTxid(chanPoint *lnrpc.ChannelPoint) (*chainhash.Hash, error) {
	var txid []byte

	// A channel point's funding txid can be get/set as a byte slice or a
	// string. In the case it is a string, decode it.
	switch chanPoint.GetFundingTxid().(type) {
	case *lnrpc.ChannelPoint_FundingTxidBytes:
		txid = chanPoint.GetFundingTxidBytes()
	case *lnrpc.ChannelPoint_FundingTxidStr:
		s := chanPoint.GetFundingTxidStr()
		h, err := chainhash.NewHashFromStr(s)
		if err != nil {
			return nil, err
		}

		txid = h[:]
	}

	return chainhash.NewHash(txid)
}
source: func (t *task) stop(ctx context.Context) error {
	if err := t.hcsStop(ctx, t.hcsContainer.Shutdown); err != nil {
		return t.hcsStop(ctx, t.hcsContainer.Terminate)
	}
	t.hcsContainer.Close()
	return nil
}
source: func SetLevelString(levelstr string) LogLevel {
	logMux.Lock()
	defer logMux.Unlock()
	current := logLevel
	switch strings.ToLower(levelstr) {
	case "debug":
		logLevel = LevelDebug
	case "info":
		logLevel = LevelInfo
	case "warning":
		logLevel = LevelWarning
	case "error":
		logLevel = LevelError
	case "critical":
		logLevel = LevelCritical
	case "fatal":
		logLevel = LevelFatal
	}
	return current
}
source: func (t emptyDirTracker) addFile(path string) {
	dir := filepath.Dir(path)
	for dir != "." {
		delete(t, dir)
		dir = filepath.Dir(dir)
	}
}
source: func (enc *Encoder) EncodeBool(v bool) error {
	if enc.isPooled == 1 {
		panic(InvalidUsagePooledEncoderError("Invalid usage of pooled encoder"))
	}
	_, _ = enc.encodeBool(v)
	_, err := enc.Write()
	if err != nil {
		enc.err = err
		return err
	}
	return nil
}
source: func (opts *Options) Namer() *Namer {
	if opts.nmr == nil {
		opts.nmr = NewNamer(&NOpts{base: opts.filename, zero: 1, start: 2})
	}
	return opts.nmr
}
source: func postRetentionPolicy(ctx context.Context, lcli chat1.LocalClient, tui libkb.TerminalUI,
	conv *chat1.ConversationLocal, policy chat1.RetentionPolicy, setChannel bool, doPrompt bool) (err error) {
	teamInvolved := (conv.Info.MembersType == chat1.ConversationMembersType_TEAM)
	teamWide := teamInvolved && !setChannel

	if doPrompt {
		promptText := fmt.Sprintf("Set the conversation retention policy?\nHit Enter to confirm, or Ctrl-C to cancel.")
		if teamInvolved {
			promptText = fmt.Sprintf("Set the channel retention policy?\nHit Enter to confirm, or Ctrl-C to cancel.")
		}
		if teamWide {
			promptText = fmt.Sprintf("Set the team-wide retention policy?\nHit Enter to confirm, or Ctrl-C to cancel.")
		}
		if _, err = tui.Prompt(PromptDescriptorChatSetRetention, promptText); err != nil {
			return err
		}
	}

	if teamWide {
		teamID, err := keybase1.TeamIDFromString(conv.Info.Triple.Tlfid.String())
		if err != nil {
			return err
		}
		return lcli.SetTeamRetentionLocal(ctx, chat1.SetTeamRetentionLocalArg{
			TeamID: teamID,
			Policy: policy,
		})
	}
	return lcli.SetConvRetentionLocal(ctx, chat1.SetConvRetentionLocalArg{
		ConvID: conv.Info.Id,
		Policy: policy,
	})
}
source: func (o *Cluster) SetJobFlowRole(v *string) *Cluster {
	if o.JobFlowRole = v; o.JobFlowRole == nil {
		o.nullFields = append(o.nullFields, "JobFlowRole")
	}
	return o
}
source: func (r *Router) Redirect(w http.ResponseWriter, req *http.Request, path string, code int) {
	http.Redirect(w, req, r.prefix+path, code)
}
source: func GetPage(w http.ResponseWriter, r *http.Request) {
	w.Header().Set("Cache-Control", "must-revalidate")
	w.Header().Set("Content-Type", "application/json")
	w.Header().Set("Access-Control-Allow-Origin", "*")
	w.Header().Set("Access-Control-Allow-Methods", "POST, GET, PUT, OPTIONS")
	var col, page, total string
	if !Require(w, r, "col", &col) {
		return
	}
	if !Require(w, r, "page", &page) {
		return
	}
	if !Require(w, r, "total", &total) {
		return
	}
	totalPage, err := strconv.Atoi(total)
	if err != nil || totalPage < 1 {
		http.Error(w, fmt.Sprintf("Invalid total page number '%v'.", totalPage), 400)
		return
	}
	pageNum, err := strconv.Atoi(page)
	if err != nil || pageNum < 0 || pageNum >= totalPage {
		http.Error(w, fmt.Sprintf("Invalid page number '%v'.", page), 400)
		return
	}
	dbcol := HttpDB.Use(col)
	if dbcol == nil {
		http.Error(w, fmt.Sprintf("Collection '%s' does not exist.", col), 400)
		return
	}
	docs := make(map[string]interface{})
	dbcol.ForEachDocInPage(pageNum, totalPage, func(id int, doc []byte) bool {
		var docObj map[string]interface{}
		if err := json.Unmarshal(doc, &docObj); err == nil {
			docs[strconv.Itoa(id)] = docObj
		}
		return true
	})
	resp, err := json.Marshal(docs)
	if err != nil {
		http.Error(w, fmt.Sprint(err), 500)
		return
	}
	w.Write(resp)
}
source: func (s *Http) SetHttpURL(v string) *Http {
	s.HttpURL = &v
	return s
}
source: func CommandRunner(h *host.Host) (bootstrapper.CommandRunner, error) {
	if h.DriverName == constants.DriverNone {
		return &bootstrapper.ExecRunner{}, nil
	}
	client, err := sshutil.NewSSHClient(h.Driver)
	if err != nil {
		return nil, errors.Wrap(err, "getting ssh client for bootstrapper")
	}
	return bootstrapper.NewSSHRunner(client), nil
}
source: func (cli *Client) postHijacked(ctx context.Context, path string, query url.Values, body interface{}, headers map[string][]string) (types.HijackedResponse, error) {
	bodyEncoded, err := encodeData(body)
	if err != nil {
		return types.HijackedResponse{}, err
	}

	apiPath := cli.getAPIPath(ctx, path, query)
	req, err := http.NewRequest("POST", apiPath, bodyEncoded)
	if err != nil {
		return types.HijackedResponse{}, err
	}
	req = cli.addHeaders(req, headers)

	conn, err := cli.setupHijackConn(ctx, req, "tcp")
	if err != nil {
		return types.HijackedResponse{}, err
	}

	return types.HijackedResponse{Conn: conn, Reader: bufio.NewReader(conn)}, err
}
source: func ValidateSysctl(val string) (string, error) {
	validSysctlMap := map[string]bool{
		"kernel.msgmax":          true,
		"kernel.msgmnb":          true,
		"kernel.msgmni":          true,
		"kernel.sem":             true,
		"kernel.shmall":          true,
		"kernel.shmmax":          true,
		"kernel.shmmni":          true,
		"kernel.shm_rmid_forced": true,
	}
	validSysctlPrefixes := []string{
		"net.",
		"fs.mqueue.",
	}
	arr := strings.Split(val, "=")
	if len(arr) < 2 {
		return "", fmt.Errorf("sysctl '%s' is not whitelisted", val)
	}
	if validSysctlMap[arr[0]] {
		return val, nil
	}

	for _, vp := range validSysctlPrefixes {
		if strings.HasPrefix(arr[0], vp) {
			return val, nil
		}
	}
	return "", fmt.Errorf("sysctl '%s' is not whitelisted", val)
}
source: func (a *Account) AddStreamExport(subject string, accounts []*Account) error {
	a.mu.Lock()
	defer a.mu.Unlock()
	if a == nil {
		return ErrMissingAccount
	}
	if a.exports.streams == nil {
		a.exports.streams = make(map[string]*exportAuth)
	}
	ea := a.exports.streams[subject]
	if accounts != nil {
		if ea == nil {
			ea = &exportAuth{}
		}
		// empty means auth required but will be import token.
		if len(accounts) == 0 {
			ea.tokenReq = true
		} else {
			if ea.approved == nil {
				ea.approved = make(map[string]*Account, len(accounts))
			}
			for _, acc := range accounts {
				ea.approved[acc.Name] = acc
			}
		}
	}
	a.exports.streams[subject] = ea
	return nil
}
source: func (s *session) StmtCommit() error {
	defer s.txn.cleanup()
	st := &s.txn
	var count int
	err := kv.WalkMemBuffer(st.buf, func(k kv.Key, v []byte) error {
		failpoint.Inject("mockStmtCommitError", func(val failpoint.Value) {
			if val.(bool) {
				count++
			}
		})

		if count > 3 {
			return errors.New("mock stmt commit error")
		}

		if len(v) == 0 {
			return st.Transaction.Delete(k)
		}
		return st.Transaction.Set(k, v)
	})
	if err != nil {
		st.doNotCommit = err
		return err
	}

	// Need to flush binlog.
	for tableID, delta := range st.mutations {
		mutation := getBinlogMutation(s, tableID)
		mergeToMutation(mutation, delta)
	}

	if len(st.dirtyTableOP) > 0 {
		dirtyDB := executor.GetDirtyDB(s)
		for _, op := range st.dirtyTableOP {
			mergeToDirtyDB(dirtyDB, op)
		}
	}
	return nil
}
source: func NewOneVsAllModel(f func(string) base.Classifier) *OneVsAllModel {
	return &OneVsAllModel{
		f,
		nil,
		nil,
		0,
		nil,
		nil,
	}
}
source: func UpdateEndpointsMap(endpointsMap EndpointsMap, changes *EndpointChangeTracker) (result UpdateEndpointMapResult) {
	result.StaleEndpoints = make([]ServiceEndpoint, 0)
	result.StaleServiceNames = make([]ServicePortName, 0)
	result.LastChangeTriggerTimes = make([]time.Time, 0)

	endpointsMap.apply(
		changes, &result.StaleEndpoints, &result.StaleServiceNames, &result.LastChangeTriggerTimes)

	// TODO: If this will appear to be computationally expensive, consider
	// computing this incrementally similarly to endpointsMap.
	result.HCEndpointsLocalIPSize = make(map[types.NamespacedName]int)
	localIPs := GetLocalEndpointIPs(endpointsMap)
	for nsn, ips := range localIPs {
		result.HCEndpointsLocalIPSize[nsn] = len(ips)
	}

	return result
}
source: func NewStorage(optsGetter generic.RESTOptionsGetter) *VolumeAttachmentStorage {
	store := &genericregistry.Store{
		NewFunc:                  func() runtime.Object { return &storageapi.VolumeAttachment{} },
		NewListFunc:              func() runtime.Object { return &storageapi.VolumeAttachmentList{} },
		DefaultQualifiedResource: storageapi.Resource("volumeattachments"),

		CreateStrategy:      volumeattachment.Strategy,
		UpdateStrategy:      volumeattachment.Strategy,
		DeleteStrategy:      volumeattachment.Strategy,
		ReturnDeletedObject: true,

		TableConvertor: printerstorage.TableConvertor{TableGenerator: printers.NewTableGenerator().With(printersinternal.AddHandlers)},
	}
	options := &generic.StoreOptions{RESTOptions: optsGetter}
	if err := store.CompleteWithOptions(options); err != nil {
		panic(err) // TODO: Propagate error up
	}

	statusStore := *store
	statusStore.UpdateStrategy = volumeattachment.StatusStrategy

	return &VolumeAttachmentStorage{
		VolumeAttachment: &REST{store},
		Status:           &StatusREST{store: &statusStore},
	}
}
source: func NewAtomicWebSocketSet() AtomicWebSocketSet {
	return AtomicWebSocketSet{
		sockets: map[uint64]*websocket.Conn{},
		mutex:   &sync.Mutex{},
	}
}
source: func (b *Client) AnalogWrite(pin int, value int) error {
	b.pins[pin].Value = value
	return b.write([]byte{AnalogMessage | byte(pin), byte(value & 0x7F), byte((value >> 7) & 0x7F)})
}
source: func (rm *roleManager) removeMember(ctx context.Context, member *membership.Member) {
	// Quorum safeguard - quorum should have been checked before a node was allowed to be demoted, but if in the
	// intervening time some other node disconnected, removing this node would result in a loss of cluster quorum.
	// We leave it
	if !rm.raft.CanRemoveMember(member.RaftID) {
		// TODO(aaronl): Retry later
		log.G(ctx).Debugf("can't demote node %s at this time: removing member from raft would result in a loss of quorum", member.NodeID)
		return
	}

	rmCtx, rmCancel := context.WithTimeout(rm.ctx, removalTimeout)
	defer rmCancel()

	if member.RaftID == rm.raft.Config.ID {
		// Don't use rmCtx, because we expect to lose
		// leadership, which will cancel this context.
		log.G(ctx).Info("demoted; transferring leadership")
		err := rm.raft.TransferLeadership(context.Background())
		if err == nil {
			return
		}
		log.G(ctx).WithError(err).Info("failed to transfer leadership")
	}
	if err := rm.raft.RemoveMember(rmCtx, member.RaftID); err != nil {
		// TODO(aaronl): Retry later
		log.G(ctx).WithError(err).Debugf("can't demote node %s at this time", member.NodeID)
	}
}
source: func parseCSRExtensions(rawAttributes []asn1.RawValue) ([]pkix.Extension, error) {
	// pkcs10Attribute reflects the Attribute structure from section 4.1 of
	// https://tools.ietf.org/html/rfc2986.
	type pkcs10Attribute struct {
		Id     asn1.ObjectIdentifier
		Values []asn1.RawValue `asn1:"set"`
	}

	var ret []pkix.Extension
	for _, rawAttr := range rawAttributes {
		var attr pkcs10Attribute
		if rest, err := asn1.Unmarshal(rawAttr.FullBytes, &attr); err != nil || len(rest) != 0 || len(attr.Values) == 0 {
			// Ignore attributes that don't parse.
			continue
		}

		if !attr.Id.Equal(oidExtensionRequest) {
			continue
		}

		var extensions []pkix.Extension
		if _, err := asn1.Unmarshal(attr.Values[0].FullBytes, &extensions); err != nil {
			return nil, err
		}
		ret = append(ret, extensions...)
	}

	return ret, nil
}
source: func Traceback(l, l1 *State, message string, level int) {
	const levels1, levels2 = 12, 10
	levels := countLevels(l1)
	mark := 0
	if levels > levels1+levels2 {
		mark = levels1
	}
	buf := message
	if buf != "" {
		buf += "\n"
	}
	buf += "stack traceback:"
	for f, ok := Stack(l1, level); ok; f, ok = Stack(l1, level) {
		if level++; level == mark {
			buf += "\n\t..."
			level = levels - levels2
		} else {
			d, _ := Info(l1, "Slnt", f)
			buf += "\n\t" + d.ShortSource + ":"
			if d.CurrentLine > 0 {
				buf += fmt.Sprintf("%d:", d.CurrentLine)
			}
			buf += " in " + functionName(l, d)
			if d.IsTailCall {
				buf += "\n\t(...tail calls...)"
			}
		}
	}
	l.PushString(buf)
}
source: func docIDInt64(modelUUID string, localID int64) string {
	return modelUUID + ":" + strconv.FormatInt(localID, 10)
}
source: func (b *BackgroundEphemeralPurger) initQueue(ctx context.Context) {
	b.queueLock.Lock()
	defer b.queueLock.Unlock()

	// Create a new queue
	b.pq = newPriorityQueue()
	heap.Init(b.pq)

	allPurgeInfo, err := b.storage.GetAllPurgeInfo(ctx, b.uid)
	if err != nil {
		b.Debug(ctx, "unable to get purgeInfo: %v", allPurgeInfo)
	}
	for _, purgeInfo := range allPurgeInfo {
		if purgeInfo.IsActive {
			b.updateQueue(purgeInfo)
		}
	}
}
source: func (t *Table) printRow(columns [][]string, rowIdx int) {
	// Get Maximum Height
	max := t.rs[rowIdx]
	total := len(columns)

	// TODO Fix uneven col size
	// if total < t.colSize {
	//	for n := t.colSize - total; n < t.colSize ; n++ {
	//		columns = append(columns, []string{SPACE})
	//		t.cs[n] = t.mW
	//	}
	//}

	// Pad Each Height
	pads := []int{}

	// Checking for ANSI escape sequences for columns
	is_esc_seq := false
	if len(t.columnsParams) > 0 {
		is_esc_seq = true
	}
	t.fillAlignment(total)

	for i, line := range columns {
		length := len(line)
		pad := max - length
		pads = append(pads, pad)
		for n := 0; n < pad; n++ {
			columns[i] = append(columns[i], "  ")
		}
	}
	//fmt.Println(max, "\n")
	for x := 0; x < max; x++ {
		for y := 0; y < total; y++ {

			// Check if border is set
			fmt.Fprint(t.out, ConditionString((!t.borders.Left && y == 0), SPACE, t.pColumn))

			fmt.Fprintf(t.out, SPACE)
			str := columns[y][x]

			// Embedding escape sequence with column value
			if is_esc_seq {
				str = format(str, t.columnsParams[y])
			}

			// This would print alignment
			// Default alignment  would use multiple configuration
			switch t.columnsAlign[y] {
			case ALIGN_CENTER: //
				fmt.Fprintf(t.out, "%s", Pad(str, SPACE, t.cs[y]))
			case ALIGN_RIGHT:
				fmt.Fprintf(t.out, "%s", PadLeft(str, SPACE, t.cs[y]))
			case ALIGN_LEFT:
				fmt.Fprintf(t.out, "%s", PadRight(str, SPACE, t.cs[y]))
			default:
				if decimal.MatchString(strings.TrimSpace(str)) || percent.MatchString(strings.TrimSpace(str)) {
					fmt.Fprintf(t.out, "%s", PadLeft(str, SPACE, t.cs[y]))
				} else {
					fmt.Fprintf(t.out, "%s", PadRight(str, SPACE, t.cs[y]))

					// TODO Custom alignment per column
					//if max == 1 || pads[y] > 0 {
					//	fmt.Fprintf(t.out, "%s", Pad(str, SPACE, t.cs[y]))
					//} else {
					//	fmt.Fprintf(t.out, "%s", PadRight(str, SPACE, t.cs[y]))
					//}

				}
			}
			fmt.Fprintf(t.out, SPACE)
		}
		// Check if border is set
		// Replace with space if not set
		fmt.Fprint(t.out, ConditionString(t.borders.Left, t.pColumn, SPACE))
		fmt.Fprint(t.out, t.newLine)
	}

	if t.rowLine {
		t.printLine(true)
	}
}
source: func (s *CustomKeyStoresListEntry) SetConnectionErrorCode(v string) *CustomKeyStoresListEntry {
	s.ConnectionErrorCode = &v
	return s
}
source: func (f *Form) AddButton(label string, selected func()) *Form {
	f.buttons = append(f.buttons, NewButton(label).SetSelectedFunc(selected))
	return f
}
source: func (b *backups) Remove(id string) error {
	return errors.Trace(b.storage.Remove(id))
}
source: func NewPipe(pipe *Pipe, path string) *Pipe {

	p := &Pipe{
		Out:    make([]messageChan, 0),
		path:   path,
		chStop: make(chan struct{}),
	}

	if pipe != nil {
		pipe.Out = append(pipe.Out, newMessageChan())
		p.In = pipe.Out[len(pipe.Out)-1] // use the last out channel
		p.Err = pipe.Err
		p.Event = pipe.Event
	} else {
		p.Err = make(chan error)
		p.Event = make(chan events.Event, 10) // buffer the event channel
	}

	return p
}
source: func NewArrayIndexer(array ArrayIndexer) IteratorIndexer {
	return &arrayIteratorIndexer{
		basicArrayIterator: basicArrayIterator{array: array, pos: -1},
		array:              array,
	}
}
source: func Connect(connectionString string) (*Database, error) {
	var e error
	db := new(Database)
	if db.db, e = sql.Open("postgres", connectionString); e != nil {
		return nil, e
	}

	// Ping the database to see if the connection is real
	if e = db.DB().Ping(); e != nil {
		return nil, errors.New("Connection failed. Unable to ping the DB: " + e.Error())
	}

	db.connectionString = connectionString
	db.clear()
	return db, nil
}
source: func Set(key string, value interface{}) {
	parts := strings.Split(key, ":")
	last := map[interface{}]interface{}{
		parts[len(parts)-1]: value,
	}
	for i := len(parts) - 2; i >= 0; i-- {
		last = map[interface{}]interface{}{
			parts[i]: last,
		}
	}
	configs.Lock()
	defer configs.Unlock()
	configs.store(mergeMaps(configs.data, last))
}
source: func redirectedWarn(time string, caller string, message string) {
	logger.WithFields(map[string]interface{}{callerKey: caller, "time": time}).Warn(message)
}
source: func (l *LineStroker) Close() {
	if len(l.vertices) > 1 {
		l.appendVertex(l.vertices[0], l.vertices[1], l.rewind[0], l.rewind[1])
	}
}
source: func (cb *CreateBuilder) Table(name string) *CreateTableBuilder {
	return &CreateTableBuilder{
		name:    name,
		columns: make([]tableColumn, 0),
	}
}
source: func runPolicyListCmd(args cli.Args) {
	targetURL := args.First()
	policies, err := doGetAccessRules(targetURL)
	if err != nil {
		switch err.ToGoError().(type) {
		case APINotImplemented:
			fatalIf(err.Trace(), "Unable to list policies of a non S3 url `"+targetURL+"`.")
		default:
			fatalIf(err.Trace(targetURL), "Unable to list policies of target `"+targetURL+"`.")
		}
	}
	for k, v := range policies {
		printMsg(policyRules{Resource: k, Allow: v})
	}
}
source: func (statement *Statement) join(joinOP string, tablename interface{}, condition string, args ...interface{}) *Statement {
	join := statement.joinTables.New(statement)
	join.Operator = joinOP
	join.Table = ``
	join.Alias = ``
	join.ONStr = condition
	join.Args = args

	switch t := tablename.(type) {
	case []string:
		if len(t) > 1 {
			join.Table = statement.withPrefix(t[0])
			join.Alias = t[1]
		} else if len(t) == 1 {
			join.Table = statement.withPrefix(t[0])
		}
	case []interface{}:
		l := len(t)
		var table string
		if l > 0 {
			f := t[0]
			v := rValue(f)
			t := v.Type()
			if t.Kind() == reflect.String {
				table = f.(string)
			} else if t.Kind() == reflect.Struct {
				r := statement.Engine.autoMapType(v)
				table = r.Name
			} else {
				table = fmt.Sprintf("%v", f)
			}
			join.Table = statement.withPrefix(table)
		}
		if l > 1 {
			join.Alias = fmt.Sprintf("%v", t[1])
		}
	case core.SQL:
		join.SQLStr = joinOP + ` JOIN ` + string(t)
	case string:
		join.Table = statement.withPrefix(t)
	default:
		v := rValue(tablename)
		typ := v.Type()
		if typ.Kind() == reflect.Struct {
			r := statement.Engine.autoMapType(v)
			join.Table = r.Name
		} else {
			join.Table = statement.withPrefix(fmt.Sprintf("%v", tablename))
		}
	}
	return statement
}
source: func getAltNames(cfg *kubeadmapi.InitConfiguration, certName string) (*certutil.AltNames, error) {
	// advertise address
	advertiseAddress := net.ParseIP(cfg.LocalAPIEndpoint.AdvertiseAddress)
	if advertiseAddress == nil {
		return nil, errors.Errorf("error parsing LocalAPIEndpoint AdvertiseAddress %v: is not a valid textual representation of an IP address",
			cfg.LocalAPIEndpoint.AdvertiseAddress)
	}

	// create AltNames with defaults DNSNames/IPs
	altNames := &certutil.AltNames{
		DNSNames: []string{cfg.NodeRegistration.Name, "localhost"},
		IPs:      []net.IP{advertiseAddress, net.IPv4(127, 0, 0, 1), net.IPv6loopback},
	}

	if cfg.Etcd.Local != nil {
		if certName == kubeadmconstants.EtcdServerCertName {
			appendSANsToAltNames(altNames, cfg.Etcd.Local.ServerCertSANs, kubeadmconstants.EtcdServerCertName)
		} else if certName == kubeadmconstants.EtcdPeerCertName {
			appendSANsToAltNames(altNames, cfg.Etcd.Local.PeerCertSANs, kubeadmconstants.EtcdPeerCertName)
		}
	}
	return altNames, nil
}
source: func (s *Selection) ReplaceWithHtml(html string) *Selection {
	return s.ReplaceWithNodes(parseHtml(html)...)
}
source: func (f *File) Fsync(ctx context.Context, req *fuse.FsyncRequest) (err error) {
	ctx = f.folder.fs.config.MaybeStartTrace(
		ctx, "File.Fsync", f.node.GetBasename())
	defer func() { f.folder.fs.config.MaybeFinishTrace(ctx, err) }()

	f.folder.fs.vlog.CLogf(ctx, libkb.VLog1, "File Fsync")
	defer func() { err = f.folder.processError(ctx, libkbfs.WriteMode, err) }()

	// This fits in situation 1 as described in libkbfs/delayed_cancellation.go
	err = libcontext.EnableDelayedCancellationWithGracePeriod(
		ctx, f.folder.fs.config.DelayedCancellationGracePeriod())
	if err != nil {
		return err
	}

	return f.sync(ctx)
} 81%|████████  | 4049/5000 [00:05<00:01, 510.64it/s] 
source: func (c *Checkpoint) key(streamName, shardID string) string {
	return fmt.Sprintf("%v:checkpoint:%v:%v", c.appName, streamName, shardID)
}
source: func (a *Agent) Stop() error {
	if !atomic.CompareAndSwapUint32(&a.stopped, 0, 1) {
		return nil
	}

	log.Infof("Autopilot Agent stopping")

	close(a.quit)
	a.wg.Wait()

	return nil
}
source: func (s *Scanner) emitSimple(t tokenType, v string) *Token {
	token := &Token{t, v, s.row, s.col}
	s.col += len(v)
	s.pos += len(v)
	return token
}
source: func (g *Group) FindOptionByShortName(shortName rune) *Option {
	return g.findOption(func(option *Option) bool {
		return option.ShortName == shortName
	})
}
source: func (r Product_Package_Preset) GetStorageGroupTemplateArrays() (resp []datatypes.Configuration_Storage_Group_Template_Group, err error) {
	err = r.Session.DoRequest("SoftLayer_Product_Package_Preset", "getStorageGroupTemplateArrays", nil, &r.Options, &resp)
	return
}
source: func (m *MockIndex) Map(arg0 map[int]hash.Hash) {
	m.ctrl.T.Helper()
	m.ctrl.Call(m, "Map", arg0)
}
source: func envError(r *http.Request, err error) *http.Request {
	return contextSave(r, errorKey, err)
}
source: func (dc *Context) Scale(x, y float64) {
	dc.matrix = dc.matrix.Scale(x, y)
}
source: func (p *TextParser) parseError(msg string) {
	p.err = ParseError{
		Line: p.lineCount,
		Msg:  msg,
	}
}
source: func (c *Container) MakeRequest(action string, request SkygearRequest) (response *SkygearResponse, err error) {
	url := c.actionURL(action)
	payload := request.MakePayload()
	c.fixRequestPayload(action, payload)

	jsonStr, err := json.Marshal(payload)
	if err != nil {
		return nil, err
	}

	req, err := c.createRequest("POST", url, "", bytes.NewBuffer(jsonStr))
	if err != nil {
		return nil, err
	}

	jsonDataFromHTTP, err := getBytesResponse(req)
	if err != nil {
		return nil, err
	}

	var jsonData map[string]interface{}
	err = json.Unmarshal(jsonDataFromHTTP, &jsonData)
	if err != nil {
		return
	}

	return &SkygearResponse{Payload: jsonData}, nil

}
source: func NewInmemoryStore() *DBStore {
	db, err := leveldb.Open(storage.NewMemStorage(), nil)
	if err != nil {
		panic(err)
	}
	return &DBStore{
		db: db,
	}
}
source: func (c *DiskTokenCache) readCacheFile() (*cacheFile, error) {
	// Minimize the time the file is locked on Windows by reading it all at once
	// and decoding later.
	//
	// We also need to open it with FILE_SHARE_DELETE sharing mode to allow
	// writeCacheFile() below to replace open files (even though it tries to wait
	// for the file to be closed). For some reason, omitting FILE_SHARE_DELETE
	// flag causes random sharing violation errors when opening the file for
	// reading.
	f, err := openSharedDelete(c.absPath())
	switch {
	case os.IsNotExist(err):
		return &cacheFile{}, nil
	case err != nil:
		return nil, err
	}
	blob, err := ioutil.ReadAll(f)
	f.Close()
	if err != nil {
		return nil, err
	}

	cache := &cacheFile{}
	if err := json.Unmarshal(blob, cache); err != nil {
		// If the cache file got broken somehow, it makes sense to treat it as
		// empty (so it can later be overwritten), since it's unlikely it's going
		// to "fix itself".
		logging.WithError(err).Warningf(c.Context, "The token cache %s is broken", c.absPath())
		return &cacheFile{}, nil
	}

	return cache, nil
}
source: func parseTimeParam(queryParam string, defaultValue time.Time) (time.Time, error) {
	if queryParam != "" {
		reqStamp, err := time.Parse(time.RFC3339, queryParam)
		if err != nil {
			return time.Time{}, fmt.Errorf("timestamp argument cannot be parsed: %s", err)
		}
		return reqStamp, nil
	}
	return defaultValue, nil
}
source: func Zipmap(keys, values cty.Value) (cty.Value, error) {
	return ZipmapFunc.Call([]cty.Value{keys, values})
}
source: func (s *ReceiptAction) SetS3Action(v *S3Action) *ReceiptAction {
	s.S3Action = v
	return s
}
source: func (l *intLogger) Warn(msg string, args ...interface{}) {
	l.Log(Warn, msg, args...)
}
source: func (c *Configurator) MustRegisterTransport(t TransportSpec) {
	if err := c.RegisterTransport(t); err != nil {
		panic(err)
	}
}
source: func Execute(tplName string, w io.Writer, data interface{}) error {
	mu.RLock()
	t, ok := templaters[tplName]
	mu.RUnlock()
	if !ok {
		return ErrTemplateNotExist
	}
	return t.Execute(w, data)
}
source: func (s *Service) OrganizationAppListForOrganization(ctx context.Context, organizationIdentity string, lr *ListRange) (OrganizationAppListForOrganizationResult, error) {
	var organizationApp OrganizationAppListForOrganizationResult
	return organizationApp, s.Get(ctx, &organizationApp, fmt.Sprintf("/organizations/%v/apps", organizationIdentity), nil, lr)
}
source: func (scheduler *LatchesScheduler) UnLock(lock *Lock) {
	scheduler.RLock()
	defer scheduler.RUnlock()
	if !scheduler.closed {
		scheduler.unlockCh <- lock
	}
}
source: func (u *UnknownDeviceError) Error() string {
	return fmt.Sprintf("operation on unknown device(s) \"%s/%s/%s\" (%v): %v",
		u.Vendor, u.Type, u.Name, u.IDs, u.Err)
}
source: func (o *GetOAuth2ClientParams) WithID(id string) *GetOAuth2ClientParams {
	o.SetID(id)
	return o
}
source: func (w *Window) MakePicture(p pixel.Picture) pixel.TargetPicture {
	return w.canvas.MakePicture(p)
}
source: func (session *Session) DB() *core.DB {
	if session.db == nil {
		session.db = session.engine.db
		session.stmtCache = make(map[uint32]*core.Stmt, 0)
	}
	return session.db
}
source: func IsRFC(rfcNum uint, sa SockAddr) bool {
	rfcNetMap := KnownRFCs()
	rfcNets, ok := rfcNetMap[rfcNum]
	if !ok {
		return false
	}

	var contained bool
	for _, rfcNet := range rfcNets {
		if rfcNet.Contains(sa) {
			contained = true
			break
		}
	}
	return contained
}
source: func (s *ListComplianceStatusOutput) SetPolicyComplianceStatusList(v []*PolicyComplianceStatus) *ListComplianceStatusOutput {
	s.PolicyComplianceStatusList = v
	return s
}
source: func (s SortedTrustedCluster) Less(i, j int) bool {
	return s[i].GetName() < s[j].GetName()
}
source: func (w *deploymentWatcher) doneGroups(d *structs.Deployment) map[string]bool {
	if d == nil {
		return nil
	}

	// Collect the allocations by the task group
	snap, err := w.state.Snapshot()
	if err != nil {
		return nil
	}

	allocs, err := snap.AllocsByDeployment(nil, d.ID)
	if err != nil {
		return nil
	}

	// Go through the allocs and count up how many healthy allocs we have
	healthy := make(map[string]int, len(d.TaskGroups))
	for _, a := range allocs {
		if a.TerminalStatus() || !a.DeploymentStatus.IsHealthy() {
			continue
		}
		healthy[a.TaskGroup]++
	}

	// Go through each group and check if it done
	groups := make(map[string]bool, len(d.TaskGroups))
	for name, state := range d.TaskGroups {
		// Requires promotion
		if state.DesiredCanaries != 0 && !state.Promoted {
			groups[name] = false
			continue
		}

		// Check we have enough healthy currently running allocations
		groups[name] = healthy[name] >= state.DesiredTotal
	}

	return groups
}
source: func DefaultName(name string) string {
	return fmt.Sprintf("%s-%X", name, Rand(int(^uint(0)>>1)))
}
source: func MapGetByRankOp(binName string, rank int, returnType mapReturnType) *Operation {
	return newCDTCreateOperationValue1(_CDT_MAP_GET_BY_RANK, _MAP_READ, binName, rank, returnType)
}
source: func (h *Client) RollbackRelease(rlsName string, opts ...RollbackOption) (*rls.RollbackReleaseResponse, error) {
	reqOpts := h.opts
	for _, opt := range opts {
		opt(&reqOpts)
	}
	req := &reqOpts.rollbackReq
	req.Recreate = reqOpts.recreate
	req.Force = reqOpts.force
	req.DisableHooks = reqOpts.disableHooks
	req.DryRun = reqOpts.dryRun
	req.Name = rlsName
	ctx := NewContext()

	if reqOpts.before != nil {
		if err := reqOpts.before(ctx, req); err != nil {
			return nil, err
		}
	}
	return h.rollback(ctx, req)
}
source: func (c *Cron) Entries() []*Entry {
	if c.running {
		c.snapshot <- nil
		x := <-c.snapshot
		return x
	}
	return c.entrySnapshot()
}
source: func (c *Client) processPubrel(id packet.ID) error {
	// get packet from store
	pkt, err := c.Session.LookupPacket(session.Incoming, id)
	if err != nil {
		return c.die(err, true, false)
	}

	// get packet from store
	publish, ok := pkt.(*packet.Publish)
	if !ok {
		return nil // ignore a wrongly sent Pubrel packet
	}

	// call callback
	if c.Callback != nil {
		err = c.Callback(&publish.Message, nil)
		if err != nil {
			return c.die(err, true, true)
		}
	}

	// prepare pubcomp packet
	pubcomp := packet.NewPubcomp()
	pubcomp.ID = publish.ID

	// acknowledge Publish packet
	err = c.send(pubcomp, true)
	if err != nil {
		return c.die(err, false, false)
	}

	// remove packet from store
	err = c.Session.DeletePacket(session.Incoming, id)
	if err != nil {
		return c.die(err, true, false)
	}

	return nil
}
source: func NewServer(f *facade.Facade, tokenExpiration time.Duration) *Server {
	return &Server{f, tokenExpiration}
}
source: func (c *safeConverterWrapper) Convert(in, out, context interface{}) error {
	inObject, ok := in.(runtime.Object)
	if !ok {
		return fmt.Errorf("input type %T in not valid for object conversion", in)
	}
	return c.unsafe.Convert(inObject.DeepCopyObject(), out, context)
}
source: func (s *SerializableHttpRequest) ToJson() string {
	jsonVal, err := json.Marshal(s)
	if err != nil || jsonVal == nil {
		return fmt.Sprintf("Error marshalling SerializableHttpRequest to json: %s", err)
	}
	return string(jsonVal)
}
source: func validateMergeKeyInLists(mergeKey string, lists ...[]interface{}) error {
	for _, list := range lists {
		for _, item := range list {
			m, ok := item.(map[string]interface{})
			if !ok {
				return mergepatch.ErrBadArgType(m, item)
			}
			if _, ok = m[mergeKey]; !ok {
				return mergepatch.ErrNoMergeKey(m, mergeKey)
			}
		}
	}
	return nil
}
source: func (p *Producer) UnmarshalJSON(b []byte) error {
	var r struct {
		RemoteAddress    string   `json:"remote_address"`
		Hostname         string   `json:"hostname"`
		BroadcastAddress string   `json:"broadcast_address"`
		TCPPort          int      `json:"tcp_port"`
		HTTPPort         int      `json:"http_port"`
		Version          string   `json:"version"`
		Topics           []string `json:"topics"`
		Tombstoned       []bool   `json:"tombstones"`
	}
	if err := json.Unmarshal(b, &r); err != nil {
		return err
	}
	*p = Producer{
		RemoteAddress:    r.RemoteAddress,
		Hostname:         r.Hostname,
		BroadcastAddress: r.BroadcastAddress,
		TCPPort:          r.TCPPort,
		HTTPPort:         r.HTTPPort,
		Version:          r.Version,
	}
	for i, t := range r.Topics {
		p.Topics = append(p.Topics, ProducerTopic{Topic: t, Tombstoned: r.Tombstoned[i]})
	}
	version, err := semver.Parse(p.Version)
	if err != nil {
		version, _ = semver.Parse("0.0.0")
	}
	p.VersionObj = version
	return nil
}
source: func (v *version) ServiceAccounts() ServiceAccountInformer {
	return &serviceAccountInformer{factory: v.factory, namespace: v.namespace, tweakListOptions: v.tweakListOptions}
}
source: func (m MeterBands) WriteTo(w io.Writer) (int64, error) {
	var n int64

	for _, meter := range m {
		nn, err := meter.WriteTo(w)
		n += nn

		if err != nil {
			return n, err
		}
	}

	return n, nil
}
source: func (o *OrderGetParams) WithHTTPClient(client *http.Client) *OrderGetParams {
	o.SetHTTPClient(client)
	return o
}
source: func WaitForCacheSync(stopCh <-chan struct{}, cacheSyncs ...InformerSynced) bool {
	err := wait.PollUntil(syncedPollPeriod,
		func() (bool, error) {
			for _, syncFunc := range cacheSyncs {
				if !syncFunc() {
					return false, nil
				}
			}
			return true, nil
		},
		stopCh)
	if err != nil {
		klog.V(2).Infof("stop requested")
		return false
	}

	klog.V(4).Infof("caches populated")
	return true
}
source: func (tt TemplateType) String() string {
	var s string
	switch tt {
	case XOTemplate:
		s = "xo_db"
	case EnumTemplate:
		s = "enum"
	case ProcTemplate:
		s = "proc"
	case TypeTemplate:
		s = "type"
	case ForeignKeyTemplate:
		s = "foreignkey"
	case IndexTemplate:
		s = "index"
	case QueryTypeTemplate:
		s = "querytype"
	case QueryTemplate:
		s = "query"
	default:
		panic("unknown TemplateType")
	}
	return s
}
source: func (m *MockLinkLayerDevice) IsUp() bool {
	ret := m.ctrl.Call(m, "IsUp")
	ret0, _ := ret[0].(bool)
	return ret0
}
source: func (b *Filter) Greylist(err error) {
	s, ok := status.FromError(err)
	if !ok {
		return
	}
	if ok, peerURL := required(s); ok && peerURL != "" {
		logger.Infof("Greylisting peer %s", peerURL)
		b.greylistURLs.Store(peerURL, time.Now())
	}
}
source: func ossGeBucketInfo(ctx context.Context, client *oss.Client, bucket string) (bi minio.BucketInfo, err error) {
	bgir, err := client.GetBucketInfo(bucket)
	if err != nil {
		logger.LogIf(ctx, err)
		return bi, ossToObjectError(err, bucket)
	}

	return minio.BucketInfo{
		Name:    bgir.BucketInfo.Name,
		Created: bgir.BucketInfo.CreationDate,
	}, nil
}
source: func (p *Provider) ReadDataSource(req providers.ReadDataSourceRequest) providers.ReadDataSourceResponse {
	// call function
	var res providers.ReadDataSourceResponse

	// This should not happen
	if req.TypeName != "terraform_remote_state" {
		res.Diagnostics.Append(fmt.Errorf("Error: unsupported data source %s", req.TypeName))
		return res
	}

	newState, diags := dataSourceRemoteStateRead(&req.Config)

	res.State = newState
	res.Diagnostics = diags

	return res
}
source: func (f FindOptions) QueryParams() map[string][]string {
	qp := map[string][]string{
		"offset":     {strconv.Itoa(f.Offset)},
		"descending": {strconv.FormatBool(f.Descending)},
	}

	if f.Limit > 0 {
		qp["limit"] = []string{strconv.Itoa(f.Limit)}
	}

	if f.SortBy != "" {
		qp["sortBy"] = []string{f.SortBy}
	}

	return qp
}
source: func (r *lockedSource) seedPos(seed int64, readPos *int8) {
	r.lk.Lock()
	r.src.Seed(seed)
	*readPos = 0
	r.lk.Unlock()
}
source: func NewAPIV2(st *state.State, res facade.Resources, auth facade.Authorizer) (APIV2, error) {
	return NewAPI(st, res, auth)
}
source: func (c *ClusterManager) ObjectStoreInspect(objectstoreID string) (*api.ObjectstoreInfo, error) {
	return c.objstoreManager.ObjectStoreInspect(objectstoreID)
}
source: func newTopologyPairsMaps() *topologyPairsMaps {
	return &topologyPairsMaps{topologyPairToPods: make(map[topologyPair]podSet),
		podToTopologyPairs: make(map[string]topologyPairSet)}
}
source: func NewMurmur2HashPartitioner(topic string) kafka.Partitioner {
	p := new(Murmur2HashPartitioner)
	p.random = kafka.NewRandomPartitioner(topic)
	return p
}
source: func ShellQuoteArgs(args []string) string {
	quotedArgs := []string{}
	for _, arg := range args {
		quotedArgs = append(quotedArgs, ShellQuoteArg(arg))
	}
	return strings.Join(quotedArgs, " ")
}
source: func (b *Backend) createMongoIndexes(database string) error {

	tasksCollection := b.client.Database(database).Collection("tasks")

	expireIn := int32(b.GetConfig().ResultsExpireIn)

	_, err := tasksCollection.Indexes().CreateMany(context.Background(), []mongo.IndexModel{
		{
			Keys:    bson.M{"state": 1},
			Options: options.Index().SetBackground(true).SetExpireAfterSeconds(expireIn),
		},
		mongo.IndexModel{
			Keys:    bson.M{"lock": 1},
			Options: options.Index().SetBackground(true).SetExpireAfterSeconds(expireIn),
		},
	})
	if err != nil {
		return err
	}

	return err
}
source: func main() {
	flag.Parse()

	specfname, e := getSpecFileName("compliance.prop")
	if e != nil {
		log.Println("error -", e)
	}
	rmspec, e1 := readCommandsFromSpecFile(specfname)
	if e1 != nil {
		log.Println("error -", e1)
		return
	}

	var rctype clientType

	fmt.Println()
	fmt.Println("/////////////////////////////////////")
	fmt.Println("///  Go-Redis client compliance   ///")
	fmt.Println("/////////////////////////////////////\n")

	rctype = sync
	analyzeAndReport(rctype, rmspec)

	rctype = async
	analyzeAndReport(rctype, rmspec)
}
source: func (s *Store) SessionGet(ws memdb.WatchSet, sessionID string) (uint64, *structs.Session, error) {
	tx := s.db.Txn(false)
	defer tx.Abort()

	// Get the table index.
	idx := maxIndexTxn(tx, "sessions")

	// Look up the session by its ID
	watchCh, session, err := tx.FirstWatch("sessions", "id", sessionID)
	if err != nil {
		return 0, nil, fmt.Errorf("failed session lookup: %s", err)
	}
	ws.Add(watchCh)
	if session != nil {
		return idx, session.(*structs.Session), nil
	}
	return idx, nil, nil
}
source: func (r *rpcServer) createBackupSnapshot(backups []chanbackup.Single) (
	*lnrpc.ChanBackupSnapshot, error) {

	// Once we have the set of back ups, we'll attempt to pack them all
	// into a series of single channel backups.
	singleChanPackedBackups, err := chanbackup.PackStaticChanBackups(
		backups, r.server.cc.keyRing,
	)
	if err != nil {
		return nil, fmt.Errorf("unable to pack set of chan "+
			"backups: %v", err)
	}

	// Now that we have our set of single packed backups, we'll morph that
	// into a form that the proto response requires.
	numBackups := len(singleChanPackedBackups)
	singleBackupResp := &lnrpc.ChannelBackups{
		ChanBackups: make([]*lnrpc.ChannelBackup, 0, numBackups),
	}
	for chanPoint, singlePackedBackup := range singleChanPackedBackups {
		txid := chanPoint.Hash
		rpcChanPoint := &lnrpc.ChannelPoint{
			FundingTxid: &lnrpc.ChannelPoint_FundingTxidBytes{
				FundingTxidBytes: txid[:],
			},
			OutputIndex: chanPoint.Index,
		}

		singleBackupResp.ChanBackups = append(
			singleBackupResp.ChanBackups,
			&lnrpc.ChannelBackup{
				ChanPoint:  rpcChanPoint,
				ChanBackup: singlePackedBackup,
			},
		)
	}

	// In addition, to the set of single chan backups, we'll also create a
	// single multi-channel backup which can be serialized into a single
	// file for safe storage.
	var b bytes.Buffer
	unpackedMultiBackup := chanbackup.Multi{
		StaticBackups: backups,
	}
	err = unpackedMultiBackup.PackToWriter(&b, r.server.cc.keyRing)
	if err != nil {
		return nil, fmt.Errorf("unable to multi-pack backups: %v", err)
	}

	multiBackupResp := &lnrpc.MultiChanBackup{
		MultiChanBackup: b.Bytes(),
	}
	for _, singleBackup := range singleBackupResp.ChanBackups {
		multiBackupResp.ChanPoints = append(
			multiBackupResp.ChanPoints, singleBackup.ChanPoint,
		)
	}

	return &lnrpc.ChanBackupSnapshot{
		SingleChanBackups: singleBackupResp,
		MultiChanBackup:   multiBackupResp,
	}, nil
}
source: func toMessage(messages []*ReceivedMessage) []*Message {
	msgs := make([]*Message, len(messages))
	for i, msg := range messages {
		msgs[i] = ToWhisperMessage(msg)
	}
	return msgs
}
source: func (cp *CIDRPolicy) Validate() error {
	if cp == nil {
		return nil
	}
	if l := len(cp.Ingress.IPv6PrefixCount); l > api.MaxCIDRPrefixLengths {
		return fmt.Errorf("too many ingress CIDR prefix lengths %d/%d", l, api.MaxCIDRPrefixLengths)
	}
	return nil
}
source: func (s *Stack) createFileBasedSecrets(secrets corev1.SecretInterface) ([]childResource, error) {
	var resources []childResource
	for name, secret := range s.Spec.Secrets {
		if secret.File == "" {
			continue
		}

		fileName := filepath.Base(secret.File)
		content, err := ioutil.ReadFile(secret.File)
		if err != nil {
			return resources, err
		}

		secret, err := secrets.Create(toSecret(s.Name, name, fileName, content))
		if err != nil {
			return resources, err
		}
		resources = append(resources, &secretChildResource{client: secrets, secret: secret})
	}
	return resources, nil
}
source: func (c *Client) GetValue(key string) (data []byte, found bool, revision int64, err error) {
	var entry *decoder.FileDataEntry
	entry, found = c.db.GetDataForKey(key)
	data = entry.Value
	return
}
source: func (c *Config) SendEmailHTML(from, to, subject, bodyText, bodyHTML string) (string, error) {
	data := make(url.Values)
	data.Add("Action", "SendEmail")
	data.Add("Source", from)
	data.Add("Destination.ToAddresses.member.1", to)
	data.Add("Message.Subject.Data", subject)
	data.Add("Message.Body.Text.Data", bodyText)
	data.Add("Message.Body.Html.Data", bodyHTML)
	data.Add("AWSAccessKeyId", c.AccessKeyID)

	return sesPost(data, c.Endpoint, c.AccessKeyID, c.SecretAccessKey)
}
source: func (ss *scaleSet) GetPrimaryInterface(nodeName string) (network.Interface, error) {
	managedByAS, err := ss.isNodeManagedByAvailabilitySet(nodeName)
	if err != nil {
		klog.Errorf("Failed to check isNodeManagedByAvailabilitySet: %v", err)
		return network.Interface{}, err
	}
	if managedByAS {
		// vm is managed by availability set.
		return ss.availabilitySet.GetPrimaryInterface(nodeName)
	}

	ssName, instanceID, vm, err := ss.getVmssVM(nodeName)
	if err != nil {
		// VM is availability set, but not cached yet in availabilitySetNodesCache.
		if err == ErrorNotVmssInstance {
			return ss.availabilitySet.GetPrimaryInterface(nodeName)
		}

		klog.Errorf("error: ss.GetPrimaryInterface(%s), ss.getVmssVM(%s), err=%v", nodeName, nodeName, err)
		return network.Interface{}, err
	}

	primaryInterfaceID, err := ss.getPrimaryInterfaceID(vm)
	if err != nil {
		klog.Errorf("error: ss.GetPrimaryInterface(%s), ss.getPrimaryInterfaceID(), err=%v", nodeName, err)
		return network.Interface{}, err
	}

	nicName, err := getLastSegment(primaryInterfaceID)
	if err != nil {
		klog.Errorf("error: ss.GetPrimaryInterface(%s), getLastSegment(%s), err=%v", nodeName, primaryInterfaceID, err)
		return network.Interface{}, err
	}
	resourceGroup, err := extractResourceGroupByVMSSNicID(primaryInterfaceID)
	if err != nil {
		return network.Interface{}, err
	}

	ctx, cancel := getContextWithCancel()
	defer cancel()
	nic, err := ss.InterfacesClient.GetVirtualMachineScaleSetNetworkInterface(ctx, resourceGroup, ssName, instanceID, nicName, "")
	if err != nil {
		klog.Errorf("error: ss.GetPrimaryInterface(%s), ss.GetVirtualMachineScaleSetNetworkInterface.Get(%s, %s, %s), err=%v", nodeName, resourceGroup, ssName, nicName, err)
		return network.Interface{}, err
	}

	// Fix interface's location, which is required when updating the interface.
	// TODO: is this a bug of azure SDK?
	if nic.Location == nil || *nic.Location == "" {
		nic.Location = vm.Location
	}

	return nic, nil
}
source: func (s *IDsScanner) ID() string {
	if len(s.ids) == 0 {
		return ""
	}
	return s.ids[s.start : s.start+1][0]
}
source: func (s *SortCommand) By(pattern string) *SortCommand {
	s.by = pattern
	return s
}
source: func marshalWriter(f afero.File, configType string) error {
	return v.marshalWriter(f, configType)
}
source: func (m *CreateMetaInfo) GetProjectWithKey(key string) *MetaProject {
	for _, m := range m.Projects {
		if strings.ToLower(m.Key) == strings.ToLower(key) {
			return m
		}
	}
	return nil
}
source: func (_class VIFClass) ConfigureIpv6(sessionID SessionRef, self VIFRef, mode VifIpv6ConfigurationMode, address string, gateway string) (_err error) {
	_method := "VIF.configure_ipv6"
	_sessionIDArg, _err := convertSessionRefToXen(fmt.Sprintf("%s(%s)", _method, "session_id"), sessionID)
	if _err != nil {
		return
	}
	_selfArg, _err := convertVIFRefToXen(fmt.Sprintf("%s(%s)", _method, "self"), self)
	if _err != nil {
		return
	}
	_modeArg, _err := convertEnumVifIpv6ConfigurationModeToXen(fmt.Sprintf("%s(%s)", _method, "mode"), mode)
	if _err != nil {
		return
	}
	_addressArg, _err := convertStringToXen(fmt.Sprintf("%s(%s)", _method, "address"), address)
	if _err != nil {
		return
	}
	_gatewayArg, _err := convertStringToXen(fmt.Sprintf("%s(%s)", _method, "gateway"), gateway)
	if _err != nil {
		return
	}
	_, _err =  _class.client.APICall(_method, _sessionIDArg, _selfArg, _modeArg, _addressArg, _gatewayArg)
	return
}
source: func (s *Server) needJWT() bool {
	for _, r := range s.Resources {
		if r.NeedJWT() {
			return true
		}
	}
	return false
}
source: func (s *EventSubscription) SetSubscribedAt(v time.Time) *EventSubscription {
	s.SubscribedAt = &v
	return s
}
source: func SendGroupAttachment(hexid string, msg string, r io.Reader) (uint64, error) {
	ct, r := MIMETypeFromReader(r)
	a, err := uploadAttachment(r, ct)
	if err != nil {
		return 0, err
	}
	return sendGroupHelper(hexid, msg, a)
}
source: func ensureChartFetched(base string, source *flux_v1beta1.RepoChartSource) (string, error) {
	chartPath := makeChartPath(base, source)
	stat, err := os.Stat(chartPath)
	switch {
	case os.IsNotExist(err):
		return chartPath, downloadChart(chartPath, source)
	case err != nil:
		return chartPath, err
	case stat.IsDir():
		return chartPath, errors.New("path to chart exists but is a directory")
	}
	return chartPath, nil
}
source: func (a *TestAuthServer) Trust(remote *TestAuthServer, roleMap services.RoleMap) error {
	remoteCA, err := remote.AuthServer.GetCertAuthority(services.CertAuthID{
		Type:       services.HostCA,
		DomainName: remote.ClusterName,
	}, false)
	if err != nil {
		return trace.Wrap(err)
	}
	err = a.AuthServer.UpsertCertAuthority(remoteCA)
	if err != nil {
		return trace.Wrap(err)
	}
	remoteCA, err = remote.AuthServer.GetCertAuthority(services.CertAuthID{
		Type:       services.UserCA,
		DomainName: remote.ClusterName,
	}, false)
	if err != nil {
		return trace.Wrap(err)
	}
	remoteCA.SetRoleMap(roleMap)
	err = a.AuthServer.UpsertCertAuthority(remoteCA)
	if err != nil {
		return trace.Wrap(err)
	}
	return nil
}
source: func ErrorWithExtras(level string, err error, extras map[string]interface{}) {
	std.ErrorWithExtras(level, err, extras)
}
source: func lexDataPrefix(l *lexer) stateFn {
	l.pos += len(dataPrefix)
	l.emit(itemDataPrefix)
	return lexAfterDataPrefix
}
source: func (s *state) getBlock(name string) *parse.BlockNode {
	for _, blocks := range s.blocks {
		if block, ok := blocks[name]; ok {
			return block
		}
	}

	return nil
}
source: func getPolicyConfig(objAPI ObjectLayer, bucketName string) (*policy.Policy, error) {
	// Construct path to policy.json for the given bucket.
	configFile := path.Join(bucketConfigPrefix, bucketName, bucketPolicyConfig)

	configData, err := readConfig(context.Background(), objAPI, configFile)
	if err != nil {
		if err == errConfigNotFound {
			err = BucketPolicyNotFound{Bucket: bucketName}
		}

		return nil, err
	}

	return policy.ParseConfig(bytes.NewReader(configData), bucketName)
}
source: func MissingParamError(name string) error {
	msg := fmt.Sprintf("missing required parameter %#v", name)
	return ErrInvalidRequest(msg, "name", name)
}
source: func (s ClusterRoleBindingGeneratorV1) StructuredGenerate() (runtime.Object, error) {
	if err := s.validate(); err != nil {
		return nil, err
	}
	clusterRoleBinding := &rbacv1beta1.ClusterRoleBinding{}
	clusterRoleBinding.Name = s.Name
	clusterRoleBinding.RoleRef = rbacv1beta1.RoleRef{
		APIGroup: rbacv1beta1.GroupName,
		Kind:     "ClusterRole",
		Name:     s.ClusterRole,
	}
	for _, user := range sets.NewString(s.Users...).List() {
		clusterRoleBinding.Subjects = append(clusterRoleBinding.Subjects, rbacv1beta1.Subject{
			Kind:     rbacv1beta1.UserKind,
			APIGroup: rbacv1beta1.GroupName,
			Name:     user,
		})
	}
	for _, group := range sets.NewString(s.Groups...).List() {
		clusterRoleBinding.Subjects = append(clusterRoleBinding.Subjects, rbacv1beta1.Subject{
			Kind:     rbacv1beta1.GroupKind,
			APIGroup: rbacv1beta1.GroupName,
			Name:     group,
		})
	}
	for _, sa := range sets.NewString(s.ServiceAccounts...).List() {
		tokens := strings.Split(sa, ":")
		if len(tokens) != 2 || tokens[0] == "" || tokens[1] == "" {
			return nil, fmt.Errorf("serviceaccount must be <namespace>:<name>")
		}
		clusterRoleBinding.Subjects = append(clusterRoleBinding.Subjects, rbacv1beta1.Subject{
			Kind:      rbacv1beta1.ServiceAccountKind,
			APIGroup:  "",
			Namespace: tokens[0],
			Name:      tokens[1],
		})
	}

	return clusterRoleBinding, nil
}
source: func BuildTableInfoFromAST(s *ast.CreateTableStmt) (*model.TableInfo, error) {
	return buildTableInfoWithCheck(mock.NewContext(), nil, s, mysql.DefaultCharset)
}
source: func (c *Etcd2Lock) addSemaphoreKey() (string, uint64, error) {
	// CreateInOrder is an atomic operation that can be used to enqueue a
	// request onto a semaphore. In the rest of the comments, we refer to the
	// resulting key as a "semaphore key".
	// https://coreos.com/etcd/docs/2.0.8/api.html#atomically-creating-in-order-keys
	opts := &client.CreateInOrderOptions{
		TTL: Etcd2LockTTL,
	}
	response, err := c.kAPI.CreateInOrder(context.Background(), c.semaphoreDirKey, c.value, opts)
	if err != nil {
		return "", 0, err
	}
	return response.Node.Key, response.Index, nil
}
source: func (c *DefaultClient) NewSubscriber(exchange, name string, durable, autoDelete bool) Subscriber {
	return &DefaultSubscriber{
		DefaultChannelClient: DefaultChannelClient{
			ctx:      c.ctx,
			client:   c,
			exchange: exchange,
			name:     "Subscriber",
		},
		name:       name,
		durable:    durable,
		autoDelete: autoDelete,
	}
}
source: func Convert_v1_DeploymentList_To_apps_DeploymentList(in *v1.DeploymentList, out *apps.DeploymentList, s conversion.Scope) error {
	return autoConvert_v1_DeploymentList_To_apps_DeploymentList(in, out, s)
}
source: func AppendIfMissing(slice []string, i string) []string {
	if StrListContains(slice, i) {
		return slice
	}
	return append(slice, i)
}
source: func (i *Index) openExistenceField() error {
	f, err := i.createFieldIfNotExists(existenceFieldName, FieldOptions{CacheType: CacheTypeNone, CacheSize: 0})
	if err != nil {
		return errors.Wrap(err, "creating existence field")
	}
	i.existenceFld = f
	return nil
}
source: func (p *PacketOut) ReadFrom(r io.Reader) (int64, error) {
	var plen uint16

	n, err := encoding.ReadFrom(r, &p.Buffer, &p.InPort,
		&plen, &defaultPad6)

	if err != nil {
		return n, err
	}

	limrd := io.LimitReader(r, int64(plen))
	p.Actions = nil

	nn, err := p.Actions.ReadFrom(limrd)
	if n += nn; err != nil {
		return n, err
	}

	p.Data, err = ioutil.ReadAll(r)
	return n + int64(len(p.Data)), err
}
source: func (o querySet) GroupBy(exprs ...string) QuerySeter {
	o.groups = exprs
	return &o
}
source: func (e *loginProvision) ppStream(m libkb.MetaContext) (ret *libkb.PassphraseStream, err error) {
	defer m.Trace("loginProvision#ppStream", func() error { return err })()
	if ret = m.PassphraseStream(); ret != nil {
		return ret, nil
	}
	if err = e.passphraseLogin(m); err != nil {
		return nil, err
	}
	if ret = m.PassphraseStream(); ret != nil {
		return ret, nil
	}
	return nil, errors.New("no passphrase available")
}
source: func (b *bpfService) getBackendsV2() map[BackendAddrID]ServiceValue {
	b.mutex.RLock()
	defer b.mutex.RUnlock()

	backends := make(map[BackendAddrID]ServiceValue, len(b.backendsV2))
	for addrID, backend := range b.backendsV2 {
		backends[addrID] = backend
	}

	return backends
}
source: func (s *IpRouteInfo) SetIpRouteStatusMsg(v string) *IpRouteInfo {
	s.IpRouteStatusMsg = &v
	return s
}
source: func (t *Tombstoner) TombstoneFiles() []FileStat {
	t.mu.RLock()
	if t.statsLoaded {
		stats := t.fileStats
		t.mu.RUnlock()
		return stats
	}
	t.mu.RUnlock()

	stat, err := os.Stat(t.tombstonePath())
	if os.IsNotExist(err) || err != nil {
		t.mu.Lock()
		// The file doesn't exist so record that we tried to load it so
		// we don't continue to keep trying.  This is the common case.
		t.statsLoaded = os.IsNotExist(err)
		t.fileStats = t.fileStats[:0]
		t.mu.Unlock()
		return nil
	}

	t.mu.Lock()
	t.fileStats = append(t.fileStats[:0], FileStat{
		Path:         t.tombstonePath(),
		LastModified: stat.ModTime().UnixNano(),
		Size:         uint32(stat.Size()),
	})
	t.statsLoaded = true
	stats := t.fileStats
	t.mu.Unlock()

	return stats
}
source: func (o *Compute) SetSubnets(v []*Subnet) *Compute {
	if o.Subnets = v; o.Subnets == nil {
		o.nullFields = append(o.nullFields, "Subnets")
	}
	return o
}
source: func (f *Frame) UnmarshalFCS(b []byte) error {
	// Must contain enough data for FCS, to avoid panics
	if len(b) < 4 {
		return io.ErrUnexpectedEOF
	}

	// Verify checksum in slice versus newly computed checksum
	want := binary.BigEndian.Uint32(b[len(b)-4:])
	got := crc32.ChecksumIEEE(b[0 : len(b)-4])
	if want != got {
		return ErrInvalidFCS
	}

	return f.UnmarshalBinary(b[0 : len(b)-4])
}
source: func (service *Service) EvaluatePrereqsTemplate(gs GetService, fc FindChildService, instanceID int) (err error) {
	log.WithFields(log.Fields{
		"servicename": service.Name,
		"serviceid": service.ID,
		"instanceid": instanceID,
	}).Debug("Evaluating Prereq scripts")

	for i, prereq := range service.Prereqs {
		err, result := service.evaluateTemplate(gs, fc, instanceID, prereq.Script)
		if err != nil {
			return err
		}
		if result != "" {
			prereq.Script = result
			service.Prereqs[i] = prereq
		}
	}
	return
}
source: func MinInt8N(v ...int8) int8 {
	switch len(v) {
	case 0:
		return 0
	case 1:
		return v[0]
	case 2:
		return MinInt8(v[0], v[1])
	default:
		l := len(v) / 2
		return MinInt8N(MinInt8N(v[:l]...), MinInt8N(v[l:]...))
	}
}
source: func (m *Monitor) AddCheck(check *Check) {
	m.Lock()
	defer m.Unlock()
	log.Printf("Adding health check: %s (ID: %s), Args: %s", check.Type, check.ID, check.Args)
	m.Checks[check.ID] = check
}
source: func (cl *Client) Torrent(ih metainfo.Hash) (t *Torrent, ok bool) {
	cl.lock()
	defer cl.unlock()
	t, ok = cl.torrents[ih]
	return
}
source: func Convert_apps_ControllerRevisionList_To_v1beta1_ControllerRevisionList(in *apps.ControllerRevisionList, out *v1beta1.ControllerRevisionList, s conversion.Scope) error {
	return autoConvert_apps_ControllerRevisionList_To_v1beta1_ControllerRevisionList(in, out, s)
}
source: func (c container) Blobs() ([]Blob, error) {
	//TODO(axw) handle pagination.
	resp, err := c.Container.ListBlobs(storage.ListBlobsParameters{})
	if err != nil {
		return nil, errors.Trace(err)
	}
	blobs := make([]Blob, len(resp.Blobs))
	for i := range blobs {
		blobs[i] = blob{&resp.Blobs[i]}
	}
	return blobs, nil
}
source: func (cs *ConsensusState) OpenWAL(walFile string) (WAL, error) {
	wal, err := NewWAL(walFile)
	if err != nil {
		cs.Logger.Error("Failed to open WAL for consensus state", "wal", walFile, "err", err)
		return nil, err
	}
	wal.SetLogger(cs.Logger.With("wal", walFile))
	if err := wal.Start(); err != nil {
		return nil, err
	}
	return wal, nil
}
source: func newBufConn(conn net.Conn) *bufConn {
	return &bufConn{
		conn: conn,
		r:    bufio.NewReader(conn),
	}
}
source: func (api *KrakenApi) Assets() (*AssetsResponse, error) {
	resp, err := api.queryPublic("Assets", nil, &AssetsResponse{})
	if err != nil {
		return nil, err
	}

	return resp.(*AssetsResponse), nil
}
source: func (m *metricSet) observe(elapsed time.Duration, labels ...string) {
	elapsedSeconds := elapsed.Seconds()
	m.latencies.WithLabelValues(labels...).Observe(elapsedSeconds)
	if m.latenciesSummary != nil {
		m.latenciesSummary.WithLabelValues(labels...).Observe(elapsedSeconds)
	}
}
source: func (r *SearchRequest) sourceAsMap() (interface{}, error) {
	if r.source == nil {
		// Default: No custom source specified
		return r.searchSource.Source()
	}
	switch t := r.source.(type) {
	default:
		body, err := json.Marshal(r.source)
		if err != nil {
			return "", err
		}
		return RawStringQuery(body), nil
	case *SearchSource:
		return t.Source()
	case json.RawMessage:
		return RawStringQuery(string(t)), nil
	case *json.RawMessage:
		return RawStringQuery(string(*t)), nil
	case string:
		return RawStringQuery(t), nil
	case *string:
		if t != nil {
			return RawStringQuery(*t), nil
		}
		return RawStringQuery("{}"), nil
	}
}
source: func Slug(s string) string {
	buf := make([]rune, 0, len(s))
	dash := false
	for _, r := range norm.NFKD.String(s) {
		switch {
		// unicode 'letters' like mandarin characters pass through
		case unicode.IsOneOf(lat, r):
			buf = append(buf, unicode.ToLower(r))
			dash = true
		case unicode.IsOneOf(nop, r):
			// skip
		case dash:
			buf = append(buf, '-')
			dash = false
		}
	}
	if i := len(buf) - 1; i >= 0 && buf[i] == '-' {
		buf = buf[:i]
	}
	return string(buf)
}
source: func (q *QueryChannelRange) Encode(w io.Writer, pver uint32) error {
	return WriteElements(w,
		q.ChainHash[:],
		q.FirstBlockHeight,
		q.NumBlocks,
	)
}
source: func WithLocation(loc *time.Location) Option {
	return option.New(optkeyClock, clockFn(func() time.Time {
		return time.Now().In(loc)
	}))
}
source: func ExtractRanking(opts ...interface{}) *opt.RankingOption {
	for _, o := range opts {
		if v, ok := o.(*opt.RankingOption); ok {
			return v
		}
	}
	return nil
}
source: func diffDays(date1, date2 time.Time) int64 {
	return int64(date2.Sub(date1) / (24 * time.Hour))
}
source: func (u *user) UnmarshalJSONObject(dec *gojay.Decoder, key string) error {
	switch key {
	case "id":
		return dec.Int(&u.id)
	case "created":
		return dec.Uint64(&u.created)
	case "age":
		return dec.Float(&u.age)
	case "name":
		return dec.String(&u.name)
	case "email":
		return dec.String(&u.email)
	case "friend":
		uu := &user{}
		return dec.Object(uu)
	}
	return nil
}
source: func NewSpritesheetWithBorderFromFile(textureName string, cellWidth, cellHeight, borderWidth, borderHeight int) *Spritesheet {
	res, err := engo.Files.Resource(textureName)
	if err != nil {
		log.Println("[WARNING] [NewSpritesheetWithBorderFromFile]: Received error:", err)
		return nil
	}

	img, ok := res.(TextureResource)
	if !ok {
		log.Println("[WARNING] [NewSpritesheetWithBorderFromFile]: Resource not of type `TextureResource`:", textureName)
		return nil
	}

	return NewSpritesheetWithBorderFromTexture(&img, cellWidth, cellHeight, borderWidth, borderHeight)
}
source: func (o *IntOptions) Validate(n models.ConfigurationMap) error {
	o.optsMU.RLock()
	defer o.optsMU.RUnlock()
	for k, v := range n {
		_, newVal, err := ParseKeyValue(o.Library, k, v)
		if err != nil {
			return err
		}

		// Ignore validation if value is identical
		if oldVal, ok := o.Opts[k]; ok && oldVal == newVal {
			continue
		}

		if err := o.Library.Validate(k, v); err != nil {
			return err
		}
	}

	return nil
}
source: func IsBare() (bool, error) {
	s, err := subprocess.SimpleExec(
		"git", "rev-parse", "--is-bare-repository")

	if err != nil {
		return false, err
	}

	return strconv.ParseBool(s)
}
source: func (ec *EthereumClient) GetHeaderByNumber(ctx *Context, number int64) (header *Header, _ error) {
	if number < 0 {
		rawHeader, err := ec.client.HeaderByNumber(ctx.context, nil)
		return &Header{rawHeader}, err
	}
	rawHeader, err := ec.client.HeaderByNumber(ctx.context, big.NewInt(number))
	return &Header{rawHeader}, err
}
source: func (p *Prometheus) Use(e *gin.Engine) {
	e.Use(p.HandlerFunc())
	p.SetMetricsPath(e)
}
source: func Convert_apps_DaemonSetList_To_v1_DaemonSetList(in *apps.DaemonSetList, out *v1.DaemonSetList, s conversion.Scope) error {
	return autoConvert_apps_DaemonSetList_To_v1_DaemonSetList(in, out, s)
}
source: func SplitResourceArgument(arg string) []string {
	out := []string{}
	set := sets.NewString()
	for _, s := range strings.Split(arg, ",") {
		if set.Has(s) {
			continue
		}
		set.Insert(s)
		out = append(out, s)
	}
	return out
}
source: func (settings FileSettings) ServicePrincipalTokenFromClientCredentials(baseURI string) (*adal.ServicePrincipalToken, error) {
	resource, err := settings.getResourceForToken(baseURI)
	if err != nil {
		return nil, err
	}
	return settings.ServicePrincipalTokenFromClientCredentialsWithResource(resource)
}
source: func DecodeConfig(r io.Reader) (image.Config, error) {
	d, err := newDecoder(r)
	if err != nil {
		return image.Config{}, err
	}
	return d.config, nil
}
source: func (f *Function) Create(zip []byte) error {
	f.Log.Info("creating function")

	params := &lambda.CreateFunctionInput{
		FunctionName: &f.FunctionName,
		Description:  &f.Description,
		MemorySize:   &f.Memory,
		Timeout:      &f.Timeout,
		Runtime:      &f.Runtime,
		Handler:      &f.Handler,
		Role:         &f.Role,
		KMSKeyArn:    &f.KMSKeyArn,
		Publish:      aws.Bool(true),
		Environment:  f.environment(),
		Code: &lambda.FunctionCode{
			ZipFile: zip,
		},
		VpcConfig: &lambda.VpcConfig{
			SecurityGroupIds: aws.StringSlice(f.VPC.SecurityGroups),
			SubnetIds:        aws.StringSlice(f.VPC.Subnets),
		},
	}

	if f.DeadLetterARN != "" {
		params.DeadLetterConfig = &lambda.DeadLetterConfig{
			TargetArn: &f.DeadLetterARN,
		}
	}

	created, err := f.Service.CreateFunction(params)
	if err != nil {
		return err
	}

	if err := f.CreateOrUpdateAlias(f.Alias, *created.Version); err != nil {
		return err
	}

	f.Log.WithFields(log.Fields{
		"version": *created.Version,
		"name":    f.FunctionName,
	}).Info("function created")

	return nil
}
source: func NewHTTPClientTarget(host xnet.Host, w http.ResponseWriter) (*HTTPClientTarget, error) {
	uuid, err := getNewUUID()
	if err != nil {
		return nil, err
	}
	c := &HTTPClientTarget{
		id:      event.TargetID{ID: "httpclient" + "+" + uuid + "+" + host.Name, Name: host.Port.String()},
		w:       w,
		eventCh: make(chan []byte),
		DoneCh:  make(chan struct{}),
		stopCh:  make(chan struct{}),
	}
	c.start()
	return c, nil
}
source: func AcquireWithTimeout(lock sync.Locker, timeout time.Duration) (err error) {
	ctx2, cancel := context.WithTimeout(context.Background(), timeout)
	defer cancel()
	return AcquireWithContext(ctx2, lock)
}
source: func FieldByIndexes(v reflect.Value, indexes []int) reflect.Value {
	for _, i := range indexes {
		v = reflect.Indirect(v).Field(i)
		// if this is a pointer and it's nil, allocate a new value and set it
		if v.Kind() == reflect.Ptr && v.IsNil() {
			alloc := reflect.New(Deref(v.Type()))
			v.Set(alloc)
		}
		if v.Kind() == reflect.Map && v.IsNil() {
			v.Set(reflect.MakeMap(v.Type()))
		}
	}
	return v
}
source: func (l *loggerImpl) print(level int, lstr string, msg string, args ...interface{}) {
	l.Lock()
	defer l.Unlock()
	var t = time.Now().Format("15:04:05.000000")
	var c = colors[level]
	c.Println(fmt.Sprintf("%s%s %s %s", l.prefix, lstr, t, fmt.Sprintf(msg, args...)))
}
source: func cloneHeader(h http.Header) http.Header {
	h2 := make(http.Header, len(h))
	for k, vv := range h {
		vv2 := make([]string, len(vv))
		copy(vv2, vv)
		h2[k] = vv2
	}
	return h2
}
source: func (p *Plugin) ScopedPath(s string) string {
	if p.PluginObj.Config.PropagatedMount != "" && strings.HasPrefix(s, p.PluginObj.Config.PropagatedMount) {
		// re-scope to the propagated mount path on the host
		return filepath.Join(filepath.Dir(p.Rootfs), "propagated-mount", strings.TrimPrefix(s, p.PluginObj.Config.PropagatedMount))
	}
	return filepath.Join(p.Rootfs, s)
}
source: func (r *RateLimiter) LockBucket(bucketID string) *Bucket {
	return r.LockBucketObject(r.GetBucket(bucketID))
}
source: func (c *MockConnection) Close() {
	if !atomic.CompareAndSwapInt32(&c.closed, 0, 1) {
		// Already closed
		return
	}

	c.producer.Close()
	close(c.rcvch)
}
source: func NewAsyncTransport(token string, endpoint string, buffer int) *AsyncTransport {
	transport := &AsyncTransport{
		Token:               token,
		Endpoint:            endpoint,
		Buffer:              buffer,
		RetryAttempts:       DefaultRetryAttempts,
		PrintPayloadOnError: true,
		bodyChannel:         make(chan payload, buffer),
	}

	go func() {
		for p := range transport.bodyChannel {
			err, canRetry := transport.post(p)
			if err != nil {
				if canRetry && p.retriesLeft > 0 {
					p.retriesLeft -= 1
					select {
					case transport.bodyChannel <- p:
					default:
						// This can happen if the bodyChannel had an item added to it from another
						// thread while we are processing such that the channel is now full. If we try
						// to send the payload back to the channel without this select statement we
						// could deadlock. Instead we consider this a retry failure.
						if transport.PrintPayloadOnError {
							writePayloadToStderr(transport.Logger, p.body)
						}
						transport.waitGroup.Done()
					}
				} else {
					if transport.PrintPayloadOnError {
						writePayloadToStderr(transport.Logger, p.body)
					}
					transport.waitGroup.Done()
				}
			} else {
				transport.waitGroup.Done()
			}
		}
	}()
	return transport
}
source: func (col *Col) indexDoc(id int, doc map[string]interface{}) {
	for idxName, idxPath := range col.indexPaths {
		for _, idxVal := range GetIn(doc, idxPath) {
			if idxVal != nil {
				hashKey := StrHash(fmt.Sprint(idxVal))
				partNum := hashKey % col.db.numParts
				ht := col.hts[partNum][idxName]
				ht.Lock.Lock()
				ht.Put(hashKey, id)
				ht.Lock.Unlock()
			}
		}
	}
}
source: func (dfs *DistributedFilesystem) export(path string) error {
	if err := dfs.net.AddVolume(path); err != nil {
		glog.Errorf("Error notifying storage of new volume %s: %s", path, err)
		return err
	} else if err := dfs.net.Sync(); err != nil {
		glog.Errorf("Error syncing storage for volume %s: %s", path, err)
		return err
	}
	return nil
}
source: func ISP(ip goexpr.Expr) goexpr.Expr {
	return &ispExpr{"ISP", ip, func(ip string) (interface{}, bool) {
		return getProvider().ISP(ip)
	}}
}
source: func NewClient(ctx context.Context, addr string, ctype ClientType,
	queueSize int, flushInterval time.Duration, effectiveUser string,
	readTimeout time.Duration) (hrpc.RegionClient, error) {
	var d net.Dialer
	conn, err := d.DialContext(ctx, "tcp", addr)
	if err != nil {
		return nil, fmt.Errorf("failed to connect to the RegionServer at %s: %s", addr, err)
	}
	c := &client{
		addr:          addr,
		conn:          conn,
		rpcs:          make(chan hrpc.Call),
		done:          make(chan struct{}),
		sent:          make(map[uint32]hrpc.Call),
		rpcQueueSize:  queueSize,
		flushInterval: flushInterval,
		effectiveUser: effectiveUser,
		readTimeout:   readTimeout,
	}
	// time out send hello if it take long
	// TODO: do we even need to bother, we are going to retry anyway?
	if deadline, ok := ctx.Deadline(); ok {
		conn.SetWriteDeadline(deadline)
	}
	if err := c.sendHello(ctype); err != nil {
		conn.Close()
		return nil, fmt.Errorf("failed to send hello to the RegionServer at %s: %s", addr, err)
	}
	// reset write deadline
	conn.SetWriteDeadline(time.Time{})

	if ctype == RegionClient {
		go c.processRPCs() // Batching goroutine
	}
	go c.receiveRPCs() // Reader goroutine
	return c, nil
}
source: func NewSet(key string, vals ...string) []*api.GenericResource {
	rs := make([]*api.GenericResource, 0, len(vals))

	for _, v := range vals {
		rs = append(rs, NewString(key, v))
	}

	return rs
}
source: func (v *Values) Put(key Key, value interface{}) (changed bool) {
	v.lock.Lock()
	defer v.lock.Unlock()

	return v.put(key, value)
}
source: func (be *BinaryEncoder) WriteInt(x int32) {
	_, _ = be.buffer.Write(be.encodeVarint32(x))
}
source: func (h *AuthHandlers) fetchRoleSet(cert *ssh.Certificate, ca services.CertAuthority, teleportUser string, clusterName string) (services.RoleSet, error) {
	// for local users, go and check their individual permissions
	var roles services.RoleSet
	if clusterName == ca.GetClusterName() {
		u, err := h.AccessPoint.GetUser(teleportUser)
		if err != nil {
			return nil, trace.Wrap(err)
		}
		// Pass along the traits so we get the substituted roles for this user.
		roles, err = services.FetchRoles(u.GetRoles(), h.AccessPoint, u.GetTraits())
		if err != nil {
			return nil, trace.Wrap(err)
		}
	} else {
		certRoles, err := extractRolesFromCert(cert)
		if err != nil {
			return nil, trace.AccessDenied("failed to parse certificate roles")
		}
		roleNames, err := ca.CombinedMapping().Map(certRoles)
		if err != nil {
			return nil, trace.AccessDenied("failed to map roles")
		}
		// pass the principals on the certificate along as the login traits
		// to the remote cluster.
		traits := map[string][]string{
			teleport.TraitLogins: cert.ValidPrincipals,
		}
		roles, err = services.FetchRoles(roleNames, h.AccessPoint, traits)
		if err != nil {
			return nil, trace.Wrap(err)
		}
	}

	return roles, nil
}
source: func AddCondToFlags(cond *sync.Cond, flags ...*Flag) {
	for _, f := range flags {
		f.addCond(cond)
	}
}
source: func (d *defaulter) AsUint64(v Valuer, dv uint64) uint64 {
	value, err := v.Value()
	if err != nil {
		d.logValuerError(err)
		return dv
	}
	uivalue, err := strconv.ParseUint(value, 10, 64)
	if err != nil {
		d.logFormatError("uint64", err)
		return dv
	}
	return uint64(uivalue)
}
source: func Convert_apps_DaemonSetSpec_To_v1beta1_DaemonSetSpec(in *apps.DaemonSetSpec, out *v1beta1.DaemonSetSpec, s conversion.Scope) error {
	return autoConvert_apps_DaemonSetSpec_To_v1beta1_DaemonSetSpec(in, out, s)
}
source: func SyncFile(localPath string, remote string, timeout int) error {
	fileInfo, err := os.Stat(localPath)
	if err != nil {
		log.Errorf("Failed to get size of source file: %s, err: %s", localPath, err)
		return err
	}
	fileSize := fileInfo.Size()
	directIO := (fileSize%Blocks == 0)
	log.Infof("source file size: %d, setting up directIo: %v", fileSize, directIO)

	var fileIo FileIoProcessor
	if directIO {
		fileIo, err = NewDirectFileIoProcessor(localPath, os.O_RDONLY, 0)
	} else {
		fileIo, err = NewBufferedFileIoProcessor(localPath, os.O_RDONLY, 0)
	}
	if err != nil {
		log.Error("Failed to open local source file:", localPath)
		return err
	}
	defer fileIo.Close()

	client := &syncClient{remote, timeout, localPath, fileSize, fileIo}

	defer client.closeServer() // kill the server no matter success or not, best effort

	err = client.syncFileContent(fileIo, fileSize)
	if err != nil {
		log.Errorf("syncFileContent failed: %s", err)
		return err
	}

	return err
}
source: func (m *Schema) Schema(schemaName string) (*Schema, error) {
	// We always lower-case schema names
	schemaName = strings.ToLower(schemaName)
	m.mu.RLock()
	defer m.mu.RUnlock()
	child, ok := m.schemas[schemaName]
	if ok && child != nil && child.DS != nil {
		return child, nil
	}
	return nil, fmt.Errorf("Could not find a Schema by that name %q", schemaName)
}
source: func InstantiatePurgeMgr(ledgerid string, db privacyenabledstate.DB, btlPolicy pvtdatapolicy.BTLPolicy, bookkeepingProvider bookkeeping.Provider) (PurgeMgr, error) {
	return &purgeMgr{
		btlPolicy: btlPolicy,
		db:        db,
		expKeeper: newExpiryKeeper(ledgerid, bookkeepingProvider),
		lock:      &sync.Mutex{},
		waitGrp:   &sync.WaitGroup{},
	}, nil
}
source: func (s *AwsSecurityFindingFilters) SetProcessPath(v []*StringFilter) *AwsSecurityFindingFilters {
	s.ProcessPath = v
	return s
}
source: func generateUUIDLabel() labels.Label {
	return labels.NewLabel(generatedLabelNameUUID, uuid.NewUUID().String(), labels.LabelSourceCiliumGenerated)
}
source: func rangeSelection(str string) Selection {
	m := selRx.FindStringSubmatch(str)
	if len(m) >= 2 {
		from, _ := strconv.Atoi(m[1])
		to, _ := strconv.Atoi(m[2])
		if from < to {
			return makeSelection([][]int{{from, to}})
		}
	}
	return nil
}
source: func writeIDs(idsList []id, outfile string) error {
	data, err := json.Marshal(idsList)
	if err != nil {
		return err
	}
	data = append(data, '\n')

	if outfile != "" {
		return ioutil.WriteFile(outfile, data, 0644)
	}

	fmt.Printf("%s", data)
	return nil
}
source: func Convert_v1alpha1_FlunderStatus_To_wardle_FlunderStatus(in *FlunderStatus, out *wardle.FlunderStatus, s conversion.Scope) error {
	return autoConvert_v1alpha1_FlunderStatus_To_wardle_FlunderStatus(in, out, s)
}
source: func Minimal(x interface{}) (resolved []ast.Ref, err error) {
	rawResolved, err := All(x)
	if err != nil {
		return nil, err
	}

	if len(rawResolved) == 0 {
		return nil, nil
	}

	return filter(rawResolved, func(a, b ast.Ref) bool {
		return b.HasPrefix(a)
	}), nil
}
source: func (nr *nameResolver) handleFieldList(fieldList *ast.FieldList) {
	var resultFields []*ast.ResultField
	for _, v := range fieldList.Fields {
		resultFields = append(resultFields, nr.createResultFields(v)...)
	}
	nr.currentContext().fieldList = resultFields
}
source: func (c *Clock) Time() float32 {
	currStamp := theTimer.Now()
	return float32(float64(currStamp-c.startStamp) / float64(secondsInNano))
}
source: func (g *Generator) RemoveLinuxSysctl(key string) {
	if g.Config == nil || g.Config.Linux == nil || g.Config.Linux.Sysctl == nil {
		return
	}
	delete(g.Config.Linux.Sysctl, key)
}
source: func Decode(route string) (*Route, error) {
	r := strings.Split(route, ".")
	for _, s := range r {
		if strings.TrimSpace(s) == "" {
			return nil, ErrRouteFieldCantEmpty
		}
	}
	switch len(r) {
	case 3:
		return NewRoute(r[0], r[1], r[2]), nil
	case 2:
		return NewRoute("", r[0], r[1]), nil
	default:
		logger.Log.Errorf("invalid route: " + route)
		return nil, ErrInvalidRoute
	}
}
source: func Convert_networking_HTTPIngressRuleValue_To_v1beta1_HTTPIngressRuleValue(in *networking.HTTPIngressRuleValue, out *v1beta1.HTTPIngressRuleValue, s conversion.Scope) error {
	return autoConvert_networking_HTTPIngressRuleValue_To_v1beta1_HTTPIngressRuleValue(in, out, s)
} 84%|████████▍ | 4205/5000 [00:05<00:01, 661.79it/s]
source: func (S *Scanner) switch2(tok0, tok1 token.Token) token.Token {
	if S.ch == '=' {
		S.next()
		return tok1
	}
	return tok0
}
source: func (g *ResourceCommand) Get(client auth.ClientI) error {
	collection, err := g.getCollection(client)
	if err != nil {
		return trace.Wrap(err)
	}

	// Note that only YAML is officially supported. Support for text and JSON
	// is experimental.
	switch g.format {
	case teleport.YAML:
		return collection.writeYAML(os.Stdout)
	case teleport.Text:
		return collection.writeText(os.Stdout)
	case teleport.JSON:
		return collection.writeJSON(os.Stdout)
	}
	return trace.BadParameter("unsupported format")
}
source: func Exponential(factor time.Duration, base float64) Algorithm {
	return func(attempt uint) time.Duration {
		return (factor * time.Duration(math.Pow(base, float64(attempt))))
	}
}
source: func NewCountersWithSingleLabel(name, help, label string, tags ...string) *CountersWithSingleLabel {
	c := &CountersWithSingleLabel{
		counters: counters{
			counts: make(map[string]*int64),
			help:   help,
		},
		label: label,
	}

	for _, tag := range tags {
		c.counts[tag] = new(int64)
	}
	if name != "" {
		publish(name, c)
	}
	return c
}
source: func createDeployment(service *api.Service, client gomarathonClientAbstractor) deployment {
	var converter = new(MarathonConverter)
	var deployment deployment

	var reqs = make(map[string]string)
	links := service.Links
	for i := range links {
		log.Printf("Linking: %s with Alias: %s", links[i].Name, links[i].Alias)
		reqs[links[i].Name] = links[i].Alias
	}

	deployment.name = service.Name
	deployment.reqs = reqs
	deployment.client = client
	deployment.startingState = requirementState
	deployment.status = status{code: DEPLOY}
	deployment.application = converter.convertToApp(service)

	return deployment
}
source: func (st *State) AddStoreCharmPlaceholder(curl *charm.URL) (err error) {
	// Perform sanity checks first.
	if curl.Schema != "cs" {
		return errors.Errorf("expected charm URL with cs schema, got %q", curl)
	}
	if curl.Revision < 0 {
		return errors.Errorf("expected charm URL with revision, got %q", curl)
	}
	charms, closer := st.db().GetCollection(charmsC)
	defer closer()

	buildTxn := func(attempt int) ([]txn.Op, error) {
		// See if the charm already exists in state and exit early if that's the case.
		var doc charmDoc
		err := charms.Find(bson.D{{"_id", curl.String()}}).Select(bson.D{{"_id", 1}}).One(&doc)
		if err != nil && err != mgo.ErrNotFound {
			return nil, errors.Trace(err)
		}
		if err == nil {
			return nil, jujutxn.ErrNoOperations
		}

		// Delete all previous placeholders so we don't fill up the database with unused data.
		deleteOps, err := deleteOldPlaceholderCharmsOps(st, charms, curl)
		if err != nil {
			return nil, errors.Trace(err)
		}
		insertOps, err := insertPlaceholderCharmOps(st, curl)
		if err != nil {
			return nil, errors.Trace(err)
		}
		ops := append(deleteOps, insertOps...)
		return ops, nil
	}
	return errors.Trace(st.db().Run(buildTxn))
}
source: func (m *Module) Login(email, password string) (string, bool, error) {
	email = strings.ToLower(email)
	userID, hashedPassword, err := m.userStore.Get(email)
	if err != nil {
		return "", false, err
	}
	return userID, AuthenticatePassword(password, hashedPassword), nil
}
source: func (bot *TgBot) NewPhotoChatFn(f func(TgBot, Message, int, string)) *TgBot {
	bot.addToConditionalFuncs(NewPhotoConditionalCall{f})
	return bot
}
source: func (f *fsImpl) moveToTrash(ctx context.Context, path string) string {
	if err := os.MkdirAll(f.trash, 0777); err != nil {
		logging.Warningf(ctx, "fs: can't create trash directory %q - %s", f.trash, err)
		return ""
	}
	trashed := filepath.Join(f.trash, pseudoRand())
	if err := atomicRename(path, trashed); err != nil {
		if !os.IsNotExist(err) {
			logging.Warningf(ctx, "fs: failed to rename(%q, %q) - %s", path, trashed, err)
		}
		return ""
	}
	return trashed
}
source: func (d *DaemonSetPrepuller) CreateFunc(component string) error {
	var image string
	if component == constants.Etcd {
		image = images.GetEtcdImage(d.cfg)
	} else {
		image = images.GetKubernetesImage(component, d.cfg)
	}
	ds := buildPrePullDaemonSet(component, image)

	// Create the DaemonSet in the API Server
	if err := apiclient.CreateOrUpdateDaemonSet(d.client, ds); err != nil {
		return errors.Wrapf(err, "unable to create a DaemonSet for prepulling the component %q", component)
	}
	return nil
}
source: func ValidateConditions(conds *Conditions) error {
	if conds.ExpectedAmount != nil {
		if *conds.ExpectedAmount > 0 && conds.MultiUse {
			return errors.Wrap(ErrInvalidDepositAddressOptions, "expected amount and multi use are mutually exclusive")
		}
	}
	return nil
}
source: func translate(pat string) (string, error) {
	res := "^"
	for _, runeVal := range pat {
		switch runeVal {
		case '\n':
			return "", fmt.Errorf("new lines are not supported in globs")
		case '*':
			res += ".*"
		default:
			res += regexp.QuoteMeta(string(runeVal))
		}
	}
	return res + "$", nil
}
source: func (d *Document) TextAfterCursor() string {
	r := []rune(d.Text)
	return string(r[d.cursorPosition:])
}
source: func NewLineTypeTable(tags core.TagSlice) (Table, error) {
	table := make(Table)

	tableSlices, err := TableEntryTags(tags)
	if err != nil {
		return table, err
	}

	for _, slice := range tableSlices {
		ltype, err := NewLineType(slice)
		if err != nil {
			return nil, err
		}
		table[ltype.Name] = ltype
	}

	return table, nil
}
source: func (s *TrustedAdvisorResourcesSummary) SetResourcesIgnored(v int64) *TrustedAdvisorResourcesSummary {
	s.ResourcesIgnored = &v
	return s
}
source: func (ds *dockerService) getPodSandboxDetails(podSandboxID string) (*dockertypes.ContainerJSON, *runtimeapi.PodSandboxMetadata, error) {
	resp, err := ds.client.InspectContainer(podSandboxID)
	if err != nil {
		return nil, nil, err
	}

	metadata, err := parseSandboxName(resp.Name)
	if err != nil {
		return nil, nil, err
	}

	return resp, metadata, nil
}
source: func RequireNoArguments(c *cobra.Command, args []string) {
	if len(args) > 0 {
		CheckErr(UsageErrorf(c, "unknown command %q", strings.Join(args, " ")))
	}
}
source: func (s *SubscribeToken) Result() map[string]byte {
	s.m.RLock()
	defer s.m.RUnlock()
	return s.subResult
}
source: func (result *Result) Truncate(l int) *Result {
	if l == 0 {
		return result
	}

	out := &Result{
		InsertID:     result.InsertID,
		RowsAffected: result.RowsAffected,
	}
	if result.Fields != nil {
		out.Fields = result.Fields[:l]
	}
	if result.Rows != nil {
		out.Rows = make([][]Value, 0, len(result.Rows))
		for _, r := range result.Rows {
			out.Rows = append(out.Rows, r[:l])
		}
	}
	if result.Extras != nil {
		out.Extras = &querypb.ResultExtras{
			Fresher: result.Extras.Fresher,
		}
		if result.Extras.EventToken != nil {
			out.Extras.EventToken = &querypb.EventToken{
				Timestamp: result.Extras.EventToken.Timestamp,
				Shard:     result.Extras.EventToken.Shard,
				Position:  result.Extras.EventToken.Position,
			}
		}
	}
	return out
}
source: func (xmlNode *XmlNode) AddChild(data interface{}) (err error) {
	switch t := data.(type) {
	default:
		if nodes, err := xmlNode.coerce(data); err == nil {
			for _, node := range nodes {
				if err = xmlNode.addChild(node); err != nil {
					break
				}
			}
		}
	case *DocumentFragment:
		if nodes, err := xmlNode.coerce(data); err == nil {
			for _, node := range nodes {
				if err = xmlNode.addChild(node); err != nil {
					break
				}
			}
		}
	case Node:
		err = xmlNode.addChild(t)
	}
	return
}
source: func (m *MockIndex) StructChan(arg0 chan struct{}) {
	m.ctrl.T.Helper()
	m.ctrl.Call(m, "StructChan", arg0)
}
source: func (m *MockCommonAPIClient) NetworkRemove(ctx context.Context, networkID string) error {
	ret := m.ctrl.Call(m, "NetworkRemove", ctx, networkID)
	ret0, _ := ret[0].(error)
	return ret0
}
source: func (ar *ActionRepository) RegisterTabletAction(name, role string, method actionTabletMethod) {
	ar.tabletActions[name] = actionTabletRecord{
		role:   role,
		method: method,
	}
}
source: func (bow *Browser) Bookmark(name string) error {
	return bow.bookmarks.Save(name, bow.ResolveUrl(bow.Url()).String())
}
source: func shuffle(members []*Member) []*Member {
	newMembers := make([]*Member, len(members), cap(members))
	newIndexes := rand.Perm(len(members))

	for o, n := range newIndexes {
		newMembers[n] = members[o]
	}

	return newMembers
}
source: func (r *raftLog) SetUint64(k []byte, v uint64) error {
	var vbytes [8]byte
	binary.BigEndian.PutUint64(vbytes[:], v)
	err := r.Set(k, vbytes[:])
	return err
}
source: func NewEndpoint(codec Codec, registry *Registry) *Endpoint {
	if registry == nil {
		registry = dummyRegistry
	}
	e := &Endpoint{}
	e.codec = codec
	e.server.registry = registry
	e.client.pending = make(map[uint64]*rpc.Call)
	return e
}
source: func (key MvccKey) Raw() []byte {
	if len(key) == 0 {
		return nil
	}
	_, k, err := codec.DecodeBytes(key, nil)
	if err != nil {
		panic(err)
	}
	return k
}
source: func (p *BlockPuller) probeEndpoint(endpoint string, minRequestedSequence uint64) (*endpointInfo, error) {
	conn, err := p.Dialer.Dial(endpoint)
	if err != nil {
		p.Logger.Warningf("Failed connecting to %s: %v", endpoint, err)
		return nil, err
	}

	lastBlockSeq, err := p.fetchLastBlockSeq(minRequestedSequence, endpoint, conn)
	if err != nil {
		conn.Close()
		return nil, err
	}

	return &endpointInfo{conn: conn, lastBlockSeq: lastBlockSeq, endpoint: endpoint}, nil
}
source: func extractChanBackups(chanBackups *lnrpc.ChanBackupSnapshot) *ChannelsToRecover {
	// If there aren't any populated channel backups, then we can exit
	// early as there's nothing to extract.
	if chanBackups == nil || (chanBackups.SingleChanBackups == nil &&
		chanBackups.MultiChanBackup == nil) {
		return nil
	}

	// Now that we know there's at least a single back up populated, we'll
	// extract the multi-chan backup (if it's there).
	var backups ChannelsToRecover
	if chanBackups.MultiChanBackup != nil {
		multiBackup := chanBackups.MultiChanBackup
		backups.PackedMultiChanBackup = chanbackup.PackedMulti(
			multiBackup.MultiChanBackup,
		)
	}

	if chanBackups.SingleChanBackups == nil {
		return &backups
	}

	// Finally, we can extract all the single chan backups as well.
	for _, backup := range chanBackups.SingleChanBackups.ChanBackups {
		singleChanBackup := backup.ChanBackup

		backups.PackedSingleChanBackups = append(
			backups.PackedSingleChanBackups, singleChanBackup,
		)
	}

	return &backups
}
source: func (ps *PeerState) SetHasProposal(proposal *types.Proposal) {
	ps.mtx.Lock()
	defer ps.mtx.Unlock()

	if ps.PRS.Height != proposal.Height || ps.PRS.Round != proposal.Round {
		return
	}

	if ps.PRS.Proposal {
		return
	}

	ps.PRS.Proposal = true

	// ps.PRS.ProposalBlockParts is set due to NewValidBlockMessage
	if ps.PRS.ProposalBlockParts != nil {
		return
	}

	ps.PRS.ProposalBlockPartsHeader = proposal.BlockID.PartsHeader
	ps.PRS.ProposalBlockParts = cmn.NewBitArray(proposal.BlockID.PartsHeader.Total)
	ps.PRS.ProposalPOLRound = proposal.POLRound
	ps.PRS.ProposalPOL = nil // Nil until ProposalPOLMessage received.
}
source: func (w *Walker) Wait() tfdiags.Diagnostics {
	// Wait for completion
	w.wait.Wait()

	var diags tfdiags.Diagnostics
	w.diagsLock.Lock()
	for v, vDiags := range w.diagsMap {
		if _, upstream := w.upstreamFailed[v]; upstream {
			// Ignore diagnostics for nodes that had failed upstreams, since
			// the downstream diagnostics are likely to be redundant.
			continue
		}
		diags = diags.Append(vDiags)
	}
	w.diagsLock.Unlock()

	return diags
}
source: func (w *Window) JustPressed(button Button) bool {
	return w.currInp.buttons[button] && !w.prevInp.buttons[button]
}
source: func JSON(w http.ResponseWriter, code int, v interface{}, pretty bool) {

	var bs []byte
	var err error

	if pretty {
		bs, err = json.MarshalIndent(v, "", "  ")
	} else {
		bs, err = json.Marshal(v)
	}

	if err != nil {
		ErrorAuto(w, err)
		return
	}
	headers := w.Header()
	headers.Add("Content-Type", "application/json")
	Bytes(w, code, bs)

	if pretty {
		w.Write([]byte("\n"))
	}
}
source: func NewColorLogger(w io.Writer, newLogger func(io.Writer) log.Logger, color func(keyvals ...interface{}) FgBgColor) log.Logger {
	if color == nil {
		panic("color func nil")
	}
	return &colorLogger{
		w:             w,
		newLogger:     newLogger,
		color:         color,
		bufPool:       sync.Pool{New: func() interface{} { return &loggerBuf{} }},
		noColorLogger: newLogger(w),
	}
}
source: func (rb *repoBuilder) LoadRootForUpdate(content []byte, minVersion int, isFinal bool) error {
	if err := rb.loadOptions(data.CanonicalRootRole, content, minVersion, !isFinal, !isFinal, true); err != nil {
		return err
	}
	if !isFinal {
		rb.prevRoot = rb.repo.Root
	}
	return nil
}
source: func (r *Request) Patch(url string) (*Response, error) {
	return r.Execute(MethodPatch, url)
}
source: func GetSongs(listLink []string) []glod.Response {

	var listSong []glod.Response
	var song glod.Response
	var zingResponse ZingResponse

	for i, _ := range listLink {
		id := GetSongID(listLink[i])
		link := linkDownloadSong + "{\"id\":\"" + id + "\"}"

		res, err := http.Get(link)
		if err != nil {
			return listSong
		}
		defer res.Body.Close()

		if err := json.NewDecoder(res.Body).Decode(&zingResponse); err != nil {
			log.Println(err)
		}

		song.Artist = zingResponse.Artist
		song.Title = zingResponse.Title
		song.StreamURL = zingResponse.Source.Url

		listSong = append(listSong, song)
	}
	return listSong
}
source: func (w *Wrapper) UpsertProxy(s services.Server) error {
	return w.Write.UpsertProxy(s)
}
source: func (m *ChannelDeMultiplexer) DeMultiplex(msg interface{}) {
	m.lock.RLock()
	defer m.lock.RUnlock()
	if m.isClosed() {
		return
	}
	for _, ch := range m.channels {
		if ch.pred(msg) {
			ch.ch <- msg
		}
	}
}
source: func (e *SortExec) keyColumnsLess(i, j int) bool {
	rowI := e.rowChunks.GetRow(e.rowPtrs[i])
	rowJ := e.rowChunks.GetRow(e.rowPtrs[j])
	return e.lessRow(rowI, rowJ)
}
source: func NewSetBlackboxPatternsArgs(patterns []string) *SetBlackboxPatternsArgs {
	args := new(SetBlackboxPatternsArgs)
	args.Patterns = patterns
	return args
}
source: func (n *Negroni) UseHandler(handler http.Handler) {
	n.Use(Wrap(handler))
}
source: func (s *Server) SettleInvoice(ctx context.Context,
	in *SettleInvoiceMsg) (*SettleInvoiceResp, error) {

	preimage, err := lntypes.MakePreimage(in.Preimage)
	if err != nil {
		return nil, err
	}

	err = s.cfg.InvoiceRegistry.SettleHodlInvoice(preimage)
	if err != nil && err != channeldb.ErrInvoiceAlreadySettled {
		return nil, err
	}

	return &SettleInvoiceResp{}, nil
}
source: func NewServiceAntiAffinityPriority(podLister algorithm.PodLister, serviceLister algorithm.ServiceLister, label string) (PriorityMapFunction, PriorityReduceFunction) {
	antiAffinity := &ServiceAntiAffinity{
		podLister:     podLister,
		serviceLister: serviceLister,
		label:         label,
	}
	return antiAffinity.CalculateAntiAffinityPriorityMap, antiAffinity.CalculateAntiAffinityPriorityReduce
}
source: func BlockDeviceSize(devicePath string) (uint64, error) {
	data, err := exec.Command("blockdev", "--getsize64", "-q", devicePath).CombinedOutput()
	output := string(data)
	if err != nil {
		return 0, errors.Wrapf(err, output)
	}

	output = strings.TrimSuffix(output, "\n")
	return strconv.ParseUint(output, 10, 64)
}
source: func (s *DefaultWorkspaceCreationProperties) SetDefaultOu(v string) *DefaultWorkspaceCreationProperties {
	s.DefaultOu = &v
	return s
}
source: func (b *Box) GetRect() (int, int, int, int) {
	return b.x, b.y, b.width, b.height
}
source: func (t *TaskEnv) List() []string {
	if t.envList != nil {
		return t.envList
	}

	env := []string{}
	for k, v := range t.EnvMap {
		env = append(env, fmt.Sprintf("%s=%s", k, v))
	}

	return env
}
source: func (e *Executor) Signal(id string, signal int) error {
	return e.client.SignalProcess(context.Background(), id, libcontainerdtypes.InitProcessName, signal)
}
source: func (f *Filter) Contains(v []byte) bool {
	h := f.hash(v)
	for i := uint64(0); i < f.k; i++ {
		loc := f.location(h, i)
		if f.b[loc>>3]&(1<<(loc&7)) == 0 {
			return false
		}
	}
	return true
}
source: func (i *Instance) SaveServer(s Server, ln net.Listener) {
	i.servers = append(i.servers, ServerListener{server: s, listener: ln})
}
source: func (m *SetRollPitchYawThrust) Pack() []byte {
	data := new(bytes.Buffer)
	binary.Write(data, binary.LittleEndian, m.ROLL)
	binary.Write(data, binary.LittleEndian, m.PITCH)
	binary.Write(data, binary.LittleEndian, m.YAW)
	binary.Write(data, binary.LittleEndian, m.THRUST)
	binary.Write(data, binary.LittleEndian, m.TARGET_SYSTEM)
	binary.Write(data, binary.LittleEndian, m.TARGET_COMPONENT)
	return data.Bytes()
}
source: func (p BlockPointer) Ref() BlockRef {
	return BlockRef{
		ID:       p.ID,
		RefNonce: p.RefNonce,
	}
}
source: func WithAction(ctx context.Context, action string) context.Context {
	return context.WithValue(ctx, actionKey, action)
}
source: func MockTableInfo(ctx sessionctx.Context, stmt *ast.CreateTableStmt, tableID int64) (*model.TableInfo, error) {
	cols, newConstraints, err := buildColumnsAndConstraints(ctx, stmt.Cols, stmt.Constraints, "", "")
	if err != nil {
		return nil, errors.Trace(err)
	}
	tbl, err := buildTableInfo(ctx, nil, stmt.Table.Name, cols, newConstraints)
	if err != nil {
		return nil, errors.Trace(err)
	}
	tbl.ID = tableID

	// The specified charset will be handled in handleTableOptions
	if err = handleTableOptions(stmt.Options, tbl); err != nil {
		return nil, errors.Trace(err)
	}

	if err = resolveDefaultTableCharsetAndCollation(tbl, ""); err != nil {
		return nil, errors.Trace(err)
	}

	return tbl, nil
}
source: func SourceShardString(source *topodatapb.Shard_SourceShard) string {
	return fmt.Sprintf("SourceShard(%v,%v/%v)", source.Uid, source.Keyspace, source.Shard)
}
source: func (lc *LightChain) SubscribeRemovedLogsEvent(ch chan<- core.RemovedLogsEvent) event.Subscription {
	return lc.scope.Track(new(event.Feed).Subscribe(ch))
}
source: func (ns *NameServer) Init() error {
	timeout := ns.Timeout
	if timeout <= 0 {
		timeout = DefaultResolverTimeout
	}

	switch strings.ToLower(ns.Protocol) {
	case "tcp":
		ns.exchanger = &dnsExchanger{
			endpoint: ns.Addr,
			client: &dns.Client{
				Net:     "tcp",
				Timeout: timeout,
			},
		}
	case "tls":
		cfg := &tls.Config{
			ServerName: ns.Hostname,
		}
		if cfg.ServerName == "" {
			cfg.InsecureSkipVerify = true
		}

		ns.exchanger = &dnsExchanger{
			endpoint: ns.Addr,
			client: &dns.Client{
				Net:       "tcp-tls",
				Timeout:   timeout,
				TLSConfig: cfg,
			},
		}
	case "https":
		u, err := url.Parse(ns.Addr)
		if err != nil {
			return err
		}
		cfg := &tls.Config{ServerName: u.Hostname()}
		transport := &http.Transport{
			TLSClientConfig:    cfg,
			DisableCompression: true,
			MaxIdleConns:       1,
		}
		http2.ConfigureTransport(transport)

		ns.exchanger = &dohExchanger{
			endpoint: u,
			client: &http.Client{
				Transport: transport,
				Timeout:   timeout,
			},
		}
	case "udp":
		fallthrough
	default:
		ns.exchanger = &dnsExchanger{
			endpoint: ns.Addr,
			client: &dns.Client{
				Net:     "udp",
				Timeout: timeout,
			},
		}
	}

	return nil
}
source: func NewTSMReader(f *os.File, options ...tsmReaderOption) (*TSMReader, error) {
	t := &TSMReader{
		logger: zap.NewNop(),
	}
	for _, option := range options {
		option(t)
	}

	stat, err := f.Stat()
	if err != nil {
		return nil, err
	}
	t.size = stat.Size()
	t.lastModified = stat.ModTime().UnixNano()
	t.accessor = &mmapAccessor{
		logger:       t.logger,
		f:            f,
		mmapWillNeed: t.madviseWillNeed,
	}

	index, err := t.accessor.init()
	if err != nil {
		return nil, err
	}

	t.index = index
	t.tombstoner = NewTombstoner(t.Path(), index.MaybeContainsKey)

	if err := t.applyTombstones(); err != nil {
		return nil, err
	}

	return t, nil
}
source: func NewSmartSyncChangePolicyType(Description string) *SmartSyncChangePolicyType {
	s := new(SmartSyncChangePolicyType)
	s.Description = Description
	return s
}
source: func Load(fname string) (err error) {
  var buff []byte
  buff, err = ioutil.ReadFile(fname)
  if err == nil {
    err = json.Unmarshal(buff, MailServer)
  }
  return
}
source: func CalculateDiff(options *Options) (*Result, error) {
	baseVersionQuery := models.GetDashboardVersionQuery{
		DashboardId: options.Base.DashboardId,
		Version:     options.Base.Version,
		OrgId:       options.OrgId,
	}

	if err := bus.Dispatch(&baseVersionQuery); err != nil {
		return nil, err
	}

	newVersionQuery := models.GetDashboardVersionQuery{
		DashboardId: options.New.DashboardId,
		Version:     options.New.Version,
		OrgId:       options.OrgId,
	}

	if err := bus.Dispatch(&newVersionQuery); err != nil {
		return nil, err
	}

	baseData := baseVersionQuery.Result.Data
	newData := newVersionQuery.Result.Data

	left, jsonDiff, err := getDiff(baseData, newData)
	if err != nil {
		return nil, err
	}

	result := &Result{}

	switch options.DiffType {
	case DiffDelta:

		deltaOutput, err := deltaFormatter.NewDeltaFormatter().Format(jsonDiff)
		if err != nil {
			return nil, err
		}
		result.Delta = []byte(deltaOutput)

	case DiffJSON:
		jsonOutput, err := NewJSONFormatter(left).Format(jsonDiff)
		if err != nil {
			return nil, err
		}
		result.Delta = []byte(jsonOutput)

	case DiffBasic:
		basicOutput, err := NewBasicFormatter(left).Format(jsonDiff)
		if err != nil {
			return nil, err
		}
		result.Delta = basicOutput

	default:
		return nil, ErrUnsupportedDiffType
	}

	return result, nil
}
source: func NewQuery(feed *Feed, time uint64, hint lookup.Epoch) *Query {
	return &Query{
		TimeLimit: time,
		Feed:      *feed,
		Hint:      hint,
	}
}
source: func Convert_v1_AzureDiskVolumeSource_To_core_AzureDiskVolumeSource(in *v1.AzureDiskVolumeSource, out *core.AzureDiskVolumeSource, s conversion.Scope) error {
	return autoConvert_v1_AzureDiskVolumeSource_To_core_AzureDiskVolumeSource(in, out, s)
}
source: func isUnitExists(err error) bool {
	if err != nil {
		if dbusError, ok := err.(dbus.Error); ok {
			return strings.Contains(dbusError.Name, "org.freedesktop.systemd1.UnitExists")
		}
	}
	return false
}
source: func (c *cookies) Float64(key string) (float64, error) {
	ck, err := c.req.Cookie(key)
	if err != nil {
		return 0, err
	}
	return strconv.ParseFloat(ck.Value, 32)
}
source: func (s *ReplicaGlobalSecondaryIndexSettingsUpdate) SetProvisionedReadCapacityAutoScalingSettingsUpdate(v *AutoScalingSettingsUpdate) *ReplicaGlobalSecondaryIndexSettingsUpdate {
	s.ProvisionedReadCapacityAutoScalingSettingsUpdate = v
	return s
}
source: func (r *RepoStats) GetTotalWikis() int {
	if r == nil || r.TotalWikis == nil {
		return 0
	}
	return *r.TotalWikis
}
source: func Convert_core_ServiceAccountTokenProjection_To_v1_ServiceAccountTokenProjection(in *core.ServiceAccountTokenProjection, out *v1.ServiceAccountTokenProjection, s conversion.Scope) error {
	return autoConvert_core_ServiceAccountTokenProjection_To_v1_ServiceAccountTokenProjection(in, out, s)
}
source: func (c *ClusterManager) GetData() (map[string]*api.Node, error) {
	nodes := make(map[string]*api.Node)
	c.nodeCacheLock.Lock()
	defer c.nodeCacheLock.Unlock()
	for _, value := range c.nodeCache {
		copyValue := value.Copy()
		nodes[value.Id] = copyValue
	}
	return nodes, nil
}
source: func LoadOrNewBlockchain(db dbm.DB, genesisDoc *genesis.GenesisDoc, logger *logging.Logger) (bool, *Blockchain, error) {
	logger = logger.WithScope("LoadOrNewBlockchain")
	logger.InfoMsg("Trying to load blockchain state from database",
		"database_key", stateKey)
	bc, err := loadBlockchain(db)
	if err != nil {
		return false, nil, fmt.Errorf("error loading blockchain state from database: %v", err)
	}
	if bc != nil {
		dbHash := bc.genesisDoc.Hash()
		argHash := genesisDoc.Hash()
		if !bytes.Equal(dbHash, argHash) {
			return false, nil, fmt.Errorf("GenesisDoc passed to LoadOrNewBlockchain has hash: 0x%X, which does not "+
				"match the one found in database: 0x%X, database genesis:\n%v\npassed genesis:\n%v\n",
				argHash, dbHash, bc.genesisDoc.JSONString(), genesisDoc.JSONString())
		}
		return true, bc, nil
	}

	logger.InfoMsg("No existing blockchain state found in database, making new blockchain")
	return false, NewBlockchain(db, genesisDoc), nil
}
source: func (c *Canvas) Draw(t pixel.Target, matrix pixel.Matrix) {
	c.sprite.Draw(t, matrix)
}
source: func (e gfPoly) equals(other gfPoly) bool {
	var minecPoly *gfPoly
	var maxecPoly *gfPoly

	if e.numTerms() > other.numTerms() {
		minecPoly = &other
		maxecPoly = &e
	} else {
		minecPoly = &e
		maxecPoly = &other
	}

	numMinTerms := minecPoly.numTerms()
	numMaxTerms := maxecPoly.numTerms()

	for i := 0; i < numMinTerms; i++ {
		if e.term[i] != other.term[i] {
			return false
		}
	}

	for i := numMinTerms; i < numMaxTerms; i++ {
		if maxecPoly.term[i] != 0 {
			return false
		}
	}

	return true
}
source: func (a allocSet) nameOrder() []*structs.Allocation {
	allocs := make([]*structs.Allocation, 0, len(a))
	for _, alloc := range a {
		allocs = append(allocs, alloc)
	}
	sort.Slice(allocs, func(i, j int) bool {
		return allocs[i].Index() < allocs[j].Index()
	})
	return allocs
}
source: func hashstr(b []byte) string {
	end := len(b)
	if end > 4 {
		end = 4
	}
	return fmt.Sprintf("%x", b[:end])
}
source: func WriteNoopCmd(w io.Writer, opaque uint32) error {
	// opcode, keyLength, extraLength, totalBodyLength
	header := makeRequestHeader(OpcodeNoop, 0, 0, 0, opaque)
	//fmt.Printf("Delete: key: %v | totalBodyLength: %v\n", string(key), len(key))

	err := writeRequestHeader(w, header)

	metrics.IncCounterBy(common.MetricBytesWrittenLocal, uint64(ReqHeaderLen))

	reqHeadPool.Put(header)

	return err
}
source: func UnmarshalProvisionToken(data []byte, opts ...MarshalOption) (ProvisionToken, error) {
	if len(data) == 0 {
		return nil, trace.BadParameter("missing provision token data")
	}

	cfg, err := collectOptions(opts)
	if err != nil {
		return nil, trace.Wrap(err)
	}

	var h ResourceHeader
	err = utils.FastUnmarshal(data, &h)
	if err != nil {
		return nil, trace.Wrap(err)
	}

	switch h.Version {
	case "":
		var p ProvisionTokenV1
		err := utils.FastUnmarshal(data, &p)
		if err != nil {
			return nil, trace.Wrap(err)
		}
		v2 := p.V2()
		if cfg.ID != 0 {
			v2.SetResourceID(cfg.ID)
		}
		return v2, nil
	case V2:
		var p ProvisionTokenV2
		if cfg.SkipValidation {
			if err := utils.FastUnmarshal(data, &p); err != nil {
				return nil, trace.BadParameter(err.Error())
			}
		} else {
			if err := utils.UnmarshalWithSchema(GetProvisionTokenSchema(), &p, data); err != nil {
				return nil, trace.BadParameter(err.Error())
			}
		}
		if err := p.CheckAndSetDefaults(); err != nil {
			return nil, trace.Wrap(err)
		}
		if cfg.ID != 0 {
			p.SetResourceID(cfg.ID)
		}
		return &p, nil
	}
	return nil, trace.BadParameter("server resource version %v is not supported", h.Version)
}
source: func (m *MockMachine) AllLinkLayerDevices() ([]containerizer.LinkLayerDevice, error) {
	ret := m.ctrl.Call(m, "AllLinkLayerDevices")
	ret0, _ := ret[0].([]containerizer.LinkLayerDevice)
	ret1, _ := ret[1].(error)
	return ret0, ret1
}
source: func futureEvalTimePretty(evalID string, client *api.Client) string {
	evaluation, _, err := client.Evaluations().Info(evalID, nil)
	// Eval time is not a critical output,
	// don't return it on errors, if its not set or already in the past
	if err != nil || evaluation.WaitUntil.IsZero() || time.Now().After(evaluation.WaitUntil) {
		return ""
	}
	return prettyTimeDiff(evaluation.WaitUntil, time.Now())
}
source: func (db *Dashboard) webHandler(w http.ResponseWriter, r *http.Request) {
	log.Debug("Request", "URL", r.URL)

	path := r.URL.String()
	if path == "/" {
		path = "/index.html"
	}
	blob, err := Asset(path[1:])
	if err != nil {
		log.Warn("Failed to load the asset", "path", path, "err", err)
		http.Error(w, "not found", http.StatusNotFound)
		return
	}
	w.Write(blob)
}
source: func FindInSearchPath(searchPath, pkg string) string {
	pathsList := filepath.SplitList(searchPath)
	for _, path := range pathsList {
		if evaluatedPath, err := filepath.EvalSymlinks(filepath.Join(path, "src", pkg)); err == nil {
			if _, err := os.Stat(evaluatedPath); err == nil {
				return evaluatedPath
			}
		}
	}
	return ""
}
source: func (bs *BundleSource) Update(newBundle *Bundle) {
	bs.bundle.Store(newBundle)
	for _, callback := range bs.callbacks {
		callback(newBundle)
	}
}
source: func (k *KeyOpsStandard) GetTLFCryptKeyServerHalf(
	ctx context.Context, serverHalfID kbfscrypto.TLFCryptKeyServerHalfID,
	key kbfscrypto.CryptPublicKey) (kbfscrypto.TLFCryptKeyServerHalf, error) {
	// get the key half from the server
	serverHalf, err := k.config.KeyServer().GetTLFCryptKeyServerHalf(
		ctx, serverHalfID, key)
	if err != nil {
		return kbfscrypto.TLFCryptKeyServerHalf{}, err
	}
	// get current uid and deviceKID
	session, err := k.config.KBPKI().GetCurrentSession(ctx)
	if err != nil {
		return kbfscrypto.TLFCryptKeyServerHalf{}, err
	}

	// verify we got the expected key
	err = kbfscrypto.VerifyTLFCryptKeyServerHalfID(
		serverHalfID, session.UID, key, serverHalf)
	if err != nil {
		return kbfscrypto.TLFCryptKeyServerHalf{}, err
	}
	return serverHalf, nil
}
source: func (s *Sem) Acquire(n int64) error {
	if n > s.max {
		return fmt.Errorf("sem: attempt to acquire more units than semaphore size %d > %d", n, s.max)
	}
	s.c.L.Lock()
	defer s.c.L.Unlock()
	for {
		debug.Printf("Acquire check max %d free %d, n %d", s.max, s.free, n)
		if s.free >= n {
			s.free -= n
			return nil
		}
		debug.Printf("Acquire Wait max %d free %d, n %d", s.max, s.free, n)
		s.c.Wait()
	}
}
source: func NewWriterHandler(w io.Writer) *WriterHandler {
	return &WriterHandler{
		BaseHandler: NewBaseHandler(),
		w:           w,
	}
}
source: func (api *Client) KickUserFromConversation(channelID string, user string) error {
	return api.KickUserFromConversationContext(context.Background(), channelID, user)
}
source: func NewTgBot(token string) *TgBot {
	bot, err := NewWithError(token)
	if err != nil {
		panic(err)
	}
	return bot
}
source: func (c *CoreScheduler) evalReap(evals, allocs []string) error {
	// Call to the leader to issue the reap
	for _, req := range c.partitionEvalReap(evals, allocs) {
		var resp structs.GenericResponse
		if err := c.srv.RPC("Eval.Reap", req, &resp); err != nil {
			c.logger.Error("eval reap failed", "error", err)
			return err
		}
	}

	return nil
}
source: func (gs GlobalScope) Trigger(key int, data interface{}) error {
	if err := gs.EventScope.Trigger(key, data); err != nil {
		return err
	}
	for _, scope := range gs.scopes {
		if err := scope.Trigger(key, data); err != nil {
			return err
		}
	}
	return nil
}
source: func (u Uint) Get() (uint, error) {
	if !u.Present() {
		var zero uint
		return zero, errors.New("value not present")
	}
	return *u.value, nil
}
source: func MostlyDeterministicMarshal(msg proto.Message) ([]byte, error) {
	buffer := proto.NewBuffer(make([]byte, 0))
	buffer.SetDeterministic(true)
	if err := buffer.Marshal(msg); err != nil {
		return nil, err
	}
	return buffer.Bytes(), nil
}
source: func MarshalContext(ctx context.Context) map[string]interface{} {
	contextMarshalFuncsMu.RLock()
	defer contextMarshalFuncsMu.RUnlock()

	allVals := map[string]interface{}{}

	for _, f := range contextMarshalFuncs {
		vals := map[string]interface{}{}
		f(ctx, vals)

		for key, val := range vals {
			if _, ok := allVals[key]; ok {
				panic("duplicate context entry for: " + key)
			}
			allVals[key] = val
		}
	}

	return allVals
}
source: func (s *EndpointResponse) SetCohortId(v string) *EndpointResponse {
	s.CohortId = &v
	return s
}
source: func ErrMaxValueInFlightTooSmall(maxValInFlight,
	minMaxValInFlight lnwire.MilliSatoshi) ReservationError {
	return ReservationError{
		fmt.Errorf("maxValueInFlight too small: %v, min is %v",
			maxValInFlight, minMaxValInFlight),
	}
}
source: func (t *ThirdPartyController) SyncOneResource(rsrc *expapi.ThirdPartyResource) error {
	// TODO: we also need to test if the existing installed resource matches the resource we are sync-ing.
	// Currently, if there is an older, incompatible resource installed, we won't remove it.  We should detect
	// older, incompatible resources and remove them before testing if the resource exists.
	hasResource, err := t.master.HasThirdPartyResource(rsrc)
	if err != nil {
		return err
	}
	if !hasResource {
		return t.master.InstallThirdPartyResource(rsrc)
	}
	return nil
}
source: func (s *UpdateVoiceChannelInput) SetVoiceChannelRequest(v *VoiceChannelRequest) *UpdateVoiceChannelInput {
	s.VoiceChannelRequest = v
	return s
}
source: func (j *JWS) GetKeyAuthorization(token string) (string, error) {
	var publicKey crypto.PublicKey
	switch k := j.privKey.(type) {
	case *ecdsa.PrivateKey:
		publicKey = k.Public()
	case *rsa.PrivateKey:
		publicKey = k.Public()
	}

	// Generate the Key Authorization for the challenge
	jwk := &jose.JSONWebKey{Key: publicKey}

	thumbBytes, err := jwk.Thumbprint(crypto.SHA256)
	if err != nil {
		return "", err
	}

	// unpad the base64URL
	keyThumb := base64.RawURLEncoding.EncodeToString(thumbBytes)

	return token + "." + keyThumb, nil
}
source: func (r *RestartTracker) GetPolicy() *structs.RestartPolicy {
	r.lock.Lock()
	defer r.lock.Unlock()
	return r.policy.Copy()
}
source: func (s *Semaphore) Acquire() error {
	select {
	case s.sem <- struct{}{}:
		return nil
	case <-time.After(s.timeout):
		return ErrNoTickets
	}
}
source: func (l *PluginLoader) validatePluginConfigs() error {
	var mErr multierror.Error
	for id, info := range l.plugins {
		if err := l.validatePluginConfig(id, info); err != nil {
			wrapped := multierror.Prefix(err, fmt.Sprintf("plugin %s:", id))
			multierror.Append(&mErr, wrapped)
		}
	}

	return mErr.ErrorOrNil()
}
source: func Endpoint2IfName(endpointID string) string {
	sum := fmt.Sprintf("%x", sha256.Sum256([]byte(endpointID)))
	// returned string length should be < unix.IFNAMSIZ
	truncateLength := uint(unix.IFNAMSIZ - len(temporaryInterfacePrefix) - 1)
	return hostInterfacePrefix + truncateString(sum, truncateLength)
}
source: func (q *BaseQueryBuilder) BuildOrderBy(cols []string) string {
	if len(cols) == 0 {
		return ""
	}
	s := ""
	for i, col := range cols {
		if i > 0 {
			s += ", "
		}
		matches := orderRegex.FindStringSubmatch(col)
		if len(matches) == 0 {
			s += q.db.QuoteColumnName(col)
		} else {
			col := col[:len(col)-len(matches[0])]
			dir := matches[1]
			s += q.db.QuoteColumnName(col) + " " + dir
		}
	}
	return "ORDER BY " + s
}
source: func (opts *IngestExternalFileOptions) SetMoveFiles(flag bool) {
	C.rocksdb_ingestexternalfileoptions_set_move_files(opts.c, boolToChar(flag))
}
source: func parseStatus(status buildbucketpb.Status) model.Status {
	if st, ok := statusMap[status]; ok {
		return st
	}
	return model.InfraFailure
}
source: func BuildByBuildConfigIndexFunc(obj interface{}) ([]string, error) {
	build, ok := obj.(*buildv1.Build)
	if !ok {
		return nil, fmt.Errorf("not a build: %v", build)
	}
	config := build.Status.Config
	if config == nil {
		return []string{"orphan"}, nil
	}
	return []string{config.Namespace + "/" + config.Name}, nil
}
source: func NewGracefulLimiter(amount int, frequency time.Duration, grace time.Duration) Limiter {
	return &simpleLimiter{
		Amount:    amount,
		Frequency: frequency,
		numRead:   minInt,
		timeRead:  time.Now().Add(grace),
	}
}
source: func (blockID BlockID) Equals(other BlockID) bool {
	return bytes.Equal(blockID.Hash, other.Hash) &&
		blockID.PartsHeader.Equals(other.PartsHeader)
}
source: func WithDomain(domain string) OptionFunc {
	return func(cs *CloudStackClient, p interface{}) error {
		ps, ok := p.(DomainIDSetter)

		if !ok || domain == "" {
			return nil
		}

		if !IsID(domain) {
			id, _, err := cs.Domain.GetDomainID(domain)
			if err != nil {
				return err
			}
			domain = id
		}

		ps.SetDomainid(domain)

		return nil
	}
}
source: func (r *bufReader) Close() error {
	closer, ok := r.reader.(io.ReadCloser)
	if !ok {
		return nil
	}
	return closer.Close()
}
source: func (s *InstanceGroup) SetInstanceGroupType(v string) *InstanceGroup {
	s.InstanceGroupType = &v
	return s
}
source: func (s *ProbeDetailsDTO) SMTPProbeDetails() (SMTPProbeDetailsDTO, error) {
	var d SMTPProbeDetailsDTO
	err := json.Unmarshal(s.data, &d)
	return d, err
}
source: func (s *AuthorizationService) UpdateAuthorization(ctx context.Context, id platform.ID, upd *platform.AuthorizationUpdate) (a *platform.Authorization, err error) {
	defer func(start time.Time) {
		labels := prometheus.Labels{
			"method": "setAuthorizationStatus",
			"error":  fmt.Sprint(err != nil),
		}
		s.requestCount.With(labels).Add(1)
		s.requestDuration.With(labels).Observe(time.Since(start).Seconds())
	}(time.Now())

	return s.AuthorizationService.UpdateAuthorization(ctx, id, upd)
}
source: func Convert_v1_LimitRangeList_To_core_LimitRangeList(in *v1.LimitRangeList, out *core.LimitRangeList, s conversion.Scope) error {
	return autoConvert_v1_LimitRangeList_To_core_LimitRangeList(in, out, s)
}
source: func (r *RedisStore) SetWithExpiration(key string, value interface{}, expiration time.Duration) error {
	return r.client.Set(key, value, expiration).Err()
}
source: func DetectLanguage(buffer_length int, text, format string) (lang Language, err error) {
	c_buffer := C.int(buffer_length)
	c_string := C.CString(text)

	var c_char = C.CString("")
	defer C.free(unsafe.Pointer(c_char))
	defer C.free(unsafe.Pointer(c_string))

	var lang_result C.Language = C.CLD2_DetectLanguage(c_string, c_buffer)

	switch {
	case format == "name":
		c_char = C.CLD2_LanguageName(lang_result)
	case format == "code":
		c_char = C.CLD2_LanguageCode(lang_result)
	case format == "declname":
		c_char = C.CLD2_LanguageDeclaredName(lang_result)
	default:
		c_char = C.CLD2_LanguageCode(lang_result)
	}

	if c_char != nil {
		lang = Language(C.GoString(c_char))
		return lang, err
	} else {
		err = Cld2NlptError{
			time.Date(1989, 3, 15, 22, 30, 0, 0, time.UTC),
			"result returned nil: C.CLD2_LanguageName(C.CLD2_DetectLanguage(cs, b_length))",
		}
		return lang, err
	}
	return
}
source: func SetErrorWithEvent(r *http.Request, format string, args ...interface{}) {
	SetError(r)
	LogEventf(r, format, args...)
}
source: func NewPublicPortManager(hostID, certFile, keyFile string, onFailure func(portAddr string, err error)) *PublicPortManager {
	return &PublicPortManager{
		hostID:    hostID,
		certFile:  certFile,
		keyFile:   keyFile,
		onFailure: onFailure,
		mu:        &sync.RWMutex{},
		ports:     make(map[string]*PublicPortHandler),
	}
}
source: func Int(v int) *int {
	p := new(int)
	*p = v
	return p
}
source: func New(maxentries int) *Cache {
	return &Cache{
		MaxEntries: maxentries,
		ll:         list.New(),
		cache:      make(map[string]*list.Element),
	}
}
source: func replaceCustomError(m metaContext, state scriptState, spec *errorT, err1 libkb.ProofError) libkb.ProofError {
	if err1 == nil {
		return err1
	}

	// Don't rewrite invalid_pvl errors
	if err1.GetProofStatus() == keybase1.ProofStatus_INVALID_PVL {
		return err1
	}

	if spec == nil {
		return err1
	}

	if (spec.Status != err1.GetProofStatus()) || (spec.Description != err1.GetDesc()) {
		newDesc := spec.Description
		subbedDesc, subErr := substituteExact(spec.Description, state)
		if subErr == nil {
			newDesc = subbedDesc
		}
		err2 := libkb.NewProofError(spec.Status, newDesc)
		debugWithState(m, state, "Replacing error with custom error")
		debugWithStateError(m, state, err2)

		return err2
	}
	return err1
}
source: func (e *Envelope) SignSecret(signer Signer, secret *Secret) error {
	payload, err := proto.Marshal(secret)
	if err != nil {
		return err
	}
	sig, err := signer(payload)
	if err != nil {
		return err
	}
	e.SecretEnvelope = &SecretEnvelope{
		Payload:   payload,
		Signature: sig,
	}
	return nil
}
source: func main() {

	var inputbytes, utf8bytes, outputbytes []byte

	flag.Parse()

	// print help/version/list/usage...
	someSortOfHelp()

	// read input from stdin or file
	inputbytes = getInputBytes()

	// convert inputformat to UTF-8 (decode)
	utf8bytes = getUtf8FromInput(inputbytes)

	// convert UTF-8 to output format (encode)
	outputbytes = convertToDesired(utf8bytes)

	// write output to stdout or file
	writeOutput(outputbytes)

}
source: func (s Signature) Single() bool {
	err, r := validSingle(s.str, 0)
	return err != nil && r == ""
}
source: func NewLineScanner(r io.Reader) *LineScanner {
	br := bufio.NewReader(r)
	ls := &LineScanner{
		Reader: br,
	}
	return ls
}
source: func Convert_security_SupplementalGroupsStrategyOptions_To_v1_SupplementalGroupsStrategyOptions(in *security.SupplementalGroupsStrategyOptions, out *v1.SupplementalGroupsStrategyOptions, s conversion.Scope) error {
	return autoConvert_security_SupplementalGroupsStrategyOptions_To_v1_SupplementalGroupsStrategyOptions(in, out, s)
}
source: func buildHandlerChain(handler http.Handler, authn authenticator.Request, authz authorizer.Authorizer) http.Handler {
	requestInfoResolver := &apirequest.RequestInfoFactory{}
	failedHandler := genericapifilters.Unauthorized(legacyscheme.Codecs, false)

	handler = genericapifilters.WithRequestInfo(handler, requestInfoResolver)
	handler = genericapifilters.WithAuthorization(handler, authz, legacyscheme.Codecs)
	handler = genericapifilters.WithAuthentication(handler, authn, failedHandler, nil)
	handler = genericapifilters.WithRequestInfo(handler, requestInfoResolver)
	handler = genericfilters.WithPanicRecovery(handler)

	return handler
}
source: func NewBoundContract(address common.Address, abi abi.ABI, caller ContractCaller, transactor ContractTransactor, filterer ContractFilterer) *BoundContract {
	return &BoundContract{
		address:    address,
		abi:        abi,
		caller:     caller,
		transactor: transactor,
		filterer:   filterer,
	}
}
source: func newDeployment(foo *samplev1alpha1.Foo) *appsv1.Deployment {
	labels := map[string]string{
		"app":        "nginx",
		"controller": foo.Name,
	}
	return &appsv1.Deployment{
		ObjectMeta: metav1.ObjectMeta{
			Name:      foo.Spec.DeploymentName,
			Namespace: foo.Namespace,
			OwnerReferences: []metav1.OwnerReference{
				*metav1.NewControllerRef(foo, samplev1alpha1.SchemeGroupVersion.WithKind("Foo")),
			},
		},
		Spec: appsv1.DeploymentSpec{
			Replicas: foo.Spec.Replicas,
			Selector: &metav1.LabelSelector{
				MatchLabels: labels,
			},
			Template: corev1.PodTemplateSpec{
				ObjectMeta: metav1.ObjectMeta{
					Labels: labels,
				},
				Spec: corev1.PodSpec{
					Containers: []corev1.Container{
						{
							Name:  "nginx",
							Image: "nginx:latest",
						},
					},
				},
			},
		},
	}
}
source: func (e *DDLExec) executeRecoverTable(s *ast.RecoverTableStmt) error {
	txn, err := e.ctx.Txn(true)
	if err != nil {
		return err
	}
	t := meta.NewMeta(txn)
	dom := domain.GetDomain(e.ctx)
	var job *model.Job
	var tblInfo *model.TableInfo
	if s.JobID != 0 {
		job, tblInfo, err = e.getRecoverTableByJobID(s, t, dom)
	} else {
		job, tblInfo, err = e.getRecoverTableByTableName(s, t, dom)
	}
	if err != nil {
		return err
	}
	// Get table original autoID before table drop.
	m, err := dom.GetSnapshotMeta(job.StartTS)
	if err != nil {
		return err
	}
	autoID, err := m.GetAutoTableID(job.SchemaID, job.TableID)
	if err != nil {
		return errors.Errorf("recover table_id: %d, get original autoID from snapshot meta err: %s", job.TableID, err.Error())
	}
	// Call DDL RecoverTable
	err = domain.GetDomain(e.ctx).DDL().RecoverTable(e.ctx, tblInfo, job.SchemaID, autoID, job.ID, job.StartTS)
	return err
}
source: func checkDaemonIsSwarmManager(ctx context.Context, dockerCli command.Cli) error {
	info, err := dockerCli.Client().Info(ctx)
	if err != nil {
		return err
	}
	if !info.Swarm.ControlAvailable {
		return errors.New("this node is not a swarm manager. Use \"docker swarm init\" or \"docker swarm join\" to connect this node to swarm and try again")
	}
	return nil
}
source: func (mc MiddlewareChain) Extend(mw ...Middleware) MiddlewareChain {
	if len(mw) == 0 {
		return mc
	}

	ext := make([]Middleware, 0, len(mc.middleware)+len(mw))
	return MiddlewareChain{append(append(ext, mc.middleware...), mw...)}
}
source: func IsRollingUpdate(deployment *apps.Deployment) bool {
	return deployment.Spec.Strategy.Type == apps.RollingUpdateDeploymentStrategyType
}
source: func (hp *HostPreparer) Prepare(containerTag names.MachineTag) error {
	devicesToBridge, reconfigureDelay, err := hp.api.HostChangesForContainer(containerTag)
	if err != nil {
		return errors.Annotate(err, "unable to setup network")
	}

	if len(devicesToBridge) == 0 {
		hp.logger.Debugf("container %q requires no additional bridges", containerTag)
		return nil
	}

	bridger, err := hp.createBridger()
	if err != nil {
		return errors.Trace(err)
	}

	hp.logger.Debugf("bridging %+v devices on host %q for container %q with delay=%v",
		devicesToBridge, hp.machineTag.String(), containerTag.String(), reconfigureDelay)
	releaser, err := hp.acquireLockFunc("bridging devices", hp.abortChan)
	if err != nil {
		return errors.Annotatef(err, "failed to acquire machine lock for bridging")
	}
	defer releaser()
	// TODO(jam): 2017-02-15 bridger.Bridge should probably also take AbortChan
	// if it is going to have reconfigureDelay
	err = bridger.Bridge(devicesToBridge, reconfigureDelay)
	if err != nil {
		return errors.Annotate(err, "failed to bridge devices")
	}

	// We just changed the hosts' network setup so discover new
	// interfaces/devices and propagate to state.
	observedConfig, err := hp.observeNetworkFunc()
	if err != nil {
		return errors.Annotate(err, "cannot discover observed network config")
	}

	if len(observedConfig) > 0 {
		hp.logger.Debugf("updating observed network config for %q to %#v", hp.machineTag.String(), observedConfig)
		err := hp.api.SetHostMachineNetworkConfig(hp.machineTag, observedConfig)
		if err != nil {
			return errors.Trace(err)
		}
	}

	return nil
}
source: func linearize_fast(v float64) float64 {
	v1 := v - 0.5
	v2 := v1 * v1
	v3 := v2 * v1
	v4 := v2 * v2
	//v5 := v3*v2
	return -0.248750514614486 + 0.925583310193438*v + 1.16740237321695*v2 + 0.280457026598666*v3 - 0.0757991963780179*v4 //+ 0.0437040411548932*v5
}
source: func (pgb *ChainDB) BlockTransactions(blockHash string) ([]string, []uint32, []int8, error) {
	ctx, cancel := context.WithTimeout(pgb.ctx, pgb.queryTimeout)
	defer cancel()
	_, blockTransactions, blockInds, trees, _, err := RetrieveTxsByBlockHash(ctx, pgb.db, blockHash)
	return blockTransactions, blockInds, trees, pgb.replaceCancelError(err)
}
source: func appendStatement(statements []Statement, statement Statement) []Statement {
	for i, s := range statements {
		if s.Actions.Equals(statement.Actions) &&
			s.Effect == statement.Effect &&
			s.Principal.AWS.Equals(statement.Principal.AWS) &&
			reflect.DeepEqual(s.Conditions, statement.Conditions) {
			statements[i].Resources = s.Resources.Union(statement.Resources)
			return statements
		} else if s.Resources.Equals(statement.Resources) &&
			s.Effect == statement.Effect &&
			s.Principal.AWS.Equals(statement.Principal.AWS) &&
			reflect.DeepEqual(s.Conditions, statement.Conditions) {
			statements[i].Actions = s.Actions.Union(statement.Actions)
			return statements
		}

		if s.Resources.Intersection(statement.Resources).Equals(statement.Resources) &&
			s.Actions.Intersection(statement.Actions).Equals(statement.Actions) &&
			s.Effect == statement.Effect &&
			s.Principal.AWS.Intersection(statement.Principal.AWS).Equals(statement.Principal.AWS) {
			if reflect.DeepEqual(s.Conditions, statement.Conditions) {
				return statements
			}
			if s.Conditions != nil && statement.Conditions != nil {
				if s.Resources.Equals(statement.Resources) {
					statements[i].Conditions = mergeConditionMap(s.Conditions, statement.Conditions)
					return statements
				}
			}
		}
	}

	if !(statement.Actions.IsEmpty() && statement.Resources.IsEmpty()) {
		return append(statements, statement)
	}

	return statements
}
source: func (self *ResourceAuth) UnmarshalJSON(b []byte) error {
	var m rawResourceAuth
	err := json.Unmarshal(b, &m)
	if err == nil {
		o := ResourceAuth(m)
		*self = o
		err = self.Validate()
	}
	return err
}
source: func (d *Driver) SetExposure(level int) (err error) {
	if level < 0 || level > 2 {
		return errors.New("Invalid exposure level")
	}

	buf, _ := d.createPacket(exposureCommand, 0x48, 1)
	d.seq++
	binary.Write(buf, binary.LittleEndian, d.seq)
	binary.Write(buf, binary.LittleEndian, byte(level))
	binary.Write(buf, binary.LittleEndian, CalculateCRC16(buf.Bytes()))

	_, err = d.cmdConn.Write(buf.Bytes())
	return
}
source: func (l LabelMap) copy() (result LabelMap) {
	result = make(map[string]string, len(l))
	for key, value := range l {
		result[key] = value
	}
	return
}
source: func Convert_v1_OpenIDIdentityProvider_To_config_OpenIDIdentityProvider(in *v1.OpenIDIdentityProvider, out *config.OpenIDIdentityProvider, s conversion.Scope) error {
	return autoConvert_v1_OpenIDIdentityProvider_To_config_OpenIDIdentityProvider(in, out, s)
}
source: func (s *GetSampledRequestsInput) SetWebAclId(v string) *GetSampledRequestsInput {
	s.WebAclId = &v
	return s
}
source: func Convert_v1beta1_FlunderSpec_To_wardle_FlunderSpec(in *FlunderSpec, out *wardle.FlunderSpec, s conversion.Scope) error {
	return autoConvert_v1beta1_FlunderSpec_To_wardle_FlunderSpec(in, out, s)
}
source: func (w *Window) SetPos(pos pixel.Vec) {
	mainthread.Call(func() {
		left, top := int(pos.X), int(pos.Y)
		w.window.SetPos(left, top)
	})
}
source: func (ba *bitArray) Serialize() ([]byte, error) {
	w := new(bytes.Buffer)

	var identifier uint8 = 'B'
	err := binary.Write(w, binary.LittleEndian, identifier)
	if err != nil {
		return nil, err
	}

	err = binary.Write(w, binary.LittleEndian, ba.lowest)
	if err != nil {
		return nil, err
	}
	err = binary.Write(w, binary.LittleEndian, ba.highest)
	if err != nil {
		return nil, err
	}

	var encodedanyset uint8
	if ba.anyset {
		encodedanyset = 1
	} else {
		encodedanyset = 0
	}
	err = binary.Write(w, binary.LittleEndian, encodedanyset)
	if err != nil {
		return nil, err
	}

	err = binary.Write(w, binary.LittleEndian, ba.blocks)
	if err != nil {
		return nil, err
	}
	return w.Bytes(), nil
}
source: func (api *Client) GetUserPresenceContext(ctx context.Context, user string) (*UserPresence, error) {
	values := url.Values{
		"token": {api.token},
		"user":  {user},
	}

	response, err := api.userRequest(ctx, "users.getPresence", values)
	if err != nil {
		return nil, err
	}
	return &response.UserPresence, nil
}
source: func (errs Errors) Error() string {
	var errors = []string{}
	for _, e := range errs {
		errors = append(errors, e.Error())
	}
	return strings.Join(errors, "; ")
}
source: func (m *Map) Resources() []terraform.ResourceType {
	ks := make([]string, 0, len(m.Mapping))
	for k, _ := range m.Mapping {
		ks = append(ks, k)
	}
	sort.Strings(ks)

	rs := make([]terraform.ResourceType, 0, len(m.Mapping))
	for _, k := range ks {
		rs = append(rs, terraform.ResourceType{
			Name: k,
		})
	}

	return rs
}
source: func (ngram *NGramIndex) countNgrams(inputNgrams []uint32) map[TokenID]int {
	counters := make(map[TokenID]int)
	for _, ngramHash := range inputNgrams {
		ngram.RLock()
		for tok := range ngram.index[ngramHash] {
			counters[tok]++
		}
		ngram.RUnlock()
	}
	return counters
}
source: func (b *backend) validateInstance(ctx context.Context, s logical.Storage, instanceID, region, accountID string) (*ec2.Instance, error) {
	// Create an EC2 client to pull the instance information
	ec2Client, err := b.clientEC2(ctx, s, region, accountID)
	if err != nil {
		return nil, err
	}

	status, err := ec2Client.DescribeInstances(&ec2.DescribeInstancesInput{
		InstanceIds: []*string{
			aws.String(instanceID),
		},
	})
	if err != nil {
		errW := errwrap.Wrapf(fmt.Sprintf("error fetching description for instance ID %q: {{err}}", instanceID), err)
		return nil, errwrap.Wrap(errW, awsutil.CheckAWSError(err))
	}
	if status == nil {
		return nil, fmt.Errorf("nil output from describe instances")
	}
	if len(status.Reservations) == 0 {
		return nil, fmt.Errorf("no reservations found in instance description")

	}
	if len(status.Reservations[0].Instances) == 0 {
		return nil, fmt.Errorf("no instance details found in reservations")
	}
	if *status.Reservations[0].Instances[0].InstanceId != instanceID {
		return nil, fmt.Errorf("expected instance ID not matching the instance ID in the instance description")
	}
	if status.Reservations[0].Instances[0].State == nil {
		return nil, fmt.Errorf("instance state in instance description is nil")
	}
	if *status.Reservations[0].Instances[0].State.Name != "running" {
		return nil, fmt.Errorf("instance is not in 'running' state")
	}
	return status.Reservations[0].Instances[0], nil
}
source: func (rule *Rule) AddCriteria(criteria *Criteria) {
	for key, existingCriteria := range rule.Criteria {
		if existingCriteria.Name == criteria.Name {
			rule.Criteria[key] = criteria
			return
		}
	}

	rule.Criteria = append(rule.Criteria, criteria)
}
source: func sortDependenciesR(root Root, seen map[string]bool, sorted *[]Root, depFunc func(Root) []Root) {
	for _, dep := range depFunc(root) {
		if !seen[dep.DSLName()] {
			seen[root.DSLName()] = true
			sortDependenciesR(dep, seen, sorted, depFunc)
		}
	}
	*sorted = append(*sorted, root)
}
source: func Encode(g geom.T) (kml.Element, error) {
	switch g := g.(type) {
	case *geom.Point:
		return EncodePoint(g), nil
	case *geom.LineString:
		return EncodeLineString(g), nil
	case *geom.LinearRing:
		return EncodeLinearRing(g), nil
	case *geom.MultiLineString:
		return EncodeMultiLineString(g), nil
	case *geom.MultiPoint:
		return EncodeMultiPoint(g), nil
	case *geom.MultiPolygon:
		return EncodeMultiPolygon(g), nil
	case *geom.Polygon:
		return EncodePolygon(g), nil
	case *geom.GeometryCollection:
		return EncodeGeometryCollection(g)
	default:
		return nil, geom.ErrUnsupportedType{Value: g}
	}
}
source: func NewWithClientSentryHook(client *raven.Client, levels []logrus.Level) (*SentryHook, error) {
	return &SentryHook{
		Timeout: 100 * time.Millisecond,
		StacktraceConfiguration: StackTraceConfiguration{
			Enable:            false,
			Level:             logrus.ErrorLevel,
			Skip:              6,
			Context:           0,
			InAppPrefixes:     nil,
			SendExceptionType: true,
		},
		client:       client,
		levels:       levels,
		ignoreFields: make(map[string]struct{}),
		extraFilters: make(map[string]func(interface{}) interface{}),
	}, nil
}
source: func (d *Dogstatsd) WriteLoop(ctx context.Context, c <-chan time.Time, w io.Writer) {
	for {
		select {
		case <-c:
			if _, err := d.WriteTo(w); err != nil {
				d.logger.Log("during", "WriteTo", "err", err)
			}
		case <-ctx.Done():
			return
		}
	}
}
source: func (s *Sender) SendMulticastNoRetry(msg *Message, registrationIds []string) (*MulticastResult, error) {
	if err := checkUnrecoverableErrors(s, "", registrationIds, msg, 0); err != nil {
		return nil, err
	}
	rawMsg := &message{Message: *msg, registrationIds: registrationIds}

	resp, err := s.sendRaw(rawMsg)
	if err != nil {
		return nil, err
	}

	result := new(MulticastResult)
	result.Success = resp.Success
	result.Failure = resp.Failure
	result.CanonicalIds = resp.CanonicalIds
	result.MulticastID = resp.MulticastID
	if resp.Results != nil {
		result.Results = make([]Result, len(resp.Results))
		for i, res := range resp.Results {
			result.Results[i] = Result{
				MessageID:               res.MessageID,
				CanonicalRegistrationID: res.RegistrationID,
				Error: res.Err,
			}
		}
	}
	return result, nil
}
source: func allShutdownCallbacks() []error {
	var errs []error
	instancesMu.Lock()
	for _, inst := range instances {
		errs = append(errs, inst.ShutdownCallbacks()...)
	}
	instancesMu.Unlock()
	return errs
}
source: func (p *Paths) Migrate(newPaths Paths) {
	if newPaths.DataDir != "" {
		p.DataDir = newPaths.DataDir
	}
	if newPaths.LogDir != "" {
		p.LogDir = newPaths.LogDir
	}
	if newPaths.MetricsSpoolDir != "" {
		p.MetricsSpoolDir = newPaths.MetricsSpoolDir
	}
	if newPaths.ConfDir != "" {
		p.ConfDir = newPaths.ConfDir
	}
}
source: func (l *lexer) errorf(format string, args ...interface{}) stateFn {
	l.tokens <- token{
		tokenError,
		fmt.Sprintf(format, args...),
		l.lineNum(),
		l.columnNum(),
	}
	return nil
}
source: func (f Filter) NotEq(val interface{}) Filter {
	f.Op = "!="
	f.Val = val
	return f
}
source: func (clnt *Clnt) Unmount() {
	clnt.Lock()
	clnt.err = &Error{"connection closed", EIO}
	clnt.conn.Close()
	clnt.Unlock()
}
source: func (c *runCommand) SetFlags(f *gnuflag.FlagSet) {
	c.ActionCommandBase.SetFlags(f)
	c.out.AddFlags(f, "yaml", output.DefaultFormatters)
	f.Var(&c.paramsYAML, "params", "Path to yaml-formatted params file")
	f.BoolVar(&c.parseStrings, "string-args", false, "Use raw string values of CLI args")
	f.Var(&c.wait, "wait", "Wait for results, with optional timeout")
}
source: func (s *Session) StderrPipe() (io.Reader, error) {
	if s.Stderr != nil {
		return nil, errors.New("ssh: Stderr already set")
	}
	if s.started {
		return nil, errors.New("ssh: StderrPipe after process started")
	}
	s.stderrpipe = true
	return s.ch.Stderr(), nil
}
source: func (r Hardware_Router) GetMetricTrackingObject() (resp datatypes.Metric_Tracking_Object_HardwareServer, err error) {
	err = r.Session.DoRequest("SoftLayer_Hardware_Router", "getMetricTrackingObject", nil, &r.Options, &resp)
	return
}
source: func (c *Client) pingRoutine() {
	ticker := time.NewTicker(time.Second * 5)
	defer ticker.Stop()

	var timestamp uint64
	var tcpPingAvg float32
	var tcpPingVar float32
	packet := MumbleProto.Ping{
		Timestamp:  &timestamp,
		TcpPackets: &c.tcpPacketsReceived,
		TcpPingAvg: &tcpPingAvg,
		TcpPingVar: &tcpPingVar,
	}

	t := time.Now()
	for {
		timestamp = uint64(t.UnixNano())
		tcpPingAvg = math.Float32frombits(atomic.LoadUint32(&c.tcpPingAvg))
		tcpPingVar = math.Float32frombits(atomic.LoadUint32(&c.tcpPingVar))
		c.Conn.WriteProto(&packet)

		select {
		case <-c.end:
			return
		case t = <-ticker.C:
			// continue to top of loop
		}
	}
}
source: func RangeField(name string, min, max, step int) *Field {
	ret := FieldWithType(name, formcommon.RANGE)
	ret.SetParam("min", fmt.Sprintf("%d", min))
	ret.SetParam("max", fmt.Sprintf("%d", max))
	ret.SetParam("step", fmt.Sprintf("%d", step))
	return ret
}
source: func addModelType(models map[string]*ControllerModels) error {
	changes := false
	for _, cm := range models {
		for name, m := range cm.Models {
			if m.ModelType == "" {
				changes = true
				m.ModelType = model.IAAS
				cm.Models[name] = m
			}
		}
	}
	if changes {
		return WriteModelsFile(models)
	}
	return nil
} 87%|████████▋ | 4355/5000 [00:05<00:00, 804.89it/s]
source: func (d *eventDispatcher) AddEventListener(typ string, listener EventListener) {
	d.Lock()
	defer d.Unlock()
	d.listeners[typ] = append(d.listeners[typ], listener)
}
source: func (r *RequestConfig) Header(name, value string) *RequestConfig {
	r.HeaderMap.Add(name, value)
	return r
}
source: func (m *Principal_Set) Validate() error {
	if m == nil {
		return nil
	}

	if len(m.GetIds()) < 1 {
		return Principal_SetValidationError{
			field:  "Ids",
			reason: "value must contain at least 1 item(s)",
		}
	}

	for idx, item := range m.GetIds() {
		_, _ = idx, item

		{
			tmp := item

			if v, ok := interface{}(tmp).(interface{ Validate() error }); ok {

				if err := v.Validate(); err != nil {
					return Principal_SetValidationError{
						field:  fmt.Sprintf("Ids[%v]", idx),
						reason: "embedded message failed validation",
						cause:  err,
					}
				}
			}
		}

	}

	return nil
}
source: func (h *Handler) serveGetRaftPeers(w http.ResponseWriter, r *http.Request, params httprouter.Params) {
	peers, err := h.Store.GetPeers()
	if err != nil {
		hh.Error(w, err)
	}

	hh.JSON(w, 200, peers)
}
source: func (s *Server) StartMonitoring() error {
	// Snapshot server options.
	opts := s.getOpts()

	// Specifying both HTTP and HTTPS ports is a misconfiguration
	if opts.HTTPPort != 0 && opts.HTTPSPort != 0 {
		return fmt.Errorf("can't specify both HTTP (%v) and HTTPs (%v) ports", opts.HTTPPort, opts.HTTPSPort)
	}
	var err error
	if opts.HTTPPort != 0 {
		err = s.startMonitoring(false)
	} else if opts.HTTPSPort != 0 {
		if opts.TLSConfig == nil {
			return fmt.Errorf("TLS cert and key required for HTTPS")
		}
		err = s.startMonitoring(true)
	}
	return err
}
source: func (s *SendBounceInput) SetMessageDsn(v *MessageDsn) *SendBounceInput {
	s.MessageDsn = v
	return s
}
source: func (c *callback) makeArgTypes() {
	fntype := c.fn.Type()
	// Skip receiver and context.Context parameter (if present).
	firstArg := 0
	if c.rcvr.IsValid() {
		firstArg++
	}
	if fntype.NumIn() > firstArg && fntype.In(firstArg) == contextType {
		c.hasCtx = true
		firstArg++
	}
	// Add all remaining parameters.
	c.argTypes = make([]reflect.Type, fntype.NumIn()-firstArg)
	for i := firstArg; i < fntype.NumIn(); i++ {
		c.argTypes[i-firstArg] = fntype.In(i)
	}
}
source: func applyNewLevelToLoggers(lls *logLevelSetting, loggers map[string]*logger) {
	for _, l := range loggers {
		if !ancestor(lls.loggerName, l.loggerName) {
			continue
		}
		if ancestor(l.lls.loggerName, lls.loggerName) {
			l.setLogLevelSetting(lls)
		}
	}
}
source: func (s *Scheme) Default(src Object) {
	if fn, ok := s.defaulterFuncs[reflect.TypeOf(src)]; ok {
		fn(src)
	}
}
source: func NewAccountsStorage(ctx *cli.Context) *AccountsStorage {
	// TODO: move to account struct? Currently MUST pass email.
	email := getEmail(ctx)

	serverURL, err := url.Parse(ctx.GlobalString("server"))
	if err != nil {
		log.Fatal(err)
	}

	rootPath := filepath.Join(ctx.GlobalString("path"), baseAccountsRootFolderName)
	serverPath := strings.NewReplacer(":", "_", "/", string(os.PathSeparator)).Replace(serverURL.Host)
	accountsPath := filepath.Join(rootPath, serverPath)
	rootUserPath := filepath.Join(accountsPath, email)

	return &AccountsStorage{
		userID:          email,
		rootPath:        rootPath,
		rootUserPath:    rootUserPath,
		keysPath:        filepath.Join(rootUserPath, baseKeysFolderName),
		accountFilePath: filepath.Join(rootUserPath, accountFileName),
		ctx:             ctx,
	}
}
source: func PutWS(ws *websocket.Conn) {
	msg := wsmessage{
		Command: PUT,
		WS:      ws}
	wschannel <- msg

}
source: func NewShowcaseUntrashedType(Description string) *ShowcaseUntrashedType {
	s := new(ShowcaseUntrashedType)
	s.Description = Description
	return s
}
source: func New(config Config) (*Worker, error) {
	if err := config.Validate(); err != nil {
		return nil, errors.Trace(err)
	}
	phase, err := config.Facade.Phase(config.Model)
	if err != nil {
		return nil, errors.Trace(err)
	}

	w := &Worker{
		config: config,
		phase:  phase,
	}
	err = catacomb.Invoke(catacomb.Plan{
		Site: &w.catacomb,
		Work: w.loop,
	})
	if err != nil {
		return nil, errors.Trace(err)
	}
	return w, nil
}
source: func (r *Resampler) SetRatio(ratio float64) {
	r.pos = int(float64(r.pos) * r.ratio / ratio)
	r.ratio = ratio
}
source: func TryLoadKeyFromDisk(pkiPath, name string) (crypto.Signer, error) {
	privateKeyPath := pathForKey(pkiPath, name)

	// Parse the private key from a file
	privKey, err := keyutil.PrivateKeyFromFile(privateKeyPath)
	if err != nil {
		return nil, errors.Wrapf(err, "couldn't load the private key file %s", privateKeyPath)
	}

	// Allow RSA and ECDSA formats only
	var key crypto.Signer
	switch k := privKey.(type) {
	case *rsa.PrivateKey:
		key = k
	case *ecdsa.PrivateKey:
		key = k
	default:
		return nil, errors.Errorf("the private key file %s is neither in RSA nor ECDSA format", privateKeyPath)
	}

	return key, nil
}
source: func (s *GetDataSourceOutput) SetDataSourceSchema(v string) *GetDataSourceOutput {
	s.DataSourceSchema = &v
	return s
}
source: func (v *PVector) ConsV(o interface{}) iseq.PVector {
	if v.cnt-v.tailoff() < branchFactor {
		newTail := make([]interface{}, len(v.tail)+1)
		copy(newTail, v.tail)
		newTail[len(v.tail)] = o
		return &PVector{AMeta: AMeta{v.meta}, cnt: v.cnt + 1, shift: v.shift, root: v.root, tail: newTail}
	}
	// full tail, push into tree
	tailNode := &vnode{v.tail}
	newShift := v.shift

	var newRoot *vnode

	// overflow root?
	if (v.cnt >> baseShift) > (1 << v.shift) {
		newRoot = &vnode{make([]interface{}, branchFactor)}
		newRoot.array[0] = v.root
		newRoot.array[1] = newPath(v.shift, tailNode)
		newShift = newShift + baseShift
	} else {
		newRoot = v.pushTail(v.shift, v.root, tailNode)
	}

	return &PVector{AMeta: AMeta{v.meta}, cnt: v.cnt + 1, shift: newShift, root: newRoot, tail: []interface{}{o}}
}
source: func modifiableCharsetAndCollation(toCharset, toCollate, origCharset, origCollate string) error {
	if !charset.ValidCharsetAndCollation(toCharset, toCollate) {
		return ErrUnknownCharacterSet.GenWithStack("Unknown character set: '%s', collation: '%s'", toCharset, toCollate)
	}
	if toCharset == charset.CharsetUTF8MB4 && origCharset == charset.CharsetUTF8 {
		// TiDB only allow utf8 to be changed to utf8mb4.
		return nil
	}

	if toCharset != origCharset {
		msg := fmt.Sprintf("charset from %s to %s", origCharset, toCharset)
		return errUnsupportedModifyCharset.GenWithStackByArgs(msg)
	}
	if toCollate != origCollate {
		msg := fmt.Sprintf("collate from %s to %s", origCollate, toCollate)
		return errUnsupportedModifyCharset.GenWithStackByArgs(msg)
	}
	return nil
}
source: func (c *CipherWriter) Write(p []byte) (n int, err error) {
	cp := pbytes.GetLen(len(p))
	defer pbytes.Put(cp)

	copy(cp, p)
	ws.Cipher(cp, c.mask, c.pos)
	n, err = c.w.Write(cp)
	c.pos += n

	return
}
source: func (scf SvcConfigFile) ValidEntity() error {
	vErr := validation.NewValidationError()
	vErr.Add(validation.NotEmpty("ID", scf.ID))
	vErr.Add(validation.NotEmpty("ServiceTenantID", scf.ServiceTenantID))
	vErr.Add(validation.NotEmpty("ServicePath", scf.ServicePath))

	//path must start with /
	if !strings.HasPrefix(scf.ServicePath, "/") {
		vErr.AddViolation("field ServicePath must start with /")
	}

	vErr.Add(validation.NotEmpty("Content", scf.ConfFile.Content))
	vErr.Add(validation.NotEmpty("FileName", scf.ConfFile.Filename))

	if vErr.HasError() {
		return vErr
	}
	return nil
}
source: func (s *Server) Listen() error {
	if s.hasListeners { // already done this
		return nil
	}

	if s.hasScheme(schemeHTTPS) {
		// Use http host if https host wasn't defined
		if s.TLSHost == "" {
			s.TLSHost = s.Host
		}
		// Use http listen limit if https listen limit wasn't defined
		if s.TLSListenLimit == 0 {
			s.TLSListenLimit = s.ListenLimit
		}
		// Use http tcp keep alive if https tcp keep alive wasn't defined
		if int64(s.TLSKeepAlive) == 0 {
			s.TLSKeepAlive = s.KeepAlive
		}
		// Use http read timeout if https read timeout wasn't defined
		if int64(s.TLSReadTimeout) == 0 {
			s.TLSReadTimeout = s.ReadTimeout
		}
		// Use http write timeout if https write timeout wasn't defined
		if int64(s.TLSWriteTimeout) == 0 {
			s.TLSWriteTimeout = s.WriteTimeout
		}
	}

	if s.hasScheme(schemeUnix) {
		domSockListener, err := net.Listen("unix", string(s.SocketPath))
		if err != nil {
			return err
		}
		s.domainSocketL = domSockListener
	}

	if s.hasScheme(schemeHTTP) {
		listener, err := net.Listen("tcp", net.JoinHostPort(s.Host, strconv.Itoa(s.Port)))
		if err != nil {
			return err
		}

		h, p, err := swag.SplitHostPort(listener.Addr().String())
		if err != nil {
			return err
		}
		s.Host = h
		s.Port = p
		s.httpServerL = listener
	}

	if s.hasScheme(schemeHTTPS) {
		tlsListener, err := net.Listen("tcp", net.JoinHostPort(s.TLSHost, strconv.Itoa(s.TLSPort)))
		if err != nil {
			return err
		}

		sh, sp, err := swag.SplitHostPort(tlsListener.Addr().String())
		if err != nil {
			return err
		}
		s.TLSHost = sh
		s.TLSPort = sp
		s.httpsServerL = tlsListener
	}

	s.hasListeners = true
	return nil
}
source: func (e *engineImpl) launchTask(c context.Context, inv *Invocation) error {
	assertNotInTransaction(c)

	// Grab the corresponding TaskManager to launch the task through it.
	ctl, err := controllerForInvocation(c, e, inv)
	if err != nil {
		// Note: controllerForInvocation returns both ctl and err on errors, with
		// ctl not fully initialized (but good enough for what's done below).
		ctl.DebugLog("Failed to initialize task controller - %s", err)
		ctl.State().Status = task.StatusFailed
		return ctl.Save(c)
	}

	// Ask the manager to start the task. If it returns no errors, it should also
	// move the invocation out of an initial state (a failure to do so is a fatal
	// error). If it returns an error, the invocation is forcefully moved to
	// StatusRetrying or StatusFailed state (depending on whether the error is
	// transient or not and how many retries are left). In either case, invocation
	// never ends up in StatusStarting state.
	err = ctl.manager.LaunchTask(c, ctl)
	if err != nil {
		logging.WithError(err).Errorf(c, "Failed to LaunchTask")
	}
	if status := ctl.State().Status; status.Initial() && err == nil {
		err = fmt.Errorf("LaunchTask didn't move invocation out of initial %s state", status)
	}
	if transient.Tag.In(err) && inv.RetryCount+1 >= invocationRetryLimit {
		err = fmt.Errorf("Too many retries, giving up (original error - %s)", err)
	}

	// The task must always end up in a non-initial state. Do it on behalf of the
	// controller if necessary.
	if ctl.State().Status.Initial() {
		if transient.Tag.In(err) {
			// This invocation object will be reused for a retry later.
			ctl.State().Status = task.StatusRetrying
		} else {
			// The invocation has crashed with the fatal error.
			ctl.State().Status = task.StatusFailed
		}
	}

	// Add a notice into the invocation log that we'll attempt to retry.
	isRetrying := ctl.State().Status == task.StatusRetrying
	if isRetrying {
		ctl.DebugLog("The invocation will be retried")
	}

	// We MUST commit the state of the invocation. A failure to save the state
	// may cause the job state machine to get stuck. If we can't save it, we need
	// to retry the whole launch attempt from scratch (redoing all the work,
	// a properly implemented LaunchTask should be idempotent).
	if err := ctl.Save(c); err != nil {
		logging.WithError(err).Errorf(c, "Failed to save invocation state")
		return err
	}

	// Task retries happen via the task queue, need to explicitly trigger a retry
	// by returning a transient error.
	if isRetrying {
		return errRetryingLaunch
	}

	return nil
}
source: func (p *Profile) FilterSamplesByName(focus, ignore, hide, show *regexp.Regexp) (fm, im, hm, hnm bool) {
	focusOrIgnore := make(map[uint64]bool)
	hidden := make(map[uint64]bool)
	for _, l := range p.Location {
		if ignore != nil && l.matchesName(ignore) {
			im = true
			focusOrIgnore[l.ID] = false
		} else if focus == nil || l.matchesName(focus) {
			fm = true
			focusOrIgnore[l.ID] = true
		}

		if hide != nil && l.matchesName(hide) {
			hm = true
			l.Line = l.unmatchedLines(hide)
			if len(l.Line) == 0 {
				hidden[l.ID] = true
			}
		}
		if show != nil {
			l.Line = l.matchedLines(show)
			if len(l.Line) == 0 {
				hidden[l.ID] = true
			} else {
				hnm = true
			}
		}
	}

	s := make([]*Sample, 0, len(p.Sample))
	for _, sample := range p.Sample {
		if focusedAndNotIgnored(sample.Location, focusOrIgnore) {
			if len(hidden) > 0 {
				var locs []*Location
				for _, loc := range sample.Location {
					if !hidden[loc.ID] {
						locs = append(locs, loc)
					}
				}
				if len(locs) == 0 {
					// Remove sample with no locations (by not adding it to s).
					continue
				}
				sample.Location = locs
			}
			s = append(s, sample)
		}
	}
	p.Sample = s

	return
}
source: func (r Account_Shipment) GetAllCouriersByType(courierTypeKeyName *string) (resp []datatypes.Auxiliary_Shipping_Courier, err error) {
	params := []interface{}{
		courierTypeKeyName,
	}
	err = r.Session.DoRequest("SoftLayer_Account_Shipment", "getAllCouriersByType", params, &r.Options, &resp)
	return
}
source: func ObjectGoPrintSideBySide(a, b interface{}) string {
	s := spew.ConfigState{
		Indent: " ",
		// Extra deep spew.
		DisableMethods: true,
	}
	sA := s.Sdump(a)
	sB := s.Sdump(b)

	linesA := strings.Split(sA, "\n")
	linesB := strings.Split(sB, "\n")
	width := 0
	for _, s := range linesA {
		l := len(s)
		if l > width {
			width = l
		}
	}
	for _, s := range linesB {
		l := len(s)
		if l > width {
			width = l
		}
	}
	buf := &bytes.Buffer{}
	w := tabwriter.NewWriter(buf, width, 0, 1, ' ', 0)
	max := len(linesA)
	if len(linesB) > max {
		max = len(linesB)
	}
	for i := 0; i < max; i++ {
		var a, b string
		if i < len(linesA) {
			a = linesA[i]
		}
		if i < len(linesB) {
			b = linesB[i]
		}
		fmt.Fprintf(w, "%s\t%s\n", a, b)
	}
	w.Flush()
	return buf.String()
}
source: func New(typesMap derive.TypesMap, p derive.Printer, deps map[string]derive.Dependency) derive.Generator {
	return &gen{
		TypesMap: typesMap,
		printer:  p,
		mathPkg:  p.NewImport("math", "math"),
		keys:     deps["keys"],
		sort:     deps["sort"],
	}
}
source: func IsTokenRefreshError(err error) bool {
	if _, ok := err.(adal.TokenRefreshError); ok {
		return true
	}
	if de, ok := err.(DetailedError); ok {
		return IsTokenRefreshError(de.Original)
	}
	return false
}
source: func (db *DB) ComQuery(c *mysql.Conn, query string, callback func(*sqltypes.Result) error) error {
	return db.Handler.HandleQuery(c, query, callback)
}
source: func (n *NodeRegistration) Deny(reason string) {
	n.Status.Allowed = false
	n.Status.Reason = reason
}
source: func (w *Window) Close() (err error) {
	if err = w.isActionable(); err != nil {
		return
	}
	_, err = synchronousEvent(w.c, w, w.w, Event{Name: EventNameWindowCmdClose, TargetID: w.id}, EventNameWindowEventClosed)
	return
}
source: func NewFrameReader(frames <-chan *StreamFrame, errCh <-chan error, cancelCh chan struct{}) *FrameReader {
	return &FrameReader{
		frames:   frames,
		errCh:    errCh,
		cancelCh: cancelCh,
	}
}
source: func (c *Client) PreviousPlaylistResults(s *SearchResult) error {
	if s.Playlists == nil || s.Playlists.Previous == "" {
		return ErrNoMorePages
	}
	return c.get(s.Playlists.Previous, s)
}
source: func (s *UpdateNumberOfDomainControllersInput) SetDesiredNumber(v int64) *UpdateNumberOfDomainControllersInput {
	s.DesiredNumber = &v
	return s
}
source: func (r *resourceRecordSets) Get(name string) ([]dnsprovider.ResourceRecordSet, error) {
	snapshot := r.zone.dnsView.Snapshot()

	records := snapshot.RecordsForZoneAndName(r.zone.zoneInfo, name)
	if records == nil {
		return nil, nil
	}

	var rrs []dnsprovider.ResourceRecordSet
	for _, rr := range records {
		rrs = append(rrs, &resourceRecordSet{data: rr})
	}
	return rrs, nil
}
source: func NormalDistribution(generator *rand.Rand, standardDeviation float64) Transformation {
	random := fallbackNewRandom(generator)

	return func(duration time.Duration) time.Duration {
		return time.Duration(random.NormFloat64()*standardDeviation + float64(duration))
	}
}
source: func (p *parser) parseBracket() error {
	if p.peek() == '?' {
		return p.parseFilter()
	} else if p.peek() == '*' {
		p.scan() // eat *
		if p.scan() != ']' {
			return fmt.Errorf("expected closing bracket after [* at %d", p.column())
		}
		return p.prepareWildcard()
	}
	return p.parseArray()
}
source: func Params(kbCtx libkbfs.Context,
	storageRoot string, paramsBase *libkbfs.InitParams) (
	params libkbfs.InitParams, tempDir string, err error) {
	tempDir, err = ioutil.TempDir(storageRoot, libkbfs.GitStorageRootPrefix)
	if err != nil {
		return libkbfs.InitParams{}, "", err
	}

	if paramsBase != nil {
		params = *paramsBase
	} else {
		params = libkbfs.DefaultInitParams(kbCtx)
	}
	params.LogToFile = true
	// Set the debug default to true only if the env variable isn't
	// explicitly set to a false option.
	envDebug := os.Getenv("KBFSGIT_DEBUG")
	if envDebug != "0" && envDebug != "false" && envDebug != "no" {
		params.Debug = true
	}
	// This is set to false in docker tests for now, but we need it. So
	// override it to true here.
	params.EnableJournal = true
	params.DiskCacheMode = libkbfs.DiskCacheModeRemote
	params.StorageRoot = tempDir
	params.Mode = libkbfs.InitSingleOpString
	params.TLFJournalBackgroundWorkStatus =
		libkbfs.TLFJournalSingleOpBackgroundWorkEnabled

	if baddr := os.Getenv(paramKeybaseGitBServerAddr); len(baddr) > 0 {
		params.BServerAddr = baddr
	}
	if mdaddr := os.Getenv(paramKeybaseGitMDServerAddr); len(mdaddr) > 0 {
		params.MDServerAddr = mdaddr
	}

	return params, tempDir, nil
}
source: func NewOnewayHandler(params OnewayHandlerParams) transport.OnewayHandler {
	return newOnewayHandler(params.Handle, params.NewRequest)
}
source: func ValidateSubdir(subdir string) error {
	if subdir == "" { // empty is fine
		return nil
	}
	if strings.Contains(subdir, "\\") {
		return fmt.Errorf(`bad subdir: backslashes not allowed (use "/"): %q`, subdir)
	}
	if strings.Contains(subdir, ":") {
		return fmt.Errorf(`bad subdir: colons are not allowed: %q`, subdir)
	}
	if cleaned := path.Clean(subdir); cleaned != subdir {
		return fmt.Errorf("bad subdir: %q (should be %q)", subdir, cleaned)
	}
	if strings.HasPrefix(subdir, "./") || strings.HasPrefix(subdir, "../") || subdir == "." {
		return fmt.Errorf(`bad subdir: invalid ".": %q`, subdir)
	}
	if strings.HasPrefix(subdir, "/") {
		return fmt.Errorf("bad subdir: absolute paths not allowed: %q", subdir)
	}
	return nil
}
source: func intersectInterval16s(a, b interval16) (res interval16, isEmpty bool) {
	if !haveOverlap16(a, b) {
		isEmpty = true
		return
	}
	if b.start > a.start {
		res.start = b.start
	} else {
		res.start = a.start
	}

	bEnd := b.last()
	aEnd := a.last()
	var resEnd uint16

	if bEnd < aEnd {
		resEnd = bEnd
	} else {
		resEnd = aEnd
	}
	res.length = resEnd - res.start
	return
}
source: func (c *Client) StartTLS(tlsConfig *tls.Config) error {
	if c.isTLS {
		return ErrTLSAlreadyEnabled
	}

	cmd := new(commands.StartTLS)

	err := c.Upgrade(func(conn net.Conn) (net.Conn, error) {
		// Flag connection as in upgrading
		c.upgrading = true
		if status, err := c.execute(cmd, nil); err != nil {
			return nil, err
		} else if err := status.Err(); err != nil {
			return nil, err
		}

		// Wait for reader to block.
		c.conn.WaitReady()
		tlsConn := tls.Client(conn, tlsConfig)
		if err := tlsConn.Handshake(); err != nil {
			return nil, err
		}

		// Capabilities change when TLS is enabled
		c.locker.Lock()
		c.caps = nil
		c.locker.Unlock()

		return tlsConn, nil
	})
	if err != nil {
		return err
	}

	c.isTLS = true
	return nil
}
source: func (p *ExamplePlugin) subscribeWatcher() (err error) {
	prefix := etcdKeyPrefix(p.ServiceLabel.GetAgentLabel())
	p.Log.Infof("Prefix: %v", prefix)

	p.watchDataReg, err = p.Watcher.Watch("ExamplePlugin",
		p.changeChannel, p.resyncChannel, prefix)
	if err != nil {
		return err
	}

	p.Log.Info("KeyValProtoWatcher subscribed")

	return nil
}
source: func (c *Page) AddScriptToEvaluateOnLoad(scriptSource string) (string, error) {
	var v PageAddScriptToEvaluateOnLoadParams
	v.ScriptSource = scriptSource
	return c.AddScriptToEvaluateOnLoadWithParams(&v)
}
source: func NewGetterFromClient(c clientset.Interface, secretLister v1listers.SecretLister, serviceAccountLister v1listers.ServiceAccountLister, podLister v1listers.PodLister) serviceaccount.ServiceAccountTokenGetter {
	return clientGetter{c, secretLister, serviceAccountLister, podLister}
}
source: func (service *Service) ServeFiles(path, filename string) error {
	ctrl := service.NewController("FileServer")
	return ctrl.ServeFiles(path, filename)
}
source: func Manifold(config ManifoldConfig) dependency.Manifold {
	typedConfig := engine.AgentAPIManifoldConfig{
		AgentName:     config.AgentName,
		APICallerName: config.APICallerName,
	}
	manifold := engine.AgentAPIManifold(typedConfig, config.start)
	manifold.Output = config.output
	return manifold
}
source: func buildUserAgent(command, version, os, arch, commit string) string {
	return fmt.Sprintf(
		"%s/%s (%s/%s) kubernetes/%s", command, version, os, arch, commit)
}
source: func (vm *ViewLists) Get(tag string) Views {
	ind, ok := vm.index(tag)

	if !ok {
		return nil
	}

	var v Views

	vm.ro.RLock()
	v = vm.lists[ind]
	vm.ro.RUnlock()

	return v

}
source: func (e Entry) Debug(v ...interface{}) {
	e.Message = fmt.Sprint(v...)
	e.Level = DebugLevel
	HandleEntry(e)
}
source: func (t Tile) SharedParent(tile Tile) Tile {
	// bring both tiles to the lowest zoom.
	if t.Z != tile.Z {
		if t.Z < tile.Z {
			tile = tile.toZoom(t.Z)
		} else {
			t = t.toZoom(tile.Z)
		}
	}

	if t == tile {
		return t
	}

	// go version < 1.9
	// bit package usage was about 10% faster
	//
	// TODO: use build flags to support older versions of go.
	//
	// move from most significant to least until there isn't a match.
	// for i := t.Z - 1; i >= 0; i-- {
	// 	if t.X&(1<<i) != tile.X&(1<<i) ||
	// 		t.Y&(1<<i) != tile.Y&(1<<i) {
	// 		return Tile{
	// 			t.X >> (i + 1),
	// 			t.Y >> (i + 1),
	// 			t.Z - (i + 1),
	// 		}
	// 	}
	// }
	//
	// if we reach here the tiles are the same, which was checked above.
	// panic("unreachable")

	// bits different for x and y
	xc := uint32(32 - bits.LeadingZeros32(t.X^tile.X))
	yc := uint32(32 - bits.LeadingZeros32(t.Y^tile.Y))

	// max of xc, yc
	maxc := xc
	if yc > maxc {
		maxc = yc

	}

	return Tile{
		X: t.X >> maxc,
		Y: t.Y >> maxc,
		Z: t.Z - Zoom(maxc),
	}
}
source: func newLexer(input io.Reader) *lexer {
	// TODO: lexer should use the reader.
	i, _ := ioutil.ReadAll(input)
	return &lexer{0, 0, 1, 0, string(i), make(chan token), nil, modeNormal, token{}, 0}
}
source: func (s *Server) sendSubsToRoute(route *client) {
	s.mu.Lock()
	// Estimated size of all protocols. It does not have to be accurate at all.
	eSize := 0
	// Send over our account subscriptions.
	// copy accounts into array first
	accs := make([]*Account, 0, 32)
	s.accounts.Range(func(k, v interface{}) bool {
		a := v.(*Account)
		accs = append(accs, a)
		a.mu.RLock()
		// Proto looks like: "RS+ <account name> <subject>[ <queue weight>]\r\n"
		// If we wanted to have better estimates (or even accurate), we would
		// collect the subs here instead of capturing the accounts and then
		// later going over each account.
		eSize += len(a.rm) * (4 + len(a.Name) + 256)
		a.mu.RUnlock()
		return true
	})
	s.mu.Unlock()

	sendSubs := func(accs []*Account) {
		var raw [32]*subscription
		var closed bool

		route.mu.Lock()
		for _, a := range accs {
			subs := raw[:0]

			a.mu.RLock()
			c := a.randomClient()
			if c == nil {
				a.mu.RUnlock()
				continue
			}
			for key, n := range a.rm {
				// FIXME(dlc) - Just pass rme around.
				// Construct a sub on the fly. We need to place
				// a client (or im) to properly set the account.
				var subj, qn []byte
				s := strings.Split(key, " ")
				subj = []byte(s[0])
				if len(s) > 1 {
					qn = []byte(s[1])
				}
				// TODO(dlc) - This code needs to change, but even if left alone could be more
				// efficient with these tmp subs.
				sub := &subscription{client: c, subject: subj, queue: qn, qw: n}
				subs = append(subs, sub)

			}
			a.mu.RUnlock()

			closed = route.sendRouteSubProtos(subs, false, func(sub *subscription) bool {
				return route.canImport(string(sub.subject))
			})

			if closed {
				route.mu.Unlock()
				return
			}
		}
		route.mu.Unlock()
		if !closed {
			route.Debugf("Sent local subscriptions to route")
		}
	}
	// Decide if we call above function in go routine or in place.
	if eSize > sendRouteSubsInGoRoutineThreshold {
		s.startGoRoutine(func() {
			sendSubs(accs)
			s.grWG.Done()
		})
	} else {
		sendSubs(accs)
	}
}
source: func (l *ListenerConn) acquireSenderLock() error {
	// we must acquire senderLock first to avoid deadlocks; see ExecSimpleQuery
	l.senderLock.Lock()

	l.connectionLock.Lock()
	err := l.err
	l.connectionLock.Unlock()
	if err != nil {
		l.senderLock.Unlock()
		return err
	}
	return nil
}
source: func (c *Conn) WriteMessage(messageType int, data []byte) error {

	if c.isServer && (c.newCompressionWriter == nil || !c.enableWriteCompression) {
		// Fast path with no allocations and single frame.

		var mw messageWriter
		if err := c.beginMessage(&mw, messageType); err != nil {
			return err
		}
		n := copy(c.writeBuf[mw.pos:], data)
		mw.pos += n
		data = data[n:]
		return mw.flushFrame(true, data)
	}

	w, err := c.NextWriter(messageType)
	if err != nil {
		return err
	}
	if _, err = w.Write(data); err != nil {
		return err
	}
	return w.Close()
}
source: func (s *podPresetLister) List(selector labels.Selector) (ret []*v1alpha1.PodPreset, err error) {
	err = cache.ListAll(s.indexer, selector, func(m interface{}) {
		ret = append(ret, m.(*v1alpha1.PodPreset))
	})
	return ret, err
}
source: func (a *AnalyzedSchema) inherits(other *AnalyzedSchema) {
	if other == nil {
		return
	}
	a.hasProps = other.hasProps
	a.hasAllOf = other.hasAllOf
	a.hasItems = other.hasItems
	a.hasAdditionalItems = other.hasAdditionalItems
	a.hasAdditionalProps = other.hasAdditionalProps
	a.hasRef = other.hasRef

	a.IsKnownType = other.IsKnownType
	a.IsSimpleSchema = other.IsSimpleSchema
	a.IsArray = other.IsArray
	a.IsSimpleArray = other.IsSimpleArray
	a.IsMap = other.IsMap
	a.IsSimpleMap = other.IsSimpleMap
	a.IsExtendedObject = other.IsExtendedObject
	a.IsTuple = other.IsTuple
	a.IsTupleWithExtra = other.IsTupleWithExtra
	a.IsBaseType = other.IsBaseType
	a.IsEnum = other.IsEnum
}
source: func (r *FastHttpResponse) Set(key int, value interface{}) (set bool) {
	switch key {
	case revel.ENGINE_RESPONSE_STATUS:
		r.Header().SetStatus(value.(int))
		set = true
	case revel.HTTP_WRITER:
		r.SetWriter(value.(io.Writer))
		set = true
	}
	return
}
source: func ParsePGPUpdateChainLink(b GenericChainLink) (ret *PGPUpdateChainLink, err error) {
	var kid keybase1.KID

	pgpUpdate := b.UnmarshalPayloadJSON().AtPath("body.pgp_update")

	if pgpUpdate.IsNil() {
		err = ChainLinkError{fmt.Sprintf("missing pgp_update section @%s", b.ToDebugString())}
		return
	}

	if kid, err = GetKID(pgpUpdate.AtKey("kid")); err != nil {
		err = ChainLinkError{fmt.Sprintf("Missing kid @%s: %s", b.ToDebugString(), err)}
		return
	}

	ret = &PGPUpdateChainLink{b, kid}

	if fh := ret.GetPGPFullHash(); fh == "" {
		err = ChainLinkError{fmt.Sprintf("Missing full_hash @%s", b.ToDebugString())}
		ret = nil
		return
	}

	return
}
source: func (r *Store) GetBoolDefault(key string, def bool) bool {
	if v, err := r.GetBool(key); err == nil {
		return v
	}

	return def
}
source: func (te *TxEngine) AcceptReadWrite() error {
	te.beginRequests.Wait()
	te.stateLock.Lock()

	switch te.state {
	case AcceptingReadAndWrite:
		// Nothing to do
		te.stateLock.Unlock()
		return nil

	case NotServing:
		te.state = AcceptingReadAndWrite
		te.open()
		te.stateLock.Unlock()
		return nil

	case Transitioning:
		te.nextState = AcceptingReadAndWrite
		te.stateLock.Unlock()
		te.blockUntilEndOfTransition()
		return nil

	case AcceptingReadOnly:
		// We need to restart the tx-pool to make sure we handle 2PC correctly
		te.close(true)
		te.state = AcceptingReadAndWrite
		te.open()
		te.stateLock.Unlock()
		return nil

	default:
		return te.unknownStateError()
	}
}
source: func serviceWatch(params map[string]interface{}) (WatcherFunc, error) {
	stale := false
	if err := assignValueBool(params, "stale", &stale); err != nil {
		return nil, err
	}

	var (
		service string
		tags    []string
	)
	if err := assignValue(params, "service", &service); err != nil {
		return nil, err
	}
	if service == "" {
		return nil, fmt.Errorf("Must specify a single service to watch")
	}
	if err := assignValueStringSlice(params, "tag", &tags); err != nil {
		return nil, err
	}

	passingOnly := false
	if err := assignValueBool(params, "passingonly", &passingOnly); err != nil {
		return nil, err
	}

	fn := func(p *Plan) (BlockingParamVal, interface{}, error) {
		health := p.client.Health()
		opts := makeQueryOptionsWithContext(p, stale)
		defer p.cancelFunc()
		nodes, meta, err := health.ServiceMultipleTags(service, tags, passingOnly, &opts)
		if err != nil {
			return nil, nil, err
		}
		return WaitIndexVal(meta.LastIndex), nodes, err
	}
	return fn, nil
}
source: func (f *fsClient) Get(sse encrypt.ServerSide) (io.ReadCloser, *probe.Error) {
	return f.get()
}
source: func (rin *relationNetworksState) Networks(relationKey string) (RelationNetworks, error) {
	coll, closer := rin.st.db().GetCollection(relationNetworksC)
	defer closer()

	var doc relationNetworksDoc
	err := coll.FindId(relationNetworkDocID(relationKey, rin.direction, relationNetworkAdmin)).One(&doc)
	if err == mgo.ErrNotFound {
		err = coll.FindId(relationNetworkDocID(relationKey, rin.direction, relationNetworkDefault)).One(&doc)
	}
	if err == mgo.ErrNotFound {
		return nil, errors.NotFoundf("%v networks for relation %v", rin.direction, relationKey)
	}
	if err != nil {
		return nil, errors.Trace(err)
	}
	return &relationNetworks{
		st:  rin.st,
		doc: doc,
	}, nil
}
source: func (r *GormWorkItemTypeGroupRepository) Load(ctx context.Context, groupID uuid.UUID) (*WorkItemTypeGroup, error) {
	defer goa.MeasureSince([]string{"goa", "db", "workitemtypegroup", "load"}, time.Now())
	log.Debug(ctx, map[string]interface{}{"witg_id": groupID}, "loading work item type group ")
	res := WorkItemTypeGroup{}
	db := r.db.Model(&res).Where("id=?", groupID).First(&res)
	if db.RecordNotFound() {
		log.Error(ctx, map[string]interface{}{"witg_id": groupID}, "work item type group not found")
		return nil, errors.NewNotFoundError("work item type group", groupID.String())
	}
	if err := db.Error; err != nil {
		return nil, errors.NewInternalError(ctx, err)
	}
	typeList, err := r.loadTypeList(ctx, res.ID)
	if err != nil {
		return nil, errs.WithStack(err)
	}
	res.TypeList = typeList
	return &res, nil
}
source: func (o *PostIPAMCreated) WithPayload(payload *models.IPAMResponse) *PostIPAMCreated {
	o.Payload = payload
	return o
}
source: func (s *DeploymentLaunchConfig) SetPreLaunchFile(v string) *DeploymentLaunchConfig {
	s.PreLaunchFile = &v
	return s
}
source: func (m *Meta) contextOpts() *terraform.ContextOpts {
	var opts terraform.ContextOpts
	opts.Hooks = []terraform.Hook{m.uiHook()}
	opts.Hooks = append(opts.Hooks, m.ExtraHooks...)

	opts.Targets = m.targets
	opts.UIInput = m.UIInput()
	opts.Parallelism = m.parallelism

	// If testingOverrides are set, we'll skip the plugin discovery process
	// and just work with what we've been given, thus allowing the tests
	// to provide mock providers and provisioners.
	if m.testingOverrides != nil {
		opts.ProviderResolver = m.testingOverrides.ProviderResolver
		opts.Provisioners = m.testingOverrides.Provisioners
	} else {
		opts.ProviderResolver = m.providerResolver()
		opts.Provisioners = m.provisionerFactories()
	}

	opts.ProviderSHA256s = m.providerPluginsLock().Read()
	if v := os.Getenv(ProviderSkipVerifyEnvVar); v != "" {
		opts.SkipProviderVerify = true
	}

	opts.Meta = &terraform.ContextMeta{
		Env: m.Workspace(),
	}

	return &opts
}
source: func DefaultGenParameters() *GenParameters {
	seed := time.Now().UnixNano()

	return &GenParameters{
		MinSize:        0,
		MaxSize:        100,
		MaxShrinkCount: 1000,
		Rng:            rand.New(NewLockedSource(seed)),
	}
}
source: func New(config Config, client rest.Client, path string) *Downloader {
	return &Downloader{
		config: config,
		client: client,
		path:   path,
		stop:   make(chan chan struct{}),
	}
}
source: func (c *config) ContainersForReference(reference string) (result []string) {
	containers := []string{}
	if len(reference) == 0 {
		// reference not given
		var defaultGroup []string
		for group, containers := range c.groups {
			if group == "default" {
				defaultGroup = containers
				break
			}
		}
		if defaultGroup != nil {
			// If default group exists, return its containers
			containers = defaultGroup
		} else {
			// Otherwise, return all containers
			for name := range c.containerMap {
				containers = append(containers, name)
			}
		}
	} else {
		// reference given
		reference = expandEnv(reference)
		// Select reference from listed groups
		for group, groupContainers := range c.groups {
			if group == reference {
				containers = append(containers, groupContainers...)
				break
			}
		}
		if len(containers) == 0 {
			// The reference might just be one container
			for name := range c.containerMap {
				if name == reference {
					containers = append(containers, reference)
					break
				}
			}
		}
		if len(containers) == 0 {
			// reference was not found anywhere
			panic(StatusError{fmt.Errorf("No group or container matching `%s`", reference), 64})
		}
	}
	// ensure all container references exist
	for _, container := range containers {
		containerDeclared := false
		for name := range c.containerMap {
			if container == name {
				containerDeclared = true
				break
			}
		}
		if !containerDeclared {
			panic(StatusError{fmt.Errorf("Invalid container reference `%s`", container), 64})
		}
		if !includes(result, container) {
			result = append(result, container)
		}
	}
	return
}
source: func (s *UpdateServicePrimaryTaskSetInput) SetPrimaryTaskSet(v string) *UpdateServicePrimaryTaskSetInput {
	s.PrimaryTaskSet = &v
	return s
}
source: func (u *UsersClient) Update(ctx context.Context, userObj interface{}) (envelope.UserInf, error) {
	e := envelope.Unsigned{}
	err := u.client.RoundTrip(ctx, "PATCH", "/users/self", nil, userObj, &e)
	if err != nil {
		return nil, err
	}

	return envelope.ConvertUser(&e)
}
source: func (registry streamRegistry) GetStreamName(streamID MessageStreamID) string {
	switch streamID {
	case LogInternalStreamID:
		return LogInternalStream

	case WildcardStreamID:
		return WildcardStream

	case InvalidStreamID:
		return InvalidStream

	case TraceInternalStreamID:
		return TraceInternalStream

	default:
		registry.nameGuard.RLock()
		name, exists := registry.name[streamID]
		registry.nameGuard.RUnlock()

		if exists {
			return name // ### return, found ###
		}
	}
	return ""
}
source: func (api *API) Info() serverInfo {
	si := api.server.systemInfo
	// we don't report errors on failures to get this information
	physicalCores, logicalCores, _ := si.CPUCores()
	mhz, _ := si.CPUMHz()
	mem, _ := si.MemTotal()
	return serverInfo{
		ShardWidth:       ShardWidth,
		CPUPhysicalCores: physicalCores,
		CPULogicalCores:  logicalCores,
		CPUMHz:           mhz,
		CPUType:          si.CPUModel(),
		Memory:           mem,
	}
}
source: func (s *S3CopyObjectOperation) SetNewObjectMetadata(v *S3ObjectMetadata) *S3CopyObjectOperation {
	s.NewObjectMetadata = v
	return s
}
source: func (s *CodeContentDescription) SetS3ApplicationCodeLocationDescription(v *S3ApplicationCodeLocationDescription) *CodeContentDescription {
	s.S3ApplicationCodeLocationDescription = v
	return s
}
source: func (s *Snapshot) SetAccountsWithRestoreAccess(v []*AccountWithRestoreAccess) *Snapshot {
	s.AccountsWithRestoreAccess = v
	return s
}
source: func listenForCamliNet(ws *webserver.Server, config *serverinit.Config) (baseURL string, err error) {
	camliNetIP := config.CamliNetIP()
	if camliNetIP == "" {
		return "", errors.New("no camliNetIP")
	}
	if ip := net.ParseIP(camliNetIP); ip == nil {
		return "", fmt.Errorf("camliNetIP value %q is not a valid IP address", camliNetIP)
	} else if ip.To4() == nil {
		// TODO: support IPv6 when GCE supports IPv6: https://code.google.com/p/google-compute-engine/issues/detail?id=8
		return "", errors.New("CamliNetIP should be an IPv4, as IPv6 is not yet supported on GCE")
	}
	challengeHostname := camliNetIP + gpgchallenge.SNISuffix
	selfCert, selfKey, err := httputil.GenSelfTLS(challengeHostname)
	if err != nil {
		return "", fmt.Errorf("could not generate self-signed certificate: %v", err)
	}
	gpgchallengeCert, err := tls.X509KeyPair(selfCert, selfKey)
	if err != nil {
		return "", fmt.Errorf("could not load TLS certificate: %v", err)
	}
	_, keyId, err := config.KeyRingAndId()
	if err != nil {
		return "", fmt.Errorf("could not get keyId for camliNet hostname: %v", err)
	}
	// catch future length changes
	if len(keyId) != 16 {
		panic("length of GPG keyId is not 16 anymore")
	}
	shortKeyId := keyId[8:]
	camliNetHostName = strings.ToLower(shortKeyId + "." + camliNetDomain)
	m := autocert.Manager{
		Prompt:     autocert.AcceptTOS,
		HostPolicy: autocert.HostWhitelist(camliNetHostName),
		Cache:      autocert.DirCache(osutil.DefaultLetsEncryptCache()),
	}
	go func() {
		err := http.ListenAndServe(":http", m.HTTPHandler(nil))
		log.Fatalf("Could not start server for http-01 challenge: %v", err)
	}()
	getCertificate := func(hello *tls.ClientHelloInfo) (*tls.Certificate, error) {
		if hello.ServerName == challengeHostname {
			return &gpgchallengeCert, nil
		}
		return m.GetCertificate(hello)
	}
	log.Printf("TLS enabled, with Let's Encrypt for %v", camliNetHostName)
	ws.SetTLS(webserver.TLSSetup{CertManager: getCertificate})

	err = ws.Listen(fmt.Sprintf(":%d", gpgchallenge.ClientChallengedPort))
	if err != nil {
		return "", fmt.Errorf("Listen: %v", err)
	}
	return fmt.Sprintf("https://%s", camliNetHostName), nil
}
source: func Mul3(a, b, c *T) T {
	q := Mul(a, b)
	return Mul(&q, c)
}
source: func (s *Server) ServeHTTP(w http.ResponseWriter, req *http.Request) {
	defer httplog.NewLogged(req, &w).StacktraceWhen(
		httplog.StatusIsNot(
			http.StatusOK,
			http.StatusFound,
			http.StatusMovedPermanently,
			http.StatusTemporaryRedirect,
			http.StatusBadRequest,
			http.StatusNotFound,
			http.StatusSwitchingProtocols,
		),
	).Log()

	// monitor http requests
	var serverType string
	if s.auth == nil {
		serverType = "readonly"
	} else {
		serverType = "readwrite"
	}

	method, path, host := req.Method, trimURLPath(req.URL.Path), req.URL.Host

	longRunning := strconv.FormatBool(isLongRunningRequest(path))

	servermetrics.HTTPRequests.WithLabelValues(method, path, host, serverType, longRunning).Inc()

	servermetrics.HTTPInflightRequests.WithLabelValues(method, path, host, serverType, longRunning).Inc()
	defer servermetrics.HTTPInflightRequests.WithLabelValues(method, path, host, serverType, longRunning).Dec()

	startTime := time.Now()
	defer servermetrics.HTTPRequestsDuration.WithLabelValues(method, path, host, serverType, longRunning).Observe(servermetrics.SinceInSeconds(startTime))

	s.restfulCont.ServeHTTP(w, req)
}
source: func (s *Input) SetDecryptionSettings(v *InputDecryptionSettings) *Input {
	s.DecryptionSettings = v
	return s
}
source: func ExtractSearchableAttributes(opts ...interface{}) *opt.SearchableAttributesOption {
	for _, o := range opts {
		if v, ok := o.(*opt.SearchableAttributesOption); ok {
			return v
		}
	}
	return nil
}
source: func (ph *permissionHandler) ServeHTTP(w http.ResponseWriter, req *http.Request) {
	// Check if the user has the right admin/user rights
	if ph.perm.Rejected(w, req) {
		// Let the user know, by calling the custom "permission denied" function
		ph.perm.DenyFunction()(w, req)
		// Reject the request by not calling the next handler below
		return
	}
	// Serve the requested page if permissions were granted
	ph.mux.ServeHTTP(w, req)
}
source: func Decode(r io.Reader, v interface{}, order binary.ByteOrder) error {
	b, err := Read(r, order)
	if err != nil {
		return err
	}
	err = json.Unmarshal(b, v)
	if err != nil {
		return errors.New(err.Error() + string(b))
	}
	return nil
}
source: func (s *PutTemplateService) Version(version int) *PutTemplateService {
	s.version = &version
	return s
}
source: func NewMemDb(name string, cols []string) (*MemDb, error) {
	return NewMemDbForSchema(name, cols)
}
source: func (r *StatusResp) Err() error {
	if r == nil {
		// No status response, connection closed before we get one
		return errors.New("imap: connection closed during command execution")
	}

	if r.Type == StatusRespNo || r.Type == StatusRespBad {
		return errors.New(r.Info)
	}
	return nil
}
source: func (s *ChainService) handleCFiltersResponse(q *cfiltersQuery,
	resp wire.Message, quit chan<- struct{}) {

	// We're only interested in "cfilter" messages.
	response, ok := resp.(*wire.MsgCFilter)
	if !ok {
		return
	}

	// If the response doesn't match our request, ignore this message.
	if q.filterType != response.FilterType {
		return
	}

	// If this filter is for a block not in our index, we can ignore it, as
	// we either already got it, or it is out of our queried range.
	i, ok := q.headerIndex[response.BlockHash]
	if !ok {
		return
	}

	gotFilter, err := gcs.FromNBytes(
		builder.DefaultP, builder.DefaultM, response.Data,
	)
	if err != nil {
		// Malformed filter data. We can ignore this message.
		return
	}

	// Now that we have a proper filter, ensure that re-calculating the
	// filter header hash for the header _after_ the filter in the chain
	// checks out. If not, we can ignore this response.
	curHeader := q.filterHeaders[i]
	prevHeader := q.filterHeaders[i-1]
	gotHeader, err := builder.MakeHeaderForFilter(
		gotFilter, prevHeader,
	)
	if err != nil {
		return
	}

	if gotHeader != curHeader {
		return
	}

	// At this point, the filter matches what we know about it and we
	// declare it sane. If this is the filter requested initially, send it
	// to the caller immediately.
	if response.BlockHash == q.targetHash {
		q.filterChan <- gotFilter
	}

	// Put the filter in the cache and persistToDisk if the caller
	// requested it.
	// TODO(halseth): for an LRU we could take care to insert the next
	// height filter last.
	dbFilterType := filterdb.RegularFilter
	evict, err := s.putFilterToCache(
		&response.BlockHash, dbFilterType, gotFilter,
	)
	if err != nil {
		log.Warnf("Couldn't write filter to cache: %v", err)
	}

	// TODO(halseth): dynamically increase/decrease the batch size to match
	// our cache capacity.
	numFilters := q.stopHeight - q.startHeight + 1
	if evict && s.FilterCache.Len() < int(numFilters) {
		log.Debugf("Items evicted from the cache with less "+
			"than %d elements. Consider increasing the "+
			"cache size...", numFilters)
	}

	qo := defaultQueryOptions()
	qo.applyQueryOptions(q.options...)
	if qo.persistToDisk {
		err = s.FilterDB.PutFilter(
			&response.BlockHash, gotFilter, dbFilterType,
		)
		if err != nil {
			log.Warnf("Couldn't write filter to filterDB: "+
				"%v", err)
		}

		log.Tracef("Wrote filter for block %s, type %d",
			&response.BlockHash, dbFilterType)
	}

	// Finally, we can delete it from the headerIndex.
	delete(q.headerIndex, response.BlockHash)

	// If the headerIndex is empty, we got everything we wanted, and can
	// exit.
	if len(q.headerIndex) == 0 {
		close(quit)
	}
}
source: func NewPinnedProvider(onlyRoots bool) func(pinning pin.Pinner, dag ipld.DAGService) KeyChanFunc {
	return func(pinning pin.Pinner, dag ipld.DAGService) KeyChanFunc {
		return func(ctx context.Context) (<-chan cid.Cid, error) {
			set, err := pinSet(ctx, pinning, dag, onlyRoots)
			if err != nil {
				return nil, err
			}

			outCh := make(chan cid.Cid)
			go func() {
				defer close(outCh)
				for c := range set.New {
					select {
					case <-ctx.Done():
						return
					case outCh <- c:
					}
				}

			}()

			return outCh, nil
		}
	}
}
source: func basicHandle(hh Handle) (x *BasicHandle) {
	x = hh.getBasicHandle()
	// ** We need to simulate once.Do, to ensure no data race within the block.
	// ** Consequently, below would not work.
	// if atomic.CompareAndSwapUint32(&x.inited, 0, 1) {
	// 	x.be = hh.isBinary()
	// 	_, x.js = hh.(*JsonHandle)
	// 	x.n = hh.Name()[0]
	// }

	// simulate once.Do using our own stored flag and mutex as a CompareAndSwap
	// is not sufficient, since a race condition can occur within init(Handle) function.
	// init is made noinline, so that this function can be inlined by its caller.
	if atomic.LoadUint32(&x.inited) == 0 {
		x.init(hh)
	}
	return
}
source: func (scheduler *LatchesScheduler) Close() {
	scheduler.RWMutex.Lock()
	defer scheduler.RWMutex.Unlock()
	if !scheduler.closed {
		close(scheduler.unlockCh)
		scheduler.closed = true
	}
}
source: func CheckRootKeyIsEncrypted(pemBytes []byte) error {
	block, _ := pem.Decode(pemBytes)
	if block == nil {
		return ErrNoValidPrivateKey
	}

	if block.Type == "ENCRYPTED PRIVATE KEY" {
		return nil
	}
	if !notary.FIPSEnabled() && x509.IsEncryptedPEMBlock(block) {
		return nil
	}

	return ErrRootKeyNotEncrypted
}
source: func (p *Pool) Wait(timeout time.Duration) error {
	const waitPollInterval = 500 * time.Millisecond

	ctx := context.Background()
	if timeout > 0 {
		var cancel context.CancelFunc
		ctx, cancel = context.WithTimeout(context.Background(), timeout)
		defer cancel()
	}

	ticker := time.NewTicker(waitPollInterval)
	defer ticker.Stop()

	for {
		if p.busy == 0 {
			return nil
		}
		select {
		case <-ctx.Done():
			return ctx.Err()
		case <-ticker.C:
		}
	}
}
source: func hasAddrsplosion(addrs []ma.Multiaddr) bool {
	aset := make(map[string]int)

	for _, a := range addrs {
		key, port := addrKeyAndPort(a)
		xport, ok := aset[key]
		if ok && port != xport {
			return true
		}
		aset[key] = port
	}

	return false
}
source: func TarGzip(r io.Reader) (VFS, error) {
	zr, err := gzip.NewReader(r)
	if err != nil {
		return nil, err
	}
	defer zr.Close()
	return Tar(zr)
}
source: func (e Encoder) AppendUints(dst []byte, vals []uint) []byte {
	major := majorTypeArray
	l := len(vals)
	if l == 0 {
		return e.AppendArrayEnd(e.AppendArrayStart(dst))
	}
	if l <= additionalMax {
		lb := byte(l)
		dst = append(dst, byte(major|lb))
	} else {
		dst = appendCborTypePrefix(dst, major, uint64(l))
	}
	for _, v := range vals {
		dst = e.AppendUint(dst, v)
	}
	return dst
}
source: func MatchHeaders(req *http.Request, ereq *Request) (bool, error) {
	for key, value := range ereq.Header {
		var err error
		var match bool

		for _, field := range req.Header[key] {
			match, err = regexp.MatchString(value[0], field)
			if err != nil {
				return false, err
			}
			if match {
				break
			}
		}

		if !match {
			return false, nil
		}
	}
	return true, nil
}
source: func parseBool(value interface{}) (bool, error) {
	var enabled bool
	var err error
	switch value.(type) {
	case string:
		enabled, err = strconv.ParseBool(value.(string))
	case bool:
		enabled = value.(bool)
	default:
		err = fmt.Errorf("%v couldn't be converted to boolean value", value)
	}

	return enabled, err
}
source: func NewMetrics(factory metrics.Factory, globalTags map[string]string) *Metrics {
	m := &Metrics{}
	// TODO the namespace "jaeger" should be configurable
	metrics.MustInit(m, factory.Namespace(metrics.NSOptions{Name: "jaeger"}).Namespace(metrics.NSOptions{Name: "tracer"}), globalTags)
	return m
}
source: func (pp protocolPorts) union(other protocolPorts) protocolPorts {
	result := make(protocolPorts)
	for protocol, ports := range pp {
		result[protocol] = ports
	}
	for protocol, otherPorts := range other {
		resultPorts := result[protocol]
		for _, other := range otherPorts {
			found := false
			for _, myRange := range resultPorts {
				if myRange == other {
					found = true
					break
				}
			}
			if !found {
				resultPorts = append(resultPorts, other)
			}
		}
		result[protocol] = resultPorts
	}
	return result
}
source: func Get(name string) *chroma.Style {
	if style, ok := Registry[name]; ok {
		return style
	}
	return Fallback
}
source: func (s *HlsGroupSettings) SetDirectoryStructure(v string) *HlsGroupSettings {
	s.DirectoryStructure = &v
	return s
}
source: func NewPool(capacity int, itemFactory ItemFactory) (Pool, error) {

	q, err := queue.NewChannelQueue(capacity)
	if err != nil {
		return nil, err
	}

	itemMap := make(map[uint64]*Item)
	pool := itemPool{itemMap: itemMap, itemQ: q, capacity: capacity, itemFactory: itemFactory}
	return &pool, nil
}
source: func (d *Dataset) InsertDynamicColumn(index int, header string, fn DynamicColumn) error {
	if index < 0 || index >= d.cols {
		return ErrInvalidColumnIndex
	}

	d.insertHeader(index, header)

	// for each row, insert the column
	for i, r := range d.data {
		row := make([]interface{}, 0, d.cols)
		row = append(row, r[:index]...)
		row = append(row, fn)
		row = append(row, r[index:]...)
		d.data[i] = row
	}

	return nil
}
source: func (rc *CryptoReadCloser) Read(b []byte) (int, error) {
	if rc.isClosed {
		return 0, io.EOF
	}
	return rc.Decrypter.Read(b)
}
source: func (api *CloudSpecAPI) WatchCloudSpecChanges() (watcher.NotifyWatcher, error) {
	var results params.NotifyWatchResults
	args := params.Entities{Entities: []params.Entity{{api.modelTag.String()}}}
	err := api.facade.FacadeCall("WatchCloudSpecsChanges", args, &results)
	if err != nil {
		return nil, err
	}
	if n := len(results.Results); n != 1 {
		return nil, errors.Errorf("expected 1 result, got %d", n)
	}
	result := results.Results[0]
	if result.Error != nil {
		return nil, errors.Annotate(result.Error, "API request failed")
	}
	return apiwatcher.NewNotifyWatcher(api.facade.RawAPICaller(), result), nil
}
source: func (cp *Data) GetData() ([]PodDevicesEntry, map[string][]string) {
	return cp.Data.PodDeviceEntries, cp.Data.RegisteredDevices
}
source: func Encode(b []byte, value int64) int {
	// 111111xx Byte-inverted negative two bit number (~xx)
	if value <= -1 && value >= -4 {
		b[0] = 0xFC | byte(^value&0xFF)
		return 1
	}
	// 111110__ + varint Negative recursive varint
	if value < 0 {
		b[0] = 0xF8
		return 1 + Encode(b[1:], -value)
	}
	// 0xxxxxxx 7-bit positive number
	if value <= 0x7F {
		b[0] = byte(value)
		return 1
	}
	// 10xxxxxx + 1 byte 14-bit positive number
	if value <= 0x3FFF {
		b[0] = byte(((value >> 8) & 0x3F) | 0x80)
		b[1] = byte(value & 0xFF)
		return 2
	}
	// 110xxxxx + 2 bytes 21-bit positive number
	if value <= 0x1FFFFF {
		b[0] = byte((value>>16)&0x1F | 0xC0)
		b[1] = byte((value >> 8) & 0xFF)
		b[2] = byte(value & 0xFF)
		return 3
	}
	// 1110xxxx + 3 bytes 28-bit positive number
	if value <= 0xFFFFFFF {
		b[0] = byte((value>>24)&0xF | 0xE0)
		b[1] = byte((value >> 16) & 0xFF)
		b[2] = byte((value >> 8) & 0xFF)
		b[3] = byte(value & 0xFF)
		return 4
	}
	// 111100__ + int (32-bit) 32-bit positive number
	if value <= math.MaxInt32 {
		b[0] = 0xF0
		binary.BigEndian.PutUint32(b[1:], uint32(value))
		return 5
	}
	// 111101__ + long (64-bit) 64-bit number
	if value <= math.MaxInt64 {
		b[0] = 0xF4
		binary.BigEndian.PutUint64(b[1:], uint64(value))
		return 9
	}

	return 0
}
source: func (s *Latency) SetP50(v float64) *Latency {
	s.P50 = &v
	return s
}
source: func (e *BinXMLEntityReference) Parse(reader io.ReadSeeker) error {
	err := encoding.Unmarshal(reader, &e.Token, Endianness)
	if err != nil {
		return err
	}
	err = encoding.Unmarshal(reader, &e.NameOffset, Endianness)
	if err != nil {
		return err
	}
	o := BackupSeeker(reader)
	// if the Entity Name is just after
	if int64(e.NameOffset) == o {
		return e.Name.Parse(reader)
	}
	// We jump to the right offset
	GoToSeeker(reader, int64(e.NameOffset))
	err = e.Name.Parse(reader)
	// We restore our position
	GoToSeeker(reader, o)
	return err
} 90%|████████▉ | 4479/5000 [00:05<00:00, 885.18it/s]
source: func (q *Query) Index(indexName string) *Query {
	if strings.Contains(indexName, ".") {
		// NOTE: I may reconsider this in the future
		panic("Nested indexes are not supported.  Only top level structures can be indexed")
	}
	q.index = indexName
	return q
}
source: func NewTokenStore(ctx context.Context, logger log.Logger, core *Core, config *logical.BackendConfig) (*TokenStore, error) {
	// Create a sub-view
	view := core.systemBarrierView.SubView(tokenSubPath)

	// Initialize the store
	t := &TokenStore{
		activeContext:         ctx,
		core:                  core,
		batchTokenEncryptor:   core.barrier,
		baseBarrierView:       view,
		idBarrierView:         view.SubView(idPrefix),
		accessorBarrierView:   view.SubView(accessorPrefix),
		parentBarrierView:     view.SubView(parentPrefix),
		rolesBarrierView:      view.SubView(rolesPrefix),
		cubbyholeDestroyer:    destroyCubbyhole,
		logger:                logger,
		tokenLocks:            locksutil.CreateLocks(),
		tokensPendingDeletion: &sync.Map{},
		saltLock:              sync.RWMutex{},
		tidyLock:              new(uint32),
		quitContext:           core.activeContext,
		salts:                 make(map[string]*salt.Salt),
	}

	// Setup the framework endpoints
	t.Backend = &framework.Backend{
		AuthRenew: t.authRenew,

		PathsSpecial: &logical.Paths{
			Root: []string{
				"revoke-orphan/*",
				"accessors*",
			},

			// Most token store items are local since tokens are local, but a
			// notable exception is roles
			LocalStorage: []string{
				idPrefix,
				accessorPrefix,
				parentPrefix,
				salt.DefaultLocation,
			},
		},
		BackendType: logical.TypeCredential,
	}

	t.Backend.Paths = append(t.Backend.Paths, t.paths()...)

	t.Backend.Setup(ctx, config)

	return t, nil
}
source: func (p *SdkPolicyManager) Inspect(
	ctx context.Context,
	req *api.SdkOpenStoragePolicyInspectRequest,
) (*api.SdkOpenStoragePolicyInspectResponse, error) {
	if req.GetName() == "" {
		return nil, status.Error(codes.InvalidArgument, "Must supply a Storage Policy Name")
	}

	kvp, err := p.kv.Get(prefixWithName(req.GetName()))
	if err == kvdb.ErrNotFound {
		return nil, status.Errorf(codes.NotFound, "Policy %s not found", req.GetName())
	} else if err != nil {
		return nil, status.Errorf(codes.Internal, "Failed to get policy %s information: %v", req.GetName(), err)
	}

	storPolicy := &api.SdkStoragePolicy{}
	err = jsonpb.UnmarshalString(string(kvp.Value), storPolicy)
	if err != nil {
		return nil, status.Errorf(codes.Internal, "Json Unmarshal failed for policy %s: %v", req.GetName(), err)
	}

	if !storPolicy.IsPermitted(ctx, api.Ownership_Read) {
		return nil, status.Errorf(codes.PermissionDenied, "Access denied to storage policy %s", storPolicy.GetName())
	}

	return &api.SdkOpenStoragePolicyInspectResponse{
		StoragePolicy: storPolicy,
	}, nil
}
source: func Range(start, end int) []int {
	if end < start {
		panic("range must have end greater than or equal to start")
	}
	r := make([]int, end-start)
	for i := start; i < end; i++ {
		r[i-start] = i
	}
	return r
}
source: func (c *Card) AddURLAttachment(attachment *Attachment) error {
	path := fmt.Sprintf("cards/%s/attachments", c.ID)
	args := Arguments{
		"url":  attachment.URL,
		"name": attachment.Name,
	}
	err := c.client.Post(path, args, &attachment)
	if err != nil {
		err = errors.Wrapf(err, "Error adding attachment to card %s", c.ID)
	}
	return err

}
source: func (v *vserver) downAll() {
	for _, s := range v.services {
		if v.active[s.ip] {
			v.down(s.ip)
		}
		if s.active {
			s.down()
		}
	}
}
source: func (ckf ComputedKeyFamily) ExportAllPGPKeys() (keys []keybase1.PublicKey) {
	for _, key := range ckf.GetAllActiveSibkeys() {
		if _, isPGP := key.(*PGPKeyBundle); isPGP {
			keys = append(keys, ckf.exportPublicKey(key))
		}
	}
	for _, key := range ckf.GetAllActiveSubkeys() {
		if _, isPGP := key.(*PGPKeyBundle); isPGP {
			keys = append(keys, ckf.exportPublicKey(key))
		}
	}
	sort.Sort(PublicKeyList(keys))
	return keys
}
source: func (v *VserverEntry) Snapshot() *seesaw.VserverEntry {
	return &seesaw.VserverEntry{
		Port:          v.Port,
		Proto:         v.Proto,
		Scheduler:     v.Scheduler,
		Mode:          v.Mode,
		Persistence:   v.Persistence,
		OnePacket:     v.OnePacket,
		HighWatermark: v.HighWatermark,
		LowWatermark:  v.LowWatermark,
		LThreshold:    v.LThreshold,
		UThreshold:    v.UThreshold,
	}
}
source: func (m mathUtil) RadianAdd(base, delta float64) float64 {
	value := base + delta
	if value > _2pi {
		return math.Mod(value, _2pi)
	} else if value < 0 {
		return math.Mod(_2pi+value, _2pi)
	}
	return value
}
source: func isSystemRoot(path string) bool {
	if len(path) != rootPathLength {
		return false
	}

	return os.PathSeparator == path[rootPathLength-1]
}
source: func (v ByteView) Reader() io.ReadSeeker {
	if v.b != nil {
		return bytes.NewReader(v.b)
	}
	return strings.NewReader(v.s)
}
source: func (g *Group) Connect(path string, handler context.Handler) {
	g.Handle(http.MethodConnect, path, handler)
}
source: func NewFrame(pc uintptr) Frame {
	frame := Frame{ProgramCounter: pc}
	if frame.Func() == nil {
		return frame
	}
	frame.Package, frame.Name = packageAndName(frame.Func())

	// pc -1 because the program counters we use are usually return addresses,
	// and we want to show the line that corresponds to the function call
	frame.File, frame.LineNumber = frame.Func().FileLine(pc - 1)
	frame.IsSystemPackage = isSystemPackage(frame.File, frame.Package)

	return frame
}
source: func (it *Not) Contains(ctx context.Context, val graph.Value) bool {
	graph.ContainsLogIn(it, val)
	it.runstats.Contains += 1

	if it.primaryIt.Contains(ctx, val) {
		return graph.ContainsLogOut(it, val, false)
	}

	it.err = it.primaryIt.Err()
	if it.err != nil {
		// Explicitly return 'false', since an error occurred.
		return false
	}

	it.result = val
	return graph.ContainsLogOut(it, val, true)
}
source: func (v *Function) String() string {
	if v == nil {
		return "<nil>"
	}

	var fields [7]string
	i := 0
	fields[i] = fmt.Sprintf("Name: %v", v.Name)
	i++
	fields[i] = fmt.Sprintf("ThriftName: %v", v.ThriftName)
	i++
	fields[i] = fmt.Sprintf("Arguments: %v", v.Arguments)
	i++
	if v.ReturnType != nil {
		fields[i] = fmt.Sprintf("ReturnType: %v", v.ReturnType)
		i++
	}
	if v.Exceptions != nil {
		fields[i] = fmt.Sprintf("Exceptions: %v", v.Exceptions)
		i++
	}
	if v.OneWay != nil {
		fields[i] = fmt.Sprintf("OneWay: %v", *(v.OneWay))
		i++
	}
	if v.Annotations != nil {
		fields[i] = fmt.Sprintf("Annotations: %v", v.Annotations)
		i++
	}

	return fmt.Sprintf("Function{%v}", strings.Join(fields[:i], ", "))
}
source: func NewProxyWithOptions(router route.Router, o Options) (*Proxy, error) {
	o, err := validateOptions(o)
	if err != nil {
		return nil, err
	}

	p := &Proxy{
		options: o,
		router:  router,
	}
	return p, nil
}
source: func (r *StateRestore) NodeRestore(node *structs.Node) error {
	if err := r.txn.Insert("nodes", node); err != nil {
		return fmt.Errorf("node insert failed: %v", err)
	}
	return nil
}
source: func (s *PrivateAccountAPI) UnlockAccount(ctx context.Context, addr common.Address, password string, duration *uint64) (bool, error) {
	// When the API is exposed by external RPC(http, ws etc), unless the user
	// explicitly specifies to allow the insecure account unlocking, otherwise
	// it is disabled.
	if s.b.ExtRPCEnabled() && !s.b.AccountManager().Config().InsecureUnlockAllowed {
		return false, errors.New("account unlock with HTTP access is forbidden")
	}

	const max = uint64(time.Duration(math.MaxInt64) / time.Second)
	var d time.Duration
	if duration == nil {
		d = 300 * time.Second
	} else if *duration > max {
		return false, errors.New("unlock duration too large")
	} else {
		d = time.Duration(*duration) * time.Second
	}
	err := fetchKeystore(s.am).TimedUnlock(accounts.Account{Address: addr}, password, d)
	if err != nil {
		log.Warn("Failed account unlock attempt", "address", addr, "err", err)
	}
	return err == nil, err
}
source: func (t *TeamKeyManager) RotateSharedSecretBoxes(mctx libkb.MetaContext, senderKey libkb.GenericKey, recipients map[keybase1.UserVersion]keybase1.PerUserKey) (boxes *PerTeamSharedSecretBoxes, keySection *SCPerTeamKey, err error) {
	defer mctx.Trace("RotateSharedSecretBoxes", func() error { return err })()

	// make a new secret
	nextSecret, err := newSharedSecret()
	if err != nil {
		return nil, nil, err
	}

	// derive new key from new secret for PrevKey
	key := derivedSecret(nextSecret, libkb.TeamPrevKeySecretBoxDerivationString)
	var keyb [32]byte
	copy(keyb[:], key)

	// encrypt existing secret with derived key and nonce counter 0
	nonce, err := newNonce24()
	if err != nil {
		return nil, nil, err
	}
	nonceBytes, counter := nonce.Nonce()
	if counter != 0 {
		// this should never happen, but might as well make sure it is zero
		return nil, nil, errors.New("nonce counter not 0 for first use")
	}
	sealed := secretbox.Seal(nil, t.sharedSecret.ToBytes(), &nonceBytes, &keyb)

	// encode encrypted prev key
	prevKeyEncoded, err := encodeSealedPrevKey(nonceBytes, sealed)
	if err != nil {
		return nil, nil, err
	}

	// make the recipient boxes with the new secret and the incrementing nonce24
	t.setNextSharedSecret(mctx, nextSecret)
	boxes, err = t.sharedBoxes(t.sharedSecret, t.generation, nonce, senderKey, recipients)
	if err != nil {
		return nil, nil, err
	}

	// insert encoded encrypted PrevKey
	boxes.PrevKey = &prevKeyEncoded

	// need a new PerTeamKey section since the key was rotated
	keySection, err = t.perTeamKeySection()
	if err != nil {
		return nil, nil, err
	}

	return boxes, keySection, nil
}
source: func New(uri string) (*MetaInspector, error) {
	if uri == "" {
		return nil, errors.New("Url is empty!")
	}

	u, err := url.Parse(uri)
	if err != nil {
		return nil, err
	}

	scraper, err := newScraper(fixURL(u), 20)
	if err != nil {
		return nil, err
	}

	return &MetaInspector{uri,
		u.Scheme,
		u.Host,
		root(u),
		scraper.title,
		scraper.language,
		scraper.author,
		scraper.description,
		scraper.generator,
		scraper.feed,
		scraper.charset,
		scraper.links,
		scraper.images,
		scraper.keywords,
		scraper.compatibility}, nil
}
source: func ModelInfoFromParams(info params.ModelInfo, now time.Time) (ModelInfo, error) {
	ownerTag, err := names.ParseUserTag(info.OwnerTag)
	if err != nil {
		return ModelInfo{}, errors.Trace(err)
	}
	cloudTag, err := names.ParseCloudTag(info.CloudTag)
	if err != nil {
		return ModelInfo{}, errors.Trace(err)
	}
	modelInfo := ModelInfo{
		ShortName:      info.Name,
		Name:           jujuclient.JoinOwnerModelName(ownerTag, info.Name),
		Type:           model.ModelType(info.Type),
		UUID:           info.UUID,
		ControllerUUID: info.ControllerUUID,
		IsController:   info.IsController,
		Owner:          ownerTag.Id(),
		Life:           string(info.Life),
		Cloud:          cloudTag.Id(),
		CloudRegion:    info.CloudRegion,
	}
	if info.AgentVersion != nil {
		modelInfo.AgentVersion = info.AgentVersion.String()
	}
	// Although this may be more performance intensive, we have to use reflection
	// since structs containing map[string]interface {} cannot be compared, i.e
	// cannot use simple '==' here.
	if !reflect.DeepEqual(info.Status, params.EntityStatus{}) {
		modelInfo.Status = &ModelStatus{
			Current: info.Status.Status,
			Message: info.Status.Info,
			Since:   FriendlyDuration(info.Status.Since, now),
		}
	}
	if info.Migration != nil {
		status := modelInfo.Status
		if status == nil {
			status = &ModelStatus{}
			modelInfo.Status = status
		}
		status.Migration = info.Migration.Status
		status.MigrationStart = FriendlyDuration(info.Migration.Start, now)
		status.MigrationEnd = FriendlyDuration(info.Migration.End, now)
	}

	if info.ProviderType != "" {
		modelInfo.ProviderType = info.ProviderType

	}
	if len(info.Users) != 0 {
		modelInfo.Users = ModelUserInfoFromParams(info.Users, now)
	}
	if len(info.Machines) != 0 {
		modelInfo.Machines = ModelMachineInfoFromParams(info.Machines)
	}
	if info.SLA != nil {
		modelInfo.SLA = ModelSLAFromParams(info.SLA)
		modelInfo.SLAOwner = ModelSLAOwnerFromParams(info.SLA)
	}

	if info.CloudCredentialTag != "" {
		credTag, err := names.ParseCloudCredentialTag(info.CloudCredentialTag)
		if err != nil {
			return ModelInfo{}, errors.Trace(err)
		}
		modelInfo.Credential = &ModelCredential{
			Name:  credTag.Name(),
			Owner: credTag.Owner().Id(),
			Cloud: credTag.Cloud().Id(),
		}
	}

	return modelInfo, nil
}
source: func (rw *GCS) NewReader(id string) (io.ReadCloser, error) {
	ctx := context.Background()
	obj := rw.bucket.Object(rw.Prefixed.Name(id))
	return obj.NewReader(ctx)
}
source: func (c *Cron) Schedule(schedule Schedule, cmd Job) {
	entry := &Entry{
		Schedule: schedule,
		Job:      cmd,
	}
	if !c.running {
		c.entries = append(c.entries, entry)
		return
	}

	c.add <- entry
}
source: func (h *Hash) IsHash64() bool {
	_, ok := h.Hash.(hash.Hash64)
	return ok
}
source: func (i Interval) Equal(oi Interval) bool {
	return i == oi || i.IsEmpty() && oi.IsEmpty()
}
source: func (c *Command) Start() error {

	cmd, err := c.buildCmd()
	if err != nil {
		return err
	}
	cmd.Stdout = logfile(c.GetLogfile())
	cmd.Stderr = logfile(c.GetLogfile())
	if c.WorkingDir != "" {
		cmd.Dir = c.WorkingDir
	}

	if c.UseEnv {
		flagEnv := filepath.Join(cmd.Dir, ".env")
		env, _ := ReadEnv(flagEnv)
		cmd.Env = env.asArray()
	} else if len(c.Env) > 0 {
		cmd.Env = c.Env.asArray()
	}

	pid, err := start(cmd)
	if err != nil {
		return err
	}
	c.Pid = pid
	return nil
}
source: func Walk(x Syntax, before, after func(Syntax)) {
	seen := map[Syntax]bool{
		nil:           true,
		(*Decl)(nil):  true,
		(*Init)(nil):  true,
		(*Type)(nil):  true,
		(*Expr)(nil):  true,
		(*Stmt)(nil):  true,
		(*Label)(nil): true,
	}
	walk(x, before, after, seen)
}
source: func (m *model) Index(deviceID protocol.DeviceID, folder string, fs []protocol.FileInfo) {
	m.handleIndex(deviceID, folder, fs, false)
}
source: func Login(session *mgo.Session, user, password string) error {
	admin := session.DB("admin")
	if err := admin.Login(user, password); err != nil {
		return MaybeUnauthorizedf(err, "cannot log in to admin database as %q", user)
	}
	return nil
}
source: func (s *Store) SetMetadata(md map[string]string) error {
	return s.setMetadata(s.raftID, md)
}
source: func NewAttributes(event *audit.Event) (authorizer.Attributes, error) {
	a := attributes{
		event: event,
	}
	if event.ObjectRef == nil {
		u, err := url.ParseRequestURI(a.event.RequestURI)
		if err != nil {
			return nil, fmt.Errorf("could not parse url: %v", err)
		}
		a.path = u.Path
	}
	return &a, nil
}
source: func (s *session) Write(data []byte) error {
	select {
	case s.recvC <- data:
		return nil
	case <-s.conn.Context().Done():
		return s.conn.Context().Err()
	}
}
source: func ParseClientType(str string) ClientType {
	str = strings.ToLower(str)
	switch str {
	case "integration":
		return IntegrationClient
	case "controller":
		return ControllerClient
	}
	return UnknownClientType
}
source: func (n *Node) Uptime() time.Duration {
	return time.Now().Sub(n.startTime)
}
source: func extractCallerDetails() (file string, line int, pkg string, function string, err error) {
	if pc, file, line, ok := runtime.Caller(2); ok {
		fName := runtime.FuncForPC(pc).Name()

		parts := strings.Split(fName, ".")
		pl := len(parts)
		pName := ""

		if parts[pl-2][0] == '(' {
			pName = strings.Join(parts[0:pl-2], ".")
		} else {
			pName = strings.Join(parts[0:pl-1], ".")
		}

		pName = strings.Replace(pName, defaultPackageName, "", -1)

		return file, line, pName, fName, nil
	}

	return "", 0, "", "", errors.New("unable to extract the caller details")
}
source: func (s *Server) setupSegments(config *Config, port int, rpcListeners map[string]net.Listener) error {
	if len(config.Segments) > 0 {
		return structs.ErrSegmentsNotSupported
	}

	return nil
}
source: func MakeValueItem(it *config.Config) ValueItem {
	return ValueItem{
		ConfigSet:   string(it.ConfigSet),
		Path:        it.Path,
		ContentHash: it.ContentHash,
		Revision:    it.Revision,
		ViewURL:     it.Meta.ViewURL,
		Content:     []byte(it.Content),
		Formatter:   it.FormatSpec.Formatter,
		FormatData:  []byte(it.FormatSpec.Data),
	}
}
source: func (s *Server) ReadSSFPacketSocket(serverConn net.PacketConn, packetPool *sync.Pool) {
	// TODO This is duplicated from ReadMetricSocket and feels like it could be it's
	// own function?
	p := packetPool.Get().([]byte)
	if len(p) == 0 {
		log.WithField("len", len(p)).Fatal(
			"packetPool making empty slices: trace_max_length_bytes must be >= 0")
	}
	packetPool.Put(p)

	for {
		buf := packetPool.Get().([]byte)
		n, _, err := serverConn.ReadFrom(buf)
		if err != nil {
			// In tests, the probably-best way to
			// terminate this reader is to issue a shutdown and close the listening
			// socket, which returns an error, so let's handle it here:
			select {
			case <-s.shutdown:
				log.WithError(err).Info("Ignoring ReadFrom error while shutting down")
				return
			default:
				log.WithError(err).Error("Error reading from UDP trace socket")
				continue
			}
		}

		s.HandleTracePacket(buf[:n])
		packetPool.Put(buf)
	}
}
source: func (b *Blob) Encode(o plumbing.EncodedObject) (err error) {
	o.SetType(plumbing.BlobObject)

	w, err := o.Writer()
	if err != nil {
		return err
	}

	defer ioutil.CheckClose(w, &err)

	r, err := b.Reader()
	if err != nil {
		return err
	}

	defer ioutil.CheckClose(r, &err)

	_, err = io.Copy(w, r)
	return err
}
source: func (l *Log) Info(args ...interface{}) {
	opts := getLoggerOpts(l.module, api.INFO)
	if !opts.levelEnabled {
		return
	}
	if l.loadCustomLogger() {
		l.customLogger.Info(args...)
		return
	}
	l.log(opts, api.INFO, args...)
}
source: func (s *Set) Sample(sample string, sampleRate float32) {
	s.Hll.Insert([]byte(sample))
}
source: func UnretrievableAttributesEqual(o1, o2 *UnretrievableAttributesOption) bool {
	if o1 != nil {
		return o1.Equal(o2)
	}
	if o2 != nil {
		return o2.Equal(o1)
	}
	return true
}
source: func newExponentialBackoff() *exponentialBackoff {
	b := &backoff.Backoff{
		Min:    DefaultMinBackoff,
		Max:    DefaultMaxBackoff,
		Jitter: true,
	}
	return &exponentialBackoff{b: *b, currentDelay: b.Duration()}
}
source: func (b *rescanBatch) merge(job *RescanJob) {
	if job.InitialSync {
		b.initialSync = true
	}
	b.addrs = append(b.addrs, job.Addrs...)

	for op, addr := range job.OutPoints {
		b.outpoints[op] = addr
	}

	if job.BlockStamp.Height < b.bs.Height {
		b.bs = job.BlockStamp
	}
	b.errChans = append(b.errChans, job.err)
}
source: func (r *Rule) Identifier() string {
	return C.GoString(C.rule_identifier(r.cptr))
}
source: func Config() (*DefaultConfig, error) {
	var err error
	config, err := LoadConfig("")
	if err != nil {
		return nil, err
	}

	return config, nil
}
source: func (pool *ObjectPool) IsClosed() bool {
	pool.closeLock.Lock()
	defer pool.closeLock.Unlock()
	// in java commons pool, closed is volatile, golang has not volatile, so use mutex to avoid data race
	return pool.closed
}
source: func include(file, tag string) (string, error) {
	f, err := os.Open(file)
	if err != nil {
		return "", err
	}
	defer f.Close()

	startre, err := regexp.Compile("!\\+" + tag + "$")
	if err != nil {
		return "", err
	}
	endre, err := regexp.Compile("!\\-" + tag + "$")
	if err != nil {
		return "", err
	}

	var text bytes.Buffer
	in := bufio.NewScanner(f)
	var on bool
	for in.Scan() {
		line := in.Text()
		switch {
		case startre.MatchString(line):
			on = true
		case endre.MatchString(line):
			on = false
		case on:
			text.WriteByte('\t')
			text.WriteString(line)
			text.WriteByte('\n')
		}
	}
	if text.Len() == 0 {
		return "", fmt.Errorf("no lines of %s matched tag %q", file, tag)
	}
	return text.String(), nil
}
source: func (c *Client) DeleteAllDeadJobs() error {
	conn := c.pool.Get()
	defer conn.Close()
	_, err := conn.Do("DEL", redisKeyDead(c.namespace))
	if err != nil {
		logError("client.delete_all_dead_jobs", err)
		return err
	}

	return nil
}
source: func CreateOrUpdateDaemonSet(client clientset.Interface, ds *apps.DaemonSet) error {
	if _, err := client.AppsV1().DaemonSets(ds.ObjectMeta.Namespace).Create(ds); err != nil {
		if !apierrors.IsAlreadyExists(err) {
			return errors.Wrap(err, "unable to create daemonset")
		}

		if _, err := client.AppsV1().DaemonSets(ds.ObjectMeta.Namespace).Update(ds); err != nil {
			return errors.Wrap(err, "unable to update daemonset")
		}
	}
	return nil
}
source: func (cache *HealthStatusCache) DeleteInstance(serviceID string, instanceID int) {
	cache.mu.Lock()
	defer cache.mu.Unlock()
	for key := range cache.data {
		if key.ServiceID == serviceID && key.InstanceID == instanceID {
			cache.delete(key)
		}
	}
}
source: func AddKey(username string, k map[string]string) error {
	var u User
	conn, err := db.Conn()
	if err != nil {
		return err
	}
	defer conn.Close()
	if err := conn.User().FindId(username).One(&u); err != nil {
		return ErrUserNotFound
	}
	return addKeys(k, u.Name)
}
source: func ReadWait(readWait time.Duration) func(*WSClient) {
	return func(c *WSClient) {
		c.readWait = readWait
	}
}
source: func (o *oracleInstance) waitForMachineStatus(state ociCommon.InstanceState, timeout time.Duration) error {
	timer := o.env.clock.NewTimer(timeout)
	defer timer.Stop()

	for {
		select {
		case <-timer.Chan():
			return errors.Errorf(
				"Timed out waiting for instance to transition from %v to %v",
				o.machine.State, state,
			)
		case <-o.env.clock.After(10 * time.Second):
			err := o.refresh()
			if err != nil {
				return err
			}
			if o.machine.State == state {
				return nil
			}
		}
	}
}
source: func (n *Stan) Subscribe(route string, handler stan.MsgHandler, opts ...stan.SubscriptionOption) error {
	subsc, err := n.Con.Subscribe(route, handler, opts...)
	if err != nil {
		return errors.New("Failed to make subcriptions for " + route + ": " + err.Error())
	}
	n.Opts.routes = append(n.Opts.routes, &Route{route: route, handler: handler, subsc: subsc})
	return nil
}
source: func (*ImageReader) Read(url *url.URL) (io.ReadCloser, error) {
	return nil, s2ierr.NewScriptsInsideImageError(url.String())
}
source: func (c *EndpointConfig) Timeout(tType fab.TimeoutType) time.Duration {
	return c.getTimeout(tType)
}
source: func (s *fsResourceAnalyzer) GetPodVolumeStats(uid types.UID) (PodVolumeStats, bool) {
	cache := s.cachedVolumeStats.Load().(statCache)
	statCalc, found := cache[uid]
	if !found {
		// TODO: Differentiate between stats being empty
		// See issue #20679
		return PodVolumeStats{}, false
	}
	return statCalc.GetLatest()
}
source: func GenerateACI(layerNumber int, manhash string, layerData types.DockerImageData, dockerURL *common.ParsedDockerURL, outputDir string, layerFile *os.File, curPwl []string, compression common.Compression, debug log.Logger) (string, *schema.ImageManifest, error) {
	manifest, err := GenerateManifest(layerData, manhash, dockerURL, debug)
	if err != nil {
		return "", nil, fmt.Errorf("error generating the manifest: %v", err)
	}

	imageName := strings.Replace(dockerURL.ImageName, "/", "-", -1)
	aciPath := generateACIPath(outputDir, imageName, layerData.ID, dockerURL.Tag, layerData.OS, layerData.Architecture, layerNumber)

	manifest, err = writeACI(layerFile, *manifest, curPwl, aciPath, compression)
	if err != nil {
		return "", nil, fmt.Errorf("error writing ACI: %v", err)
	}

	if err := ValidateACI(aciPath); err != nil {
		return "", nil, fmt.Errorf("invalid ACI generated: %v", err)
	}

	return aciPath, manifest, nil
}
source: func (s *Server) GetMockers(w http.ResponseWriter, req *http.Request) {

	list := GetMockerList()
	s.JSON(w, http.StatusOK, list)
}
source: func machineJobFromParams(job multiwatcher.MachineJob) (state.MachineJob, error) {
	switch job {
	case multiwatcher.JobHostUnits:
		return state.JobHostUnits, nil
	case multiwatcher.JobManageModel:
		return state.JobManageModel, nil
	default:
		return -1, errors.Errorf("invalid machine job %q", job)
	}
}
source: func (c *Client) renderOptions(opts []grpc.CallOption) (*Options, error) {
	var options *Options
	if c.Options != nil {
		cpy := *c.Options
		options = &cpy
	} else {
		options = DefaultOptions()
	}
	if err := options.apply(opts); err != nil {
		return nil, err
	}
	return options, nil
}
source: func (c *Client) ListAppUsageEventsByQuery(query url.Values) ([]AppUsageEvent, error) {
	var appUsageEvents []AppUsageEvent
	requestURL := fmt.Sprintf("/v2/app_usage_events?%s", query.Encode())
	for {
		var appUsageEventsResponse AppUsageEventsResponse
		r := c.NewRequest("GET", requestURL)
		resp, err := c.DoRequest(r)
		if err != nil {
			return nil, errors.Wrap(err, "error requesting events")
		}
		defer resp.Body.Close()
		if err := json.NewDecoder(resp.Body).Decode(&appUsageEventsResponse); err != nil {
			return nil, errors.Wrap(err, "error unmarshaling events")
		}
		for _, e := range appUsageEventsResponse.Resources {
			e.Entity.GUID = e.Meta.Guid
			e.Entity.CreatedAt = e.Meta.CreatedAt
			e.Entity.c = c
			appUsageEvents = append(appUsageEvents, e.Entity)
		}
		requestURL = appUsageEventsResponse.NextURL
		if requestURL == "" {
			break
		}
	}
	return appUsageEvents, nil
}
source: func subpacketsLength(subpackets []outputSubpacket, hashed bool) (length int) {
	for _, subpacket := range subpackets {
		if subpacket.hashed == hashed {
			length += subpacketLengthLength(len(subpacket.contents) + 1)
			length += 1 // type byte
			length += len(subpacket.contents)
		}
	}
	return
}
source: func (w *backstopWorker) recoverViaBootstrap(server *raft.Server) error {
	newServer := *server
	newServer.Suffrage = raft.Voter
	configuration := raft.Configuration{
		Servers: []raft.Server{newServer},
	}
	w.config.Logger.Infof("rebootstrapping raft configuration: %#v", configuration)
	err := w.config.Raft.BootstrapCluster(configuration).Error()
	if err != nil {
		return errors.Annotate(err, "re-bootstrapping cluster")
	}
	return nil
}
source: func (cs *CachableSource) Hash(path string) (string, error) {
	n := cs.getRoot()
	// TODO: check this for symlinks
	v, ok := n.Get([]byte(path))
	if !ok {
		return path, nil
	}
	return v.(*fileInfo).sum, nil
}
source: func ToInt(value interface{}) (int64, error) {
	v := reflect.ValueOf(value)
	switch v.Kind() {
	case reflect.Int, reflect.Int8, reflect.Int16, reflect.Int32, reflect.Int64:
		return v.Int(), nil
	}
	return 0, fmt.Errorf("cannot convert %v to int64", v.Kind())
}
source: func (s *systemdServiceManager) CopyAgentBinary(
	machineAgent string,
	unitAgents []string,
	dataDir, toSeries, fromSeries string,
	jujuVersion version.Number,
) (err error) {
	defer func() {
		if err != nil {
			err = errors.Annotate(err, "failed to copy tools")
		}
	}()

	// Setup new and old version.Binary instances with different series.
	fromVers := version.Binary{
		Number: jujuVersion,
		Arch:   arch.HostArch(),
		Series: fromSeries,
	}
	toVers := version.Binary{
		Number: jujuVersion,
		Arch:   arch.HostArch(),
		Series: toSeries,
	}

	// If tools with the new series don't already exist, copy
	// current tools to new directory with correct series.
	if _, err = os.Stat(tools.SharedToolsDir(dataDir, toVers)); err != nil {
		// Copy tools to new directory with correct series.
		if err = fs.Copy(tools.SharedToolsDir(dataDir, fromVers), tools.SharedToolsDir(dataDir, toVers)); err != nil {
			return err
		}
	}

	// Write tools metadata with new version, however don't change
	// the URL, so we know where it came from.
	jujuTools, err := tools.ReadTools(dataDir, toVers)
	if err != nil {
		return errors.Trace(err)
	}

	// Only write once
	if jujuTools.Version != toVers {
		jujuTools.Version = toVers
		if err = tools.WriteToolsMetadataData(tools.ToolsDir(dataDir, toVers.String()), jujuTools); err != nil {
			return err
		}
	}

	// Update Agent Tool links
	var lastError error
	for _, agentName := range append(unitAgents, machineAgent) {
		toolPath := tools.ToolsDir(dataDir, toVers.String())
		toolsDir := tools.ToolsDir(dataDir, agentName)

		err = symlink.Replace(toolsDir, toolPath)
		if err != nil {
			lastError = err
		}
	}

	return lastError
}
source: func (e *PerfEvent) allocateBuffers() {
	// C.malloc() will crash the program if allocation fails, skip check:
	// https://golang.org/cmd/cgo/
	e.state = C.malloc(C.size_t(unsafe.Sizeof(C.struct_read_state{})))
	e.buf = C.malloc(C.size_t(e.pagesize))
}
source: func NewCommandLineApp(v interface{}) (*kingpin.Application, error) {
	s := reflect.ValueOf(v).Elem()
	app := kingpin.New("app", "Auto generated command line application")
	if err := setupApp(app, s); err != nil {
		return nil, trace.Wrap(err)
	}
	return app, nil
}
source: func (cli *Client) newPUBLISHPacket(opts *PublishOptions) (packet.Packet, error) {
	// Define a Packet Identifier.
	var packetID uint16

	if opts.QoS != mqtt.QoS0 {
		// Lock for reading and updating the Session.
		cli.muSess.Lock()

		defer cli.muSess.Unlock()

		// Define an error.
		var err error

		// Generate a Packet Identifer.
		if packetID, err = cli.generatePacketID(); err != nil {
			return nil, err
		}
	}

	// Create a PUBLISH Packet.
	p, err := packet.NewPUBLISH(&packet.PUBLISHOptions{
		QoS:       opts.QoS,
		Retain:    opts.Retain,
		TopicName: opts.TopicName,
		PacketID:  packetID,
		Message:   opts.Message,
	})
	if err != nil {
		return nil, err
	}

	if opts.QoS != mqtt.QoS0 {
		// Set the Packet to the Session.
		cli.sess.sendingPackets[packetID] = p
	}

	// Return the Packet.
	return p, nil
}
source: func (r *ImageStreamByAnnotationSearcher) Search(precise bool, terms ...string) (ComponentMatches, []error) {
	matches := ComponentMatches{}
	var errs []error
	for _, namespace := range r.Namespaces {
		streams, err := r.getImageStreams(namespace)
		if err != nil {
			errs = append(errs, err)
			continue
		}
		for i := range streams {
			for _, term := range terms {
				if term == "__imagestreamannotation_fail" {
					errs = append(errs, fmt.Errorf("unable to find the specified image: %s", term))
					continue
				}
				klog.V(5).Infof("Checking imagestream %s/%s for supports annotation %q", namespace, streams[i].Name, term)
				matches = append(matches, r.annotationMatches(&streams[i], term)...)
			}
		}
		if precise {
			for _, m := range matches {
				if m.Score == 0.0 {
					return matches, errs
				}
			}
		}
	}
	return matches, errs
}
source: func GetSrcPath(importPath string) (appPath string, err error) {
	paths := GetGOPATHs()
	for _, p := range paths {
		if IsExist(p + "/src/" + importPath + "/") {
			appPath = p + "/src/" + importPath + "/"
			break
		}
	}

	if len(appPath) == 0 {
		return "", errors.New("Unable to locate source folder path")
	}

	appPath = filepath.Dir(appPath) + "/"
	if runtime.GOOS == "windows" {
		// Replace all '\' to '/'.
		appPath = strings.Replace(appPath, "\\", "/", -1)
	}

	return appPath, nil
}
source: func (c *Conn) parseRow(data []byte, fields []*querypb.Field) ([]sqltypes.Value, error) {
	colNumber := len(fields)
	result := make([]sqltypes.Value, colNumber)
	pos := 0
	for i := 0; i < colNumber; i++ {
		if data[pos] == 0xfb {
			pos++
			continue
		}
		var s []byte
		var ok bool
		s, pos, ok = readLenEncStringAsBytes(data, pos)
		if !ok {
			return nil, NewSQLError(CRMalformedPacket, SSUnknownSQLState, "decoding string failed")
		}
		result[i] = sqltypes.MakeTrusted(fields[i].Type, s)
	}
	return result, nil
}
source: func (m *Mounter) reload(device string, newM *Info) error {
	m.Lock()
	defer m.Unlock()

	// New mountable has no mounts, delete old mounts.
	if newM == nil {
		delete(m.mounts, device)
		return nil
	}

	// Old mountable had no mounts, copy over new mounts.
	oldM, ok := m.mounts[device]
	if !ok {
		m.mounts[device] = newM
		return nil
	}

	// Overwrite old mount entries into new mount table, preserving refcnt.
	for _, oldP := range oldM.Mountpoint {
		for j, newP := range newM.Mountpoint {
			if newP.Path == oldP.Path {
				newM.Mountpoint[j] = oldP
				break
			}
		}
	}

	// Purge old mounts.
	m.mounts[device] = newM
	return nil
}
source: func Create(db walletdb.DB, pubPass, privPass, seed []byte, params *chaincfg.Params,
	birthday time.Time) error {

	// If a seed was provided, ensure that it is of valid length. Otherwise,
	// we generate a random seed for the wallet with the recommended seed
	// length.
	if seed == nil {
		hdSeed, err := hdkeychain.GenerateSeed(
			hdkeychain.RecommendedSeedLen)
		if err != nil {
			return err
		}
		seed = hdSeed
	}
	if len(seed) < hdkeychain.MinSeedBytes ||
		len(seed) > hdkeychain.MaxSeedBytes {
		return hdkeychain.ErrInvalidSeedLen
	}

	return walletdb.Update(db, func(tx walletdb.ReadWriteTx) error {
		addrmgrNs, err := tx.CreateTopLevelBucket(waddrmgrNamespaceKey)
		if err != nil {
			return err
		}
		txmgrNs, err := tx.CreateTopLevelBucket(wtxmgrNamespaceKey)
		if err != nil {
			return err
		}

		err = waddrmgr.Create(
			addrmgrNs, seed, pubPass, privPass, params, nil,
			birthday,
		)
		if err != nil {
			return err
		}
		return wtxmgr.Create(txmgrNs)
	})
}
source: func (s *ReportStatus) Decode(r io.Reader) error {
	scan := pktline.NewScanner(r)
	if err := s.scanFirstLine(scan); err != nil {
		return err
	}

	if err := s.decodeReportStatus(scan.Bytes()); err != nil {
		return err
	}

	flushed := false
	for scan.Scan() {
		b := scan.Bytes()
		if isFlush(b) {
			flushed = true
			break
		}

		if err := s.decodeCommandStatus(b); err != nil {
			return err
		}
	}

	if !flushed {
		return fmt.Errorf("missing flush")
	}

	return scan.Err()
}
source: func equalExtensions(base reflect.Type, x1, x2 XXX_InternalExtensions) bool {
	em1, _ := x1.extensionsRead()
	em2, _ := x2.extensionsRead()
	return equalExtMap(base, em1, em2)
}
source: func (r *SublistResult) addSubToResult(sub *subscription) *SublistResult {
	// Copy since others may have a reference.
	nr := copyResult(r)
	if sub.queue == nil {
		nr.psubs = append(nr.psubs, sub)
	} else {
		if i := findQSlot(sub.queue, nr.qsubs); i >= 0 {
			nr.qsubs[i] = append(nr.qsubs[i], sub)
		} else {
			nr.qsubs = append(nr.qsubs, []*subscription{sub})
		}
	}
	return nr
}
source: func (s *State) StateSnapshotMeta() statemgr.SnapshotMeta {
	return statemgr.SnapshotMeta{
		Lineage: s.lineage,
		Serial:  s.serial,
	}
}
source: func typeForSchema(schema *openapi.Schema) string {
	if schema.XRef != "" {
		return "reference"
	}
	if len(schema.Enum) > 0 {
		enumType := typeNameForSchema(schema)
		return "enum-of-" + enumType
	}
	typeName := typeNameForSchema(schema)
	if typeName == "array" {
		if schema.Items != nil {
			// items contains an array of schemas
			itemType := ""
			for i, itemSchema := range schema.Items.Schema {
				if i > 0 {
					itemType += "|"
				}
				itemType += typeForSchema(itemSchema)
			}
			return "array-of-" + itemType
		} else if schema.XRef != "" {
			return "array-of-reference"
		} else {
			// we need to do more work to understand this type
			return fmt.Sprintf("array-of-[%+v]", schema)
		}
	} else if typeName == "object" {
		// this object might be representable with a map
		// but not if it has properties
		if (schema.Properties != nil) && (len(schema.Properties.AdditionalProperties) > 0) {
			return typeName
		}
		if schema.AdditionalProperties != nil {
			if schema.AdditionalProperties.GetSchema() != nil {
				additionalPropertiesSchemaType := typeForSchema(schema.AdditionalProperties.GetSchema())
				return "map-of-" + additionalPropertiesSchemaType
			}
			if schema.AdditionalProperties.GetBoolean() == false {
				// no additional properties are allowed, so we're not sure what to do if we get here...
				return typeName
			}
		}
		if schema.Items != nil {
			itemType := ""
			for i, itemSchema := range schema.Items.Schema {
				if i > 0 {
					itemType += "|"
				}
				itemType += typeForSchema(itemSchema)
			}
			return "map-of-" + itemType
		}
		return "map-of-object"
	} else {
		return typeName
	}
}
source: func (s *Struct) nested(val reflect.Value) interface{} {
	var finalVal interface{}

	v := reflect.ValueOf(val.Interface())
	if v.Kind() == reflect.Ptr {
		v = v.Elem()
	}

	switch v.Kind() {
	case reflect.Struct:
		n := New(val.Interface())
		n.TagName = s.TagName
		m := n.Map()

		// do not add the converted value if there are no exported fields, ie:
		// time.Time
		if len(m) == 0 {
			finalVal = val.Interface()
		} else {
			finalVal = m
		}
	case reflect.Map:
		// get the element type of the map
		mapElem := val.Type()
		switch val.Type().Kind() {
		case reflect.Ptr, reflect.Array, reflect.Map,
			reflect.Slice, reflect.Chan:
			mapElem = val.Type().Elem()
			if mapElem.Kind() == reflect.Ptr {
				mapElem = mapElem.Elem()
			}
		}

		// only iterate over struct types, ie: map[string]StructType,
		// map[string][]StructType,
		if mapElem.Kind() == reflect.Struct ||
			(mapElem.Kind() == reflect.Slice &&
				mapElem.Elem().Kind() == reflect.Struct) {
			m := make(map[string]interface{}, val.Len())
			for _, k := range val.MapKeys() {
				m[k.String()] = s.nested(val.MapIndex(k))
			}
			finalVal = m
			break
		}

		// TODO(arslan): should this be optional?
		finalVal = val.Interface()
	case reflect.Slice, reflect.Array:
		if val.Type().Kind() == reflect.Interface {
			finalVal = val.Interface()
			break
		}

		// TODO(arslan): should this be optional?
		// do not iterate of non struct types, just pass the value. Ie: []int,
		// []string, co... We only iterate further if it's a struct.
		// i.e []foo or []*foo
		if val.Type().Elem().Kind() != reflect.Struct &&
			!(val.Type().Elem().Kind() == reflect.Ptr &&
				val.Type().Elem().Elem().Kind() == reflect.Struct) {
			finalVal = val.Interface()
			break
		}

		slices := make([]interface{}, val.Len())
		for x := 0; x < val.Len(); x++ {
			slices[x] = s.nested(val.Index(x))
		}
		finalVal = slices
	default:
		finalVal = val.Interface()
	}

	return finalVal
}
source: func (s *Location) SetLocationCode(v string) *Location {
	s.LocationCode = &v
	return s
}
source: func (fcr *FileCustomRule) GetRules() (qrs *rules.Rules, version int64, err error) {
	return fcr.currentRuleSet.Copy(), fcr.currentRuleSetTimestamp, nil
}
source: func sliceDiff(expected, actual []string) *Result {
	udiff := difflib.UnifiedDiff{
		A:        expected,
		FromFile: "expected",
		B:        actual,
		ToFile:   "actual",
		Context:  2,
	}
	diff, err := difflib.GetUnifiedDiffString(udiff)
	if err != nil {
		// This can only happen if a write to a byte buffer fails, so can
		// effectively be ignored, except in case of hardware failure or OOM.
		panic(err)
	}
	if diff == "" {
		return nil
	}
	return &Result{diff: diff}

}
source: func (d *DockerMonitor) Resync(ctx context.Context) error {

	if !d.syncAtStart || d.config.Policy == nil {
		zap.L().Debug("No synchronization of containers performed")
		return nil
	}

	zap.L().Debug("Syncing all existing containers")

	options := types.ContainerListOptions{All: true}
	containers, err := d.dockerClient.ContainerList(ctx, options)
	if err != nil {
		return fmt.Errorf("unable to get container list: %s", err)
	}

	return d.resyncContainers(ctx, containers)
}
source: func (user *User) UnmarshalJSON(data []byte) error {
	var ccUser struct {
		Metadata internal.Metadata `json:"metadata"`
	}
	err := cloudcontroller.DecodeJSON(data, &ccUser)
	if err != nil {
		return err
	}

	user.GUID = ccUser.Metadata.GUID
	return nil
}
source: func listSeparator() string {
	if pathListSep == "" {
		len := utf8.RuneLen(filepath.ListSeparator)
		if len < 0 {
			panic("filepath.ListSeparator is not valid utf8?!")
		}
		buf := make([]byte, len)
		len = utf8.EncodeRune(buf, filepath.ListSeparator)
		pathListSep = string(buf[:len])
	}

	return pathListSep
}
source: func ParseAppKey(input string) (key AppKey, err error) {
	aes128key, err := ParseAES128Key(input)
	if err != nil {
		return
	}
	key = AppKey(aes128key)
	return
}
source: func (fs *FileSessionStore) Get(key interface{}) interface{} {
	fs.lock.RLock()
	defer fs.lock.RUnlock()
	if v, ok := fs.values[key]; ok {
		return v
	}
	return nil
}
source: func (s *SelectQuery) UnionAll(q *Query) *SelectQuery {
	s.union = append(s.union, UnionInfo{true, q})
	return s
}
source: func MultipleChoices(w http.ResponseWriter, response interface{}) {
	Respond(w, http.StatusMultipleChoices, response)
}
source: func atoi(b []byte) (int, error) {
	if len(b) > len(powers) {
		return 0, fmt.Errorf("sam: integer overflow: %q", b)
	}
	var n int64
	k := len(b) - 1
	for i, v := range b {
		n += int64(v-'0') * powers[k-i]
		if int64(int(n)) != n {
			return 0, fmt.Errorf("sam: integer overflow: %q at %d", b, i)
		}
	}
	return int(n), nil
}
source: func (s *stopChan) IfElseStopped(stopped func(), notStopped func()) {
	if s == nil {
		stopped()
		return
	}
	s.cond.L.Lock()
	defer s.cond.L.Unlock()
	if s.stopped {
		stopped()
	} else {
		notStopped()
	}
}
source: func (h *HotSwapHandler) Set(key string, value interface{}, args ...interface{}) error {
	return h.handler.Set(key, value, args...)
}
source: func NewMustRunAs(options *policy.RunAsUserStrategyOptions) (RunAsUserStrategy, error) {
	if options == nil {
		return nil, fmt.Errorf("MustRunAs requires run as user options")
	}
	if len(options.Ranges) == 0 {
		return nil, fmt.Errorf("MustRunAs requires at least one range")
	}
	return &mustRunAs{
		opts: options,
	}, nil
}
source: func IsConnErr(err error) bool {
	return err == ErrNoClient || errors.Cause(err) == ErrNoClient
}
source: func (f Firewall) RemoveACLAndRules(machineId string) error {
	groupName := f.machineGroupName(machineId)
	resourceName := f.client.ComposeName(groupName)
	secRules, err := f.getAllSecurityRules(resourceName)
	if err != nil {
		return err
	}
	for _, val := range secRules {
		err := f.client.DeleteSecurityRule(val.Name)
		if err != nil {
			if !api.IsNotFound(err) {
				return err
			}
		}
	}
	err = f.client.DeleteAcl(resourceName)
	if err != nil {
		if !api.IsNotFound(err) {
			return err
		}
	}
	return nil
}
source: func After(f func(context.Context, ...*cdp.Node) error) QueryOption {
	return func(s *Selector) {
		s.after = f
	}
}
source: func enforceRequirements(flags *applyPlanFlags, dryRun bool, newK8sVersion string) (clientset.Interface, upgrade.VersionGetter, *kubeadmapi.InitConfiguration, error) {
	ignorePreflightErrorsSet, err := validation.ValidateIgnorePreflightErrors(flags.ignorePreflightErrors)
	if err != nil {
		return nil, nil, nil, err
	}

	// Ensure the user is root
	klog.V(1).Info("running preflight checks")
	if err := runPreflightChecks(ignorePreflightErrorsSet); err != nil {
		return nil, nil, nil, err
	}

	client, err := getClient(flags.kubeConfigPath, dryRun)
	if err != nil {
		return nil, nil, nil, errors.Wrapf(err, "couldn't create a Kubernetes client from file %q", flags.kubeConfigPath)
	}

	// Check if the cluster is self-hosted
	if upgrade.IsControlPlaneSelfHosted(client) {
		return nil, nil, nil, errors.New("cannot upgrade a self-hosted control plane")
	}

	// Run healthchecks against the cluster
	if err := upgrade.CheckClusterHealth(client, ignorePreflightErrorsSet); err != nil {
		return nil, nil, nil, errors.Wrap(err, "[upgrade/health] FATAL")
	}

	// Fetch the configuration from a file or ConfigMap and validate it
	fmt.Println("[upgrade/config] Making sure the configuration is correct:")

	var cfg *kubeadmapi.InitConfiguration
	if flags.cfgPath != "" {
		cfg, err = configutil.LoadInitConfigurationFromFile(flags.cfgPath)
	} else {
		cfg, err = configutil.FetchInitConfigurationFromCluster(client, os.Stdout, "upgrade/config", false)
	}

	if err != nil {
		if apierrors.IsNotFound(err) {
			fmt.Printf("[upgrade/config] In order to upgrade, a ConfigMap called %q in the %s namespace must exist.\n", constants.KubeadmConfigConfigMap, metav1.NamespaceSystem)
			fmt.Println("[upgrade/config] Without this information, 'kubeadm upgrade' won't know how to configure your upgraded cluster.")
			fmt.Println("")
			fmt.Println("[upgrade/config] Next steps:")
			fmt.Printf("\t- OPTION 1: Run 'kubeadm config upload from-flags' and specify the same CLI arguments you passed to 'kubeadm init' when you created your control-plane.\n")
			fmt.Printf("\t- OPTION 2: Run 'kubeadm config upload from-file' and specify the same config file you passed to 'kubeadm init' when you created your control-plane.\n")
			fmt.Printf("\t- OPTION 3: Pass a config file to 'kubeadm upgrade' using the --config flag.\n")
			fmt.Println("")
			err = errors.Errorf("the ConfigMap %q in the %s namespace used for getting configuration information was not found", constants.KubeadmConfigConfigMap, metav1.NamespaceSystem)
		}
		return nil, nil, nil, errors.Wrap(err, "[upgrade/config] FATAL")
	}

	// If a new k8s version should be set, apply the change before printing the config
	if len(newK8sVersion) != 0 {
		cfg.KubernetesVersion = newK8sVersion
	}

	// If features gates are passed to the command line, use it (otherwise use featureGates from configuration)
	if flags.featureGatesString != "" {
		cfg.FeatureGates, err = features.NewFeatureGate(&features.InitFeatureGates, flags.featureGatesString)
		if err != nil {
			return nil, nil, nil, errors.Wrap(err, "[upgrade/config] FATAL")
		}
	}

	// Check if feature gate flags used in the cluster are consistent with the set of features currently supported by kubeadm
	if msg := features.CheckDeprecatedFlags(&features.InitFeatureGates, cfg.FeatureGates); len(msg) > 0 {
		for _, m := range msg {
			fmt.Printf("[upgrade/config] %s\n", m)
		}
		return nil, nil, nil, errors.New("[upgrade/config] FATAL. Unable to upgrade a cluster using deprecated feature-gate flags. Please see the release notes")
	}

	// If the user told us to print this information out; do it!
	if flags.printConfig {
		printConfiguration(&cfg.ClusterConfiguration, os.Stdout)
	}

	// Use a real version getter interface that queries the API server, the kubeadm client and the Kubernetes CI system for latest versions
	return client, upgrade.NewOfflineVersionGetter(upgrade.NewKubeVersionGetter(client, os.Stdout), newK8sVersion), cfg, nil
}
source: func NewProvider(config *ProviderConfig) (*Provider, error) {
	if err := validateConfig(config); err != nil {
		return nil, err
	}

	// Create logger
	if config.LogOutput == nil {
		config.LogOutput = os.Stderr
	}
	logger := log.New(config.LogOutput, "", log.LstdFlags)

	p := &Provider{
		config:     config,
		logger:     logger,
		shutdownCh: make(chan struct{}),
	}
	go p.run()
	return p, nil
}
source: func NewWriter(w io.Writer) WriteCloser {
	return &writer{W: w, lock: new(sync.Mutex)}
}
source: func NewLogger(api LoggerAPI, tag names.Tag, loggingOverride string, updateCallback func(string) error) (worker.Worker, error) {
	logger := &Logger{
		api:            api,
		tag:            tag,
		updateCallback: updateCallback,
		lastConfig:     loggo.LoggerInfo(),
		configOverride: loggingOverride,
	}
	log.Debugf("initial log config: %q", logger.lastConfig)

	w, err := watcher.NewNotifyWorker(watcher.NotifyConfig{
		Handler: logger,
	})
	if err != nil {
		return nil, errors.Trace(err)
	}
	return w, nil
}
source: func (r *Application) AddPortDefinition(portDefinition PortDefinition) *Application {
	if r.PortDefinitions == nil {
		r.EmptyPortDefinitions()
	}

	portDefinitions := *r.PortDefinitions
	portDefinitions = append(portDefinitions, portDefinition)
	r.PortDefinitions = &portDefinitions
	return r
}
source: func identityReferencesUser(identity *userapi.Identity, user *userapi.User) bool {
	return identity.User.Name == user.Name && identity.User.UID == user.UID
}
source: func (t *TreeView) SetRoot(root *TreeNode) *TreeView {
	t.root = root
	return t
}
source: func (doc *PluginDocument) DumpString() string {
	str := ""
	str += "==================== START DUMP ============================\n"
	str += "PackageName: [" + doc.PackageName + "]\n"
	str += "PluginName:  [" + doc.PluginName + "]\n"
	str += "BlockHeading: [" + doc.BlockHeading + "]\n"
	str += "Description: [" + doc.Description + "]\n\n"
	str += "Parameters: [" + "\n"
	str += doc.Parameters.dumpString() + "\n"
	str += "]\n\n"
	for parentName, defMap := range doc.InheritedParameters {
		str += "Parameters (from " + parentName + ")[\n"
		str += defMap.dumpString() + "\n"
		str += "]\n\n"
	}
	str += "Metadata: [" + "\n"
	str += doc.Metadata.dumpString() + "\n"
	for parentName, defMap := range doc.InheritedMetadata {
		str += "Metadata (from " + parentName + ")[\n"
		str += defMap.dumpString() + "\n"
		str += "]\n\n"
	}
	str += "Example: [" + "\n------------\n" + doc.Example + "\n----------]\n"
	str += "==================== END DUMP ============================\n"
	return str
}
source: func (d *DirtyBlockCacheStandard) Shutdown() error {
	func() {
		d.shutdownLock.Lock()
		defer d.shutdownLock.Unlock()
		d.isShutdown = true
		close(d.shutdownChan)
	}()

	d.reqWg.Wait()
	close(d.requestsChan)
	d.lock.Lock()
	defer d.lock.Unlock()
	// Clear out the remaining requests
	for req := range d.requestsChan {
		d.updateWaitBufLocked(req.bytes)
	}
	if d.syncBufBytes != 0 || d.waitBufBytes != 0 || d.ignoreSyncBytes != 0 {
		return fmt.Errorf("Unexpected dirty bytes leftover on shutdown: "+
			"syncBuf=%d, waitBuf=%d, ignore=%d",
			d.syncBufBytes, d.waitBufBytes, d.ignoreSyncBytes)
	}
	return nil
}
source: func (t Term) Avg(args ...interface{}) Term {
	return constructMethodTerm(t, "Avg", p.Term_AVG, funcWrapArgs(args), map[string]interface{}{})
}
source: func (n *Node) isLeader() bool {
	if !n.IsMember() {
		return false
	}

	if n.Status().Lead == n.Config.ID {
		return true
	}
	return false
}
source: func (s *CreateCachediSCSIVolumeInput) SetSourceVolumeARN(v string) *CreateCachediSCSIVolumeInput {
	s.SourceVolumeARN = &v
	return s
}
source: func (config FlagConfig) Validate() error {
	if config.Clock == nil {
		return errors.NotValidf("nil Clock")
	}
	if config.Facade == nil {
		return errors.NotValidf("nil Facade")
	}
	if config.Duration <= 0 {
		return errors.NotValidf("non-positive Duration")
	}
	return nil
}
source: func RunGit(args ...string) string {
	cmd := exec.Command("git", args...)
	var stdout, stderr bytes.Buffer
	cmd.Stdout, cmd.Stderr = &stdout, &stderr
	if err := cmd.Run(); err == exec.ErrNotFound {
		if !warnedAboutGit {
			log.Println("Warning: can't find 'git' in PATH")
			warnedAboutGit = true
		}
		return ""
	} else if err != nil {
		log.Fatal(strings.Join(cmd.Args, " "), ": ", err, "\n", stderr.String())
	}
	return strings.TrimSpace(stdout.String())
}
source: func New(err error) HandlerError {
	return HandlerError{Err: err, Stack: debug.Stack()}
}
source: func (s *Server) resolveRevision(ctx context.Context, app *appv1.Application, syncReq *ApplicationSyncRequest) (string, string, error) {
	ambiguousRevision := syncReq.Revision
	if ambiguousRevision == "" {
		ambiguousRevision = app.Spec.Source.TargetRevision
	}
	if git.IsCommitSHA(ambiguousRevision) {
		// If it's already a commit SHA, then no need to look it up
		return ambiguousRevision, ambiguousRevision, nil
	}
	repo, err := s.db.GetRepository(ctx, app.Spec.Source.RepoURL)
	if err != nil {
		// If we couldn't retrieve from the repo service, assume public repositories
		repo = &appv1.Repository{Repo: app.Spec.Source.RepoURL}
	}
	gitClient, err := s.gitFactory.NewClient(repo.Repo, "", repo.Username, repo.Password, repo.SSHPrivateKey, repo.InsecureIgnoreHostKey)
	if err != nil {
		return "", "", err
	}
	commitSHA, err := gitClient.LsRemote(ambiguousRevision)
	if err != nil {
		return "", "", err
	}
	displayRevision := fmt.Sprintf("%s (%s)", ambiguousRevision, commitSHA)
	return commitSHA, displayRevision, nil
}
source: func (row *Row) GetUpdatePlaceholders(driver string) []string {
	placeholders := make([]string, row.GetUpdateColumnsLength())
	for i, c := range row.GetUpdateColumns() {
		if driver == postgresDriver {
			placeholders[i] = fmt.Sprintf("%s = $%d", c, i+1)
		} else {
			placeholders[i] = fmt.Sprintf("%s = ?", c)
		}
	}
	return placeholders
}
source: func (ew *EventWorker) Flush() []ssf.SSFSample {
	ew.mutex.Lock()

	retsamples := ew.samples
	// these slices will be allocated again at append time
	ew.samples = nil

	ew.mutex.Unlock()
	if len(retsamples) != 0 {
		ew.stats.Count("worker.other_samples_flushed_total", int64(len(retsamples)), nil, 1.0)
	}
	return retsamples
}
source: func NewCmdPatch(fullName string, f kcmdutil.Factory, streams genericclioptions.IOStreams) *cobra.Command {
	cmd := patch.NewCmdPatch(f, streams)
	cmd.Long = patchLong
	cmd.Example = fmt.Sprintf(patchExample, fullName)
	return cmd
}
source: func deserializeChainedAddress(row *dbAddressRow) (*dbChainAddressRow, error) {
	// The serialized chain address raw data format is:
	//   <branch><index>
	//
	// 4 bytes branch + 4 bytes address index
	if len(row.rawData) != 8 {
		str := "malformed serialized chained address"
		return nil, managerError(ErrDatabase, str, nil)
	}

	retRow := dbChainAddressRow{
		dbAddressRow: *row,
	}

	retRow.branch = binary.LittleEndian.Uint32(row.rawData[0:4])
	retRow.index = binary.LittleEndian.Uint32(row.rawData[4:8])

	return &retRow, nil
}
source: func (c Configuration) NewOptions() Options {
	opts := NewOptions()
	if c.MaxPositiveSkew != 0 {
		opts = opts.SetMaxPositiveSkew(c.MaxPositiveSkew)
	}
	if c.MaxNegativeSkew != 0 {
		opts = opts.SetMaxNegativeSkew(c.MaxNegativeSkew)
	}
	return opts
}
source: func JoinEnvNumbered(prefix, delimiter string, startInt uint8, includeBase bool) string {
	vals := []string{}
	if includeBase {
		val := os.Getenv(prefix)
		if len(val) > 0 {
			vals = append(vals, val)
		}
	}
	i := startInt
	for {
		val := os.Getenv(fmt.Sprintf("%s_%d", prefix, i))
		if len(val) > 0 {
			vals = append(vals, val)
		} else {
			break
		}
		i++
	}
	return strings.Join(vals, delimiter)
}
source: func LowercaseKey(handler cfg.Handler) cfg.Handler {
	return Apply(func(key string) (string, error) { return strings.ToLower(key), nil }, nil, handler)
}
source: func (sm *SyncManager) Stop() error {
	if atomic.AddInt32(&sm.shutdown, 1) != 1 {
		log.Warnf("Sync manager is already in the process of " +
			"shutting down")
		return nil
	}

	log.Infof("Sync manager shutting down")
	close(sm.quit)
	sm.wg.Wait()
	return nil
}
source: func newSocket(s *Server) *Socket {
	a := &Socket{
		writeChan: make(chan string, global.WriteChanSize),
		readChan:  make(chan string, global.ReadChanSize),
	}

	// Set the closer function.
	a.closer = closer.New(func() {
		// Remove the ajax socket from the map.
		if len(a.uid) > 0 {
			func() {
				s.socketsMutex.Lock()
				defer s.socketsMutex.Unlock()

				delete(s.sockets, a.uid)
			}()
		}
	})

	return a
} 92%|█████████▏| 4602/5000 [00:05<00:00, 954.76it/s]
source: func applyRBAC(kubeContext *KubernetesContext) error {
	k8sClient, err := kubeContext.KubernetesClient()
	if err != nil {
		return fmt.Errorf("error connecting to kubernetes: %v", err)
	}
	clientset := k8sClient.(*kubernetes.Clientset)

	var errors []error
	// kube-dns & kube-proxy service accounts
	if err := createServiceAccounts(clientset); err != nil {
		errors = append(errors, fmt.Errorf("error creating service accounts: %v", err))
	}
	//Currently all kubeadm specific
	if err := createClusterRoleBindings(clientset); err != nil {
		errors = append(errors, fmt.Errorf("error creating cluster role bindings: %v", err))
	}

	if len(errors) != 0 {
		if len(errors) != 1 {
			for _, err := range errors {
				glog.Warningf("Error configuring RBAC: %v", err)
			}
		}
		return errors[0]
	}

	return nil
}
source: func (n *Name) AddTextEntry(field, value string) error {
	cfield := C.CString(field)
	defer C.free(unsafe.Pointer(cfield))
	cvalue := (*C.uchar)(unsafe.Pointer(C.CString(value)))
	defer C.free(unsafe.Pointer(cvalue))
	ret := C.X509_NAME_add_entry_by_txt(
		n.name, cfield, C.MBSTRING_ASC, cvalue, -1, -1, 0)
	if ret != 1 {
		return errors.New("failed to add x509 name text entry")
	}
	return nil
}
source: func EncodeComparableVarint(b []byte, v int64) []byte {
	if v < 0 {
		// All negative value has a tag byte prefix (negativeTagEnd - length).
		// Smaller negative value encodes to more bytes, has smaller tag.
		if v >= -0xff {
			return append(b, negativeTagEnd-1, byte(v))
		} else if v >= -0xffff {
			return append(b, negativeTagEnd-2, byte(v>>8), byte(v))
		} else if v >= -0xffffff {
			return append(b, negativeTagEnd-3, byte(v>>16), byte(v>>8), byte(v))
		} else if v >= -0xffffffff {
			return append(b, negativeTagEnd-4, byte(v>>24), byte(v>>16), byte(v>>8), byte(v))
		} else if v >= -0xffffffffff {
			return append(b, negativeTagEnd-5, byte(v>>32), byte(v>>24), byte(v>>16), byte(v>>8), byte(v))
		} else if v >= -0xffffffffffff {
			return append(b, negativeTagEnd-6, byte(v>>40), byte(v>>32), byte(v>>24), byte(v>>16), byte(v>>8),
				byte(v))
		} else if v >= -0xffffffffffffff {
			return append(b, negativeTagEnd-7, byte(v>>48), byte(v>>40), byte(v>>32), byte(v>>24), byte(v>>16),
				byte(v>>8), byte(v))
		}
		return append(b, negativeTagEnd-8, byte(v>>56), byte(v>>48), byte(v>>40), byte(v>>32), byte(v>>24),
			byte(v>>16), byte(v>>8), byte(v))
	}
	return EncodeComparableUvarint(b, uint64(v))
}
source: func open() (pty, tty *os.File, err error) {
	p, err := os.OpenFile("/dev/ptmx", os.O_RDWR, 0)
	if err != nil {
		return nil, nil, err
	}
	// In case of error after this point, make sure we close the ptmx fd.
	defer func() {
		if err != nil {
			_ = p.Close() // Best effort.
		}
	}()

	sname, err := ptsname(p)
	if err != nil {
		return nil, nil, err
	}

	if err := grantpt(p); err != nil {
		return nil, nil, err
	}

	if err := unlockpt(p); err != nil {
		return nil, nil, err
	}

	t, err := os.OpenFile(sname, os.O_RDWR, 0)
	if err != nil {
		return nil, nil, err
	}
	return p, t, nil
}
source: func InNamed(column, name string) Cmp {
	return Cmp{
		op:     in,
		column: column,
		value:  param(name),
	}
}
source: func (entry ImageEntry) MarshalJSON() ([]byte, error) {
	// We can only do it this way because it's explicitly an either-or
	// -- I don't know of a way to inline all the fields when one of
	// the things you're inlining defines its own MarshalJSON.
	if entry.ExcludedReason != "" {
		return json.Marshal(entry.Excluded)
	}
	return json.Marshal(entry.Info)
}
source: func NewZipkin(enabled bool, headersToLog []string, logger logger.Logger) *Zipkin {
	return &Zipkin{
		zipkinEnabled: enabled,
		headersToLog:  headersToLog,
		logger:        logger,
	}
}
source: func waitForPods(k8s config.KubernetesConfig, quiet bool) error {
	// Do not wait for "k8s-app" pods in the case of CNI, as they are managed
	// by a CNI plugin which is usually started after minikube has been brought
	// up. Otherwise, minikube won't start, as "k8s-app" pods are not ready.
	componentsOnly := k8s.NetworkPlugin == "cni"

	if !quiet {
		console.OutStyle("waiting-pods", "Waiting for pods:")
	}
	client, err := util.GetClient()
	if err != nil {
		return errors.Wrap(err, "k8s client")
	}

	for _, p := range PodsByLayer {
		if componentsOnly && p.key != "component" {
			continue
		}

		if !quiet {
			console.Out(" %s", p.name)
		}
		selector := labels.SelectorFromSet(labels.Set(map[string]string{p.key: p.value}))
		if err := util.WaitForPodsWithLabelRunning(client, "kube-system", selector); err != nil {
			return errors.Wrap(err, fmt.Sprintf("waiting for %s=%s", p.key, p.value))
		}
	}
	if !quiet {
		console.OutLn("")
	}
	return nil
}
source: func (q *ParentIdQuery) QueryName(queryName string) *ParentIdQuery {
	q.queryName = queryName
	return q
}
source: func NewProfiler() (p *Profiler) {
	prof := numa.NewProfiler()
	return &Profiler{Profiler: prof, Builder: fb.NewBuilder(0)}
}
source: func (r Row) GetFloat64(colIdx int) float64 {
	col := r.c.columns[colIdx]
	return *(*float64)(unsafe.Pointer(&col.data[r.idx*8]))
}
source: func (sa *StorageAuthority) CountPendingAuthorizations(_ context.Context, _ int64) (int, error) {
	return 0, nil
}
source: func IsManagedObjectNotFoundError(err error) bool {
	isManagedObjectNotFoundError := false
	if soap.IsSoapFault(err) {
		_, isManagedObjectNotFoundError = soap.ToSoapFault(err).VimFault().(types.ManagedObjectNotFound)
	}
	return isManagedObjectNotFoundError
}
source: func WithHandle500(fn func(rw http.ResponseWriter, req *http.Request, err error)) option {
	return func(m *Module) {
		m.handle500 = fn
	}
}
source: func (bg *Writer) Close() error {
	if !bg.closed {
		c := bg.active
		bg.queue <- c
		bg.qwg.Add(1)
		<-bg.waiting
		c.writeBlock()
		bg.closed = true
		close(bg.queue)
		bg.wg.Wait()
		if bg.err == nil {
			_, bg.err = bg.w.Write([]byte(magicBlock))
		}
	}
	return bg.err
}
source: func GetIP(code dhcp4.OptionCode, o dhcp4.Options) IP {
	v := o.Get(code)
	if v == nil {
		return nil
	}
	var ip IP
	if err := (&ip).UnmarshalBinary(v); err != nil {
		return nil
	}
	return ip
}
source: func (ctr *ContainerController) HandleGetAccessories(r io.Reader) (io.Reader, error) {
	result, err := json.Marshal(ctr.container)
	return bytes.NewBuffer(result), err
}
source: func (s *FileSet) Position(p Pos) (pos Position) {
	if p != NoPos {
		// TODO(gri) consider optimizing the case where p
		//           is in the last file addded, or perhaps
		//           looked at - will eliminate one level
		//           of search
		s.mutex.RLock()
		if f := s.file(p); f != nil {
			pos = f.position(p)
		}
		s.mutex.RUnlock()
	}
	return
}
source: func (f *FlowPolicy) EncodedActionString() string {

	var e string

	if f.Action.Accepted() && !f.Action.Rejected() {
		if f.ObserveAction.ObserveContinue() {
			e = "1"
		} else if f.ObserveAction.ObserveApply() {
			e = "2"
		} else {
			e = "3"
		}
	} else if !f.Action.Accepted() && f.Action.Rejected() {
		if f.ObserveAction.ObserveContinue() {
			e = "4"
		} else if f.ObserveAction.ObserveApply() {
			e = "5"
		} else {
			e = "6"
		}
	} else {
		if f.ObserveAction.ObserveContinue() {
			e = "7"
		} else if f.ObserveAction.ObserveApply() {
			e = "8"
		} else {
			e = "9"
		}
	}
	return e
}
source: func NetworkAddresses(addrs ...Address) []network.Address {
	naddrs := make([]network.Address, len(addrs))
	for i, addr := range addrs {
		naddrs[i] = addr.NetworkAddress()
	}
	return naddrs
}
source: func (_class VUSBClass) GetAll(sessionID SessionRef) (_retval []VUSBRef, _err error) {
	_method := "VUSB.get_all"
	_sessionIDArg, _err := convertSessionRefToXen(fmt.Sprintf("%s(%s)", _method, "session_id"), sessionID)
	if _err != nil {
		return
	}
	_result, _err := _class.client.APICall(_method, _sessionIDArg)
	if _err != nil {
		return
	}
	_retval, _err = convertVUSBRefSetToGo(_method + " -> ", _result.Value)
	return
}
source: func (h *ResponseHeaders) Set(value string) error {
	splitResult := strings.SplitN(value, "=", 2)

	if len(splitResult) != 2 {
		return errors.New("header flag must be in name=value format")
	}

	*h = append(*h, Header{Name: splitResult[0], Value: splitResult[1]})
	return nil
}
source: func GetServiceProfileCache(p *redis.Pool, id uuid.UUID) (ServiceProfile, error) {
	var sp ServiceProfile
	key := fmt.Sprintf(ServiceProfileKeyTempl, id)

	c := p.Get()
	defer c.Close()

	val, err := redis.Bytes(c.Do("GET", key))
	if err != nil {
		if err == redis.ErrNil {
			return sp, ErrDoesNotExist
		}
		return sp, errors.Wrap(err, "get error")
	}

	err = gob.NewDecoder(bytes.NewReader(val)).Decode(&sp)
	if err != nil {
		return sp, errors.Wrap(err, "gob decode error")
	}

	return sp, nil
}
source: func WithAbsoluteExpiration(value time.Duration) options.Opt {
	return func(p options.Params) {
		logger.Debug("Checking absoluteExpirationSetter")
		if setter, ok := p.(absoluteExpirationSetter); ok {
			setter.SetAbsoluteExpiration(value)
		}
	}
}
source: func OptionalWordsEqual(o1, o2 *OptionalWordsOption) bool {
	if o1 != nil {
		return o1.Equal(o2)
	}
	if o2 != nil {
		return o2.Equal(o1)
	}
	return true
}
source: func (m *Monitor) GetX11Monitor() C.RROutput {
	ret := C.glfwGetX11Monitor(m.data)
	panicError()
	return ret
}
source: func (e Encoding) String() string {
	switch e {
	case UTF8:
		return "UTF8"
	case UTF16BigEndian:
		return "UTF16BigEndian"
	case UTF16LittleEndian:
		return "UTF16LittleEndian"
	case UTF32BigEndian:
		return "UTF32BigEndian"
	case UTF32LittleEndian:
		return "UTF32LittleEndian"
	default:
		return "Unknown"
	}
}
source: func ListNetworksQuery(query HostComputeQuery) ([]HostComputeNetwork, error) {
	queryJson, err := json.Marshal(query)
	if err != nil {
		return nil, err
	}

	networks, err := enumerateNetworks(string(queryJson))
	if err != nil {
		return nil, err
	}
	return networks, nil
}
source: func (fields UserProfileCustomFields) MarshalJSON() ([]byte, error) {
	if len(fields.fields) == 0 {
		return []byte("[]"), nil
	}
	return json.Marshal(fields.fields)
}
source: func (in *Injector) FailErr(err *error) bool {
	if !in.ShouldFail() {
		return false
	}
	*err = fakeErr
	return true
}
source: func ResourceNames(resources corev1.ResourceList) []corev1.ResourceName {
	result := []corev1.ResourceName{}
	for resourceName := range resources {
		result = append(result, resourceName)
	}
	return result
}
source: func (this *RedisStore) Delete(id string) error {
	key := id
	if this.opts.KeyPrefix != "" {
		key = this.opts.KeyPrefix + ":" + id
	}
	_, err := this.conn.Do("DEL", key)
	if err != nil {
		return err
	}
	return nil
}
source: func (i *InternalTokenHelper) populateTokenPath() {
	homePath, err := homedir.Dir()
	if err != nil {
		panic(fmt.Sprintf("error getting user's home directory: %v", err))
	}
	i.tokenPath = filepath.Join(homePath, ".vault-token")
}
source: func (w *deploymentWatcher) shouldFail() (fail, rollback bool, err error) {
	snap, err := w.state.Snapshot()
	if err != nil {
		return false, false, err
	}

	d, err := snap.DeploymentByID(nil, w.deploymentID)
	if err != nil {
		return false, false, err
	}
	if d == nil {
		// The deployment wasn't in the state store, possibly due to a system gc
		return false, false, fmt.Errorf("deployment id not found: %q", w.deploymentID)
	}

	fail = false
	for tg, state := range d.TaskGroups {
		// If we are in a canary state we fail if there aren't enough healthy
		// allocs to satisfy DesiredCanaries
		if state.DesiredCanaries > 0 && !state.Promoted {
			if state.HealthyAllocs >= state.DesiredCanaries {
				continue
			}
		} else if state.HealthyAllocs >= state.DesiredTotal {
			continue
		}

		// We have failed this TG
		fail = true

		// We don't need to autorevert this group
		upd := w.j.LookupTaskGroup(tg).Update
		if upd == nil || !upd.AutoRevert {
			continue
		}

		// Unhealthy allocs and we need to autorevert
		return true, true, nil
	}

	return fail, false, nil
}
source: func (s *APNSMessage) SetPreferredAuthenticationMethod(v string) *APNSMessage {
	s.PreferredAuthenticationMethod = &v
	return s
}
source: func Convert_v1_RouteList_To_route_RouteList(in *v1.RouteList, out *route.RouteList, s conversion.Scope) error {
	return autoConvert_v1_RouteList_To_route_RouteList(in, out, s)
}
source: func (c *AlicloudAccessConfig) Client() (*ClientWrapper, error) {
	if c.client != nil {
		return c.client, nil
	}
	if c.SecurityToken == "" {
		c.SecurityToken = os.Getenv("SECURITY_TOKEN")
	}

	client, err := ecs.NewClientWithStsToken(c.AlicloudRegion, c.AlicloudAccessKey,
		c.AlicloudSecretKey, c.SecurityToken)
	if err != nil {
		return nil, err
	}

	client.AppendUserAgent(Packer, version.FormattedVersion())
	client.SetReadTimeout(DefaultRequestReadTimeout)
	c.client = &ClientWrapper{client}

	return c.client, nil
}
source: func (c *RawClient) sendDHCP(target net.HardwareAddr, dhcp []byte, dstIP net.IP, srcIP net.IP) error {

	proto := 17

	udpsrc := uint(67)
	udpdst := uint(68)

	udp := udphdr{
		src: uint16(udpsrc),
		dst: uint16(udpdst),
	}

	udplen := 8 + len(dhcp)

	ip := iphdr{
		vhl:   0x45,
		tos:   0,
		id:    0x0000, // the kernel overwrites id if it is zero
		off:   0,
		ttl:   128,
		proto: uint8(proto),
	}
	copy(ip.src[:], srcIP.To4())
	copy(ip.dst[:], dstIP.To4())

	udp.ulen = uint16(udplen)
	udp.checksum(&ip, dhcp)

	totalLen := 20 + udplen

	ip.iplen = uint16(totalLen)
	ip.checksum()

	buf := bytes.NewBuffer([]byte{})
	err := binary.Write(buf, binary.BigEndian, &udp)
	if err != nil {
		log.Fatal(err)
	}

	udpHeader := buf.Bytes()
	dataWithHeader := append(udpHeader, dhcp...)

	buff := bytes.NewBuffer([]byte{})
	err = binary.Write(buff, binary.BigEndian, &ip)
	if err != nil {
		log.Fatal(err)
	}

	ipHeader := buff.Bytes()
	packet := append(ipHeader, dataWithHeader...)

	// Create Ethernet frame
	f := &ethernet.Frame{
		Destination: target,
		Source:      c.ifi.HardwareAddr,
		EtherType:   ethernet.EtherTypeIPv4,
		Payload:     packet,
	}
	fb, err := f.MarshalBinary()
	if err != nil {
		return err
	}

	// Send packet to target
	_, err = c.p.WriteTo(fb, &raw.Addr{
		HardwareAddr: target,
	})
	return err
}
source: func FilteredHelpFunc(include []string, f HelpFunc) HelpFunc {
	return func(commands map[string]CommandFactory) string {
		set := make(map[string]struct{})
		for _, k := range include {
			set[k] = struct{}{}
		}

		filtered := make(map[string]CommandFactory)
		for k, f := range commands {
			if _, ok := set[k]; ok {
				filtered[k] = f
			}
		}

		return f(filtered)
	}
}
source: func (s *server) NotifyWhenOffline(peerPubKey [33]byte) <-chan struct{} {
	s.mu.Lock()
	defer s.mu.Unlock()

	c := make(chan struct{})

	// If the peer is already offline, we can immediately trigger the
	// notification.
	peerPubKeyStr := string(peerPubKey[:])
	if _, ok := s.peersByPub[peerPubKeyStr]; !ok {
		srvrLog.Debugf("Notifying that peer %x is offline", peerPubKey)
		close(c)
		return c
	}

	// Otherwise, the peer is online, so we'll keep track of the channel to
	// trigger the notification once the server detects the peer
	// disconnects.
	s.peerDisconnectedListeners[peerPubKeyStr] = append(
		s.peerDisconnectedListeners[peerPubKeyStr], c,
	)

	return c
}
source: func getSeccompSecurityOpts(seccompProfile string, separator rune) ([]string, error) {
	seccompOpts, err := getSeccompDockerOpts(seccompProfile)
	if err != nil {
		return nil, err
	}
	return fmtDockerOpts(seccompOpts, separator), nil
}
source: func parseGlob(t *Template, pattern string) (*Template, error) {
	filenames, err := filepath.Glob(pattern)
	if err != nil {
		return nil, err
	}
	if len(filenames) == 0 {
		return nil, fmt.Errorf("template: pattern matches no files: %#q", pattern)
	}
	return parseFiles(t, filenames...)
}
source: func NewMetrics() *Metrics {
	m := &Metrics{
		TimeMetrics:   make(map[string]*TimeStats),
		NumberMetrics: make(map[string]*NumberStats),
		BoolMetrics:   make(map[string]*BoolStats),
	}
	return m
}
source: func (l *Conn) StartTLS(config *tls.Config) error {
	if l.isTLS {
		return NewError(ErrorNetwork, errors.New("ldap: already encrypted"))
	}

	packet := ber.Encode(ber.ClassUniversal, ber.TypeConstructed, ber.TagSequence, nil, "LDAP Request")
	packet.AppendChild(ber.NewInteger(ber.ClassUniversal, ber.TypePrimitive, ber.TagInteger, l.nextMessageID(), "MessageID"))
	request := ber.Encode(ber.ClassApplication, ber.TypeConstructed, ApplicationExtendedRequest, nil, "Start TLS")
	request.AppendChild(ber.NewString(ber.ClassContext, ber.TypePrimitive, 0, "1.3.6.1.4.1.1466.20037", "TLS Extended Command"))
	packet.AppendChild(request)
	l.Debug.PrintPacket(packet)

	msgCtx, err := l.sendMessageWithFlags(packet, startTLS)
	if err != nil {
		return err
	}
	defer l.finishMessage(msgCtx)

	l.Debug.Printf("%d: waiting for response", msgCtx.id)

	packetResponse, ok := <-msgCtx.responses
	if !ok {
		return NewError(ErrorNetwork, errors.New("ldap: response channel closed"))
	}
	packet, err = packetResponse.ReadPacket()
	l.Debug.Printf("%d: got response %p", msgCtx.id, packet)
	if err != nil {
		return err
	}

	if l.Debug {
		if err := addLDAPDescriptions(packet); err != nil {
			l.Close()
			return err
		}
		ber.PrintPacket(packet)
	}

	if resultCode, message := getLDAPResultCode(packet); resultCode == LDAPResultSuccess {
		conn := tls.Client(l.conn, config)

		if err := conn.Handshake(); err != nil {
			l.Close()
			return NewError(ErrorNetwork, fmt.Errorf("TLS handshake failed (%v)", err))
		}

		l.isTLS = true
		l.conn = conn
	} else {
		return NewError(resultCode, fmt.Errorf("ldap: cannot StartTLS (%s)", message))
	}
	go l.reader()

	return nil
}
source: func (r *rpcServer) Start() error {
	if atomic.AddInt32(&r.started, 1) != 1 {
		return nil
	}

	// First, we'll start all the sub-servers to ensure that they're ready
	// to take new requests in.
	//
	// TODO(roasbeef): some may require that the entire daemon be started
	// at that point
	for _, subServer := range r.subServers {
		rpcsLog.Debugf("Starting sub RPC server: %v", subServer.Name())

		if err := subServer.Start(); err != nil {
			return err
		}
	}

	// With all the sub-servers started, we'll spin up the listeners for
	// the main RPC server itself.
	for _, listener := range cfg.RPCListeners {
		lis, err := lncfg.ListenOnAddress(listener)
		if err != nil {
			ltndLog.Errorf(
				"RPC server unable to listen on %s", listener,
			)
			return err
		}

		r.listenerCleanUp = append(r.listenerCleanUp, func() {
			lis.Close()
		})

		go func() {
			rpcsLog.Infof("RPC server listening on %s", lis.Addr())
			r.grpcServer.Serve(lis)
		}()
	}

	// Finally, start the REST proxy for our gRPC server above. We'll ensure
	// we direct LND to connect to its loopback address rather than a
	// wildcard to prevent certificate issues when accessing the proxy
	// externally.
	//
	// TODO(roasbeef): eventually also allow the sub-servers to themselves
	// have a REST proxy.
	mux := proxy.NewServeMux()

	err := lnrpc.RegisterLightningHandlerFromEndpoint(
		context.Background(), mux, r.restProxyDest,
		r.restDialOpts,
	)
	if err != nil {
		return err
	}
	for _, restEndpoint := range cfg.RESTListeners {
		lis, err := lncfg.TLSListenOnAddress(restEndpoint, r.tlsCfg)
		if err != nil {
			ltndLog.Errorf(
				"gRPC proxy unable to listen on %s",
				restEndpoint,
			)
			return err
		}

		r.listenerCleanUp = append(r.listenerCleanUp, func() {
			lis.Close()
		})

		go func() {
			rpcsLog.Infof("gRPC proxy started at %s", lis.Addr())
			http.Serve(lis, mux)
		}()
	}

	return nil
}
source: func (hook *Hook) findHook() (*exec.Cmd, int, error) {
	// Check the hook path.
	if strings.Contains(hook.Name, "/") {
		return nil, HOOK_INVALID_NAME, fmt.Errorf("hook cannot contain '/'")
	}

	// Find our root.
	root, err := vtenv.VtRoot()
	if err != nil {
		return nil, HOOK_VTROOT_ERROR, fmt.Errorf("cannot get VTROOT: %v", err)
	}

	// See if the hook exists.
	vthook := path.Join(root, "vthook", hook.Name)
	_, err = os.Stat(vthook)
	if err != nil {
		if os.IsNotExist(err) {
			return nil, HOOK_DOES_NOT_EXIST, fmt.Errorf("missing hook %v", vthook)
		}

		return nil, HOOK_STAT_FAILED, fmt.Errorf("cannot stat hook %v: %v", vthook, err)
	}

	// Configure the command.
	log.Infof("hook: executing hook: %v %v", vthook, strings.Join(hook.Parameters, " "))
	cmd := exec.Command(vthook, hook.Parameters...)
	if len(hook.ExtraEnv) > 0 {
		cmd.Env = os.Environ()
		for key, value := range hook.ExtraEnv {
			cmd.Env = append(cmd.Env, key+"="+value)
		}
	}

	return cmd, HOOK_SUCCESS, nil
}
source: func (s *Service) AppFeatureUpdate(ctx context.Context, appIdentity string, appFeatureIdentity string, o AppFeatureUpdateOpts) (*AppFeature, error) {
	var appFeature AppFeature
	return &appFeature, s.Patch(ctx, &appFeature, fmt.Sprintf("/apps/%v/features/%v", appIdentity, appFeatureIdentity), o)
}
source: func (s *nodeConfigStatus) Sync(client clientset.Interface, nodeName string) {
	select {
	case <-s.syncCh:
	default:
		// no work to be done, return
		return
	}

	utillog.Infof("updating Node.Status.Config")

	// grab the lock
	s.mux.Lock()
	defer s.mux.Unlock()

	// if the sync fails, we want to retry
	var err error
	defer func() {
		if err != nil {
			utillog.Errorf(err.Error())
			s.sync()
		}
	}()

	// get the Node so we can check the current status
	oldNode, err := client.CoreV1().Nodes().Get(nodeName, metav1.GetOptions{})
	if err != nil {
		err = fmt.Errorf("could not get Node %q, will not sync status, error: %v", nodeName, err)
		return
	}

	status := &s.status
	// override error, if necessary
	if len(s.errorOverride) > 0 {
		// copy the status, so we don't overwrite the prior error
		// with the override
		status = status.DeepCopy()
		status.Error = s.errorOverride
	}

	// update metrics based on the status we will sync
	metrics.SetConfigError(len(status.Error) > 0)
	err = metrics.SetAssignedConfig(status.Assigned)
	if err != nil {
		err = fmt.Errorf("failed to update Assigned config metric, error: %v", err)
		return
	}
	err = metrics.SetActiveConfig(status.Active)
	if err != nil {
		err = fmt.Errorf("failed to update Active config metric, error: %v", err)
		return
	}
	err = metrics.SetLastKnownGoodConfig(status.LastKnownGood)
	if err != nil {
		err = fmt.Errorf("failed to update LastKnownGood config metric, error: %v", err)
		return
	}

	// apply the status to a copy of the node so we don't modify the object in the informer's store
	newNode := oldNode.DeepCopy()
	newNode.Status.Config = status

	// patch the node with the new status
	if _, _, err := nodeutil.PatchNodeStatus(client.CoreV1(), types.NodeName(nodeName), oldNode, newNode); err != nil {
		utillog.Errorf("failed to patch node status, error: %v", err)
	}
}
source: func (p *PullRequest) GetMergeable() bool {
	if p == nil || p.Mergeable == nil {
		return false
	}
	return *p.Mergeable
}
source: func (c *Page) SetFontFamiliesWithParams(v *PageSetFontFamiliesParams) (*gcdmessage.ChromeResponse, error) {
	return gcdmessage.SendDefaultRequest(c.target, c.target.GetSendCh(), &gcdmessage.ParamRequest{Id: c.target.GetId(), Method: "Page.setFontFamilies", Params: v})
}
source: func (a *ACLToken) SetHash() []byte {
	// Initialize a 256bit Blake2 hash (32 bytes)
	hash, err := blake2b.New256(nil)
	if err != nil {
		panic(err)
	}

	// Write all the user set fields
	hash.Write([]byte(a.Name))
	hash.Write([]byte(a.Type))
	for _, policyName := range a.Policies {
		hash.Write([]byte(policyName))
	}
	if a.Global {
		hash.Write([]byte("global"))
	} else {
		hash.Write([]byte("local"))
	}

	// Finalize the hash
	hashVal := hash.Sum(nil)

	// Set and return the hash
	a.Hash = hashVal
	return hashVal
}
source: func iterBitmapsDistinct(skip *bitmap.Bitmap, bms ...bitmap.Bitmap) iter.Func {
	return func(cb iter.Callback) {
		for _, bm := range bms {
			if !iter.All(func(i interface{}) bool {
				skip.Add(i.(int))
				return cb(i)
			}, bitmap.Sub(bm, *skip).Iter) {
				return
			}
		}
	}
}
source: func (m Map) ClusterNamesByVersion(matchingVersion string) []string {
	var ret []string
	for name, cluster := range m.nameMap {
		if matchingVersion == cluster.CurrentNodeVersion {
			ret = append(ret, name)
		}
	}
	return ret
}
source: func IsZero(a corev1.ResourceList) bool {
	zero := resource.MustParse("0")
	for _, v := range a {
		if v.Cmp(zero) != 0 {
			return false
		}
	}
	return true
}
source: func (l *Log) start(ch chan<- *Event) {
	defer close(ch)

	l.Log.Debug("enter")
	defer l.Log.Debug("exit")

	var start = l.StartTime.UnixNano() / int64(time.Millisecond)
	var nextToken *string
	var err error

	for {
		l.Log.WithField("start", start).Debug("request")
		nextToken, start, err = l.fetch(nextToken, start, ch)

		if err != nil {
			l.err = fmt.Errorf("log %q: %s", l.GroupName, err)
			break
		}

		if nextToken == nil && l.Follow {
			time.Sleep(l.PollInterval)
			l.Log.WithField("start", start).Debug("poll")
			continue
		}

		if nextToken == nil {
			break
		}
	}
}
source: func (c *Cache) remove(itmID string) {
	ci, has := c.cache[itmID]
	if !has {
		return
	}
	if c.maxEntries != UnlimitedCaching {
		c.lruIdx.Remove(c.lruRefs[itmID])
		delete(c.lruRefs, itmID)
	}
	if c.ttl > 0 {
		c.ttlIdx.Remove(c.ttlRefs[itmID])
		delete(c.ttlRefs, itmID)
	}
	c.remItemFromGroups(ci.itemID, ci.groupIDs)
	delete(c.cache, ci.itemID)
	if c.onEvicted != nil {
		c.onEvicted(ci.itemID, ci.value)
	}
}
source: func (c *PartitionedLazyCache) Get(partition, key string) (interface{}, error) {
	p, found := c.partitions[partition]

	if !found {
		return nil, nil
	}

	v, found, err := p.Get(key)
	if err != nil {
		return nil, err
	}

	if found {
		return v, nil
	}

	return nil, nil

}
source: func s3GatewayMain(ctx *cli.Context) {
	args := ctx.Args()
	if !ctx.Args().Present() {
		args = cli.Args{"https://s3.amazonaws.com"}
	}

	// Validate gateway arguments.
	logger.FatalIf(minio.ValidateGatewayArguments(ctx.GlobalString("address"), args.First()), "Invalid argument")

	// Start the gateway..
	minio.StartGateway(ctx, &S3{args.First()})
}
source: func (f *Filestore) DeleteBlock(c cid.Cid) error {
	err1 := f.bs.DeleteBlock(c)
	if err1 != nil && err1 != blockstore.ErrNotFound {
		return err1
	}

	err2 := f.fm.DeleteBlock(c)
	// if we successfully removed something from the blockstore, but the
	// filestore didnt have it, return success

	switch err2 {
	case nil:
		return nil
	case blockstore.ErrNotFound:
		if err1 == blockstore.ErrNotFound {
			return blockstore.ErrNotFound
		}
		return nil
	default:
		return err2
	}
}
source: func ExecuteErrorToLabel(err error) string {
	err = errors.Cause(err)
	switch x := err.(type) {
	case *terror.Error:
		return x.Class().String() + ":" + strconv.Itoa(int(x.Code()))
	default:
		return "unknown"
	}
}
source: func (in *DefaultAdmissionConfig) DeepCopy() *DefaultAdmissionConfig {
	if in == nil {
		return nil
	}
	out := new(DefaultAdmissionConfig)
	in.DeepCopyInto(out)
	return out
}
source: func MustIDFromString(s string) sha1 {
	b, _ := hex.DecodeString(s)
	return MustID(b)
}
source: func (client NexusClient) RemoveRepositoryFromGroup(repositoryID RepositoryID, groupID GroupID) (int, error) {
	repogroup, rc, err := client.repositoryGroup(groupID)
	if err != nil {
		return rc, err
	}
	if rc != 200 {
		Log.Printf("Nexus Client.AddRepositoryToGroup() response code: %d\n", rc)
	}

	if repoIsNotInGroup(repositoryID, repogroup) {
		return 0, nil
	}

	removeRepo(repositoryID, &repogroup)

	data, err := json.Marshal(&repogroup)
	if err != nil {
		return 0, err
	}

	retry := retry.New(3, retry.DefaultBackoffFunc)
	var responseCode int
	work := func() error {
		req, err := http.NewRequest("PUT", client.BaseURL+"/service/local/repo_groups/"+string(groupID), bytes.NewBuffer(data))
		if err != nil {
			return err
		}
		req.SetBasicAuth(client.Username, client.Password)
		req.Header.Add("Content-type", "application/json")
		req.Header.Add("Accept", "application/json")

		resp, err := client.HttpClient.Do(req)
		if err != nil {
			return err
		}
		defer resp.Body.Close()

		body, err := ioutil.ReadAll(resp.Body)
		if err != nil {
			return err
		}

		responseCode = resp.StatusCode
		if responseCode != 200 {
			return fmt.Errorf("Client.AddRepositoryToGroup(): unexpected response status: %d (%s)\n", responseCode, string(body))
		}
		return nil
	}
	return responseCode, retry.Try(work)
}
source: func (list *AccountList) Find(id string) *Account {
	for _, item := range list.Data {
		if item.ID == id {
			return item
		}
	}

	return nil
}
source: func (m *Message) Append(s Session) Session {
	s = s.AddVersion(m.Version)
	s = s.AddOrigin(m.Origin)
	s = s.AddSessionName(m.Name)
	if len(m.Info) > 0 {
		s = s.AddSessionInfo(m.Info)
	}
	if len(m.URI) > 0 {
		s = s.AddURI(m.URI)
	}
	if len(m.Email) > 0 {
		s = s.AddEmail(m.Email)
	}
	if len(m.Phone) > 0 {
		s = s.AddPhone(m.Phone)
	}
	if !m.Connection.Blank() {
		s = s.AddConnectionData(m.Connection)
	}
	for t, v := range m.Bandwidths {
		s = s.AddBandwidth(t, v)
	}
	// One or more time descriptions ("t=" and "r=" lines)
	for _, t := range m.Timing {
		s = s.AddTiming(t.Start, t.End)
		if len(t.Offsets) > 0 {
			s = s.AddRepeatTimesCompact(t.Repeat, t.Active, t.Offsets...)
		}
	}
	if len(m.TZAdjustments) > 0 {
		s = s.AddTimeZones(m.TZAdjustments...)
	}
	if !m.Encryption.Blank() {
		s = s.AddEncryption(m.Encryption)
	}
	s = s.appendAttributes(m.Attributes)

	for i := range m.Medias {
		s = s.AddMediaDescription(m.Medias[i].Description)
		if len(m.Medias[i].Title) > 0 {
			s = s.AddSessionInfo(m.Medias[i].Title)
		}
		if !m.Medias[i].Connection.Blank() {
			s = s.AddConnectionData(m.Medias[i].Connection)
		}
		for t, v := range m.Medias[i].Bandwidths {
			s = s.AddBandwidth(t, v)
		}
		if !m.Medias[i].Encryption.Blank() {
			s = s.AddEncryption(m.Medias[i].Encryption)
		}
		s = s.appendAttributes(m.Medias[i].Attributes)
	}
	return s
}
source: func (o *Disk) SetDeviceName(v *string) *Disk {
	if o.DeviceName = v; o.DeviceName == nil {
		o.nullFields = append(o.nullFields, "DeviceName")
	}
	return o
}
source: func (m ModuleInstance) TargetContains(other Targetable) bool {
	switch to := other.(type) {

	case ModuleInstance:
		if len(to) < len(m) {
			// Can't be contained if the path is shorter
			return false
		}
		// Other is contained if its steps match for the length of our own path.
		for i, ourStep := range m {
			otherStep := to[i]
			if ourStep != otherStep {
				return false
			}
		}
		// If we fall out here then the prefixed matched, so it's contained.
		return true

	case AbsResource:
		return m.TargetContains(to.Module)

	case AbsResourceInstance:
		return m.TargetContains(to.Module)

	default:
		return false
	}
}
source: func newLogDogStreamServerForPlatform(ctx context.Context, workDir string) (streamserver.StreamServer, error) {
	// POSIX, use UNIX domain socket.
	return streamserver.NewUNIXDomainSocketServer(ctx, filepath.Join(workDir, "ld.sock"))
}
source: func (s *Switch) getLink(chanID lnwire.ChannelID) (ChannelLink, error) {
	link, ok := s.linkIndex[chanID]
	if !ok {
		link, ok = s.pendingLinkIndex[chanID]
		if !ok {
			return nil, ErrChannelLinkNotFound
		}
	}

	return link, nil
}
source: func (n *Node) String() string {
	return fmt.Sprintf("%s<%s>", n.t.String(), n.id.String())
}
source: func OptionLabels(labels []string) Option {
	return func(c *Config) {
		for _, label := range labels {
			if strings.HasPrefix(label, netlabel.Prefix) {
				c.Daemon.Labels = append(c.Daemon.Labels, label)
			}
		}
	}
}
source: func newFilter(name string, indexCollectionType IndexCollectionType, valueParticleType int, begin Value, end Value) *Filter {
	return &Filter{
		name:              name,
		idxType:           indexCollectionType,
		valueParticleType: valueParticleType,
		begin:             begin,
		end:               end,
	}
}
source: func (t *TTFParser) ReadULong(fd *bytes.Reader) (uint, error) {
	buff, err := t.Read(fd, 4)
	//fmt.Printf("%#v\n", buff)
	if err != nil {
		return 0, err
	}
	n := binary.BigEndian.Uint32(buff)
	return uint(n), nil
}
source: func (he *HTTPError) Error() string {
	return fmt.Sprintf("code=%d, message=%v", he.Code, he.Message)
}
source: func (c *Client) SeekOpt(position int, opt *PlayOptions) error {
	return c.playerFuncWithOpt(
		"me/player/seek",
		url.Values{
			"position_ms": []string{strconv.FormatInt(int64(position), 10)},
		},
		opt,
	)
}
source: func releaseAll(ds *Dsync, locks *[]string, lockName string, isReadLock bool) {
	for lock := 0; lock < ds.dNodeCount; lock++ {
		if isLocked((*locks)[lock]) {
			sendRelease(ds, ds.rpcClnts[lock], lockName, (*locks)[lock], isReadLock)
			(*locks)[lock] = ""
		}
	}
}
source: func (m *MockSentPacketHandler) SentPacket(arg0 *ackhandler.Packet) {
	m.ctrl.T.Helper()
	m.ctrl.Call(m, "SentPacket", arg0)
}
source: func (sink *influxdbSink) parseRawQueryRow(rawRow influx_models.Row) ([]core.TimestampedMetricValue, error) {
	vals := make([]core.TimestampedMetricValue, len(rawRow.Values))
	wasInt := make(map[string]bool, 1)
	for i, rawVal := range rawRow.Values {
		val := core.TimestampedMetricValue{}

		if ts, err := time.Parse(time.RFC3339, rawVal[0].(string)); err != nil {
			return nil, fmt.Errorf("Unable to parse timestamp %q in series %q", rawVal[0].(string), rawRow.Name)
		} else {
			val.Timestamp = ts
		}

		if err := tryParseMetricValue("value", rawVal, &val.MetricValue, 1, wasInt); err != nil {
			glog.Errorf("Unable to parse field \"value\" in series %q: %v", rawRow.Name, err)
			return nil, fmt.Errorf("Unable to parse values in series %q", rawRow.Name)
		}

		vals[i] = val
	}

	if wasInt["value"] {
		for i := range vals {
			vals[i].MetricValue.ValueType = core.ValueInt64
		}
	} else {
		for i := range vals {
			vals[i].MetricValue.ValueType = core.ValueFloat
		}
	}

	return vals, nil
}
source: func shouldAttempt(attempt uint, strategies ...strategy.Strategy) bool {
	shouldAttempt := true

	for i := 0; shouldAttempt && i < len(strategies); i++ {
		shouldAttempt = shouldAttempt && strategies[i](attempt)
	}

	return shouldAttempt
}
source: func simpleRequest(method, url_ string) (*http.Request, error) {
	req, err := http.NewRequest(method, url_, nil)
	if err != nil {
		return nil, err
	}
	req.Header.Set("x-goog-api-version", "2")
	return req, err
}
source: func (ung UniformGenerator) Float32() float32 {
	ung.mu.Lock()
	defer ung.mu.Unlock()
	return ung.rd.Float32()
}
source: func OptionPortMapping(portBindings []types.PortBinding) SandboxOption {
	return func(sb *sandbox) {
		if sb.config.generic == nil {
			sb.config.generic = make(map[string]interface{})
		}
		// Store a copy of the bindings as generic data to pass to the driver
		pbs := make([]types.PortBinding, len(portBindings))
		copy(pbs, portBindings)
		sb.config.generic[netlabel.PortMap] = pbs
	}
}
source: func KsStat(vector govector.Vector, conf AnomalyzerConf) float64 {
	reference, active, err := extractWindows(vector, conf.referenceSize, conf.ActiveSize, conf.ActiveSize)
	if err != nil {
		return NA
	}
	n1 := len(reference)
	n2 := len(active)
	if n1%n2 != 0 {
		return NA
	}

	// First sort the active data and generate a cummulative distribution function
	// using that data. Do the same for the reference data.
	activeEcdf := active.Ecdf()
	refEcdf := reference.Ecdf()

	// We want the reference and active vectors to have the same length n, so we
	// consider the min and max for each and interpolated the points between.
	min := math.Min(reference.Min(), active.Min())
	max := math.Max(reference.Max(), active.Max())

	interpolated := interpolate(min, max, n1+n2)

	// Then we apply the distribution function over the interpolated data.
	activeDist := interpolated.Apply(activeEcdf)
	refDist := interpolated.Apply(refEcdf)

	// Find the maximum displacement between both distributions.
	d := 0.0
	for i := 0; i < n1+n2; i++ {
		d = math.Max(d, math.Abs(activeDist[i]-refDist[i]))
	}
	return d
}
source: func (in *ResourceDiff) DeepCopy() *ResourceDiff {
	if in == nil {
		return nil
	}
	out := new(ResourceDiff)
	in.DeepCopyInto(out)
	return out
}
source: func (k *Kloneable) kloneOwner() (string, error) {
	local.Printf("Attempting git clone")
	path, err := k.kloner.Clone(k.repo)
	if err != nil {
		return "", err
	}
	// Always delete origins
	local.Printf("Register remote [origin]")
	err = k.kloner.DeleteRemote("origin")
	if err != nil && !strings.Contains(err.Error(), "remote not found") {
		return path, err
	}
	// Add Origin
	// Origin is our remote URL, and location is ours too!
	err = k.kloner.AddRemote("origin", k.repo.GitRemoteUrl())
	if err != nil {
		return path, err
	}
	return path, nil
}
source: func (c *Cursor) handleError(err error) error {
	c.mu.Lock()
	defer c.mu.Unlock()

	return c.handleErrorLocked(err)
}
source: func (f *Factory) Gen(uri string) (key string, err error) {
	// we don't return the parsed url because #hash are converted to uri-compatible
	// and we don't want to encode/decode all the time, there is no need for that,
	// we save the url as the user expects if the uri validation passed.
	_, err = url.ParseRequestURI(uri)
	if err != nil {
		return "", err
	}

	key = f.generator()
	// Make sure that the key is unique
	for {
		if v := f.store.Get(key); v == "" {
			break
		}
		key = f.generator()
	}

	return key, nil
}
source: func NewController(config ControllerConfig) (*Controller, error) {
	c, err := newController(config, newResidentManager(config.Changes))
	return c, errors.Trace(err)
}
source: func DeleteServiceLB(key string) error {
	collections.serviceLBMutex.Lock()
	obj := collections.serviceLBs[key]
	collections.serviceLBMutex.Unlock()
	if obj == nil {
		log.Errorf("serviceLB %s not found", key)
		return errors.New("serviceLB not found")
	}

	// Check if we handle this object
	if objCallbackHandler.ServiceLBCb == nil {
		log.Errorf("No callback registered for serviceLB object")
		return errors.New("Invalid object type")
	}

	// Perform callback
	err := objCallbackHandler.ServiceLBCb.ServiceLBDelete(obj)
	if err != nil {
		log.Errorf("ServiceLBDelete retruned error for: %+v. Err: %v", obj, err)
		return err
	}

	// delete it from modeldb
	collections.serviceLBMutex.Lock()
	err = obj.Delete()
	collections.serviceLBMutex.Unlock()
	if err != nil {
		log.Errorf("Error deleting serviceLB %s. Err: %v", obj.Key, err)
	}

	// delete it from cache
	collections.serviceLBMutex.Lock()
	delete(collections.serviceLBs, key)
	collections.serviceLBMutex.Unlock()

	return nil
}
source: func (h *BindHandle) Size() int {
	size := 0
	for _, bindRecords := range h.bindInfo.Load().(cache) {
		size += len(bindRecords)
	}
	return size
}
source: func NewService(name string, conf common.Conf) (*Service, error) {
	m, err := NewServiceManager()
	if err != nil {
		return nil, errors.Trace(err)
	}
	return newService(name, conf, m), nil
}
source: func (watcher *AllWatcher) Next() ([]multiwatcher.Delta, error) {
	var info params.AllWatcherNextResults
	err := watcher.caller.APICall(
		watcher.objType,
		watcher.caller.BestFacadeVersion(watcher.objType),
		*watcher.id,
		"Next",
		nil, &info,
	)
	// We'll order the deltas so relation changes come last.
	// This allows the callers like the GUI to process changes
	// in the right order.
	sort.Sort(orderedDeltas(info.Deltas))
	return info.Deltas, err
}
source: func (t *tableCommon) buildIndexForRow(ctx sessionctx.Context, rm kv.RetrieverMutator, h int64, vals []types.Datum, idx table.Index) error {
	if _, err := idx.Create(ctx, rm, vals, h); err != nil {
		if kv.ErrKeyExists.Equal(err) {
			// Make error message consistent with MySQL.
			entryKey, err1 := t.genIndexKeyStr(vals)
			if err1 != nil {
				// if genIndexKeyStr failed, return the original error.
				return err
			}

			return kv.ErrKeyExists.FastGen("Duplicate entry '%s' for key '%s'", entryKey, idx.Meta().Name)
		}
		return err
	}
	return nil
}
source: func Floor(num cty.Value) (cty.Value, error) {
	return FloorFunc.Call([]cty.Value{num})
}
source: func New(lower tcpip.LinkEndpointID) tcpip.LinkEndpointID {
	return stack.RegisterLinkEndpoint(&endpoint{
		lower: stack.FindLinkEndpoint(lower),
	})
}
source: func Sha512(data []byte) string {
	sha512 := sha512.New()
	sha512.Write(data)
	return hex.EncodeToString(sha512.Sum(nil))
}
source: func NewReader(r io.Reader) *Reader {
	return &Reader{
		nil,
		bufio.NewReader(r),
	}
}
source: func ScanBareIdent(r io.RuneScanner) string {
	// Read every ident character into the buffer.
	// Non-ident characters and EOF will cause the loop to exit.
	var buf bytes.Buffer
	for {
		ch, _, err := r.ReadRune()
		if err != nil {
			break
		} else if !isIdentChar(ch) {
			r.UnreadRune()
			break
		} else {
			_, _ = buf.WriteRune(ch)
		}
	}
	return buf.String()
}
source: func (s *CreatePlatformVersionOutput) SetBuilder(v *Builder) *CreatePlatformVersionOutput {
	s.Builder = v
	return s
}
source: func NewWithOptions(enc zap.Encoder, opts ...zap.Option) gournal.Appender {
	return &appender{zap.New(enc, opts...)}
}
source: func (p uint64Slice) merge(other []uint64) []uint64 {
	ret := make([]uint64, 0, len(p))

	i, j := 0, 0
	for i < len(p) && j < len(other) {
		a, b := p[i], other[j]
		if a == b {
			ret = append(ret, a)
			i, j = i+1, j+1
		} else if a < b {
			ret = append(ret, a)
			i++
		} else {
			ret = append(ret, b)
			j++
		}
	}

	if i < len(p) {
		ret = append(ret, p[i:]...)
	} else if j < len(other) {
		ret = append(ret, other[j:]...)
	}

	return ret
}
source: func (s *Static) canBeServed(path string) bool {
	stat, err := os.Stat(path)
	if err != nil {
		log.Debugf("Error while calling os.Stat for path %s. Error: %s", path, err.Error())
	} else {
		if !stat.IsDir() {
			return true
		}
	}

	return false
}
source: func (v *ContentAddressValidator) Validate(ch Chunk) bool {
	data := ch.Data()
	if l := len(data); l < 9 || l > chunk.DefaultSize+8 {
		// log.Error("invalid chunk size", "chunk", addr.Hex(), "size", l)
		return false
	}

	hasher := v.Hasher()
	hasher.ResetWithLength(data[:8])
	hasher.Write(data[8:])
	hash := hasher.Sum(nil)

	return bytes.Equal(hash, ch.Address())
}
source: func (s *Srv) Cfg() engine.Server {
	return engine.Server{
		Id:  s.id,
		URL: s.rawURL,
	}
}
source: func (blk *TagBlock) TagValueElem(key, value []byte) TagValueElem {
	var valueElem TagBlockValueElem
	if !blk.DecodeTagValueElem(key, value, &valueElem) {
		return nil
	}
	return &valueElem
}
source: func signerType(scheme *design.SecuritySchemeDefinition) string {
	switch scheme.Kind {
	case design.JWTSecurityKind:
		return "goaclient.JWTSigner" // goa client package imported under goaclient
	case design.OAuth2SecurityKind:
		return "goaclient.OAuth2Signer"
	case design.APIKeySecurityKind:
		return "goaclient.APIKeySigner"
	case design.BasicAuthSecurityKind:
		return "goaclient.BasicSigner"
	}
	return ""
}
source: func Convert_config_NodeIPAMControllerConfiguration_To_v1alpha1_NodeIPAMControllerConfiguration(in *config.NodeIPAMControllerConfiguration, out *v1alpha1.NodeIPAMControllerConfiguration, s conversion.Scope) error {
	return autoConvert_config_NodeIPAMControllerConfiguration_To_v1alpha1_NodeIPAMControllerConfiguration(in, out, s)
}
source: func addHostPathVolume(pod *v1.Pod, container *v1.Container, hostPath v1.HostPathVolumeSource, volumeMount v1.VolumeMount) {
	vol := v1.Volume{
		Name: volumeMount.Name,
		VolumeSource: v1.VolumeSource{
			HostPath: &hostPath,
		},
	}

	if volumeMount.MountPath == "" {
		volumeMount.MountPath = hostPath.Path
	}

	pod.Spec.Volumes = append(pod.Spec.Volumes, vol)
	container.VolumeMounts = append(container.VolumeMounts, volumeMount)
}
source: func (_class GPUGroupClass) GetAllocationAlgorithm(sessionID SessionRef, self GPUGroupRef) (_retval AllocationAlgorithm, _err error) {
	_method := "GPU_group.get_allocation_algorithm"
	_sessionIDArg, _err := convertSessionRefToXen(fmt.Sprintf("%s(%s)", _method, "session_id"), sessionID)
	if _err != nil {
		return
	}
	_selfArg, _err := convertGPUGroupRefToXen(fmt.Sprintf("%s(%s)", _method, "self"), self)
	if _err != nil {
		return
	}
	_result, _err := _class.client.APICall(_method, _sessionIDArg, _selfArg)
	if _err != nil {
		return
	}
	_retval, _err = convertEnumAllocationAlgorithmToGo(_method + " -> ", _result.Value)
	return
}
source: func Psnr(a, b image.Image) ([]float64, error) {
	psnrs := []float64{}
	id, src, err := inspect(a, false)
	if err != nil {
		return nil, err
	}
	od, dst, err := inspect(b, false)
	if err != nil {
		return nil, err
	}
	if *id != *od {
		return nil, fmt.Errorf("unable to psnr different formats")
	}
	for i := 0; i < len(dst); i++ {
		psnrs = append(psnrs, psnrPlane(src[i].Data, dst[i].Data, src[i].Width*src[i].Pack, src[i].Height, src[i].Pitch, dst[i].Pitch))
	}
	return psnrs, nil
}
source: func (s *UpdateDevEndpointInput) SetAddArguments(v map[string]*string) *UpdateDevEndpointInput {
	s.AddArguments = v
	return s
}
source: func (rs Runes) IndexAll(r, sub []rune) int {
	return rs.IndexAllEx(r, sub, false)
}
source: func Stob(s string) []byte {
	return *(*[]byte)(unsafe.Pointer((*reflect.StringHeader)(unsafe.Pointer(&s))))
}
source: func RegisterDebugHealthHandler(ts *topo.Server) {
	http.HandleFunc("/debug/health", func(w http.ResponseWriter, r *http.Request) {
		if err := acl.CheckAccessHTTP(r, acl.MONITORING); err != nil {
			acl.SendError(w, err)
			return
		}
		w.Header().Set("Content-Type", "text/plain")
		if err := isHealthy(ts); err != nil {
			w.Write([]byte("not ok"))
			return
		}
		w.Write([]byte("ok"))
	})
}
source: func (s *RejectedLogEventsInfo) SetTooOldLogEventEndIndex(v int64) *RejectedLogEventsInfo {
	s.TooOldLogEventEndIndex = &v
	return s
}
source: func WrapRecoverable(msg string, err error) error {
	return &RecoverableError{Err: msg, Recoverable: IsRecoverable(err)}
}
source: func (daemon *Daemon) SystemVersion() types.Version {
	kernelVersion := kernelVersion()

	v := types.Version{
		Components: []types.ComponentVersion{
			{
				Name:    "Engine",
				Version: dockerversion.Version,
				Details: map[string]string{
					"GitCommit":     dockerversion.GitCommit,
					"ApiVersion":    api.DefaultVersion,
					"MinAPIVersion": api.MinVersion,
					"GoVersion":     runtime.Version(),
					"Os":            runtime.GOOS,
					"Arch":          runtime.GOARCH,
					"BuildTime":     dockerversion.BuildTime,
					"KernelVersion": kernelVersion,
					"Experimental":  fmt.Sprintf("%t", daemon.configStore.Experimental),
				},
			},
		},

		// Populate deprecated fields for older clients
		Version:       dockerversion.Version,
		GitCommit:     dockerversion.GitCommit,
		APIVersion:    api.DefaultVersion,
		MinAPIVersion: api.MinVersion,
		GoVersion:     runtime.Version(),
		Os:            runtime.GOOS,
		Arch:          runtime.GOARCH,
		BuildTime:     dockerversion.BuildTime,
		KernelVersion: kernelVersion,
		Experimental:  daemon.configStore.Experimental,
	}

	v.Platform.Name = dockerversion.PlatformName

	daemon.fillPlatformVersion(&v)
	return v
}
source: func (n *IcsNode) GetOneParam() (string, string) {
	if n.ParamsLen() == 0 {
		return "", ""
	}
	var key, val string
	for k, v := range n.Params {
		key, val = k, v
		break
	}
	return key, val
}
source: func MakeMapper(t TokenMapperFn, a AmountMapperFn) MapperFn {
	return func(r request.Request) (string, int64, error) {
		token, err := t(r)
		if err != nil {
			return "", -1, err
		}
		amount, err := a(r)
		if err != nil {
			return "", -1, err
		}
		return token, amount, nil
	}
}
source: func NewUserRootInfo(RootNamespaceId string, HomeNamespaceId string) *UserRootInfo {
	s := new(UserRootInfo)
	s.RootNamespaceId = RootNamespaceId
	s.HomeNamespaceId = HomeNamespaceId
	return s
}
source: func (c *Configuration) UnsetGlobalSection(key string) (string, error) {
	return c.gitConfigWrite("--global", "--remove-section", key)
}
source: func (m *matrix3x3) scale(f float64) *matrix3x3 {
	return &matrix3x3{
		[3]float64{f * m[0][0], f * m[0][1], f * m[0][2]},
		[3]float64{f * m[1][0], f * m[1][1], f * m[1][2]},
		[3]float64{f * m[2][0], f * m[2][1], f * m[2][2]},
	}
}
source: func ExtractResponseFields(opts ...interface{}) *opt.ResponseFieldsOption {
	for _, o := range opts {
		if v, ok := o.(*opt.ResponseFieldsOption); ok {
			return v
		}
	}
	return nil
}
source: func (h *ExecutorHandler) ServeHTTP(w http.ResponseWriter, r *http.Request) {
	w.Header().Set("Content-Type", "application/json")
	w.Header().Set("Access-Control-Allow-Origin", "*")
	w.Header().Set("Access-Control-Allow-Headers", r.Header.Get("Access-Control-Request-Headers"))
	if r.Method == "OPTIONS" {
		w.WriteHeader(200)
		return
	}

	//TODO(tmc): reject non-GET/OPTIONS requests
	q := r.URL.Query().Get("q")
	log.Println("query:", q)
	operation, err := parser.ParseOperation([]byte(q))
	if err != nil {
		log.Println("error parsing:", err)
		writeErr(w, err)
		return
	}
	// if err := h.validator.Validate(operation); err != nil { writeErr(w, err); return }
	ctx := context.Background()
	if r.Header.Get("X-Trace-ID") != "" {
		t, err := tracer.FromRequest(r)
		if err == nil {
			ctx = tracer.NewContext(ctx, t)
		}
	}
	ctx = context.WithValue(ctx, "http_request", r)
	if r.Header.Get("X-GraphQL-Only-Parse") == "1" {
		writeJSONIndent(w, operation, " ")
		return
	}

	data, err := h.executor.HandleOperation(ctx, operation)
	result := Result{Data: data}
	if err != nil {
		w.WriteHeader(400)
		result.Error = &Error{Message: err.Error()}
	}
	if t, ok := tracer.FromContext(ctx); ok {
		t.Done()
		result.Trace = t
	}

	writeJSONIndent(w, result, "  ")
}
source: func (z *ConstNumber) Add(x, y *ConstNumber) *ConstNumber {
	z.Type = promoteConstNumbers(x.Type, y.Type)
	z.Value.Add(&x.Value, &y.Value)
	return z
}
source: func (m *Cluster_LeastRequestLbConfig) Validate() error {
	if m == nil {
		return nil
	}

	if wrapper := m.GetChoiceCount(); wrapper != nil {

		if wrapper.GetValue() < 2 {
			return Cluster_LeastRequestLbConfigValidationError{
				field:  "ChoiceCount",
				reason: "value must be greater than or equal to 2",
			}
		}

	}

	return nil
}
source: func (xl xlObjects) readXLMetaParts(ctx context.Context, bucket, object string) (xlMetaParts []ObjectPartInfo, xlMeta map[string]string, err error) {
	var ignoredErrs []error
	for _, disk := range xl.getLoadBalancedDisks() {
		if disk == nil {
			ignoredErrs = append(ignoredErrs, errDiskNotFound)
			continue
		}
		xlMetaParts, xlMeta, err = readXLMetaParts(ctx, disk, bucket, object)
		if err == nil {
			return xlMetaParts, xlMeta, nil
		}
		// For any reason disk or bucket is not available continue
		// and read from other disks.
		if IsErrIgnored(err, objMetadataOpIgnoredErrs...) {
			ignoredErrs = append(ignoredErrs, err)
			continue
		}
		// Error is not ignored, return right here.
		return nil, nil, err
	}
	// If all errors were ignored, reduce to maximal occurrence
	// based on the read quorum.
	readQuorum := len(xl.getDisks()) / 2
	return nil, nil, reduceReadQuorumErrs(ctx, ignoredErrs, nil, readQuorum)
}
source: func NewDBStore(path string) (s *DBStore, err error) {
	db, err := leveldb.OpenFile(path, nil)
	if err != nil {
		return nil, err
	}
	return &DBStore{
		db: db,
	}, nil
}
source: func (w *mlWriter) deactivatePlugin() {
	w.stack = w.stack[:len(w.stack)-1]
}
source: func AskForInt(ctx context.Context, text string, def int) (int, error) {
	if ctxutil.IsAlwaysYes(ctx) {
		return def, nil
	}

	str, err := AskForString(ctx, text, strconv.Itoa(def))
	if err != nil {
		return 0, err
	}
	if str == "q" {
		return 0, ErrAborted
	}
	intVal, err := strconv.Atoi(str)
	if err != nil {
		return 0, errors.Wrapf(err, "failed to convert to number")
	}
	return intVal, nil
}
source: func (t *FpdfTpl) childrensTemplates() []Template {
	childrenTmpls := make([]Template, 0)

	for x := 0; x < len(t.templates); x++ {
		tmpls := t.templates[x].Templates()
		childrenTmpls = append(childrenTmpls, tmpls...)
	}

	return childrenTmpls
}
source: func NewClient(enqueueTimeout time.Duration, addrs ...string) *Client {

	pool := disque.NewPool(disque.DialFunc(func(addr string) (redis.Conn, error) {
		return redis.DialTimeout("tcp", addr, enqueueTimeout, enqueueTimeout, enqueueTimeout)
	}), addrs...)

	pool.RefreshNodes()
	pool.RunRefreshLoop()

	return &Client{
		pool:              pool,
		enqueueTimeout:    enqueueTimeout,
		replicationFactor: 0, //TODO
	}
}
source: func (r *Consumer) ConnectToNSQD(addr string) error {
	if atomic.LoadInt32(&r.stopFlag) == 1 {
		return errors.New("consumer stopped")
	}

	if atomic.LoadInt32(&r.runningHandlers) == 0 {
		return errors.New("no handlers")
	}

	atomic.StoreInt32(&r.connectedFlag, 1)

	logger, logLvl := r.getLogger()

	conn := NewConn(addr, &r.config, &consumerConnDelegate{r})
	conn.SetLogger(logger, logLvl,
		fmt.Sprintf("%3d [%s/%s] (%%s)", r.id, r.topic, r.channel))

	r.mtx.Lock()
	_, pendingOk := r.pendingConnections[addr]
	_, ok := r.connections[addr]
	if ok || pendingOk {
		r.mtx.Unlock()
		return ErrAlreadyConnected
	}
	r.pendingConnections[addr] = conn
	if idx := indexOf(addr, r.nsqdTCPAddrs); idx == -1 {
		r.nsqdTCPAddrs = append(r.nsqdTCPAddrs, addr)
	}
	r.mtx.Unlock()

	r.log(LogLevelInfo, "(%s) connecting to nsqd", addr)

	cleanupConnection := func() {
		r.mtx.Lock()
		delete(r.pendingConnections, addr)
		r.mtx.Unlock()
		conn.Close()
	}

	resp, err := conn.Connect()
	if err != nil {
		cleanupConnection()
		return err
	}

	if resp != nil {
		if resp.MaxRdyCount < int64(r.getMaxInFlight()) {
			r.log(LogLevelWarning,
				"(%s) max RDY count %d < consumer max in flight %d, truncation possible",
				conn.String(), resp.MaxRdyCount, r.getMaxInFlight())
		}
	}

	cmd := Subscribe(r.topic, r.channel)
	err = conn.WriteCommand(cmd)
	if err != nil {
		cleanupConnection()
		return fmt.Errorf("[%s] failed to subscribe to %s:%s - %s",
			conn, r.topic, r.channel, err.Error())
	}

	r.mtx.Lock()
	delete(r.pendingConnections, addr)
	r.connections[addr] = conn
	r.mtx.Unlock()

	// pre-emptive signal to existing connections to lower their RDY count
	for _, c := range r.conns() {
		r.maybeUpdateRDY(c)
	}

	return nil
}
source: func (v *EmailIsPresent) IsValid(errors *validate.Errors) {
	if !rxEmail.Match([]byte(v.Field)) {
		if v.Message == "" {
			v.Message = fmt.Sprintf("%s does not match the email format.", v.Name)
		}
		errors.Add(GenerateKey(v.Name), v.Message)
	}
}
source: func (m *ClusterStats_DroppedRequests) Validate() error {
	if m == nil {
		return nil
	}

	if len(m.GetCategory()) < 1 {
		return ClusterStats_DroppedRequestsValidationError{
			field:  "Category",
			reason: "value length must be at least 1 bytes",
		}
	}

	// no validation rules for DroppedCount

	return nil
}
source: func (p *basePlan) AddParent(parent Plan) {
	p.parents = append(p.parents, parent)
}
source: func (s *Server) HandleStacksz(w http.ResponseWriter, r *http.Request) {
	// Do not get any lock here that would prevent getting the stacks
	// if we were to have a deadlock somewhere.
	var defaultBuf [defaultStackBufSize]byte
	size := defaultStackBufSize
	buf := defaultBuf[:size]
	n := 0
	for {
		n = runtime.Stack(buf, true)
		if n < size {
			break
		}
		size *= 2
		buf = make([]byte, size)
	}
	// Handle response
	ResponseHandler(w, r, buf[:n])
}
source: func (s *APIServer) upsertAuthServer(auth ClientI, w http.ResponseWriter, r *http.Request, p httprouter.Params, version string) (interface{}, error) {
	return s.upsertServer(auth, teleport.RoleAuth, w, r, p, version)
}
source: func saveConfig(configName string, data map[string]string) error {
	klog.V(4).Info(log("saving config file %s", configName))

	dir := path.Dir(configName)
	if _, err := os.Stat(dir); err != nil {
		if !os.IsNotExist(err) {
			return err
		}
		klog.V(4).Info(log("creating config dir for config data: %s", dir))
		if err := os.MkdirAll(dir, 0750); err != nil {
			klog.Error(log("failed to create config data dir %v", err))
			return err
		}
	}

	file, err := os.Create(configName)
	if err != nil {
		klog.V(4).Info(log("failed to save config data file %s: %v", configName, err))
		return err
	}
	defer file.Close()
	if err := gob.NewEncoder(file).Encode(data); err != nil {
		klog.Error(log("failed to save config %s: %v", configName, err))
		return err
	}
	klog.V(4).Info(log("config data file saved successfully as %s", configName))
	return nil
}
source: func WriteBurstUInt64(
	smiRequest chan<- Flit64,
	smiResponse <-chan Flit64,
	writeAddrIn uintptr,
	writeOptions uint8,
	writeLengthIn uint32,
	writeDataChan <-chan uint64) bool {

	writeOk := true
	writeAddr := writeAddrIn & 0xFFFFFFFFFFFFFFF8
	writeLength := writeLengthIn << 3
	burstOffset := uint16(writeAddr) & uint16(SmiMemBurstSize-1)
	burstSize := uint16(SmiMemBurstSize) - burstOffset
	smiWriteChan := make(chan Flit64, 1)
	asmReqChan := make(chan bool, 1)
	asmDoneChan := make(chan bool, 1)
	go AssembleFrame64(asmReqChan, smiWriteChan, smiRequest, asmDoneChan)

	for writeLength != 0 {
		asmReqChan <- true
		if writeLength < uint32(burstSize) {
			burstSize = uint16(writeLength)
		}
		thisWriteOk := writeSingleBurstUInt64(
			smiWriteChan, smiResponse, writeAddr, writeOptions, burstSize, writeDataChan)
		writeOk = writeOk && thisWriteOk
		writeAddr += uintptr(burstSize)
		writeLength -= uint32(burstSize)
		burstSize = uint16(SmiMemBurstSize)
		<-asmDoneChan
	}
	asmReqChan <- false
	return writeOk
}
source: func ListenAndServe(s *http.Server, hd *HTTP) error {
	if hd == nil {
		hd = &HTTP{}
	}
	hs, err := hd.ListenAndServe(s)
	if err != nil {
		return err
	}

	waiterr := make(chan error, 1)
	go func() {
		defer close(waiterr)
		waiterr <- hs.Wait()
	}()

	signals := make(chan os.Signal, 10)
	signal.Notify(signals, syscall.SIGTERM, syscall.SIGINT)

	select {
	case err := <-waiterr:
		if err != nil {
			return err
		}
	case <-signals:
		signal.Stop(signals)
		if err := hs.Stop(); err != nil {
			return err
		}
		if err := <-waiterr; err != nil {
			return err
		}
	}
	return nil
}
source: func NewClient(user, pass, base string) *Client {
	return &Client{
		ID:          user,
		Token:       pass,
		Client:      defaultHttpClient,
		Base:        base,
		UploadType:  JSON,
		ErrorParser: DefaultErrorParser,
	}
}
source: func FromContext(ctx context.Context) (Etc, bool) {
	cfg, ok := ctx.Value(etcKey).(Etc)
	return cfg, ok
}
source: func (t *Torrent) onIncompletePiece(piece pieceIndex) {
	if t.pieceAllDirty(piece) {
		t.pendAllChunkSpecs(piece)
	}
	if !t.wantPieceIndex(piece) {
		// t.logger.Printf("piece %d incomplete and unwanted", piece)
		return
	}
	// We could drop any connections that we told we have a piece that we
	// don't here. But there's a test failure, and it seems clients don't care
	// if you request pieces that you already claim to have. Pruning bad
	// connections might just remove any connections that aren't treating us
	// favourably anyway.

	// for c := range t.conns {
	// 	if c.sentHave(piece) {
	// 		c.Drop()
	// 	}
	// }
	for conn := range t.conns {
		if conn.PeerHasPiece(piece) {
			conn.updateRequests()
		}
	}
}
source: func (r *Ruler) Rule(path string) *RulerRule {
	rule := &Rule{
		"",
		path,
		nil,
	}

	r.rules = append(r.rules, rule)

	return &RulerRule{
		r,
		rule,
	}
}
source: func (f *FileStore) Stats() []FileStat {
	f.mu.RLock()
	if len(f.lastFileStats) > 0 {
		defer f.mu.RUnlock()
		return f.lastFileStats
	}
	f.mu.RUnlock()

	// The file stats cache is invalid due to changes to files. Need to
	// recalculate.
	f.mu.Lock()
	defer f.mu.Unlock()

	if len(f.lastFileStats) > 0 {
		return f.lastFileStats
	}

	// If lastFileStats's capacity is far away from the number of entries
	// we need to add, then we'll reallocate.
	if cap(f.lastFileStats) < len(f.files)/2 {
		f.lastFileStats = make([]FileStat, 0, len(f.files))
	}

	for _, fd := range f.files {
		f.lastFileStats = append(f.lastFileStats, fd.Stats())
	}
	return f.lastFileStats
} 95%|█████████▍| 4732/5000 [00:05<00:00, 1035.60it/s]
source: func Convert_v1beta1_CSINode_To_storage_CSINode(in *v1beta1.CSINode, out *storage.CSINode, s conversion.Scope) error {
	return autoConvert_v1beta1_CSINode_To_storage_CSINode(in, out, s)
}
source: func (ta *TrackAttributes) MinAcousticness(acousticness float64) *TrackAttributes {
	ta.floatAttributes["min_acousticness"] = acousticness
	return ta
}
source: func (b *PositionBuilder) NewTokenPosition(t *scanner.Token) *position.Position {
	return &position.Position{
		StartLine: t.StartLine,
		EndLine:   t.EndLine,
		StartPos:  t.StartPos,
		EndPos:    t.EndPos,
	}
}
source: func (l *Listing) SetPageCount(n int) {
	if n > 1000 {
		n = 1000
	}
	l.nextPageCount = n
}
source: func (c *FakeFluxHelmReleases) Patch(name string, pt types.PatchType, data []byte, subresources ...string) (result *v1alpha2.FluxHelmRelease, err error) {
	obj, err := c.Fake.
		Invokes(testing.NewPatchSubresourceAction(fluxhelmreleasesResource, c.ns, name, pt, data, subresources...), &v1alpha2.FluxHelmRelease{})

	if obj == nil {
		return nil, err
	}
	return obj.(*v1alpha2.FluxHelmRelease), err
}
source: func (ethash *Ethash) Close() error {
	var err error
	ethash.closeOnce.Do(func() {
		// Short circuit if the exit channel is not allocated.
		if ethash.exitCh == nil {
			return
		}
		errc := make(chan error)
		ethash.exitCh <- errc
		err = <-errc
		close(ethash.exitCh)
	})
	return err
}
source: func remove(path string) {
	err := os.Remove(path)
	if err != nil {
		fmt.Fprintf(os.Stderr, "could not remove %v: %v\n", path, err)
	}
}
source: func streamInterceptor(ctx context.Context, desc *grpc.StreamDesc, cc *grpc.ClientConn, method string, streamer grpc.Streamer, opts ...grpc.CallOption) (grpc.ClientStream, error) {
	var credsConfigured bool
	for _, o := range opts {
		_, ok := o.(*grpc.PerRPCCredsCallOption)
		if ok {
			credsConfigured = true
		}
	}
	if !credsConfigured {
		opts = append(opts, grpc.PerRPCCredentials(oauth.NewOauthAccess(&oauth2.Token{
			AccessToken: fallbackToken,
		})))
	}
	s, err := streamer(ctx, desc, cc, method, opts...)
	if err != nil {
		return nil, err
	}
	return newWrappedStream(s), nil
}
source: func (s *UsersStore) Get(ctx context.Context, q chronograf.UserQuery) (*chronograf.User, error) {
	if q.ID != nil {
		return s.get(ctx, *q.ID)
	}

	if q.Name != nil && q.Provider != nil && q.Scheme != nil {
		var user *chronograf.User
		err := s.each(ctx, func(u *chronograf.User) {
			if user != nil {
				return
			}
			if u.Name == *q.Name && u.Provider == *q.Provider && u.Scheme == *q.Scheme {
				user = u
			}
		})

		if err != nil {
			return nil, err
		}

		if user == nil {
			return nil, chronograf.ErrUserNotFound
		}

		return user, nil
	}

	return nil, fmt.Errorf("must specify either ID, or Name, Provider, and Scheme in UserQuery")
}
source: func (endpoint *HostComputeEndpoint) Create() (*HostComputeEndpoint, error) {
	logrus.Debugf("hcn::HostComputeEndpoint::Create id=%s", endpoint.Id)

	if endpoint.HostComputeNamespace != "" {
		return nil, errors.New("endpoint create error, endpoint json HostComputeNamespace is read only and should not be set")
	}

	jsonString, err := json.Marshal(endpoint)
	if err != nil {
		return nil, err
	}

	logrus.Debugf("hcn::HostComputeEndpoint::Create JSON: %s", jsonString)
	endpoint, hcnErr := createEndpoint(endpoint.HostComputeNetwork, string(jsonString))
	if hcnErr != nil {
		return nil, hcnErr
	}
	return endpoint, nil
}
source: func (p *parser) parsePackage(fileNames []string) error {
	if len(fileNames) == 0 {
		return fmt.Errorf("fileNames is empty")
	}
	for i, name := range fileNames {
		if i > 0 && filepath.Dir(name) != filepath.Dir(fileNames[0]) {
			return fmt.Errorf("Go files belong to different directories")
		}
		if !strings.HasSuffix(name, ".go") {
			continue
		}
		file, err := goparser.ParseFile(p.fileSet, name, nil, 0)
		if err != nil {
			return fmt.Errorf("parsing %s: %s", name, err)
		}
		if len(p.files) > 0 && file.Name.Name != p.files[0].Name.Name {
			return fmt.Errorf("Go files belong to different packages")
		}
		p.files = append(p.files, file)
	}
	if len(p.files) == 0 {
		return fmt.Errorf("no buildable Go files")
	}
	return nil
}
source: func stateTag(l *lexer) stateFn {
	if strings.HasPrefix(l.input[l.pos:], "}"+l.rightDelim) {
		l.seek(1)
		l.emit(tokenRawEnd)
		return stateRightDelim
	}
	if strings.HasPrefix(l.input[l.pos:], l.rightDelim) {
		return stateRightDelim
	}
	switch r := l.next(); {
	case r == eof || r == '\n':
		return l.errorf("unclosed action")
	case whitespace(r):
		l.ignore()
	case r == '!':
		l.emit(tokenComment)
		return stateComment
	case r == '#':
		l.emit(tokenSectionStart)
	case r == '^':
		l.emit(tokenSectionInverse)
	case r == '/':
		l.emit(tokenSectionEnd)
	case r == '&':
		l.emit(tokenRawAlt)
	case r == '>':
		l.emit(tokenPartial)
	case r == '{':
		l.emit(tokenRawStart)
	case alphanum(r):
		l.backup()
		return stateIdent
	default:
		return l.errorf("unrecognized character in action: %#U", r)
	}
	return stateTag
}
source: func (dbcr *DiskBlockCacheRemote) GetLastUnrefRev(
	_ context.Context, _ tlf.ID, _ DiskBlockCacheType) (
	kbfsmd.Revision, error) {
	panic("GetLastUnrefRev() not implemented in DiskBlockCacheRemote")
}
source: func (s *Etcd) GetTree(directory string) ([]*store.KVPair, error) {
	getOpts := &etcd.GetOptions{
		Quorum:    true,
		Recursive: true,
		Sort:      true,
	}

	resp, err := s.client.Get(context.Background(), s.normalize(directory), getOpts)
	if err != nil {
		if keyNotFound(err) {
			return nil, store.ErrKeyNotFound
		}
		return nil, err
	}
	if !resp.Node.Dir { // it is a key, not a directory
		return []*store.KVPair{
			&store.KVPair{
				Key:       resp.Node.Key,
				Value:     []byte(resp.Node.Value),
				LastIndex: resp.Node.ModifiedIndex,
			},
		}, nil
	}

	return travelNodes(resp.Node.Nodes), nil
}
source: func gccld(pkg *Package, cgoCFLAGS, cgoLDFLAGS []string, ofile string, ofiles []string) error {
	args := []string{}
	args = append(args, "-o", ofile)
	args = append(args, ofiles...)
	args = append(args, cgoLDFLAGS...) // this has to go at the end, because reasons!
	t0 := time.Now()

	var cmd []string
	if len(pkg.CXXFiles) > 0 || len(pkg.SwigCXXFiles) > 0 {
		cmd = gxxCmd(pkg, pkg.Dir)
	} else {
		cmd = gccCmd(pkg, pkg.Dir)
	}
	var buf bytes.Buffer
	err := runOut(&buf, pkg.Dir, nil, cmd[0], append(cmd[1:], args...)...)
	if err != nil {
		fmt.Fprintf(os.Stderr, "# %s\n", pkg.ImportPath)
		io.Copy(os.Stderr, &buf)
	}
	pkg.Record("gccld", time.Since(t0))
	return err
}
source: func (e *ecuStats) notify(p publisher) {
	e.publishers = append(e.publishers, p)
}
source: func (b *Builder) Where(cond Cond) *Builder {
	if b.cond.IsValid() {
		b.cond = b.cond.And(cond)
	} else {
		b.cond = cond
	}
	return b
}
source: func (tracker *VoteTracker) fetchBlocks(voteInfo *dcrjson.GetVoteInfoResult) ([]int32, uint32, error) {
	blocksToRequest := 1
	// If this isn't the next block, request them all again
	if voteInfo.CurrentHeight < 0 || voteInfo.CurrentHeight != tracker.ringHeight+1 {
		blocksToRequest = int(tracker.params.BlockUpgradeNumToCheck)
	}
	r, err := tracker.node.GetStakeVersions(voteInfo.Hash, int32(blocksToRequest))
	if err != nil {
		return nil, 0, err
	}
	blockCount := len(r.StakeVersions)
	if blockCount != blocksToRequest {
		return nil, 0, fmt.Errorf("Unexpected number of blocks returns from GetStakeVersions. Asked for %d, received %d", blocksToRequest, blockCount)
	}
	blocks := make([]int32, blockCount)
	var block dcrjson.StakeVersions
	for i := 0; i < blockCount; i++ {
		block = r.StakeVersions[blockCount-i-1] // iterate backwards
		tracker.ringIndex = (tracker.ringIndex + 1) % blockCount
		blocks[i] = block.BlockVersion
	}
	return blocks, block.StakeVersion, nil
}
source: func DeepParseDeps(r io.Reader) (map[string][]string, error) {
	providedBy, requires, err := ParseDeps(r)
	if err != nil {
		return nil, err
	}
	filesDeps := make(map[string][]string)
	var deeperDeps func(namespace string) []string
	deeperDeps = func(namespace string) []string {
		if jsdeps, ok := filesDeps[namespace]; ok {
			return jsdeps
		}
		jsfiles := []string{providedBy[namespace]}
		for _, dep := range requires[namespace] {
			jsfiles = append(jsfiles, deeperDeps(dep)...)
		}
		return jsfiles
	}
	for namespace := range providedBy {
		filesDeps[namespace] = deeperDeps(namespace)
	}
	return filesDeps, nil
}
source: func (c *Client) GetDirectorBackend(i *GetDirectorBackendInput) (*DirectorBackend, error) {
	if i.Service == "" {
		return nil, ErrMissingService
	}

	if i.Version == 0 {
		return nil, ErrMissingVersion
	}

	if i.Director == "" {
		return nil, ErrMissingDirector
	}

	if i.Backend == "" {
		return nil, ErrMissingBackend
	}

	path := fmt.Sprintf("/service/%s/version/%d/director/%s/backend/%s",
		i.Service, i.Version, i.Director, i.Backend)
	resp, err := c.Get(path, nil)
	if err != nil {
		return nil, err
	}

	var b *DirectorBackend
	if err := decodeJSON(&b, resp.Body); err != nil {
		return nil, err
	}
	return b, nil
}
source: func timeDurationToStringHookFunc() mapstructure.DecodeHookFunc {
	return func(
		f reflect.Type,
		t reflect.Type,
		data interface{}) (interface{}, error) {
		dur, ok := data.(time.Duration)
		if !ok {
			return data, nil
		}
		if t.Kind() != reflect.String {
			return data, nil
		}
		if dur == 0 {
			return "", nil
		}

		// Convert it by parsing
		return data.(time.Duration).String(), nil
	}
}
source: func (p *pin) Get() bool {
	bytes := make([]byte, 1)
	_, p.err = p.valueFile.ReadAt(bytes, 0)
	return bytes[0] == bytesSet[0]
}
source: func (rf *Client) callV2(g *ogdl.Graph) (*ogdl.Graph, error) {

	// Convert graph to []byte
	buf := g.Binary()

	// Send LEN
	b4 := make([]byte, 4)
	binary.BigEndian.PutUint32(b4, uint32(len(buf)))

	rf.conn.SetDeadline(time.Now().Add(time.Second * time.Duration(rf.Timeout)))
	i, err := rf.conn.Write(b4)
	if i != 4 || err != nil {
		log.Println("ogdlrf.Client, error writing LEN header", i, err)
		return nil, errWritingHeader
	}

	i, err = rf.conn.Write(buf)
	if err != nil {
		log.Println("ogdlrf.Client, error writing body,", err)
		return nil, errWritingBody
	}
	if i != len(buf) {
		log.Println("ogdlrf.Client, error writing body, LEN is", i, "should be", len(buf))
		return nil, errWritingBody
	}

	// Read header response
	j, err := rf.conn.Read(b4)
	if j != 4 {
		log.Println("error reading incomming message LEN")
		return nil, errors.New("error in message header")
	}
	l := binary.BigEndian.Uint32(b4)

	// Read body response
	buf3 := make([]byte, 0, l)
	tmp := make([]byte, 10000)
	l2 := uint32(0)
	log.Println("starting to read, should be", l)
	for {
		log.Println("reading ...")
		i, err = rf.conn.Read(tmp)
		log.Println("reading ...", i)
		l2 += uint32(i)
		if err != nil || i == 0 {
			log.Println("Error reading body", l2, l, err)
			return nil, err
		}

		buf3 = append(buf3, tmp[:i]...)

		if l2 >= l {
			break
		}
	}

	log.Println("read ...", len(buf3))
	g = ogdl.FromBinary(buf3)

	if g == nil || g.Len() == 0 {
		return nil, errEmptyResponse
	}

	// log.Println(" - end of Call")

	return g, err
}
source: func (s *ItemResponse) SetEventsItemResponse(v map[string]*EventItemResponse) *ItemResponse {
	s.EventsItemResponse = v
	return s
}
source: func Profile(s Signer, profile string) (*config.SigningProfile, error) {
	var p *config.SigningProfile
	policy := s.Policy()
	if policy != nil && policy.Profiles != nil && profile != "" {
		p = policy.Profiles[profile]
	}

	if p == nil && policy != nil {
		p = policy.Default
	}

	if p == nil {
		return nil, cferr.Wrap(cferr.APIClientError, cferr.ClientHTTPError, errors.New("profile must not be nil"))
	}
	return p, nil
}
source: func Copy(src reflect.Value) reflect.Value {
	d := make(deepcopy)
	return d.copy(src)
}
source: func (s *Service) FQSN() string {
	components := []string{""}
	if s.File.Package != nil {
		components = append(components, s.File.GetPackage())
	}
	components = append(components, s.GetName())
	return strings.Join(components, ".")
}
source: func (b *BatchBuilder) AddStmt(stmt string, names []string) *BatchBuilder {
	b.stmts = append(b.stmts, stmt)
	b.names = append(b.names, names...)
	return b
}
source: func parseResource(s string) (Resource, error) {
	if !strings.HasPrefix(s, ResourceARNPrefix) {
		return Resource{}, fmt.Errorf("invalid resource '%v'", s)
	}

	pattern := strings.TrimPrefix(s, ResourceARNPrefix)
	tokens := strings.SplitN(pattern, "/", 2)
	bucketName := tokens[0]
	if bucketName == "" {
		return Resource{}, fmt.Errorf("invalid resource format '%v'", s)
	}

	return Resource{
		BucketName: bucketName,
		Pattern:    pattern,
	}, nil
}
source: func (s *OsdCsiServer) NodeGetId(
	ctx context.Context,
	req *csi.NodeGetIdRequest,
) (*csi.NodeGetIdResponse, error) {
	clus, err := s.cluster.Enumerate()
	if err != nil {
		return nil, status.Errorf(codes.Internal, "Unable to Enumerate cluster: %s", err)
	}

	result := &csi.NodeGetIdResponse{
		NodeId: clus.NodeId,
	}

	logrus.Infof("NodeId is %s", result.NodeId)

	return result, nil
}
source: func (mysqld *Mysqld) StartSlaveUntilAfter(ctx context.Context, targetPos mysql.Position) error {
	conn, err := getPoolReconnect(ctx, mysqld.dbaPool)
	if err != nil {
		return err
	}
	defer conn.Recycle()

	queries := []string{conn.StartSlaveUntilAfterCommand(targetPos)}

	return mysqld.executeSuperQueryListConn(ctx, conn, queries)
}
source: func (r *SplicedMemory) ReadMemory(buf []byte, addr uintptr) (n int, err error) {
	started := false
	for _, entry := range r.readers {
		if entry.offset+entry.length < addr {
			if !started {
				continue
			}
			return n, fmt.Errorf("hit unmapped area at %v after %v bytes", addr, n)
		}

		// Don't go past the region.
		pb := buf
		if addr+uintptr(len(buf)) > entry.offset+entry.length {
			pb = pb[:entry.offset+entry.length-addr]
		}
		pn, err := entry.reader.ReadMemory(pb, addr)
		n += pn
		if err != nil || pn != len(pb) {
			return n, err
		}
		buf = buf[pn:]
		addr += uintptr(pn)
		if len(buf) == 0 {
			// Done, don't bother scanning the rest.
			return n, nil
		}
	}
	if n == 0 {
		return 0, fmt.Errorf("offset %v did not match any regions", addr)
	}
	return n, nil
}
source: func (s *StatCounter) IncrementBy(v uint64) {
	atomic.AddUint64(&s.count, v)
}
source: func (f Feed) MarshalJSON() ([]byte, error) {
	type image struct {
		URL string `json:"url"`
	}
	gi := image{URL: f.Logo}

	var link Link
	if len(f.Links) > 0 {
		link = f.Links[0]
	}

	var authors []Author
	if len(f.Authors) > 0 {
		authors = f.Authors
	}

	gf := &struct {
		Title       string     `json:"title"`
		Link        Link       `json:"link"`
		Description string     `json:"description"`
		Updated     string     `json:"updated"`
		Authors     []Author   `json:"authors"`
		Image       image      `json:"image"`
		CopyRight   string     `json:"copyright"`
		Categories  []Category `json:"categories"`
		Items       []Entry    `json:"items"`
	}{
		Title:       f.Title,
		Link:        link,
		Description: f.SubTitle,
		Updated:     f.Updated,
		Authors:     authors,
		Image:       gi,
		CopyRight:   f.Rights,
		Categories:  f.Categories,
		Items:       f.Entries,
	}
	return json.Marshal(gf)
}
source: func findIntersectingShard(shardMap map[string]*topo.ShardInfo, sourceArray []*topo.ShardInfo) *topo.ShardInfo {
	for name, si := range shardMap {
		for _, sourceShardInfo := range sourceArray {
			if si.KeyRange == nil || sourceShardInfo.KeyRange == nil || key.KeyRangesIntersect(si.KeyRange, sourceShardInfo.KeyRange) {
				delete(shardMap, name)
				return si
			}
		}
	}
	return nil
}
source: func (c *edgeCollection) ReadDocument(ctx context.Context, key string, result interface{}) (DocumentMeta, error) {
	meta, _, err := c.readDocument(ctx, key, result)
	if err != nil {
		return DocumentMeta{}, WithStack(err)
	}
	return meta, nil
}
source: func (args Args) Validate(accepted map[string]bool) error {
	for name := range args.fields {
		if !accepted[name] {
			return invalidFilter(name)
		}
	}
	return nil
}
source: func Vhost() string {
	// Vhost
	vhLock.Lock()
	defer vhLock.Unlock()
	vh := os.Getenv("STOMP_VHOST")
	if vh != "" {
		vhost = vh
	} else {
		vhost = Host()
	}
	return vhost
}
source: func expression(res ...*regexp.Regexp) *regexp.Regexp {
	var s string
	for _, re := range res {
		s += re.String()
	}

	return match(s)
}
source: func (p *parser) parseBuiltinFunc() (*Decl, error) {
	var d *Decl
	var err error

	// COUNT(attribute)
	if p.is(CountToken) {
		d, err = p.consumeToken(CountToken)
		if err != nil {
			return nil, err
		}
		// Bracket
		_, err = p.consumeToken(BracketOpeningToken)
		if err != nil {
			return nil, err
		}
		// Attribute
		attr, err := p.parseAttribute()
		if err != nil {
			return nil, err
		}
		d.Add(attr)
		// Bracket
		_, err = p.consumeToken(BracketClosingToken)
		if err != nil {
			return nil, err
		}
	}

	return d, nil
}
source: func NewListFoldersContinueArg(Cursor string) *ListFoldersContinueArg {
	s := new(ListFoldersContinueArg)
	s.Cursor = Cursor
	return s
}
source: func ElementByIdReady(tab *Tab, elementAttributeId string) ConditionalFunc {
	return func(tab *Tab) bool {
		element, _, _ := tab.GetElementById(elementAttributeId)
		return (element != nil) && (element.IsReady())
	}
}
source: func New(start, size int) Allocator {
	a := &allocator{
		allocate: make(chan int, size),
	}

	for i := start; i < (start + size); i++ {
		a.allocate <- i
	}

	return a
}
source: func findGitDir() bool {
	if fileExists(".git") {
		return true
	}
	originalCwd, err := os.Getwd()
	checkErr(err)
	oldCwd := originalCwd
	for {
		checkErr(os.Chdir(".."))
		newCwd, err := os.Getwd()
		checkErr(err)
		if newCwd == oldCwd {
			log.Println("could not find GIT_DIR!")
			checkErr(os.Chdir(originalCwd))
			return false
		}
		if fileExists(".git") {
			log.Println("found GIT_DIR:", newCwd)
			return true
		}
		oldCwd = newCwd
	}
}
source: func (c *CompressResponseWriter) Write(b []byte) (int, error) {
	if c.closed {
		return 0, io.ErrClosedPipe
	}
	// Abort if parent has been closed
	if c.parentNotify != nil {
		select {
		case <-c.parentNotify:
			return 0, io.ErrClosedPipe
		default:
		}
	}
	// Abort if we ourselves have been closed
	if c.closed {
		return 0, io.ErrClosedPipe
	}

	if !c.headersWritten {
		c.prepareHeaders()
		c.headersWritten = true
	}
	if c.compressionType != "" {
		return c.compressWriter.Write(b)
	}
	return c.OriginalWriter.Write(b)
}
source: func ConnectAsAgent(a agent.Agent) (io.Closer, error) {
	return apicaller.ScaryConnect(a, api.Open)
}
source: func (admissionHandler chainAdmissionHandler) Admit(a Attributes, o ObjectInterfaces) error {
	for _, handler := range admissionHandler {
		if !handler.Handles(a.GetOperation()) {
			continue
		}
		if mutator, ok := handler.(MutationInterface); ok {
			err := mutator.Admit(a, o)
			if err != nil {
				return err
			}
		}
	}
	return nil
}
source: func (idsc IsDockerSystemdCheck) Check() (warnings, errorList []error) {
	warnings = []error{}
	driver, err := util.GetCgroupDriverDocker(exec.New())
	if err != nil {
		errorList = append(errorList, err)
		return nil, errorList
	}
	if driver != util.CgroupDriverSystemd {
		err = errors.Errorf("detected %q as the Docker cgroup driver. "+
			"The recommended driver is %q. "+
			"Please follow the guide at https://kubernetes.io/docs/setup/cri/",
			driver,
			util.CgroupDriverSystemd)
		warnings = append(warnings, err)
	}
	return warnings, nil
}
source: func (s *PhoneNumberCapabilities) SetOutboundMMS(v bool) *PhoneNumberCapabilities {
	s.OutboundMMS = &v
	return s
}
source: func (z zoneAddr) String() string {
	s := z.Transport + "://" + z.Zone + ":" + z.Port
	if z.Address != "" {
		s += " on " + z.Address
	}
	return s
}
source: func (r FutureValidateAddressResult) Receive() (*btcjson.ValidateAddressWalletResult, error) {
	res, err := receiveFuture(r)
	if err != nil {
		return nil, err
	}

	// Unmarshal result as a validateaddress result object.
	var addrResult btcjson.ValidateAddressWalletResult
	err = json.Unmarshal(res, &addrResult)
	if err != nil {
		return nil, err
	}

	return &addrResult, nil
}
source: func NewMemoryAssetTarget(d []byte, targetPath, permissions string) *MemoryAsset {
	return NewMemoryAsset(d, path.Dir(targetPath), path.Base(targetPath), permissions)
}
source: func (process *Process) CloseStdin() (err error) {
	process.handleLock.RLock()
	defer process.handleLock.RUnlock()

	operation := "hcsshim::Process::CloseStdin"
	process.logOperationBegin(operation)
	defer func() { process.logOperationEnd(operation, err) }()

	if process.handle == 0 {
		return makeProcessError(process, operation, ErrAlreadyClosed, nil)
	}

	modifyRequest := processModifyRequest{
		Operation: modifyCloseHandle,
		CloseHandle: &closeHandle{
			Handle: stdIn,
		},
	}

	modifyRequestb, err := json.Marshal(modifyRequest)
	if err != nil {
		return err
	}

	modifyRequestStr := string(modifyRequestb)

	var resultp *uint16
	err = hcsModifyProcess(process.handle, modifyRequestStr, &resultp)
	events := processHcsResult(resultp)
	if err != nil {
		return makeProcessError(process, operation, err, events)
	}

	if process.stdin != nil {
		process.stdin.Close()
	}
	return nil
}
source: func serializeAccountRow(row *dbAccountRow) []byte {
	// The serialized account format is:
	//   <acctType><rdlen><rawdata>
	//
	// 1 byte acctType + 4 bytes raw data length + raw data
	rdlen := len(row.rawData)
	buf := make([]byte, 5+rdlen)
	buf[0] = byte(row.acctType)
	binary.LittleEndian.PutUint32(buf[1:5], uint32(rdlen))
	copy(buf[5:5+rdlen], row.rawData)
	return buf
}
source: func (t *Table) RightJoinOn(
	table ReadableTable,
	onCondition BoolExpression) ReadableTable {

	return RightJoinOn(t, table, onCondition)
}
source: func (st *state) Uniter() (*uniter.State, error) {
	unitTag, ok := st.authTag.(names.UnitTag)
	if !ok {
		return nil, errors.Errorf("expected UnitTag, got %T %v", st.authTag, st.authTag)
	}
	return uniter.NewState(st, unitTag), nil
}
source: func (nc *Conn) drainConnection() {
	// Snapshot subs list.
	nc.mu.Lock()
	subs := make([]*Subscription, 0, len(nc.subs))
	for _, s := range nc.subs {
		subs = append(subs, s)
	}
	errCB := nc.Opts.AsyncErrorCB
	drainWait := nc.Opts.DrainTimeout
	nc.mu.Unlock()

	// for pushing errors with context.
	pushErr := func(err error) {
		nc.mu.Lock()
		nc.err = err
		if errCB != nil {
			nc.ach.push(func() { errCB(nc, nil, err) })
		}
		nc.mu.Unlock()
	}

	// Do subs first
	for _, s := range subs {
		if err := s.Drain(); err != nil {
			// We will notify about these but continue.
			pushErr(err)
		}
	}

	// Wait for the subscriptions to drop to zero.
	timeout := time.Now().Add(drainWait)
	for time.Now().Before(timeout) {
		if nc.NumSubscriptions() == 0 {
			break
		}
		time.Sleep(10 * time.Millisecond)
	}

	// Check if we timed out.
	if nc.NumSubscriptions() != 0 {
		pushErr(ErrDrainTimeout)
	}

	// Flip State
	nc.mu.Lock()
	nc.status = DRAINING_PUBS
	nc.mu.Unlock()

	// Do publish drain via Flush() call.
	err := nc.Flush()
	if err != nil {
		pushErr(err)
		nc.Close()
		return
	}

	// Move to closed state.
	nc.Close()
}
source: func (s *CreatePolicyVersionInput) SetSetAsDefault(v bool) *CreatePolicyVersionInput {
	s.SetAsDefault = &v
	return s
}
source: func (c *writeTroughCache) Set(key string, data []byte) error {
	err := c.memory.Set(key, data)
	if err != nil {
		return err
	}

	err = c.file.Set(key, data)
	if err != nil {
		return err
	}

	return nil
}
source: func (s *oracleVolumeSource) CreateVolumes(ctx context.ProviderCallContext, params []storage.VolumeParams) ([]storage.CreateVolumesResult, error) {
	if params == nil {
		return []storage.CreateVolumesResult{}, nil
	}
	results := make([]storage.CreateVolumesResult, len(params))
	for i, volume := range params {
		vol, err := s.createVolume(volume)
		if err != nil {
			results[i].Error = errors.Trace(err)
			continue
		}
		results[i].Volume = vol
	}
	return results, nil
}
source: func RetryOnError(ctx context.Context, req Request, retryCount int, err error) (bool, error) {
	if err == nil {
		return false, nil
	}

	e := errors.Parse(err.Error())
	if e == nil {
		return false, nil
	}

	switch e.Code {
	// retry on timeout or internal server error
	case 408, 500:
		return true, nil
	default:
		return false, nil
	}
}
source: func (statement *Statement) SQL(query interface{}, args ...interface{}) *Statement {
	switch query.(type) {
	case (*builder.Builder):
		var err error
		statement.RawSQL, statement.RawParams, err = query.(*builder.Builder).ToSQL()
		if err != nil {
			statement.Engine.logger.Error(err)
		}
	case string:
		statement.RawSQL = query.(string)
		statement.RawParams = args
	default:
		statement.Engine.logger.Error("unsupported sql type")
	}

	return statement
}
source: func generateLookupPaths(urlStr string) ([]string, error) {
	const maxPathComponents = 4

	parsedURL, err := parseURL(urlStr)
	if err != nil {
		return nil, err
	}
	path := parsedURL.Path

	paths := []string{"/"}
	var pathComponents []string
	for _, p := range strings.Split(path, "/") {
		if p != "" {
			pathComponents = append(pathComponents, p)
		}
	}

	numComponents := len(pathComponents)
	if numComponents > maxPathComponents {
		numComponents = maxPathComponents
	}

	for i := 1; i < numComponents; i++ {
		paths = append(paths, "/"+strings.Join(pathComponents[:i], "/")+"/")
	}
	if path != "/" {
		paths = append(paths, path)
	}
	if len(parsedURL.RawQuery) > 0 {
		paths = append(paths, path+"?"+parsedURL.RawQuery)
	}
	return paths, nil
}
source: func (s *Semaphore) DrainPermits() int {
	n := s.AvailablePermits()
	if n > 0 {
		s.AcquireMany(n)
	}
	return n
}
source: func (l LabelSet) Merge(other LabelSet) LabelSet {
	result := make(LabelSet, len(l))

	for k, v := range l {
		result[k] = v
	}

	for k, v := range other {
		result[k] = v
	}

	return result
}
source: func (s *CreateAutoScalingGroupInput) SetLifecycleHookSpecificationList(v []*LifecycleHookSpecification) *CreateAutoScalingGroupInput {
	s.LifecycleHookSpecificationList = v
	return s
}
source: func loadSessionV8(sid string) (*sessionV8, *probe.Error) {
	if !isSessionDirExists() {
		return nil, errInvalidArgument().Trace()
	}
	sessionFile, err := getSessionFile(sid)
	if err != nil {
		return nil, err.Trace(sid)
	}

	if _, e := os.Stat(sessionFile); e != nil {
		return nil, probe.NewError(e)
	}

	// Initialize new session.
	s := &sessionV8{
		Header: &sessionV8Header{
			Version: globalSessionConfigVersion,
		},
		SessionID: sid,
	}

	// Initialize session config loader.
	qs, e := quick.NewConfig(s.Header, nil)
	if e != nil {
		return nil, probe.NewError(e).Trace(sid, s.Header.Version)
	}

	if e = qs.Load(sessionFile); e != nil {
		return nil, probe.NewError(e).Trace(sid, s.Header.Version)
	}

	// Validate if the version matches with expected current version.
	sV8Header := qs.Data().(*sessionV8Header)
	if sV8Header.Version != globalSessionConfigVersion {
		msg := fmt.Sprintf("Session header version %s does not match mc session version %s.\n",
			sV8Header.Version, globalSessionConfigVersion)
		return nil, probe.NewError(errors.New(msg)).Trace(sid, sV8Header.Version)
	}

	s.mutex = new(sync.Mutex)
	s.Header = sV8Header

	sessionDataFile, err := getSessionDataFile(s.SessionID)
	if err != nil {
		return nil, err.Trace(sid, s.Header.Version)
	}

	dataFile, e := os.Open(sessionDataFile)
	if e != nil {
		return nil, probe.NewError(e)
	}
	s.DataFP = &sessionDataFP{false, dataFile}

	return s, nil
}
source: func NewConn(c net.Conn, side core.Side, recordProtocol string, key []byte, protected []byte) (net.Conn, error) {
	newCrypto := protocols[recordProtocol]
	if newCrypto == nil {
		return nil, fmt.Errorf("negotiated unknown next_protocol %q", recordProtocol)
	}
	crypto, err := newCrypto(side, key)
	if err != nil {
		return nil, fmt.Errorf("protocol %q: %v", recordProtocol, err)
	}
	overhead := MsgLenFieldSize + msgTypeFieldSize + crypto.EncryptionOverhead()
	payloadLengthLimit := altsRecordDefaultLength - overhead
	if protected == nil {
		// We pre-allocate protected to be of size
		// 2*altsRecordDefaultLength-1 during initialization. We only
		// read from the network into protected when protected does not
		// contain a complete frame, which is at most
		// altsRecordDefaultLength-1 (bytes). And we read at most
		// altsRecordDefaultLength (bytes) data into protected at one
		// time. Therefore, 2*altsRecordDefaultLength-1 is large enough
		// to buffer data read from the network.
		protected = make([]byte, 0, 2*altsRecordDefaultLength-1)
	}

	altsConn := &conn{
		Conn:               c,
		crypto:             crypto,
		payloadLengthLimit: payloadLengthLimit,
		protected:          protected,
		writeBuf:           make([]byte, altsWriteBufferInitialSize),
		nextFrame:          protected,
		overhead:           overhead,
	}
	return altsConn, nil
}
source: func (c *Client) SetIcon(id int) error {
	return c.ClientUpdate(NewArg(ClientIconID, id))
}
source: func (b *Backend) Workspaces() ([]string, error) {
	states := []string{backend.DefaultStateName}

	bucket := b.storageClient.Bucket(b.bucketName)
	objs := bucket.Objects(b.storageContext, &storage.Query{
		Delimiter: "/",
		Prefix:    b.prefix,
	})
	for {
		attrs, err := objs.Next()
		if err == iterator.Done {
			break
		}
		if err != nil {
			return nil, fmt.Errorf("querying Cloud Storage failed: %v", err)
		}

		name := path.Base(attrs.Name)
		if !strings.HasSuffix(name, stateFileSuffix) {
			continue
		}
		st := strings.TrimSuffix(name, stateFileSuffix)

		if st != backend.DefaultStateName {
			states = append(states, st)
		}
	}

	sort.Strings(states[1:])
	return states, nil
}
source: func Decode(r io.Reader) (*TcpMessage, error) {
	var ln uint16
	err := binary.Read(r, binary.BigEndian, &ln)
	if err != nil {
		return nil, err
	}

	packet := make([]byte, ln)
	_, err = io.ReadFull(r, packet)
	if err != nil {
		return nil, err
	}

	m := TcpMessage{}

	err = m.UnmarshalBinary(packet)
	return &m, err
}
source: func (w *Worker) UpdateEval(eval *structs.Evaluation) error {
	// Check for a shutdown before plan submission
	if w.srv.IsShutdown() {
		return fmt.Errorf("shutdown while planning")
	}
	defer metrics.MeasureSince([]string{"nomad", "worker", "update_eval"}, time.Now())

	// Store the snapshot index in the eval
	eval.SnapshotIndex = w.snapshotIndex

	// Setup the request
	req := structs.EvalUpdateRequest{
		Evals:     []*structs.Evaluation{eval},
		EvalToken: w.evalToken,
		WriteRequest: structs.WriteRequest{
			Region: w.srv.config.Region,
		},
	}
	var resp structs.GenericResponse

SUBMIT:
	// Make the RPC call
	if err := w.srv.RPC("Eval.Update", &req, &resp); err != nil {
		w.logger.Error("failed to update evaluation", "eval", log.Fmt("%#v", eval), "error", err)
		if w.shouldResubmit(err) && !w.backoffErr(backoffBaselineSlow, backoffLimitSlow) {
			goto SUBMIT
		}
		return err
	} else {
		w.logger.Debug("updated evaluation", "eval", log.Fmt("%#v", eval))
		w.backoffReset()
	}
	return nil
}
source: func (n *Graph) decSendChanRefCount(c reflect.Value) bool {
	n.sendChanMutex.Lock()
	defer n.sendChanMutex.Unlock()

	ptr := c.Pointer()
	cnt := n.sendChanRefCount[ptr]
	if cnt == 0 {
		return true //yes you may try to close a nonexistant channel, see what happens...
	}
	cnt--
	n.sendChanRefCount[ptr] = cnt
	return cnt == 0
}
source: func NewUUID(namespace, name string) ([]byte, error) {
	hash := md5.New()
	_, err := hash.Write([]byte(namespace))
	if err != nil {
		return nil, errors.Wrapf(err, "could not compute hash value for namespace %q", namespace)
	}
	_, err = hash.Write([]byte(name))
	if err != nil {
		return nil, errors.Wrapf(err, "could not compute hash value for name %q", name)
	}

	sum := hash.Sum(nil)

	uuid := make([]byte, 16)
	copy(uuid, sum)

	// set version(v3)
	internal.SetVersion(uuid, internal.VersionNameBasedMD5)
	// set layout(RFC4122)
	internal.SetLayout(uuid, internal.LayoutRFC4122)

	return uuid, nil
}
source: func (r *resp) receiveResponse() *response {
	// Receive first line.
	line, err := r.reader.ReadBytes('\n')
	if err != nil {
		rerr := errors.Annotate(err, ErrConnectionBroken, errorMessages, "receive after "+r.cmd)
		return &response{receivingError, 0, nil, rerr}
	}
	content := line[1 : len(line)-2]
	// First byte defines kind.
	switch line[0] {
	case '+':
		// Status response.
		return &response{statusResponse, 0, line[:len(line)-2], nil}
	case '-':
		// Error response.
		return &response{errorResponse, 0, line[:len(line)-2], nil}
	case ':':
		// Integer response.
		return &response{integerResponse, 0, content, nil}
	case '$':
		// Bulk response or null bulk response.
		count, err := strconv.Atoi(string(content))
		if err != nil {
			return &response{receivingError, 0, nil, errors.Annotate(err, ErrServerResponse, errorMessages)}
		}
		if count == -1 {
			// Null bulk response.
			return &response{nullBulkResponse, 0, nil, nil}
		}
		// Receive the bulk data.
		toRead := count + 2
		buffer := make([]byte, toRead)
		n, err := io.ReadFull(r.reader, buffer)
		if err != nil {
			return &response{receivingError, 0, nil, err}
		}
		if n < toRead {
			return &response{receivingError, 0, nil, errors.New(ErrServerResponse, errorMessages)}
		}
		return &response{bulkResponse, 0, buffer[0:count], nil}
	case '*':
		// Array reply. Check for timeout.
		length, err := strconv.Atoi(string(content))
		if err != nil {
			return &response{receivingError, 0, nil, errors.Annotate(err, ErrServerResponse, errorMessages)}
		}
		if length == -1 {
			// Timeout.
			return &response{timeoutError, 0, nil, nil}
		}
		return &response{arrayResponse, length, nil, nil}
	}
	return &response{receivingError, 0, nil, errors.New(ErrInvalidResponse, errorMessages, string(line))}
}
source: func (s *LoadBalancerService) UploadSslCert(p *UploadSslCertParams) (*UploadSslCertResponse, error) {
	resp, err := s.cs.newRequest("uploadSslCert", p.toURLValues())
	if err != nil {
		return nil, err
	}

	var r UploadSslCertResponse
	if err := json.Unmarshal(resp, &r); err != nil {
		return nil, err
	}

	return &r, nil
}
source: func GetUid(name string) (int, error) {
	switch name {
	case "nobody":
		return NobodyUid, nil

	case "root":
		return RootUid, nil

	default:
		userInfo, err := user.Lookup(name)
		if err != nil {
			return 0, err
		}

		return strconv.Atoi(userInfo.Uid)
	}
}
source: func NewIMUDriver(a *firmata.Adaptor) *IMUDriver {
	imu := &IMUDriver{
		name:       gobot.DefaultName("CurieIMU"),
		connection: a,
		Eventer:    gobot.NewEventer(),
	}

	return imu
}
source: func (h *Hook) Fire(entry *logrus.Entry) error {
	p := bytes.TrimSpace([]byte(entry.Message))
	short := bytes.NewBuffer(p)
	full := ""
	if i := bytes.IndexRune(p, '\n'); i > 0 {
		full = short.String()
		short.Truncate(i)
	}
	extra := map[string]interface{}{}
	// merge entry.Data & extra & facility
	for k, v := range entry.Data {
		extra["_"+k] = v // prefix with _ will be treated as an additional field
	}
	for k, v := range h.extra {
		extra["_"+k] = v // prefix with _ will be treated as an additional field
	}
	extra["_facility"] = h.facility

	m := &gelf.Message{
		Version:  "1.1",
		Host:     h.hostname,
		Short:    short.String(),
		Full:     full,
		TimeUnix: float64(now().UnixNano()) / 1e9,
		Level:    int32(entry.Level),
		Extra:    extra,
	}
	return h.w.WriteMessage(m)
}
source: func canonicalizeInstanceName(name string) string {
	ix := strings.Index(name, ".")
	if ix != -1 {
		name = name[:ix]
	}
	return name
}
source: func processBucketNotificationResponse(bucketName string, resp *http.Response) (BucketNotification, error) {
	if resp.StatusCode != http.StatusOK {
		errResponse := httpRespToErrorResponse(resp, bucketName, "")
		return BucketNotification{}, errResponse
	}
	var bucketNotification BucketNotification
	err := xmlDecoder(resp.Body, &bucketNotification)
	if err != nil {
		return BucketNotification{}, err
	}
	return bucketNotification, nil
}
source: func (f *BoolTFlag) Apply(set *flag.FlagSet) {
	f.set = set
	f.BoolTFlag.Apply(set)
}
source: func New(config fab.EndpointConfig) *InfraProvider {
	idleTime := config.Timeout(fab.ConnectionIdle)
	sweepTime := config.Timeout(fab.CacheSweepInterval)

	return &InfraProvider{
		commManager: comm.NewCachingConnector(sweepTime, idleTime),
	}
}
source: func Reset(sel interface{}, opts ...QueryOption) Action {
	return QueryAfter(sel, func(ctx context.Context, nodes ...*cdp.Node) error {
		if len(nodes) < 1 {
			return fmt.Errorf("selector `%s` did not return any nodes", sel)
		}

		var res bool
		err := EvaluateAsDevTools(fmt.Sprintf(resetJS, nodes[0].FullXPath()), &res).Do(ctx)
		if err != nil {
			return err
		}

		if !res {
			return fmt.Errorf("could not call reset on node %d", nodes[0].NodeID)
		}

		return nil
	}, opts...)
}
source: func NewModuloSampler(mod uint64) Sampler {
	if mod < 2 {
		return AlwaysSample
	}
	return func(id uint64) bool {
		return (id % mod) == 0
	}
}
source: func (r *Runc) List(context context.Context) ([]*Container, error) {
	data, err := cmdOutput(r.command(context, "list", "--format=json"), false)
	if err != nil {
		return nil, err
	}
	var out []*Container
	if err := json.Unmarshal(data, &out); err != nil {
		return nil, err
	}
	return out, nil
}
source: func (s *Store) Prune(ctx context.Context, name string) error {
	ls, err := s.List(ctx, name)
	if err != nil {
		return err
	}
	for _, e := range ls {
		if err := s.Delete(ctx, e); err != nil {
			return err
		}
	}
	return nil
}
source: func (st *State) WatchApplications() StringsWatcher {
	return newLifecycleWatcher(st, applicationsC, nil, isLocalID(st), nil)
}
source: func (c *OutboundCall) WriteToRequestMeta(ctx context.Context, reqMeta *transport.RequestMeta) (context.Context, error) {
	for _, h := range c.headers {
		reqMeta.Headers = reqMeta.Headers.With(h.k, h.v)
	}

	if c.shardKey != nil {
		reqMeta.ShardKey = *c.shardKey
	}
	if c.routingKey != nil {
		reqMeta.RoutingKey = *c.routingKey
	}
	if c.routingDelegate != nil {
		reqMeta.RoutingDelegate = *c.routingDelegate
	}

	// NB(abg): context and error are unused for now but we want to leave room
	// for CallOptions which can fail or modify the context.
	return ctx, nil
}
source: func (s *DescribeEnvironmentMembershipsOutput) SetMemberships(v []*EnvironmentMember) *DescribeEnvironmentMembershipsOutput {
	s.Memberships = v
	return s
}
source: func rightOf(s, delim string) string {
	if _, right, ok := twoFields(s, delim); ok {
		return strings.TrimSpace(right)
	}
	return ""
}
source: func (tc *TelegrafConfig) UnmarshalJSON(b []byte) error {
	tcd := new(telegrafConfigDecode)
	if err := json.Unmarshal(b, tcd); err != nil {
		return err
	}
	*tc = TelegrafConfig{
		ID:             tcd.ID,
		OrganizationID: tcd.OrganizationID,
		Name:           tcd.Name,
		Agent:          tcd.Agent,
		Plugins:        make([]TelegrafPlugin, len(tcd.Plugins)),
	}
	return decodePluginRaw(tcd, tc)
}
source: func NewReader(r io.Reader, ping bool) *Reader {
	return &Reader{
		r:    r,
		err:  make(chan error),
		ping: ping,
	}
}
source: func (f *File) Setattr(ctx context.Context, req *fuse.SetattrRequest,
	resp *fuse.SetattrResponse) (err error) {
	valid := req.Valid
	ctx = f.folder.fs.config.MaybeStartTrace(ctx, "File.SetAttr",
		fmt.Sprintf("%s %s", f.node.GetBasename(), valid))
	defer func() { f.folder.fs.config.MaybeFinishTrace(ctx, err) }()

	f.folder.fs.vlog.CLogf(ctx, libkb.VLog1, "File SetAttr %s", valid)
	defer func() { err = f.folder.processError(ctx, libkbfs.WriteMode, err) }()

	f.eiCache.destroy()

	if valid.Size() {
		if err := f.folder.fs.config.KBFSOps().Truncate(
			ctx, f.node, req.Size); err != nil {
			return err
		}
		valid &^= fuse.SetattrSize
	}

	if valid.Mode() {
		// Unix has 3 exec bits, KBFS has one; we follow the user-exec bit.
		exec := req.Mode&0100 != 0
		err := f.folder.fs.config.KBFSOps().SetEx(
			ctx, f.node, exec)
		if err != nil {
			return err
		}
		valid &^= fuse.SetattrMode
	}

	if valid.Mtime() {
		err := f.folder.fs.config.KBFSOps().SetMtime(
			ctx, f.node, &req.Mtime)
		if err != nil {
			return err
		}
		valid &^= fuse.SetattrMtime | fuse.SetattrMtimeNow
	}

	if valid.Uid() || valid.Gid() {
		// You can't set the UID/GID on KBFS files, but we don't want
		// to return ENOSYS because that causes scary warnings on some
		// programs like mv.  Instead ignore it, print a debug
		// message, and advertise this behavior on the
		// "understand_kbfs" doc online.
		f.folder.fs.vlog.CLogf(
			ctx, libkb.VLog1, "Ignoring unsupported attempt to set "+
				"the UID/GID on a file")
		valid &^= fuse.SetattrUid | fuse.SetattrGid
	}

	// KBFS has no concept of persistent atime; explicitly don't handle it
	valid &^= fuse.SetattrAtime | fuse.SetattrAtimeNow

	// things we don't need to explicitly handle
	valid &^= fuse.SetattrLockOwner | fuse.SetattrHandle

	// KBFS has no concept of chflags(2); explicitly ignore those
	valid &^= fuse.SetattrFlags

	if valid != 0 {
		// don't let an unhandled operation slip by without error
		f.folder.fs.log.CInfof(ctx, "Setattr did not handle %v", valid)
		return fuse.ENOSYS
	}

	return f.attr(ctx, &resp.Attr)
}
source: func DeleteDuplicateVouts(db *sql.DB) (int64, error) {
	execErrPrefix := "failed to delete duplicate vouts: "

	existsIdx, err := ExistsIndex(db, "uix_vout_txhash_ind")
	if err != nil {
		return 0, err
	} else if !existsIdx {
		return sqlExec(db, internal.DeleteVoutDuplicateRows, execErrPrefix)
	}

	if isuniq, err := IsUniqueIndex(db, "uix_vout_txhash_ind"); err != nil && err != sql.ErrNoRows {
		return 0, err
	} else if isuniq {
		return 0, nil
	}

	return sqlExec(db, internal.DeleteVoutDuplicateRows, execErrPrefix)
}
source: func (s Sentry) New() cue.Collector {
	if s.DSN == "" || !validDSN(s.DSN) {
		log.Warn("Sentry.New called to created a collector, but DSN param is empty or invalid.  Returning nil collector.")
		return nil
	}
	return &sentryCollector{
		Sentry: s,
		http:   collector.HTTP{RequestFormatter: s.formatRequest}.New(),
	}
}
source: func (d *dir) String() string {
	var buf bytes.Buffer

	buf.WriteString(d.name)
	buf.WriteRune(dirStartMark)

	for i, c := range d.children {
		if i != 0 {
			buf.WriteRune(dirElementSep)
		}
		buf.WriteString(c.String())
	}

	buf.WriteRune(dirEndMark)

	return buf.String()
}
source: func (pvKey FilePVKey) Save() {
	outFile := pvKey.filePath
	if outFile == "" {
		panic("cannot save PrivValidator key: filePath not set")
	}

	jsonBytes, err := cdc.MarshalJSONIndent(pvKey, "", "  ")
	if err != nil {
		panic(err)
	}
	err = cmn.WriteFileAtomic(outFile, jsonBytes, 0600)
	if err != nil {
		panic(err)
	}

}
source: func (mysqld *Mysqld) GetPrimaryKeyColumns(dbName, table string) ([]string, error) {
	conn, err := getPoolReconnect(context.TODO(), mysqld.dbaPool)
	if err != nil {
		return nil, err
	}
	defer conn.Recycle()
	qr, err := conn.ExecuteFetch(fmt.Sprintf("SHOW INDEX FROM %s.%s", sqlescape.EscapeID(dbName), sqlescape.EscapeID(table)), 100, true)
	if err != nil {
		return nil, err
	}
	keyNameIndex := -1
	seqInIndexIndex := -1
	columnNameIndex := -1
	for i, field := range qr.Fields {
		switch field.Name {
		case "Key_name":
			keyNameIndex = i
		case "Seq_in_index":
			seqInIndexIndex = i
		case "Column_name":
			columnNameIndex = i
		}
	}
	if keyNameIndex == -1 || seqInIndexIndex == -1 || columnNameIndex == -1 {
		return nil, fmt.Errorf("unknown columns in 'show index' result: %v", qr.Fields)
	}

	columns := make([]string, 0, 5)
	var expectedIndex int64 = 1
	for _, row := range qr.Rows {
		// skip non-primary keys
		if row[keyNameIndex].ToString() != "PRIMARY" {
			continue
		}

		// check the Seq_in_index is always increasing
		seqInIndex, err := sqltypes.ToInt64(row[seqInIndexIndex])
		if err != nil {
			return nil, err
		}
		if seqInIndex != expectedIndex {
			return nil, fmt.Errorf("unexpected index: %v != %v", seqInIndex, expectedIndex)
		}
		expectedIndex++

		columns = append(columns, row[columnNameIndex].ToString())
	}
	return columns, err
}
source: func (g *Group) Close() {
	for _, ch := range g.bus {
		close(ch)
	}
	g.bus = nil
}
source: func (tr *Transport) Lifespan() time.Duration {
	cert := tr.Provider.Certificate()
	if cert == nil {
		return 0
	}

	now := time.Now()
	if now.After(cert.NotAfter) {
		return 0
	}

	now = now.Add(tr.Before)
	ls := cert.NotAfter.Sub(now)
	log.Debugf("   LIFESPAN:\t%s", ls)
	if ls < 0 {
		return 0
	}
	return ls
}
source: func NotEmpty(profiler LXDProfiler) bool {
	if profile := profiler.LXDProfile(); profile != nil {
		return !profile.Empty()
	}
	return false
}
source: func ContainsComprehensions(v interface{}) bool {
	found := false
	WalkClosures(v, func(x interface{}) bool {
		switch x.(type) {
		case *ArrayComprehension, *ObjectComprehension, *SetComprehension:
			found = true
			return found
		}
		return found
	})
	return found
}
source: func (j JSONPBStateSerializer) Serialize(state interface{}) (string, error) {
	pm, ok := state.(proto.Message)
	if ok {
		return j.m.MarshalToString(pm)
	}
	return j.fbss.Serialize(state)
}
source: func (p *NetPlugin) InspectNameserver() ([]byte, error) {
	p.Lock()
	defer p.Unlock()
	return p.NetworkDriver.InspectNameserver()
}
source: func (t *Template) GetAWSRoboMakerFleetWithName(name string) (*resources.AWSRoboMakerFleet, error) {
	if untyped, ok := t.Resources[name]; ok {
		switch resource := untyped.(type) {
		case *resources.AWSRoboMakerFleet:
			return resource, nil
		}
	}
	return nil, fmt.Errorf("resource %q of type AWSRoboMakerFleet not found", name)
}
source: func (p *environProvisioner) setConfig(modelConfig *config.Config) error {
	if err := p.environ.SetConfig(modelConfig); err != nil {
		return errors.Trace(err)
	}
	p.configObserver.notify(modelConfig)
	return nil
}
source: func (s *Server) periodicUnblockFailedEvals(stopCh chan struct{}) {
	ticker := time.NewTicker(failedEvalUnblockInterval)
	defer ticker.Stop()
	for {
		select {
		case <-stopCh:
			return
		case <-ticker.C:
			// Unblock the failed allocations
			s.blockedEvals.UnblockFailed()
		}
	}
}
source: func (db *DB) Stats(s *DBStats) error {
	err := db.ok()
	if err != nil {
		return err
	}

	s.IORead = db.s.stor.reads()
	s.IOWrite = db.s.stor.writes()
	s.WriteDelayCount = atomic.LoadInt32(&db.cWriteDelayN)
	s.WriteDelayDuration = time.Duration(atomic.LoadInt64(&db.cWriteDelay))
	s.WritePaused = atomic.LoadInt32(&db.inWritePaused) == 1

	s.OpenedTablesCount = db.s.tops.cache.Size()
	if db.s.tops.bcache != nil {
		s.BlockCacheSize = db.s.tops.bcache.Size()
	} else {
		s.BlockCacheSize = 0
	}

	s.AliveIterators = atomic.LoadInt32(&db.aliveIters)
	s.AliveSnapshots = atomic.LoadInt32(&db.aliveSnaps)

	s.LevelDurations = s.LevelDurations[:0]
	s.LevelRead = s.LevelRead[:0]
	s.LevelWrite = s.LevelWrite[:0]
	s.LevelSizes = s.LevelSizes[:0]
	s.LevelTablesCounts = s.LevelTablesCounts[:0]

	v := db.s.version()
	defer v.release()

	for level, tables := range v.levels {
		duration, read, write := db.compStats.getStat(level)
		if len(tables) == 0 && duration == 0 {
			continue
		}
		s.LevelDurations = append(s.LevelDurations, duration)
		s.LevelRead = append(s.LevelRead, read)
		s.LevelWrite = append(s.LevelWrite, write)
		s.LevelSizes = append(s.LevelSizes, tables.size())
		s.LevelTablesCounts = append(s.LevelTablesCounts, len(tables))
	}

	return nil
}
source: func (p PostgreSQLArgs) Validate() error {
	if !p.Enable {
		return nil
	}
	if p.Table == "" {
		return fmt.Errorf("empty table name")
	}
	if p.Format != "" {
		f := strings.ToLower(p.Format)
		if f != event.NamespaceFormat && f != event.AccessFormat {
			return fmt.Errorf("unrecognized format value")
		}
	}

	if p.ConnectionString != "" {
		// No pq API doesn't help to validate connection string
		// prior connection, so no validation for now.
	} else {
		// Some fields need to be specified when ConnectionString is unspecified
		if p.Port == "" {
			return fmt.Errorf("unspecified port")
		}
		if _, err := strconv.Atoi(p.Port); err != nil {
			return fmt.Errorf("invalid port")
		}
		if p.Database == "" {
			return fmt.Errorf("database unspecified")
		}
	}

	return nil
}
source: func Base64Decode(str cty.Value) (cty.Value, error) {
	return Base64DecodeFunc.Call([]cty.Value{str})
}
source: func NewList(bytes []byte) (*List, error) {
	var listResponse List
	err := json.Unmarshal(bytes, &listResponse)
	return &listResponse, err
}
source: func (r NoopRecorder) MakeRecordMergePatch(obj runtime.Object) ([]byte, error) {
	return nil, nil
}
source: func Checkbox(name string, checked bool) *Field {
	ret := FieldWithType(name, formcommon.CHECKBOX)
	if checked {
		ret.AddTag("checked")
	}
	return ret
}
source: func NewManifest(path string) *Manifest {
	m := &Manifest{
		Levels:  make([]CompactionLevel, len(DefaultCompactionLevels)),
		Version: Version,
		path:    path,
	}
	copy(m.Levels, DefaultCompactionLevels[:])
	return m
}
source: func (o *VPort) CreateTCA(child *TCA) *bambou.Error {

	return bambou.CurrentSession().CreateChild(o, child)
}
source: func WithConfigured(parent context.Context, value ...bool) context.Context {
	v := true
	if len(value) == 1 {
		v = value[0]
	}
	return context.WithValue(contextOrBackground(parent), keyConfigured, v)
}
source: func (se *StateEngine) prepare(addr string) ([]string, error) {

	var points []string
	var polen int

	if addr != "." {
		addr = excessStops.ReplaceAllString(addr, ".")
		points = strings.Split(addr, ".")
		polen = len(points)
	} else {
		polen = 1
		points = []string{""}
	}

	//check if the length is below 1 then return appropriately
	if polen < 1 {
		return nil, ErrInvalidStateAddr
	}

	//if the first is an empty string, meaning the '.' root was supplied, then we shift so we just start from the first state point else we ignore and use the list as-is.
	if points[0] == "" {
		points = points[1:]
	}

	return points, nil
}
source: func Wrap(err error, msg string) error {
	renamed := errors.New(msg + ": " + err.Error())
	return NewRenamedError(err, renamed)
}
source: func (s *Server) ServePacket(pc net.PacketConn) error {
	if QUIC {
		err := s.quicServer.Serve(pc.(*net.UDPConn))
		return fmt.Errorf("serving QUIC connections: %v", err)
	}
	return nil
}
source: func NewJSONTargetEncoder(w io.Writer) TargetEncoder {
	var jw jwriter.Writer
	return func(t *Target) error {
		(*jsonTarget)(t).encode(&jw)
		if jw.Error != nil {
			return jw.Error
		}
		jw.RawByte('\n')
		_, err := jw.DumpTo(w)
		return err
	}
} 97%|█████████▋| 4857/5000 [00:05<00:00, 1082.40it/s]
source: func (registry *streamRegistry) GetRouterOrFallback(streamID MessageStreamID) Router {
	if streamID == InvalidStreamID {
		return nil // ### return, invalid stream does not have a router ###
	}

	registry.streamGuard.RLock()
	router, exists := registry.routers[streamID]
	registry.streamGuard.RUnlock()
	if exists {
		return router // ### return, already registered ###
	}

	registry.streamGuard.Lock()
	defer registry.streamGuard.Unlock()

	// Create router, avoid race conditions by check again in ciritical section
	if router, exists = registry.routers[streamID]; exists {
		return router // ### return, lost the race ###
	}

	defaultRouter := registry.createFallback(streamID)
	registry.AddWildcardProducersToRouter(defaultRouter)
	registry.routers[streamID] = defaultRouter

	MetricRouters.Inc(1)
	MetricFallbackRouters.Inc(1)

	return defaultRouter
}
source: func (c *Conn) Create(ctx context.Context, filePath string, contents []byte) (topo.Version, error) {
	if contents == nil {
		contents = []byte{}
	}

	c.factory.mu.Lock()
	defer c.factory.mu.Unlock()

	if c.factory.err != nil {
		return nil, c.factory.err
	}

	// Get the parent dir.
	dir, file := path.Split(filePath)
	p := c.factory.getOrCreatePath(c.cell, dir)
	if p == nil {
		return nil, vterrors.Errorf(vtrpc.Code_INVALID_ARGUMENT, "trying to create file %v in cell %v in a path that contains files", filePath, c.cell)
	}

	// Check the file doesn't already exist.
	if _, ok := p.children[file]; ok {
		return nil, topo.NewError(topo.NodeExists, file)
	}

	// Create the file.
	n := c.factory.newFile(file, contents, p)
	p.children[file] = n
	return NodeVersion(n.version), nil
}
source: func Receive(ctx context.Context, dst BlobReceiver, br blob.Ref, src io.Reader) (blob.SizedRef, error) {
	return receive(ctx, dst, br, src, true)
}
source: func (p *Packfile) GetByType(typ plumbing.ObjectType) (storer.EncodedObjectIter, error) {
	switch typ {
	case plumbing.AnyObject,
		plumbing.BlobObject,
		plumbing.TreeObject,
		plumbing.CommitObject,
		plumbing.TagObject:
		entries, err := p.EntriesByOffset()
		if err != nil {
			return nil, err
		}

		return &objectIter{
			// Easiest way to provide an object decoder is just to pass a Packfile
			// instance. To not mess with the seeks, it's a new instance with a
			// different scanner but the same cache and offset to hash map for
			// reusing as much cache as possible.
			p:    p,
			iter: entries,
			typ:  typ,
		}, nil
	default:
		return nil, plumbing.ErrInvalidType
	}
}
source: func (s *Server) RemoveContainer(ctx context.Context, req *pb.RemoveContainerRequest) (resp *pb.RemoveContainerResponse, err error) {
	const operation = "remove_container"
	defer func() {
		recordOperation(operation, time.Now())
		recordError(operation, err)
	}()
	logrus.Debugf("RemoveContainerRequest: %+v", req)

	// save container description to print
	c, err := s.GetContainerFromShortID(req.ContainerId)
	if err != nil {
		return nil, err
	}

	_, err = s.ContainerServer.Remove(ctx, req.ContainerId, true)
	if err != nil {
		return nil, err
	}

	logrus.Infof("Removed container %s", c.Description())
	resp = &pb.RemoveContainerResponse{}
	logrus.Debugf("RemoveContainerResponse: %+v", resp)
	return resp, nil
}
source: func (t *Tree) findUnsafe(ctx context.Context, h Hash) (ret interface{}, root Hash, err error) {
	return t.findTyped(ctx, h, true)
}
source: func createFromInt64(data [][]int64) []*TabulateRow {
	rows := make([]*TabulateRow, len(data))
	for index_1, arr := range data {
		row := make([]string, len(arr))
		for index, el := range arr {
			row[index] = strconv.FormatInt(el, 10)
		}
		rows[index_1] = &TabulateRow{Elements: row}
	}
	return rows
}
source: func (q *Queue) Watch() (eventq chan events.Event, cancel func()) {
	return q.CallbackWatch(nil)
}
source: func setDefaults(cfg *Config) {
	if cfg.ChainConfig == nil {
		cfg.ChainConfig = &params.ChainConfig{
			ChainID:        big.NewInt(1),
			HomesteadBlock: new(big.Int),
			DAOForkBlock:   new(big.Int),
			DAOForkSupport: false,
			EIP150Block:    new(big.Int),
			EIP155Block:    new(big.Int),
			EIP158Block:    new(big.Int),
		}
	}

	if cfg.Difficulty == nil {
		cfg.Difficulty = new(big.Int)
	}
	if cfg.Time == nil {
		cfg.Time = big.NewInt(time.Now().Unix())
	}
	if cfg.GasLimit == 0 {
		cfg.GasLimit = math.MaxUint64
	}
	if cfg.GasPrice == nil {
		cfg.GasPrice = new(big.Int)
	}
	if cfg.Value == nil {
		cfg.Value = new(big.Int)
	}
	if cfg.BlockNumber == nil {
		cfg.BlockNumber = new(big.Int)
	}
	if cfg.GetHashFn == nil {
		cfg.GetHashFn = func(n uint64) common.Hash {
			return common.BytesToHash(crypto.Keccak256([]byte(new(big.Int).SetUint64(n).String())))
		}
	}
}
source: func (d *Downloader) DeduceRemoteRepo(path string, insecure bool) (vendor.RemoteRepo, string, error) {
	cache := d.repos
	if insecure {
		cache = d.reposI
	}

	d.reposMu.RLock()
	for p, repo := range cache {
		if path == p || strings.HasPrefix(path, p+"/") {
			d.reposMu.RUnlock()
			extra := strings.Trim(strings.TrimPrefix(path, p), "/")
			return repo, extra, nil
		}
	}
	d.reposMu.RUnlock()

	repo, extra, err := vendor.DeduceRemoteRepo(path, insecure)
	if err != nil {
		return repo, extra, err
	}

	if !strings.HasSuffix(path, extra) {
		// Shouldn't happen, but in case just bypass the cache
		return repo, extra, err
	}
	basePath := strings.Trim(strings.TrimSuffix(path, extra), "/")
	d.reposMu.Lock()
	cache[basePath] = repo
	d.reposMu.Unlock()

	return repo, extra, err
}
source: func isBadKeyError(err error) bool {
	if err == nil {
		return false
	}
	// See https://go.googlesource.com/oauth2.git/+/197281d4/internal/oauth2.go#32
	// Unfortunately, if uses fmt.Errorf.
	s := err.Error()
	return strings.Contains(s, "private key should be a PEM") ||
		s == "private key is invalid"
}
source: func (api *UserManagerAPI) EnableUser(users params.Entities) (params.ErrorResults, error) {
	isSuperUser, err := api.hasControllerAdminAccess()
	if err != nil {
		return params.ErrorResults{}, errors.Trace(err)
	}
	if !isSuperUser {
		return params.ErrorResults{}, common.ErrPerm
	}

	if err := api.check.ChangeAllowed(); err != nil {
		return params.ErrorResults{}, errors.Trace(err)
	}
	return api.enableUserImpl(users, "enable", (*state.User).Enable)
}
source: func ValidateConfig(ctx *validation.Context, cfg []*config.Settings_SourceAcls) {
	var ACLs ACLs
	ACLs.load(ctx, cfg)
}
source: func (f *Registry) List() []Description {
	names := make([]string, 0, len(f.facades))
	for name := range f.facades {
		names = append(names, name)
	}
	sort.Strings(names)
	descriptions := make([]Description, 0, len(f.facades))
	for _, name := range names {
		facades := f.facades[name]
		description := descriptionFromVersions(name, facades)
		if len(description.Versions) > 0 {
			descriptions = append(descriptions, description)
		}
	}
	return descriptions
}
source: func (c cacheObjects) NewMultipartUpload(ctx context.Context, bucket, object string, opts ObjectOptions) (uploadID string, err error) {
	newMultipartUploadFn := c.NewMultipartUploadFn

	if c.isCacheExclude(bucket, object) || filterFromCache(opts.UserDefined) {
		return newMultipartUploadFn(ctx, bucket, object, opts)
	}

	dcache, err := c.cache.getCacheFS(ctx, bucket, object)
	if err != nil {
		// disk cache could not be located,execute backend call.
		return newMultipartUploadFn(ctx, bucket, object, opts)
	}

	uploadID, err = newMultipartUploadFn(ctx, bucket, object, opts)
	if err != nil {
		return
	}
	// create new multipart upload in cache with same uploadID
	dcache.NewMultipartUpload(ctx, bucket, object, uploadID, opts)
	return uploadID, err
}
source: func (o *OnlyExcept) Skip(n string) bool {
	if len(o.Only) > 0 {
		for _, v := range o.Only {
			if v == n {
				return false
			}
		}

		return true
	}

	if len(o.Except) > 0 {
		for _, v := range o.Except {
			if v == n {
				return true
			}
		}

		return false
	}

	return false
}
source: func (s *Spec) rewritePackageName(pkg *Package) error {
	pkgName := filepath.Base(s.Name)
	if s.Local {
		pkgName = os.Getenv("GOPACKAGE")
		if pkgName == "" {
			return errors.New("GOPACKAGE cannot be empty")
		}
	}
	for _, node := range pkg.Files {
		node.Name.Name = pkgName
	}
	return nil
}
source: func (r Software_Component) GetSoftwareLicense() (resp datatypes.Software_License, err error) {
	err = r.Session.DoRequest("SoftLayer_Software_Component", "getSoftwareLicense", nil, &r.Options, &resp)
	return
}
source: func (n *rootNode) Get(key string) (inner Node) {

	// the child key path
	path := n.keyPath(key)

	// if there is previous error, inherit
	if err := n.ParseError(); err != nil {
		return &rootNode{
			path: path,
			err:  err,
		}
	}

	if err := n.genMapBuf(); err != nil {
		if err == ErrorNotObject {
			path = n.path // fallback to the parent entity
		}
		inner = &rootNode{
			path: path,
			err: Error{
				Path: "json" + path,
				Err:  err,
			},
		}
	} else if val, ok := n.mapBuf[key]; !ok {
		inner = &rootNode{
			path: path,
			err: Error{
				Path: "json" + path,
				Err:  ErrorUndefined,
			},
		}
	} else {
		val.path = path
		inner = &val
	}
	return
}
source: func (s *Stats) TotalBytesHits() units.Size {
	out := units.Size(0)
	for _, i := range s.Hits {
		out += i
	}
	return out
}
source: func (w *VT100Writer) CursorGoTo(row, col int) {
	if row == 0 && col == 0 {
		// If no row/column parameters are provided (ie. <ESC>[H), the cursor will move to the home position.
		w.WriteRaw([]byte{0x1b, '[', 'H'})
		return
	}
	r := strconv.Itoa(row)
	c := strconv.Itoa(col)
	w.WriteRaw([]byte{0x1b, '['})
	w.WriteRaw([]byte(r))
	w.WriteRaw([]byte{';'})
	w.WriteRaw([]byte(c))
	w.WriteRaw([]byte{'H'})
	return
}
source: func NewK8sClientConfig(reader io.Reader, contextName, clusterName string, credentialResolver K8sCredentialResolver) (*ClientConfig, error) {
	if reader == nil {
		var err error
		reader, err = readKubeConfigFile()
		if err != nil {
			return nil, errors.Annotate(err, "failed to read Kubernetes config file")
		}
	}

	content, err := ioutil.ReadAll(reader)
	if err != nil {
		return nil, errors.Annotate(err, "failed to read Kubernetes config")
	}

	config, err := parseKubeConfig(content)
	if err != nil {
		return nil, errors.Annotate(err, "failed to parse Kubernetes config")
	}

	contexts, err := contextsFromConfig(config)
	if err != nil {
		return nil, errors.Annotate(err, "failed to read contexts from kubernetes config")
	}
	var context Context
	if contextName == "" {
		contextName = config.CurrentContext
	}
	if clusterName != "" {
		context, contextName, err = pickContextByClusterName(contexts, clusterName)
		if err != nil {
			return nil, errors.Annotatef(err, "picking context by cluster name %q", clusterName)
		}
	} else if contextName != "" {
		context = contexts[contextName]
		logger.Debugf("no cluster name specified, so use current context %q", config.CurrentContext)
	}
	// exclude not related contexts.
	contexts = map[string]Context{}
	if contextName != "" && !context.isEmpty() {
		contexts[contextName] = context
	}

	// try find everything below based on context.
	clouds, err := cloudsFromConfig(config, context.CloudName)
	if err != nil {
		return nil, errors.Annotate(err, "failed to read clouds from kubernetes config")
	}

	credentials, err := credentialsFromConfig(config, context.CredentialName)
	if errors.IsNotSupported(err) && credentialResolver != nil {
		// try to generate supported credential using provided credential.
		config, err = credentialResolver(config, contextName)
		if err != nil {
			return nil, errors.Annotatef(
				err, "ensuring k8s credential because auth info %q is not valid", context.CredentialName)
		}
		logger.Debugf("try again to get credentials from kubeconfig using the generated auth info")
		credentials, err = credentialsFromConfig(config, context.CredentialName)
	}
	if err != nil {
		return nil, errors.Annotate(err, "failed to read credentials from kubernetes config")
	}

	return &ClientConfig{
		Type:           "kubernetes",
		Contexts:       contexts,
		CurrentContext: config.CurrentContext,
		Clouds:         clouds,
		Credentials:    credentials,
	}, nil
}
source: func (p *pool) backendLoop(l loop.Loop) error {
	for {
		select {
		case <-l.ShallStop():
			return nil
		case request := <-p.requestChan:
			// Handle the request.
			switch request.kind {
			case forcedPullRequest:
				// Always return a new protocol.
				resp, err := newResp(p.database)
				if err != nil {
					p.respond(request, nil, err)
				} else {
					p.respond(request, resp, nil)
				}
			case unforcedPullRequest:
				// Fetch a protocol out of the pool.
				switch {
				case len(p.available) > 0:
				fetch:
					for resp := range p.available {
						delete(p.available, resp)
						p.inUse[resp] = resp
						p.respond(request, resp, nil)
						break fetch
					}
				case len(p.inUse) < p.database.poolsize:
					resp, err := newResp(p.database)
					if err != nil {
						p.respond(request, nil, err)
					} else {
						p.respond(request, resp, nil)
					}
				default:
					p.respond(request, nil, nil)
				}
			case pushRequest:
				// Return a protocol.
				delete(p.inUse, request.resp)
				if len(p.available) < p.database.poolsize {
					p.available[request.resp] = request.resp
					p.respond(request, nil, nil)
				} else {
					p.respond(request, nil, request.resp.close())
				}
			case killRequest:
				// Close w/o reusing.
				delete(p.inUse, request.resp)
				p.respond(request, nil, request.resp.close())
			case closeRequest:
				// Close all protocols.
				for resp := range p.available {
					resp.close()
				}
				for resp := range p.inUse {
					resp.close()
				}
				p.respond(request, nil, nil)
			}
		}
	}
}
source: func SystemdListeners() ([]net.Listener, error) {
	pid, err := strconv.Atoi(os.Getenv("LISTEN_PID"))
	if err != nil {
		return nil, err
	}
	if pid != os.Getpid() {
		return nil, nil
	}
	return restoreListeners("LISTEN_FDS")
}
source: func LookupHost(host string, server string, c *dns.Client, m *dns.Msg) (addrs []string, err error) {
	a, _ := LookupA(host, server, c, m)
	aaaa, _ := LookupAAAA(host, server, c, m)
	addrs = append(a, aaaa...)

	return
}
source: func (p *parserImpl) parse(
	blob json.RawMessage,
) ([]*Comment, []*Post, []*Message, error) {
	comments, posts, msgs, listingErr := parseRawListing(blob)
	if listingErr == nil {
		return comments, posts, msgs, nil
	}

	post, threadErr := parseThread(blob)
	if threadErr == nil {
		return nil, []*Post{post}, nil, nil
	}

	return nil, nil, nil, fmt.Errorf(
		"failed to parse as listing [%v] or thread [%v]",
		listingErr, threadErr,
	)
}
source: func (p *GithubStatus) Valid() bool {
	// owner, repo and ref must be empty or must be set
	ownerEmpty := len(p.Owner) == 0
	repoEmpty := len(p.Repo) == 0
	refLen := len(p.Ref) == 0
	if ownerEmpty != repoEmpty || repoEmpty != refLen {
		return false
	}

	switch p.State {
	case GithubStatePending, GithubStateSuccess, GithubStateError, GithubStateFailure:
	default:
		return false
	}

	_, err := url.Parse(p.URL)
	if err != nil || len(p.Context) == 0 {
		return false
	}

	return true
}
source: func (p *queryPlan) having() error {
	if p.stm.HasHavingClause() {
		tracer.Trace(p.tracer, func() []string {
			return []string{"Having filtering"}
		})
		eval := p.stm.HavingEvaluator()
		ok := true
		var eErr error
		p.tbl.Filter(func(r table.Row) bool {
			b, err := eval.Evaluate(r)
			if err != nil {
				ok, eErr = false, err
			}
			return !b
		})
		if !ok {
			return eErr
		}
	}
	return nil
}
source: func NetworkMechanisms() NetworkMechanismMap {
	nmap := make(NetworkMechanismMap)

	for name, constructor := range networks {
		nmap.Set(name, constructor.New())
	}

	return nmap
}
source: func Routers() <-chan types.Router {
	c := make(chan types.Router)
	go func() {
		routersRWL.RLock()
		defer routersRWL.RUnlock()
		for _, r := range routers {
			c <- r
		}
		close(c)
	}()
	return c
}
source: func Load(r io.Reader) (*MetaInfo, error) {
	var mi MetaInfo
	d := bencode.NewDecoder(r)
	err := d.Decode(&mi)
	if err != nil {
		return nil, err
	}
	return &mi, nil
}
source: func (s *TaskExecutionResultDetail) SetVerifyStatus(v string) *TaskExecutionResultDetail {
	s.VerifyStatus = &v
	return s
}
source: func New() *Bogus {
	b := &Bogus{
		paths: map[string]*paths.Path{},
	}
	b.server = httptest.NewServer(http.HandlerFunc(b.HandlePaths))

	return b
}
source: func (l *maListener) Accept() (Conn, error) {
	nconn, err := l.Listener.Accept()
	if err != nil {
		return nil, err
	}

	var raddr ma.Multiaddr
	// This block protects us in transports (i.e. unix sockets) that don't have
	// remote addresses for inbound connections.
	if nconn.RemoteAddr().String() != "" {
		raddr, err = FromNetAddr(nconn.RemoteAddr())
		if err != nil {
			return nil, fmt.Errorf("failed to convert conn.RemoteAddr: %s", err)
		}
	}

	return wrap(nconn, l.laddr, raddr), nil
}
source: func (self *GithubProvider) Redirect(w http.ResponseWriter, r *http.Request) {
	self.OAuth2Mixin.AuthorizeRedirect(w, r, self.Scope)
}
source: func Hex2Bytes(str string) []byte {
	h, _ := hex.DecodeString(str)
	return h
}
source: func (this *BufferedWriter) Write(p []byte) (n int, err error) {

	dst := make([]byte, len(p), len(p))
	copy(dst, p)

	select {
	case this.queue <- dst:
		return len(dst), nil
	default:
		return 0, BufferFull
	}
}
source: func (jenkins *Jenkins) CreateJob(mavenJobItem MavenJobItem, jobName string) error {
	mavenJobItemXml, _ := xml.Marshal(mavenJobItem)
	reader := bytes.NewReader(mavenJobItemXml)
	params := url.Values{"name": []string{jobName}}

	return jenkins.postXml("/createItem", params, reader, nil)
}
source: func (m SessionMock) ScanIterator(statement string, arguments ...interface{}) Iterator {
	return m.Called(statement, arguments).Get(0).(Iterator)
}
source: func (l Languages) IsMultihost() bool {
	if len(l) <= 1 {
		return false
	}

	for _, lang := range l {
		if lang.GetLocal("baseURL") != nil {
			return true
		}
	}
	return false
}
source: func NewDrainingJobWatcher(ctx context.Context, limiter *rate.Limiter, state *state.StateStore, logger log.Logger) *drainingJobWatcher {

	// Create a context that can cancel the blocking query so that when a new
	// job gets registered it is handled.
	queryCtx, queryCancel := context.WithCancel(ctx)

	w := &drainingJobWatcher{
		ctx:         ctx,
		queryCtx:    queryCtx,
		queryCancel: queryCancel,
		limiter:     limiter,
		logger:      logger.Named("job_watcher"),
		state:       state,
		jobs:        make(map[structs.NamespacedID]struct{}, 64),
		drainCh:     make(chan *DrainRequest),
		migratedCh:  make(chan []*structs.Allocation),
	}

	go w.watch()
	return w
}
source: func (c *CacheStorage) DeleteCache(cacheId string) (*gcdmessage.ChromeResponse, error) {
	var v CacheStorageDeleteCacheParams
	v.CacheId = cacheId
	return c.DeleteCacheWithParams(&v)
}
source: func (b *QueryBuilder) Bool() *BoolQueryBuilder {
	if b.boolQueryBuilder == nil {
		b.boolQueryBuilder = NewBoolQueryBuilder()
	}
	return b.boolQueryBuilder
}
source: func GetCommitFileStatus(repoPath, commitID string) (*CommitFileStatus, error) {
	stdout, w := io.Pipe()
	done := make(chan struct{})
	fileStatus := NewCommitFileStatus()
	go func() {
		scanner := bufio.NewScanner(stdout)
		for scanner.Scan() {
			fields := strings.Fields(scanner.Text())
			if len(fields) < 2 {
				continue
			}

			switch fields[0][0] {
			case 'A':
				fileStatus.Added = append(fileStatus.Added, fields[1])
			case 'D':
				fileStatus.Removed = append(fileStatus.Removed, fields[1])
			case 'M':
				fileStatus.Modified = append(fileStatus.Modified, fields[1])
			}
		}
		done <- struct{}{}
	}()

	stderr := new(bytes.Buffer)
	err := NewCommand("show", "--name-status", "--pretty=format:''", commitID).RunInDirPipeline(repoPath, w, stderr)
	w.Close() // Close writer to exit parsing goroutine
	if err != nil {
		return nil, concatenateError(err, stderr.String())
	}

	<-done
	return fileStatus, nil
}
source: func compressLogFile(src, dst string) (err error) {
	f, err := os.Open(src)
	if err != nil {
		return fmt.Errorf("failed to open log file: %v", err)
	}
	defer f.Close()

	fi, err := os_Stat(src)
	if err != nil {
		return fmt.Errorf("failed to stat log file: %v", err)
	}

	if err := chown(dst, fi); err != nil {
		return fmt.Errorf("failed to chown compressed log file: %v", err)
	}

	// If this file already exists, we presume it was created by
	// a previous attempt to compress the log file.
	gzf, err := os.OpenFile(dst, os.O_CREATE|os.O_TRUNC|os.O_WRONLY, fi.Mode())
	if err != nil {
		return fmt.Errorf("failed to open compressed log file: %v", err)
	}
	defer gzf.Close()

	gz := gzip.NewWriter(gzf)

	defer func() {
		if err != nil {
			os.Remove(dst)
			err = fmt.Errorf("failed to compress log file: %v", err)
		}
	}()

	if _, err := io.Copy(gz, f); err != nil {
		return err
	}
	if err := gz.Close(); err != nil {
		return err
	}
	if err := gzf.Close(); err != nil {
		return err
	}

	if err := f.Close(); err != nil {
		return err
	}
	if err := os.Remove(src); err != nil {
		return err
	}

	return nil
}
source: func (textRank *TextRank) Ranking(algorithm rank.Algorithm) {
	rank.Calculate(textRank.rank, algorithm)
}
source: func NewAttachOptions(streams genericclioptions.IOStreams) *AttachOptions {
	return &AttachOptions{
		StreamOptions: exec.StreamOptions{
			IOStreams: streams,
		},
		Attach:     &DefaultRemoteAttach{},
		AttachFunc: DefaultAttachFunc,
	}
}
source: func addCells(left, right []string) []string {
	if len(left) == 0 || len(right) == 0 {
		return nil
	}

	for _, cell := range right {
		if !InCellList(cell, left) {
			left = append(left, cell)
		}
	}
	return left
}
source: func CheckMessageKeyword(message string, keyword string) (bool, string) {
	return CheckMessageKeywords(message, keyword)
}
source: func New(url string) *Renderer {
	return &Renderer{
		client: rhttp.DefaultClient,
		url:    url,
	}
}
source: func (p *parser) parseEscape() (result string, err error) {
	if len(p.s) < p.i+2 || p.s[p.i] != '\\' {
		return "", errors.New("invalid escape sequence")
	}

	start := p.i + 1
	c := p.s[start]
	switch {
	case c == '\r' || c == '\n' || c == '\f':
		return "", errors.New("escaped line ending outside string")
	case hexDigit(c):
		// unicode escape (hex)
		var i int
		for i = start; i < p.i+6 && i < len(p.s) && hexDigit(p.s[i]); i++ {
			// empty
		}
		v, _ := strconv.ParseUint(p.s[start:i], 16, 21)
		if len(p.s) > i {
			switch p.s[i] {
			case '\r':
				i++
				if len(p.s) > i && p.s[i] == '\n' {
					i++
				}
			case ' ', '\t', '\n', '\f':
				i++
			}
		}
		p.i = i
		return string(rune(v)), nil
	}

	// Return the literal character after the backslash.
	result = p.s[start : start+1]
	p.i += 2
	return result, nil
}
source: func (env *environment) provision(nomadPath string) (*envResults, error) {
	tfArgs := []string{"apply", "-auto-approve", "-input=false", "-no-color",
		"-state", env.tfState,
		"-var", fmt.Sprintf("nomad_binary=%s", path.Join(nomadPath, "nomad")),
		env.tfPath,
	}

	// Setup the 'terraform apply' command
	ctx := context.Background()
	cmd := exec.CommandContext(ctx, env.tf, tfArgs...)

	// Funnel the stdout/stderr to logging
	stderr, err := cmd.StderrPipe()
	if err != nil {
		return nil, fmt.Errorf("failed to get stderr pipe: %v", err)
	}
	stdout, err := cmd.StdoutPipe()
	if err != nil {
		return nil, fmt.Errorf("failed to get stdout pipe: %v", err)
	}

	// Run 'terraform apply'
	cmd.Start()
	go tfLog(env.logger.Named("tf.stderr"), stderr)
	go tfLog(env.logger.Named("tf.stdout"), stdout)

	sigChan := make(chan os.Signal)
	signal.Notify(sigChan, os.Interrupt, syscall.SIGTERM)

	cmdChan := make(chan error)
	go func() {
		cmdChan <- cmd.Wait()
	}()

	// if an interrupt is received before terraform finished, forward signal to
	// child pid
	select {
	case sig := <-sigChan:
		env.logger.Error("interrupt received, forwarding signal to child process",
			"pid", cmd.Process.Pid)
		cmd.Process.Signal(sig)
		if err := procWaitTimeout(cmd.Process, 5*time.Second); err != nil {
			env.logger.Error("child process did not exit in time, killing forcefully",
				"pid", cmd.Process.Pid)
			cmd.Process.Kill()
		}
		return nil, fmt.Errorf("interrupt received")
	case err := <-cmdChan:
		if err != nil {
			return nil, fmt.Errorf("terraform exited with a non-zero status: %v", err)
		}
	}

	// Setup and run 'terraform output' to get the module output
	cmd = exec.CommandContext(ctx, env.tf, "output", "-json", "-state", env.tfState)
	out, err := cmd.Output()
	if err != nil {
		return nil, fmt.Errorf("terraform exited with a non-zero status: %v", err)
	}

	// Parse the json and pull out results
	tfOutput := make(map[string]map[string]interface{})
	err = json.Unmarshal(out, &tfOutput)
	if err != nil {
		return nil, fmt.Errorf("failed to parse terraform output: %v", err)
	}

	results := &envResults{}
	if nomadAddr, ok := tfOutput["nomad_addr"]; ok {
		results.nomadAddr = nomadAddr["value"].(string)
	} else {
		return nil, fmt.Errorf("'nomad_addr' field expected in terraform output, but was missing")
	}

	return results, nil
}
source: func (s *ExponentialRolloutRate) SetIncrementFactor(v float64) *ExponentialRolloutRate {
	s.IncrementFactor = &v
	return s
}
source: func (r reedSolomon) Split(data []byte) ([][]byte, error) {
	if len(data) == 0 {
		return nil, ErrShortData
	}
	// Calculate number of bytes per data shard.
	perShard := (len(data) + r.DataShards - 1) / r.DataShards

	if cap(data) > len(data) {
		data = data[:cap(data)]
	}

	// Only allocate memory if necessary
	if len(data) < (r.Shards * perShard) {
		// Pad data to r.Shards*perShard.
		padding := make([]byte, (r.Shards*perShard)-len(data))
		data = append(data, padding...)
	}

	// Split into equal-length shards.
	dst := make([][]byte, r.Shards)
	for i := range dst {
		dst[i] = data[:perShard]
		data = data[perShard:]
	}

	return dst, nil
}
source: func (t *Tab) GetPageSource(docNodeId int) (string, error) {
	if docNodeId == 0 {
		docNodeId = t.GetTopNodeId()
	}
	doc, ok := t.getElement(docNodeId)
	if !ok {
		return "", &ElementNotFoundErr{Message: fmt.Sprintf("docNodeId %d not found", docNodeId)}
	}
	outerParams := &gcdapi.DOMGetOuterHTMLParams{NodeId: doc.id}
	return t.DOM.GetOuterHTMLWithParams(outerParams)
}
source: func New(name string, transport peer.Transport, availableChooser peer.ListImplementation, opts ...ListOption) *List {
	options := defaultListOptions
	for _, o := range opts {
		o.apply(&options)
	}

	return &List{
		once:               lifecycle.NewOnce(),
		name:               name,
		uninitializedPeers: make(map[string]peer.Identifier, options.capacity),
		unavailablePeers:   make(map[string]*peerThunk, options.capacity),
		availablePeers:     make(map[string]*peerThunk, options.capacity),
		availableChooser:   availableChooser,
		transport:          transport,
		noShuffle:          options.noShuffle,
		randSrc:            rand.NewSource(options.seed),
		peerAvailableEvent: make(chan struct{}, 1),
	}
}
source: func handleSignal(env *Environment) {
	ch := make(chan os.Signal, 2)
	signal.Notify(ch, stopSignals...)

	go func() {
		s := <-ch
		log.Warn("well: got signal", map[string]interface{}{
			"signal": s.String(),
		})
		env.Cancel(errSignaled)
	}()
}
source: func (this *Weixinmp) SendImageMsg(touser string, mediaId string) error {
	var msg imageMsg
	msg.MsgType = "image"
	msg.Image.MediaId = mediaId
	return this.sendMsg(touser, &msg)
}
source: func filterPodsWithPDBViolation(pods []interface{}, pdbs []*policy.PodDisruptionBudget) (violatingPods, nonViolatingPods []*v1.Pod) {
	for _, obj := range pods {
		pod := obj.(*v1.Pod)
		pdbForPodIsViolated := false
		// A pod with no labels will not match any PDB. So, no need to check.
		if len(pod.Labels) != 0 {
			for _, pdb := range pdbs {
				if pdb.Namespace != pod.Namespace {
					continue
				}
				selector, err := metav1.LabelSelectorAsSelector(pdb.Spec.Selector)
				if err != nil {
					continue
				}
				// A PDB with a nil or empty selector matches nothing.
				if selector.Empty() || !selector.Matches(labels.Set(pod.Labels)) {
					continue
				}
				// We have found a matching PDB.
				if pdb.Status.PodDisruptionsAllowed <= 0 {
					pdbForPodIsViolated = true
					break
				}
			}
		}
		if pdbForPodIsViolated {
			violatingPods = append(violatingPods, pod)
		} else {
			nonViolatingPods = append(nonViolatingPods, pod)
		}
	}
	return violatingPods, nonViolatingPods
}
source: func makeHasher(h hash.Hash) hasher {
	// sha3.state supports Read to get the sum, use it to avoid the overhead of Sum.
	// Read alters the state but we reset the hash before every operation.
	type readerHash interface {
		hash.Hash
		Read([]byte) (int, error)
	}
	rh, ok := h.(readerHash)
	if !ok {
		panic("can't find Read method on hash")
	}
	outputLen := rh.Size()
	return func(dest []byte, data []byte) {
		rh.Reset()
		rh.Write(data)
		rh.Read(dest[:outputLen])
	}
}
source: func (m *Module) Verify(state, token string) (bool, error) {
	obj, err := jose.ParseEncrypted(token)
	if err != nil {
		return false, errors.Wrap(err)
	}
	b, err := obj.Decrypt(m.decryptionKey)
	csrfPayload := &csrfPayload{}
	if err = json.Unmarshal(b, csrfPayload); err != nil {
		return false, errors.Wrap(err)
	}
	if state != csrfPayload.State {
		return false, nil
	}
	if time.Now().After(csrfPayload.ExpireAfter) {
		return false, nil
	}
	return true, nil
}
source: func (i *InternalTokenHelper) Store(input string) error {
	i.populateTokenPath()
	f, err := os.OpenFile(i.tokenPath, os.O_CREATE|os.O_TRUNC|os.O_WRONLY, 0600)
	if err != nil {
		return err
	}
	defer f.Close()

	buf := bytes.NewBufferString(input)
	if _, err := io.Copy(f, buf); err != nil {
		return err
	}

	return nil
}
source: func (m *MotorDriver) Off() (err error) {
	if m.isDigital() {
		err = m.changeState(0)
	} else {
		err = m.Speed(0)
	}
	return
}
source: func Convert_v1_DeploymentConfig_To_apps_DeploymentConfig(in *v1.DeploymentConfig, out *apps.DeploymentConfig, s conversion.Scope) error {
	return autoConvert_v1_DeploymentConfig_To_apps_DeploymentConfig(in, out, s)
}
source: func (v *Service) GetModuleID() (o ModuleID) {
	if v != nil {
		o = v.ModuleID
	}
	return
}
source: func Convert_v1_UserAgentMatchRule_To_config_UserAgentMatchRule(in *v1.UserAgentMatchRule, out *config.UserAgentMatchRule, s conversion.Scope) error {
	return autoConvert_v1_UserAgentMatchRule_To_config_UserAgentMatchRule(in, out, s)
}
source: func AssignIP(dhcpHandler *DHCPHandler, ipRange string) (map[string]uint32, []net.IP) {
	couple := make(map[string]uint32)
	var iplist []net.IP
	if ipRange != "" {
		rgx, _ := regexp.Compile("((?:[0-9A-Fa-f]{2}:){5}[0-9A-Fa-f]{2}):((?:[0-9]{1,3}.){3}(?:[0-9]{1,3}))")
		ipRangeArray := strings.Split(ipRange, ",")
		if len(ipRangeArray) >= 1 {
			for _, rangeip := range ipRangeArray {
				result := rgx.FindStringSubmatch(rangeip)
				position := uint32(binary.BigEndian.Uint32(net.ParseIP(result[2]).To4())) - uint32(binary.BigEndian.Uint32(dhcpHandler.start.To4()))
				// Remove the position in the roaming bitmap
				dhcpHandler.available.ReserveIPIndex(uint64(position), result[1])
				couple[result[1]] = position
				iplist = append(iplist, net.ParseIP(result[2]))
			}
		}
	}
	return couple, iplist
}
source: func FromContext(ctx context.Context) (Logger, bool) {
	l, ok := ctx.Value(loggerKey).(Logger)
	return l, ok
}
source: func (s *GetCredentialReportOutput) SetReportFormat(v string) *GetCredentialReportOutput {
	s.ReportFormat = &v
	return s
}
source: func (e shortcutExpander) ResourcesFor(resource schema.GroupVersionResource) ([]schema.GroupVersionResource, error) {
	return e.RESTMapper.ResourcesFor(e.expandResourceShortcut(resource))
}
source: func (cmd *Command) Run(conn *Conn) (r *Reply, err error) {
	conn.Lock()
	if conn.state != connStateConnected {
		conn.Unlock()
		return nil, ErrNotConnected
	}
	defer func() {
		if err != nil {
			conn.state = connStateNotConnected
			conn.Unlock()
			conn.fail()
		} else {
			conn.Unlock()
		}
	}()
	if conn.RequestTimeout != 0 {
		conn.tcpConn.SetWriteDeadline(time.Now().Add(conn.RequestTimeout))
	}
	err = cmd.writeCommand(conn)
	if err != nil {
		return nil, ErrWrite
	}
	err = conn.wb.Flush()
	if err != nil {
		return nil, ErrWrite
	}
	if conn.RequestTimeout != 0 {
		conn.tcpConn.SetReadDeadline(time.Now().Add(conn.RequestTimeout))
	}
	return readReply(conn)
}
source: func (v *Module) Equals(rhs *Module) bool {
	if v == nil {
		return rhs == nil
	} else if rhs == nil {
		return false
	}
	if !(v.ImportPath == rhs.ImportPath) {
		return false
	}
	if !(v.Directory == rhs.Directory) {
		return false
	}
	if !(v.ThriftFilePath == rhs.ThriftFilePath) {
		return false
	}

	return true
}
source: func (acceptNew) Accept(from interface{}) bool {
	_, meta, err := objectMetaData(from)
	if err != nil {
		return false
	}
	if len(meta.GetResourceVersion()) > 0 {
		return false
	}
	return true
}
source: func UniqueItems(path, in string, data interface{}) *errors.Validation {
	val := reflect.ValueOf(data)
	if val.Kind() != reflect.Slice {
		return nil
	}
	var unique []interface{}
	for i := 0; i < val.Len(); i++ {
		v := val.Index(i).Interface()
		for _, u := range unique {
			if reflect.DeepEqual(v, u) {
				return errors.DuplicateItems(path, in)
			}
		}
		unique = append(unique, v)
	}
	return nil
}
source: func (p *ExamplePlugin) AfterInit() error {
	resync.DefaultPlugin.DoResync()

	go p.etcdPublisher()

	go p.closeExample()

	return nil
}
source: func Convert_core_SecurityContext_To_v1_SecurityContext(in *core.SecurityContext, out *v1.SecurityContext, s conversion.Scope) error {
	return autoConvert_core_SecurityContext_To_v1_SecurityContext(in, out, s)
}
source: func (t *Thread) SetCurrentBreakpoint() error {
	t.clearBreakpointState()
	regs, err := t.Registers(false)
	if err != nil {
		return err
	}
	pc := regs.PC()
	if bp, ok := t.p.FindBreakpoint(pc); ok {
		if t.regs.PC() != bp.Addr {
			if err := t.SetPC(bp.Addr); err != nil {
				return err
			}
		}
		t.CurrentBreakpoint = bp.CheckCondition(t)
		if t.CurrentBreakpoint.Breakpoint != nil && t.CurrentBreakpoint.Active {
			if g, err := proc.GetG(t); err == nil {
				t.CurrentBreakpoint.HitCount[g.ID]++
			}
			t.CurrentBreakpoint.TotalHitCount++
		}
	}
	return nil
}
source: func NewCustomClient(client *http.Client) (*Client, error) {
	version := "1"
	endpoint := "https://api.trello.com/" + version

	return &Client{
		client:   client,
		endpoint: endpoint,
		version:  version,
	}, nil
}
source: func (ms *FileMsgStore) readIndex(r io.Reader) (uint64, *msgIndex, error) {
	_buf := [msgIndexRecSize]byte{}
	buf := _buf[:]
	if _, err := io.ReadFull(r, buf); err != nil {
		return 0, nil, err
	}
	mindex := &msgIndex{}
	seq := util.ByteOrder.Uint64(buf)
	mindex.offset = int64(util.ByteOrder.Uint64(buf[8:]))
	mindex.timestamp = int64(util.ByteOrder.Uint64(buf[16:]))
	mindex.msgSize = util.ByteOrder.Uint32(buf[24:])
	// If all zeros, return that caller should rewind (for recovery)
	if seq == 0 && mindex.offset == 0 && mindex.timestamp == 0 && mindex.msgSize == 0 {
		storedCRC := util.ByteOrder.Uint32(buf[msgIndexRecSize-crcSize:])
		if storedCRC == 0 {
			return 0, nil, errNeedRewind
		}
	}
	if ms.fstore.opts.DoCRC {
		storedCRC := util.ByteOrder.Uint32(buf[msgIndexRecSize-crcSize:])
		crc := crc32.Checksum(buf[:msgIndexRecSize-crcSize], ms.fstore.crcTable)
		if storedCRC != crc {
			return 0, nil, fmt.Errorf("corrupted data, expected crc to be 0x%08x, got 0x%08x", storedCRC, crc)
		}
	}
	return seq, mindex, nil
}
source: func (n *Network) PeersInOrg(orgName string) []*Peer {
	peers := []*Peer{}
	for _, o := range n.Peers {
		if o.Organization == orgName {
			peers = append(peers, o)
		}
	}
	return peers
}
source: func (it *NodeIterator) Next() bool {
	// If the iterator failed previously, don't do anything
	if it.Error != nil {
		return false
	}
	// Otherwise step forward with the iterator and report any errors
	if err := it.step(); err != nil {
		it.Error = err
		return false
	}
	return it.retrieve()
}
source: func (m *FaultAbort) Validate() error {
	if m == nil {
		return nil
	}

	{
		tmp := m.GetPercentage()

		if v, ok := interface{}(tmp).(interface{ Validate() error }); ok {

			if err := v.Validate(); err != nil {
				return FaultAbortValidationError{
					field:  "Percentage",
					reason: "embedded message failed validation",
					cause:  err,
				}
			}
		}
	}

	switch m.ErrorType.(type) {

	case *FaultAbort_HttpStatus:

		if val := m.GetHttpStatus(); val < 200 || val >= 600 {
			return FaultAbortValidationError{
				field:  "HttpStatus",
				reason: "value must be inside range [200, 600)",
			}
		}

	default:
		return FaultAbortValidationError{
			field:  "ErrorType",
			reason: "value is required",
		}

	}

	return nil
}
source: func CoerceDatum(sc *variable.StatementContext, a, b Datum) (x, y Datum, err error) {
	if a.IsNull() || b.IsNull() {
		return x, y, nil
	}
	var (
		hasUint    bool
		hasDecimal bool
		hasFloat   bool
	)
	x = a.convergeType(&hasUint, &hasDecimal, &hasFloat)
	y = b.convergeType(&hasUint, &hasDecimal, &hasFloat)
	if hasFloat {
		switch x.Kind() {
		case KindInt64:
			x.SetFloat64(float64(x.GetInt64()))
		case KindUint64:
			x.SetFloat64(float64(x.GetUint64()))
		case KindMysqlHex:
			x.SetFloat64(x.GetMysqlHex().ToNumber())
		case KindMysqlBit:
			x.SetFloat64(x.GetMysqlBit().ToNumber())
		case KindMysqlEnum:
			x.SetFloat64(x.GetMysqlEnum().ToNumber())
		case KindMysqlSet:
			x.SetFloat64(x.GetMysqlSet().ToNumber())
		case KindMysqlDecimal:
			fval, err := x.ToFloat64(sc)
			if err != nil {
				return x, y, errors.Trace(err)
			}
			x.SetFloat64(fval)
		}
		switch y.Kind() {
		case KindInt64:
			y.SetFloat64(float64(y.GetInt64()))
		case KindUint64:
			y.SetFloat64(float64(y.GetUint64()))
		case KindMysqlHex:
			y.SetFloat64(y.GetMysqlHex().ToNumber())
		case KindMysqlBit:
			y.SetFloat64(y.GetMysqlBit().ToNumber())
		case KindMysqlEnum:
			y.SetFloat64(y.GetMysqlEnum().ToNumber())
		case KindMysqlSet:
			y.SetFloat64(y.GetMysqlSet().ToNumber())
		case KindMysqlDecimal:
			fval, err := y.ToFloat64(sc)
			if err != nil {
				return x, y, errors.Trace(err)
			}
			y.SetFloat64(fval)
		}
	} else if hasDecimal {
		var dec *MyDecimal
		dec, err = ConvertDatumToDecimal(sc, x)
		if err != nil {
			return x, y, errors.Trace(err)
		}
		x.SetMysqlDecimal(dec)
		dec, err = ConvertDatumToDecimal(sc, y)
		if err != nil {
			return x, y, errors.Trace(err)
		}
		y.SetMysqlDecimal(dec)
	}
	return
}
source: func (c *nodes) PatchStatus(nodeName string, data []byte) (*v1.Node, error) {
	result := &v1.Node{}
	err := c.client.Patch(types.StrategicMergePatchType).
		Resource("nodes").
		Name(nodeName).
		SubResource("status").
		Body(data).
		Do().
		Into(result)
	return result, err
}
source: func (b *Bucket) Nodes() []Node {
	b.RLock()
	defer b.RUnlock()
	ret := *(*[]Node)(b.nodeList)
	return ret
}
source: func (c *ClassifierSerializer) WriteAttributeForKey(key string, a Attribute) error {
	b, err := SerializeAttribute(a)
	if err != nil {
		return WrapError(err)
	}
	return c.WriteBytesForKey(key, b)
}
source: func (s *LabelingJobInputConfig) SetDataAttributes(v *LabelingJobDataAttributes) *LabelingJobInputConfig {
	s.DataAttributes = v
	return s
}
source: func (s *Set) PrintUsage(w io.Writer) {
	parts := make([]string, 2, 4)
	parts[0] = "Usage:"
	parts[1] = s.program
	if usage := s.UsageLine(); usage != "" {
		parts = append(parts, usage)
	}
	if s.parameters != "" {
		parts = append(parts, s.parameters)
	}
	fmt.Fprintln(w, strings.Join(parts, " "))
	s.PrintOptions(w)
}
source: func InstallUpdater(context Context, keybaseBinPath string, force bool, timeout time.Duration, log Log) error {
	if context.GetRunMode() != libkb.ProductionRunMode {
		return fmt.Errorf("Updater not supported in this run mode")
	}
	keybaseBinPath, err := chooseBinPath(keybaseBinPath)
	if err != nil {
		return err
	}
	updaterBinPath := filepath.Join(filepath.Dir(keybaseBinPath), "updater")
	if err != nil {
		return err
	}
	log.Debug("Using updater path: %s", updaterBinPath)

	label := DefaultUpdaterLabel(context.GetRunMode())
	service := launchd.NewService(label)
	plist, err := updaterPlist(context, label, updaterBinPath, keybaseBinPath, log)
	if err != nil {
		return err
	}

	UninstallUpdaterService(context, log)
	log.Debug("Installing updater service (%s, timeout=%s)", label, timeout)
	if _, err := installUpdaterService(context, service, plist, timeout, log); err != nil {
		log.Errorf("Error installing updater service: %s", err)
		_, err = fallbackStartProcess(context, service, plist, log)
		return err
	}
	return nil
}
source: func (s *SessionRegistry) leaveSession(party *party) error {
	sess := party.s
	s.Lock()
	defer s.Unlock()

	// Emit session leave event to both the Audit Log as well as over the
	// "x-teleport-event" channel in the SSH connection.
	s.emitSessionLeaveEvent(party)

	// Remove member from in-members representation of party.
	if err := sess.removeParty(party); err != nil {
		return trace.Wrap(err)
	}

	// this goroutine runs for a short amount of time only after a session
	// becomes empty (no parties). It allows session to "linger" for a bit
	// allowing parties to reconnect if they lost connection momentarily
	lingerAndDie := func() {
		lingerTTL := sess.GetLingerTTL()
		if lingerTTL > 0 {
			time.Sleep(lingerTTL)
		}
		// not lingering anymore? someone reconnected? cool then... no need
		// to die...
		if !sess.isLingering() {
			s.log.Infof("Session %v has become active again.", sess.id)
			return
		}
		s.log.Infof("Session %v will be garbage collected.", sess.id)

		// no more people left? Need to end the session!
		s.Lock()
		delete(s.sessions, sess.id)
		s.Unlock()

		// send an event indicating that this session has ended
		sess.recorder.GetAuditLog().EmitAuditEvent(events.SessionEnd, events.EventFields{
			events.SessionEventID: string(sess.id),
			events.EventUser:      party.user,
			events.EventNamespace: s.srv.GetNamespace(),
		})

		// close recorder to free up associated resources
		// and flush data
		sess.recorder.Close()

		if err := sess.Close(); err != nil {
			s.log.Errorf("Unable to close session %v: %v", sess.id, err)
		}

		// mark it as inactive in the DB
		if s.srv.GetSessionServer() != nil {
			False := false
			s.srv.GetSessionServer().UpdateSession(rsession.UpdateRequest{
				ID:        sess.id,
				Active:    &False,
				Namespace: s.srv.GetNamespace(),
			})
		}
	}
	go lingerAndDie()
	return nil
}
source: func ExceptionType_Values() []ExceptionType {
	return []ExceptionType{
		ExceptionTypeUnknown,
		ExceptionTypeUnknownMethod,
		ExceptionTypeInvalidMessageType,
		ExceptionTypeWrongMethodName,
		ExceptionTypeBadSequenceID,
		ExceptionTypeMissingResult,
		ExceptionTypeInternalError,
		ExceptionTypeProtocolError,
		ExceptionTypeInvalidTransform,
		ExceptionTypeInvalidProtocol,
		ExceptionTypeUnsupportedClientType,
	}
}
source: func (c *Gcd) GetFirstTab() (*ChromeTarget, error) {
	connectableTargets, err := c.getConnectableTargets()
	if err != nil {
		return nil, err
	}
	for _, tabTarget := range connectableTargets {
		if tabTarget.Type == "page" {
			return openChromeTarget(c.addr, tabTarget)
		}
	}
	return nil, ErrNoTabAvailable
}
source: func (r *SourceRepository) RemoteURL() (*s2igit.URL, bool, error) {
	if r.remoteURL != nil {
		return r.remoteURL, true, nil
	}
	if r.url.IsLocal() {
		gitRepo := git.NewRepository()
		remote, ok, err := gitRepo.GetOriginURL(r.url.LocalPath())
		if err != nil && err != git.ErrGitNotAvailable {
			return nil, false, err
		}
		if !ok {
			return nil, ok, nil
		}
		ref := gitRepo.GetRef(r.url.LocalPath())
		if len(ref) > 0 {
			remote = fmt.Sprintf("%s#%s", remote, ref)
		}

		if r.remoteURL, err = s2igit.Parse(remote); err != nil {
			return nil, false, err
		}
	} else {
		r.remoteURL = &r.url
	}
	return r.remoteURL, true, nil
}
source: func (d DateTime) DayOfWeek(v reflect.Value) (interface{}, error) {
	return d.dayOfWeek(), nil
}
source: func processDeadFilesystems(ctx *context, tags []names.FilesystemTag, filesystemResults []params.FilesystemResult) error {
	for _, tag := range tags {
		removePendingFilesystem(ctx, tag)
	}
	var destroy []names.FilesystemTag
	var remove []names.Tag
	for i, result := range filesystemResults {
		tag := tags[i]
		if result.Error == nil {
			logger.Debugf("filesystem %s is provisioned, queuing for deprovisioning", tag.Id())
			filesystem, err := filesystemFromParams(result.Result)
			if err != nil {
				return errors.Annotate(err, "getting filesystem info")
			}
			updateFilesystem(ctx, filesystem)
			destroy = append(destroy, tag)
			continue
		}
		if params.IsCodeNotProvisioned(result.Error) {
			logger.Debugf("filesystem %s is not provisioned, queuing for removal", tag.Id())
			remove = append(remove, tag)
			continue
		}
		return errors.Annotatef(result.Error, "getting filesystem information for filesystem %s", tag.Id())
	}
	if len(destroy) > 0 {
		ops := make([]scheduleOp, len(destroy))
		for i, tag := range destroy {
			ops[i] = &removeFilesystemOp{tag: tag}
		}
		scheduleOperations(ctx, ops...)
	}
	if err := removeEntities(ctx, remove); err != nil {
		return errors.Annotate(err, "removing filesystems from state")
	}
	return nil
}
source: func Fprint(w io.Writer, a ...interface{}) (int, error) {
	return fmt.Fprint(w, compile(fmt.Sprint(a...)))
}
source: func lte(lhs Expression, rhs interface{}) BooleanExpression {
	return boolean{op: LTE_OP, lhs: lhs, rhs: rhs}
}
source: func DiscoveredServersHandler(cb ConnHandler) Option {
	return func(o *Options) error {
		o.DiscoveredServersCB = cb
		return nil
	}
}
source: func (s *OutputUpdate) SetLambdaOutputUpdate(v *LambdaOutputUpdate) *OutputUpdate {
	s.LambdaOutputUpdate = v
	return s
}
source: func NewTranslator(apiKey string) translator.Translator {
	authenticator := newAuthenticator(apiKey)
	router := newRouter()

	return &api{
		lp: newLanguageProvider(authenticator, router),
		tp: newTranslationProvider(authenticator, router),
	}
}
source: func getKeyType(ctx *cli.Context) certcrypto.KeyType {
	keyType := ctx.GlobalString("key-type")
	switch strings.ToUpper(keyType) {
	case "RSA2048":
		return certcrypto.RSA2048
	case "RSA4096":
		return certcrypto.RSA4096
	case "RSA8192":
		return certcrypto.RSA8192
	case "EC256":
		return certcrypto.EC256
	case "EC384":
		return certcrypto.EC384
	}

	log.Fatalf("Unsupported KeyType: %s", keyType)
	return ""
}
source: func (rc *Record) String() string {
	return fmt.Sprintf("%s %v", rc.Key, rc.Bins)
}
source: func ParsePortSpec(rawPort string) ([]PortMapping, error) {
	var proto string
	rawIP, hostPort, containerPort := splitParts(rawPort)
	proto, containerPort = SplitProtoPort(containerPort)

	// Strip [] from IPV6 addresses
	ip, _, err := net.SplitHostPort(rawIP + ":")
	if err != nil {
		return nil, fmt.Errorf("Invalid ip address %v: %s", rawIP, err)
	}
	if ip != "" && net.ParseIP(ip) == nil {
		return nil, fmt.Errorf("Invalid ip address: %s", ip)
	}
	if containerPort == "" {
		return nil, fmt.Errorf("No port specified: %s<empty>", rawPort)
	}

	startPort, endPort, err := ParsePortRange(containerPort)
	if err != nil {
		return nil, fmt.Errorf("Invalid containerPort: %s", containerPort)
	}

	var startHostPort, endHostPort uint64 = 0, 0
	if len(hostPort) > 0 {
		startHostPort, endHostPort, err = ParsePortRange(hostPort)
		if err != nil {
			return nil, fmt.Errorf("Invalid hostPort: %s", hostPort)
		}
	}

	if hostPort != "" && (endPort-startPort) != (endHostPort-startHostPort) {
		// Allow host port range iff containerPort is not a range.
		// In this case, use the host port range as the dynamic
		// host port range to allocate into.
		if endPort != startPort {
			return nil, fmt.Errorf("Invalid ranges specified for container and host Ports: %s and %s", containerPort, hostPort)
		}
	}

	if !validateProto(strings.ToLower(proto)) {
		return nil, fmt.Errorf("Invalid proto: %s", proto)
	}

	ports := []PortMapping{}
	for i := uint64(0); i <= (endPort - startPort); i++ {
		containerPort = strconv.FormatUint(startPort+i, 10)
		if len(hostPort) > 0 {
			hostPort = strconv.FormatUint(startHostPort+i, 10)
		}
		// Set hostPort to a range only if there is a single container port
		// and a dynamic host port.
		if startPort == endPort && startHostPort != endHostPort {
			hostPort = fmt.Sprintf("%s-%s", hostPort, strconv.FormatUint(endHostPort, 10))
		}
		port, err := NewPort(strings.ToLower(proto), containerPort)
		if err != nil {
			return nil, err
		}

		binding := PortBinding{
			HostIP:   ip,
			HostPort: hostPort,
		}
		ports = append(ports, PortMapping{Port: port, Binding: binding})
	}
	return ports, nil
}
source: func NewDynamicSharedInformerFactory(client dynamic.Interface, defaultResync time.Duration) DynamicSharedInformerFactory {
	return NewFilteredDynamicSharedInformerFactory(client, defaultResync, metav1.NamespaceAll, nil)
}
source: func removeMember(tel string, members []string) []string {
	for i, m := range members {
		if m == tel {
			members = append(members[:i], members[i+1:]...)
			break
		}
	}
	return members
}
source: func NewApprovalRequest(response *http.Response) (*ApprovalRequest, error) {
	body, err := ioutil.ReadAll(response.Body)
	if err != nil {
		return nil, err
	}

	jsonResponse := struct {
		Success         bool             `json:"success"`
		ApprovalRequest *ApprovalRequest `json:"approval_request"`
		Message         string           `json:"message"`
	}{}

	err = json.Unmarshal(body, &jsonResponse)
	if err != nil {
		return nil, err
	}

	if !jsonResponse.Success {
		return nil, fmt.Errorf("invalid approval request response: %s", jsonResponse.Message)
	}
	approvalRequest := jsonResponse.ApprovalRequest
	approvalRequest.HTTPResponse = response

	return approvalRequest, nil
}
source: func Fsck(repoPath string, timeout time.Duration, args ...string) error {
	// Make sure timeout makes sense.
	if timeout <= 0 {
		timeout = -1
	}
	_, err := NewCommand("fsck").AddArguments(args...).RunInDirTimeout(timeout, repoPath)
	return err
}
source: func (m *UnpartitionedMemoryIdx) indexTags(def *schema.MetricDefinition) {
	tags, ok := m.tags[def.OrgId]
	if !ok {
		tags = make(TagIndex)
		m.tags[def.OrgId] = tags
	}

	for _, tag := range def.Tags {
		tagSplits := strings.SplitN(tag, "=", 2)
		if len(tagSplits) < 2 {
			// should never happen because every tag in the index
			// must have a valid format
			invalidTag.Inc()
			log.Errorf("memory-idx: Tag %q of id %q has an invalid format", tag, def.Id)
			continue
		}

		tagName := tagSplits[0]
		tagValue := tagSplits[1]
		tags.addTagId(tagName, tagValue, def.Id)
	}
	tags.addTagId("name", def.Name, def.Id)

	m.defByTagSet.add(def)
}
source: func (s Spec) Validate() error {
	if s.Cancel == nil {
		if !s.NoCancel {
			return errors.NotValidf("missing Cancel")
		}
	}
	if s.Worker == "" {
		return errors.NotValidf("mssing Worker")
	}
	return nil
}
source: func (ar *Reader) Read(b []byte) (n int, err error) {
	if ar.nb == 0 {
		// file consumed
		return 0, io.EOF
	}

	if int64(len(b)) > ar.nb {
		b = b[0:ar.nb]
	}
	n, err = ar.r.Read(b)
	ar.nb -= int64(n)

	if err == io.EOF && ar.nb > 0 {
		err = io.ErrUnexpectedEOF
	}
	ar.err = err
	return
}
source: func (l *TeamLoader) ImplicitAdmins(ctx context.Context, teamID keybase1.TeamID) (impAdmins []keybase1.UserVersion, err error) {
	impAdminsMap := make(map[string]keybase1.UserVersion) // map to remove dups
	err = l.MapTeamAncestors(ctx, func(t keybase1.TeamSigChainState) error {
		ancestorChain := TeamSigChainState{inner: t}
		// Gather the admins.
		adminRoles := []keybase1.TeamRole{keybase1.TeamRole_OWNER, keybase1.TeamRole_ADMIN}
		for _, role := range adminRoles {
			uvs, err := ancestorChain.GetUsersWithRole(role)
			if err != nil {
				return err
			}
			for _, uv := range uvs {
				impAdminsMap[uv.String()] = uv
			}
		}
		return nil
	}, teamID, "implicitAdminsAncestor", func(keybase1.TeamSigChainState) bool { return true })
	if err != nil {
		return nil, err
	}
	for _, uv := range impAdminsMap {
		impAdmins = append(impAdmins, uv)
	}
	return impAdmins, nil
}
source: func (tl *TeeLogger) Warningf(format string, v ...interface{}) {
	tl.WarningDepth(1, fmt.Sprintf(format, v...))
}
source: func loadCascadeClassifier(haar string) *gocv.CascadeClassifier {
	if classifier != nil {
		return classifier
	}

	c := gocv.NewCascadeClassifier()
	c.Load(haar)
	classifier = &c
	return classifier
}
source: func (db *DB) AddPayment(payment *OutgoingPayment) error {
	// Validate the field of the inner voice within the outgoing payment,
	// these must also adhere to the same constraints as regular invoices.
	if err := validateInvoice(&payment.Invoice); err != nil {
		return err
	}

	// We first serialize the payment before starting the database
	// transaction so we can avoid creating a DB payment in the case of a
	// serialization error.
	var b bytes.Buffer
	if err := serializeOutgoingPayment(&b, payment); err != nil {
		return err
	}
	paymentBytes := b.Bytes()

	return db.Batch(func(tx *bbolt.Tx) error {
		payments, err := tx.CreateBucketIfNotExists(paymentBucket)
		if err != nil {
			return err
		}

		// Obtain the new unique sequence number for this payment.
		paymentID, err := payments.NextSequence()
		if err != nil {
			return err
		}

		// We use BigEndian for keys as it orders keys in
		// ascending order. This allows bucket scans to order payments
		// in the order in which they were created.
		paymentIDBytes := make([]byte, 8)
		binary.BigEndian.PutUint64(paymentIDBytes, paymentID)

		return payments.Put(paymentIDBytes, paymentBytes)
	})
}
source: func (t Timestamp) Parse() (time.Time, error) {
	return time.Parse(time.RFC3339, string(t))
}
source: func Provision(noop bool,
	serviceName string,
	serviceDescription string,
	lambdaAWSInfos []*LambdaAWSInfo,
	api *API,
	site *S3Site,
	s3Bucket string,
	useCGO bool,
	inplace bool,
	buildID string,
	codePipelineTrigger string,
	buildTags string,
	linkerFlags string,
	writer io.Writer,
	workflowHooks *WorkflowHooks,
	logger *logrus.Logger) error {
	logger.Error("Provision() not supported in AWS Lambda binary")
	return errors.New("Provision not supported for this binary")
}
source: func (c Client) removeBucketPolicy(bucketName string) error {
	// Input validation.
	if err := s3utils.CheckValidBucketName(bucketName); err != nil {
		return err
	}
	// Get resources properly escaped and lined up before
	// using them in http request.
	urlValues := make(url.Values)
	urlValues.Set("policy", "")

	// Execute DELETE on objectName.
	resp, err := c.executeMethod(context.Background(), "DELETE", requestMetadata{
		bucketName:       bucketName,
		queryValues:      urlValues,
		contentSHA256Hex: emptySHA256Hex,
	})
	defer closeResponse(resp)
	if err != nil {
		return err
	}
	return nil
}
source: func (o *GetEndpointIDConfigOK) WithPayload(payload *models.EndpointConfigurationStatus) *GetEndpointIDConfigOK {
	o.Payload = payload
	return o
}
source: func (c *MutableTLSCreds) Role() string {
	c.Lock()
	defer c.Unlock()

	return c.subject.OrganizationalUnit[0]
}
source: func REPL(od storage.Store, input *os.File, rl ReadLiner, chanSize, bulkSize, builderSize int, done chan bool) int {
	var tracer io.Writer
	ctx, isTracingToFile, sessionStart := context.Background(), false, time.Now()

	driverPlain := func() storage.Store {
		return od
	}

	driverWithMemoization := func() storage.Store {
		return memoization.New(od)
	}

	driver := driverWithMemoization

	stopTracing := func() {
		if tracer != nil {
			if isTracingToFile {
				fmt.Println("Closing tracing file.")
				tracer.(*os.File).Close()
			}
			tracer, isTracingToFile = nil, false
		}
	}
	defer stopTracing()

	fmt.Printf("Welcome to BadWolf vCli (%d.%d.%d-%s)\n", version.Major, version.Minor, version.Patch, version.Release)
	fmt.Printf("Using driver %s/%s. Type quit; to exit.\n", driver().Name(ctx), driver().Version(ctx))
	fmt.Printf("Session started at %v.\n", sessionStart.Format("2006-01-02T15:04:05.999999-07:00"))
	fmt.Println("Memoization enabled. Type help; to print help.")
	fmt.Println()
	defer func() {
		fmt.Printf("\n\nThanks for all those BQL queries!\nSession duration: %v\n\n", time.Now().Sub(sessionStart))
	}()

	for l := range rl(done) {
		if strings.HasPrefix(l, "quit") {
			done <- true
			break
		}
		if strings.HasPrefix(l, "help") {
			printHelp()
			done <- false
			continue
		}
		if strings.HasPrefix(l, "enable memoization") {
			driver = driverWithMemoization
			fmt.Println("[OK] Partial query memoization is on.")
			done <- false
			continue
		}
		if strings.HasPrefix(l, "disable memoization") {
			driver = driverPlain
			fmt.Println("[OK] Partial query memoization is off.")
			done <- false
			continue
		}
		if strings.HasPrefix(l, "start tracing") {
			args := strings.Split(strings.TrimSpace(l)[:len(l)-1], " ")
			switch len(args) {
			case 2:
				// Start tracing to the console.
				stopTracing()
				tracer, isTracingToFile = os.Stdout, false
				fmt.Println("[WARNING] Tracing is on. This may slow your BQL queries.")
			case 3:
				// Start tracing to file.
				stopTracing()
				f, err := os.Create(args[2])
				if err != nil {
					fmt.Println(err)
				} else {
					tracer, isTracingToFile = f, true
					fmt.Println("[WARNING] Tracing is on. This may slow your BQL queries.")
				}
			default:
				fmt.Println("Invalid syntax\n\tstart tracing [trace_file]")
			}
			done <- false
			continue
		}
		if strings.HasPrefix(l, "stop tracing") {
			stopTracing()
			fmt.Println("Tracing is off.")
			done <- false
			continue
		}
		if strings.HasPrefix(l, "export") {
			now := time.Now()
			args := strings.Split("bw "+strings.TrimSpace(l)[:len(l)-1], " ")
			usage := "Wrong syntax\n\n\tload <graph_names_separated_by_commas> <file_path>\n"
			export.Eval(ctx, usage, args, driver(), bulkSize)
			fmt.Println("[OK] Time spent: ", time.Now().Sub(now))
			done <- false
			continue
		}
		if strings.HasPrefix(l, "load") {
			now := time.Now()
			args := strings.Split("bw "+strings.TrimSpace(l[:len(l)-1]), " ")
			usage := "Wrong syntax\n\n\tload <file_path> <graph_names_separated_by_commas>\n"
			load.Eval(ctx, usage, args, driver(), bulkSize, builderSize)
			fmt.Println("[OK] Time spent: ", time.Now().Sub(now))
			done <- false
			continue
		}
		if strings.HasPrefix(l, "desc") {
			pln, err := planBQL(ctx, l[4:], driver(), chanSize, bulkSize, nil)
			if err != nil {
				fmt.Printf("[ERROR] %s\n\n", err)
			} else {
				if pln != nil {
					fmt.Println(pln.String(ctx))
				}
				fmt.Println("[OK]")
			}
			done <- false
			continue
		}
		if strings.HasPrefix(l, "run") {
			now := time.Now()
			path, cmds, err := runBQLFromFile(ctx, driver(), chanSize, bulkSize, strings.TrimSpace(l[:len(l)-1]), tracer)
			if err != nil {
				fmt.Printf("[ERROR] %s\n\n", err)
			} else {
				fmt.Printf("Loaded %q and run %d BQL commands successfully\n\n", path, cmds)
			}
			fmt.Println("Time spent: ", time.Now().Sub(now))
			done <- false
			continue
		}

		now := time.Now()
		table, err := runBQL(ctx, l, driver(), chanSize, bulkSize, tracer)
		bqlDiff := time.Now().Sub(now)
		if err != nil {
			fmt.Printf("[ERROR] %s\n", err)
			fmt.Println("Time spent: ", time.Now().Sub(now))
			fmt.Println()
		} else {
			if table == nil {
				fmt.Printf("[OK] 0 rows retrieved. BQL time: %v. Display time: %v\n",
					bqlDiff, time.Now().Sub(now)-bqlDiff)
			} else {
				if len(table.Bindings()) > 0 {
					fmt.Println(table.String())
				}
				fmt.Printf("[OK] %d rows retrieved. BQL time: %v. Display time: %v\n",
					table.NumRows(), bqlDiff, time.Now().Sub(now)-bqlDiff)
			}
		}
		done <- false
	}
	return 0
}100%|█████████▉| 4981/5000 [00:05<00:00, 1050.45it/s]
source: func (self *Stack) Peek() Token {
	if len(self.Values) == 0 {
		return Token{}
	}
	return self.Values[len(self.Values)-1]
}
source: func suggestionList(input string, options []string) []string {
	dists := []float64{}
	filteredOpts := []string{}
	inputThreshold := float64(len(input) / 2)

	for _, opt := range options {
		dist := lexicalDistance(input, opt)
		threshold := math.Max(inputThreshold, float64(len(opt)/2))
		threshold = math.Max(threshold, 1)
		if dist <= threshold {
			filteredOpts = append(filteredOpts, opt)
			dists = append(dists, dist)
		}
	}
	//sort results
	suggested := suggestionListResult{filteredOpts, dists}
	sort.Sort(suggested)
	return suggested.Options
}
source: func (val *Validation) CheckSetErrorAndPanic(retError *error) *Validation {
	if val == nil || len(val.Errors) <= 0 {
		return val
	}

	*retError = val.constructErrorMessage()
	panic(*retError)
}
source: func (s *SourceScriptHandler) Get(script string) *api.InstallResult {
	location := filepath.Join(s.DestinationDir, constants.SourceScripts, script)
	if s.fs.Exists(location) {
		return &api.InstallResult{Script: script, URL: location}
	}
	// TODO: The '.sti/bin' path inside the source code directory is deprecated
	// and this should (and will) be removed soon.
	location = filepath.FromSlash(strings.Replace(filepath.ToSlash(location), "s2i/bin", "sti/bin", 1))
	if s.fs.Exists(location) {
		glog.Info("DEPRECATED: Use .s2i/bin instead of .sti/bin")
		return &api.InstallResult{Script: script, URL: location}
	}
	return nil
}
source: func (m *ProcessManager) Stat(u *url.URL) (os.FileInfo, error) {
	name := path.Join("/proc", u.Path)

	info, err := os.Stat(name)
	if err == nil && info.Size() == 0 {
		// This is a real /proc file
		return &procFileInfo{info}, nil
	}

	dir, file := path.Split(u.Path)

	pid, err := strconv.ParseInt(path.Base(dir), 10, 64)
	if err != nil {
		return nil, os.ErrNotExist
	}

	m.mu.Lock()
	p := m.entries[pid]
	m.mu.Unlock()

	if p == nil || p.IO == nil {
		return nil, os.ErrNotExist
	}

	pf := &ProcessFile{
		name:   name,
		Closer: ioutil.NopCloser(nil), // via hgfs, nop for stdout and stderr
	}

	var r *bytes.Buffer

	switch file {
	case "stdin":
		pf.Writer = p.IO.In.Writer
		pf.Closer = p.IO.In.Closer
		return pf, nil
	case "stdout":
		r = p.IO.Out
	case "stderr":
		r = p.IO.Err
	default:
		return nil, os.ErrNotExist
	}

	select {
	case <-p.ctx.Done():
	case <-time.After(time.Second):
		// The vmx guest RPC calls are queue based, serialized on the vmx side.
		// There are 5 seconds between "ping" RPC calls and after a few misses,
		// the vmx considers tools as not running.  In this case, the vmx would timeout
		// a file transfer after 60 seconds.
		//
		// vix.FileAccessError is converted to a CannotAccessFile fault,
		// so the client can choose to retry the transfer in this case.
		// Would have preferred vix.ObjectIsBusy (EBUSY), but VC/ESX converts that
		// to a general SystemErrorFault with nothing but a localized string message
		// to check against: "<reason>vix error codes = (5, 0).</reason>"
		// Is standard vmware-tools, EACCES is converted to a CannotAccessFile fault.
		return nil, vix.Error(vix.FileAccessError)
	}

	pf.Reader = r
	pf.size = r.Len()

	return pf, nil
}
source: func SavePNGRW(surface *sdl.Surface, dst *sdl.RWops, freedst int) error {
	_surface := (*C.SDL_Surface)(unsafe.Pointer(surface))
	_dst := (*C.SDL_RWops)(unsafe.Pointer(dst))
	_freedst := (C.int)(freedst)
	_ret := C.IMG_SavePNG_RW(_surface, _dst, _freedst)
	if _ret < 0 {
		return GetError()
	}
	return nil
}
source: func LvlFromString(lvlString string) (Lvl, error) {
	switch lvlString {
	case "trace", "trce":
		return LvlTrace, nil
	case "debug", "dbug":
		return LvlDebug, nil
	case "info":
		return LvlInfo, nil
	case "warn":
		return LvlWarn, nil
	case "error", "eror":
		return LvlError, nil
	case "crit":
		return LvlCrit, nil
	default:
		return LvlDebug, fmt.Errorf("Unknown level: %v", lvlString)
	}
}
source: func is_spacez(b []byte, i int) bool {
	//return is_space(b, i) || is_breakz(b, i)
	return ( // is_space:
	b[i] == ' ' ||
		// is_breakz:
		b[i] == '\r' || // CR (#xD)
		b[i] == '\n' || // LF (#xA)
		b[i] == 0xC2 && b[i+1] == 0x85 || // NEL (#x85)
		b[i] == 0xE2 && b[i+1] == 0x80 && b[i+2] == 0xA8 || // LS (#x2028)
		b[i] == 0xE2 && b[i+1] == 0x80 && b[i+2] == 0xA9 || // PS (#x2029)
		b[i] == 0)
}
source: func (n *NotifyRouter) SetChannels(i ConnectionID, nc keybase1.NotificationChannels) {
	n.setNotificationChannels(i, nc)
}
source: func (self Object) Keys() []string {
	var keys []string
	self.object.enumerate(false, func(name string) bool {
		keys = append(keys, name)
		return true
	})
	return keys
}
source: func (l *httpFileSystem) MkDir(path string, mode int) error {
	return trace.BadParameter("directories are not supported in http file transfer")
}
source: func Convert_core_PersistentVolumeStatus_To_v1_PersistentVolumeStatus(in *core.PersistentVolumeStatus, out *v1.PersistentVolumeStatus, s conversion.Scope) error {
	return autoConvert_core_PersistentVolumeStatus_To_v1_PersistentVolumeStatus(in, out, s)
}
source: func (z *Zone) CopyWithoutApex() *Zone {
	z1 := NewZone(z.origin, z.file)
	z1.TransferTo = z.TransferTo
	z1.TransferFrom = z.TransferFrom
	z1.Expired = z.Expired

	return z1
}
source: func (m *Meta) DropDatabase(dbID int64) error {
	// Check if db exists.
	dbKey := m.dbKey(dbID)
	if err := m.txn.HClear(dbKey); err != nil {
		return errors.Trace(err)
	}

	if err := m.txn.HDel(mDBs, dbKey); err != nil {
		return errors.Trace(err)
	}

	return nil
}
source: func Convert_core_HTTPHeader_To_v1_HTTPHeader(in *core.HTTPHeader, out *v1.HTTPHeader, s conversion.Scope) error {
	return autoConvert_core_HTTPHeader_To_v1_HTTPHeader(in, out, s)
}
source: func differenceArrayRun(a, b *Container) *Container {
	statsHit("difference/ArrayRun")
	// func (ac *arrayContainer) iandNotRun16(rc *runContainer16) container {

	if a.n == 0 || b.n == 0 {
		return a.Clone()
	}

	output := NewContainerArray(make([]uint16, 0, a.n))
	// cardinality upper bound: card(A)

	i := 0 // array index
	j := 0 // run index
	aa, rb := a.array(), b.runs()

	// handle overlap
	for i < int(a.n) {

		// keep all array elements before beginning of runs
		if aa[i] < rb[j].start {
			output.add(aa[i])
			i++
			continue
		}

		// if array element in run, skip it
		if aa[i] >= rb[j].start && aa[i] <= rb[j].last {
			i++
			continue
		}

		// if array element larger than current run, check next run
		if aa[i] > rb[j].last {
			j++
			if j == len(rb) {
				break
			}
		}
	}

	if i < len(aa) {
		// keep all array elements after end of runs
		// It's possible that output was converted from array to bitmap in output.add()
		// so check container type before proceeding.
		if output.typ == containerArray {
			array := output.array()
			array = append(array, aa[i:]...)
			output.setArray(array)
			// TODO: consider handling container.n mutations in one place
			// like we do with container.add().
			output.n += int32(len(aa[i:]))
		} else {
			for _, v := range aa[i:] {
				output.add(v)
			}
		}
	}
	return output
}
source: func WithIPv6Mask(mask net.IPMask) Option {
	return func(o *Options) {
		o.IPv6Mask = mask
	}
}
source: func (n *NodeState) UnmarshalJSON(data []byte) error {
	s := string(data)
	switch s {
	case "0", `"NodeNotReady"`:
		*n = NodeNotReady
	case "1", `"NodeReady"`:
		*n = NodeReady
	case "2", `"NodeUnreachable"`:
		*n = NodeUnreachable
	default:
		return fmt.Errorf("unrecognized NodeState %q", s)
	}
	return nil
}
source: func Convert_v1beta1_LimitedResource_To_resourcequota_LimitedResource(in *LimitedResource, out *resourcequota.LimitedResource, s conversion.Scope) error {
	return autoConvert_v1beta1_LimitedResource_To_resourcequota_LimitedResource(in, out, s)
}
source: func (cons *LogConsumer) Consume(threads *sync.WaitGroup) {
	// Wait for control statements
	for {
		select {
		case msg := <-cons.queue:
			cons.logRouter.Enqueue(msg)

		case command := <-cons.control:
			if command == PluginControlStopConsumer {
				cons.queue.Close()
				for msg := range cons.queue {
					cons.logRouter.Enqueue(msg)
				}
				cons.stopped = true
				return // ### return ###
			}
		}
	}
}100%|██████████| 5000/5000 [00:05<00:00, 854.22it/s] 

source: func (d *DefaultMetricCollector) Failures() *rolling.Number {
	d.mutex.RLock()
	defer d.mutex.RUnlock()
	return d.failures
}
source: func (p *Parser) parseShowMeasurementsStatement() (*ShowMeasurementsStatement, error) {
	stmt := &ShowMeasurementsStatement{}
	var err error

	// Parse optional ON clause.
	if tok, _, _ := p.ScanIgnoreWhitespace(); tok == ON {
		// Parse the database.
		stmt.Database, err = p.ParseIdent()
		if err != nil {
			return nil, err
		}
	} else {
		p.Unscan()
	}

	// Parse optional WITH clause.
	if tok, _, _ := p.ScanIgnoreWhitespace(); tok == WITH {
		// Parse required MEASUREMENT token.
		if err := p.parseTokens([]Token{MEASUREMENT}); err != nil {
			return nil, err
		}

		// Parse required operator: = or =~.
		tok, pos, lit := p.ScanIgnoreWhitespace()
		switch tok {
		case EQ, EQREGEX:
			// Parse required source (measurement name or regex).
			if stmt.Source, err = p.parseSource(false); err != nil {
				return nil, err
			}
		default:
			return nil, newParseError(tokstr(tok, lit), []string{"=", "=~"}, pos)
		}
	} else {
		// Not a WITH clause so put the token back.
		p.Unscan()
	}

	// Parse condition: "WHERE EXPR".
	if stmt.Condition, err = p.parseCondition(); err != nil {
		return nil, err
	}

	// Parse sort: "ORDER BY FIELD+".
	if stmt.SortFields, err = p.parseOrderBy(); err != nil {
		return nil, err
	}

	// Parse limit: "LIMIT <n>".
	if stmt.Limit, err = p.ParseOptionalTokenAndInt(LIMIT); err != nil {
		return nil, err
	}

	// Parse offset: "OFFSET <n>".
	if stmt.Offset, err = p.ParseOptionalTokenAndInt(OFFSET); err != nil {
		return nil, err
	}

	return stmt, nil
}
source: func (s *VotingPolicy) SetApprovalThresholdPolicy(v *ApprovalThresholdPolicy) *VotingPolicy {
	s.ApprovalThresholdPolicy = v
	return s
}
source: func NewCard(title string, content *valente.Panel, actions []*valente.Link) *Card {
	card := &Card{}

	d := valente.Panel{}

	card.AddClass("card")
	d.AddClass("card-content")

	stitle := valente.Span{Text: title}
	stitle.AddClass("card-title")

	d.AddElement(stitle)
	d.AddElement(content)

	card.AddElement(d)

	if len(actions) > 0 {
		caction := valente.Panel{}
		caction.AddClass("card-action")

		for _, a := range actions {
			caction.AddElement(*a)
		}
		card.AddElement(caction)
	}

	return card
}
source: func NewFromDB(service *bolt.DB, bucketName string) (*Database, error) {
	bucket := []byte(bucketName)

	service.Update(func(tx *bolt.Tx) (err error) {
		_, err = tx.CreateBucketIfNotExists(bucket)
		return
	})

	db := &Database{table: bucket, Service: service}

	runtime.SetFinalizer(db, closeDB)
	return db, db.cleanup()
}
source: func setupFormatter() logrus.Formatter {
	fileFormat := new(logrus.TextFormatter)
	fileFormat.DisableTimestamp = true
	fileFormat.DisableColors = true
	switch os.Getenv("INITSYSTEM") {
	case "SYSTEMD":
		fileFormat.FullTimestamp = true
	default:
		fileFormat.TimestampFormat = time.RFC3339
	}

	// TODO: switch to a per-logger version when we upgrade to logrus >1.0.3
	return fileFormat
}
source: func ParseLogLevel(level string) LogLevel {
	switch strings.ToLower(level) {
	case "debug":
		return DebugLevel
	case "info":
		return InfoLevel
	case "warn", "warning":
		return WarnLevel
	case "error":
		return ErrorLevel
	case "fatal":
		return FatalLevel
	case "panic":
		return PanicLevel
	default:
		return InfoLevel
	}
}
